{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f25497-8be5-480a-854c-cf728b6da55c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Final exam preparation: guiding questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc0bcc5-d8ae-45d6-ab33-81b3d9d15c92",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58c8084-8c94-4ac8-9550-8e5fb8991bbb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "DATA_DIR = os.path.join(os.path.abspath(\"..\"), \"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac559b-01bc-41ad-8cfa-1e447d1d9c54",
   "metadata": {},
   "source": [
    "## Study tips\n",
    "\n",
    "- Review the course learning objectives, found at the start of the lecture notes, to clarify expectations. The overall course objectives are available [here](https://ubc-cs.github.io/cpsc330-2024W1/learning-objectives.html). Consider creating a checklist for each objective and rate your confidence in performing each task.\n",
    "- Focus on understanding not just **how** to do something, but also **why** it's done that way. This will prepare you for exam questions requiring novel applications of concepts.\n",
    "- If reasoning questions are challenging, try explaining concepts out loud. Articulating your thoughts often highlights gaps in understanding.\n",
    "- Revisit homework assignments thoroughly. Review the problems, your solutions, and any feedback to deepen your understanding.\n",
    "- Use active recall techniques like flashcards, summary sheets, or teaching concepts to peers to test your memory and comprehension.\n",
    "- Develop a strong grasp of core machine learning concepts. For each, know the definition, application, and implications in real-world contexts.\n",
    "- Review case studies and examples from the course to see how theoretical concepts are applied in practice.\n",
    "- Take advantage of office hours, tutorials, and other available resources.\n",
    "- Create a study schedule that prioritizes topics where you feel less confident.\n",
    "- Study in focused intervals (e.g., 25 minutes of work followed by a 5-minute break) to maintain concentration.\n",
    "- Begin each study session with a minute or two of focused breathing to calm your mind and improve focus.\n",
    "- Join or form study groups to discuss material and exchange ideas. Teaching others is one of the most effective ways to solidify your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37e03a-fbcf-41a4-a829-c02187a726e2",
   "metadata": {},
   "source": [
    "## Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95002bc-6289-4192-8f00-2d73e5a5effa",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- What is ML? When is it suitable?\n",
    "- ML terminology\n",
    "- ML types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568c7cf-39e5-48c7-b2e7-a6b0ff49878f",
   "metadata": {},
   "source": [
    "### ML fundamentals\n",
    "\n",
    "- What are four splits of data we have seen so far? \n",
    "- What are the advantages of cross-validation?\n",
    "- Why it's important to look at sub-scores of cross-validation?\n",
    "- What is the fundamental trade-off in supervised machine learning?\n",
    "- What is the Golden rule in supervised machine learning?\n",
    "- Scenarios for data leakage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6efe36-72ac-4244-97f3-9e47f99e7f84",
   "metadata": {},
   "source": [
    "### Pros, cons, parameters and hyperparameters of different ML models\n",
    "\n",
    "- Decision trees\n",
    "- KNNs, SVM RBFs\n",
    "- Linear models \n",
    "- Random forests\n",
    "- Grading Boosting, LGBM, CatBoost\n",
    "- Stacking, averaging\n",
    "\n",
    "**Comparison of models**\n",
    "| **Model**        | Parameters and hyperparameters | **Strengths**  | **Weaknesses**     |\n",
    "|------------------|--------------------------------|---------------------------|---------------------------|\n",
    "| **Decision Trees**               |  |  |  |\n",
    "| **KNNs**              |  |  |  |\n",
    "| **SVM RBF**            |  |  |  |\n",
    "| **Linear models**         |  |  | | \n",
    "| **Random forests**         |  |  | | \n",
    "| **Gradient boosting**         |  |  | | \n",
    "| **Stacking**         |  |  | | \n",
    "| **Averaging**         |  |  | | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43fa4c-5691-4397-a057-a881d1d94179",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bd743-456a-4f6f-b5ef-139c52d6818e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3e86b-a3e0-48c3-821b-58ca287647d8",
   "metadata": {},
   "source": [
    "- What are various data preprocessing steps such as scaling, OHE, ordinal encoding, and handling missing values. Why and when each step is necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46551fbd-cf55-418c-867d-f8c7705fe7d1",
   "metadata": {},
   "source": [
    "**`sklearn` Transformers** \n",
    "| **Transformer**        | Hyperparameters | **When to use?** |\n",
    "|------------------|--------------------------------|---------------------------|\n",
    "| `SimpleImputer`  |  |  | \n",
    "| `StandardScaler`              |  |  | \n",
    "| `OneHotEncoder`            |  |  | \n",
    "| `OrdinalEncoder`         |  |  | \n",
    "| `CountVectorizer`        |  |  | \n",
    "| `TransformedTargetRegressor` | | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30b454-9f43-481e-9b1c-da43031fc0d8",
   "metadata": {},
   "source": [
    "Let's bring back our quiz2 grades toy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a854ff-7887-40d0-b2fe-a1c3c0189b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enjoy_course</th>\n",
       "      <th>ml_experience</th>\n",
       "      <th>major</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>university_years</th>\n",
       "      <th>lab1</th>\n",
       "      <th>lab2</th>\n",
       "      <th>lab3</th>\n",
       "      <th>lab4</th>\n",
       "      <th>quiz1</th>\n",
       "      <th>quiz2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>93.0</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Average</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Poor</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>85.0</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>not A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>83.0</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  enjoy_course  ml_experience                   major class_attendance  \\\n",
       "0          yes              1        Computer Science        Excellent   \n",
       "1          yes              1  Mechanical Engineering          Average   \n",
       "2          yes              0             Mathematics             Poor   \n",
       "3           no              0             Mathematics        Excellent   \n",
       "4          yes              0              Psychology             Good   \n",
       "\n",
       "   university_years  lab1  lab2  lab3  lab4  quiz1   quiz2  \n",
       "0                 3    92  93.0    84    91     92      A+  \n",
       "1                 2    94  90.0    80    83     91  not A+  \n",
       "2                 3    78  85.0    83    80     80  not A+  \n",
       "3                 3    91   NaN    92    91     89      A+  \n",
       "4                 4    77  83.0    90    92     85      A+  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.read_csv(DATA_DIR + 'quiz2-grade-toy-col-transformer.csv')\n",
    "grades_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e081808-d250-40a2-8500-0fba312533a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = grades_df.drop(columns=['quiz2']), grades_df['quiz2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f74c704-4c1a-42ef-8838-3f0ae6b36a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = [\"university_years\", \"lab1\", \"lab3\", \"lab4\", \"quiz1\"]  # apply scaling\n",
    "categorical_feats = [\"major\"]  # apply one-hot encoding\n",
    "passthrough_feats = [\"ml_experience\"]  # do not apply any transformation\n",
    "drop_feats = [\n",
    "    \"lab2\",\n",
    "    \"class_attendance\",\n",
    "    \"enjoy_course\",\n",
    "]  # do not include these features in modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef7234a-0368-4716-876e-ef0da500c0a2",
   "metadata": {},
   "source": [
    "- What's the difference between sklearn estimators and transformers?  \n",
    "- Can you think of a better way to impute missing values compared to `SimpleImputer`? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b10938-8e20-4be4-aefd-22b686c4851f",
   "metadata": {},
   "source": [
    "**One-hot encoding**\n",
    "- What's the purpose of the following arguments of one-hot encoding?\n",
    "    - handle_unknown=\"ignore\"\n",
    "    - sparse=False\n",
    "    - drop=\"if_binary\"    \n",
    "- How do you deal with categorical features with only two possible categories? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf3d09-b521-476b-80cc-ea9e87ad191e",
   "metadata": {},
   "source": [
    "**Ordinal encoding**\n",
    "\n",
    "- What's the difference between ordinal encoding and one-hot encoding? \n",
    "- What happens if we do not order the categories when we apply ordinal encoding?  Does it matter if we order the categories in ascending or descending order? \n",
    "- What would happen if an unknown category shows up during validation or test time during ordinal encoding? For example, for `class_attendance` feature what if a category called \"super poor\" shows up? \n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca74bc0b-3175-4c9d-be61-cef9b8bee30a",
   "metadata": {},
   "source": [
    "**OHE vs. ordinal encoding**\n",
    "\n",
    "- Since `enjoy_course` feature is binary you decide to apply one-hot encoding with `drop=\"if_binary\"`. Your friend decide to apply ordinal encoding on it. Will it make any difference in the transformed data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3037d867-ed9d-4a08-b027-3dea90c8d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop=\"if_binary\", sparse_output=False)\n",
    "ohe_encoded = ohe.fit_transform(grades_df[['enjoy_course']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f82887-36f1-428d-a423-c70ffd104c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OrdinalEncoder()\n",
    "oe_encoded = oe.fit_transform(grades_df[['enjoy_course']]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f89b3cb-b42d-40b5-94e7-c6dfbf010c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oe_encoded</th>\n",
       "      <th>ohe_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    oe_encoded  ohe_encoded\n",
       "0          1.0          1.0\n",
       "1          1.0          1.0\n",
       "2          1.0          1.0\n",
       "3          0.0          0.0\n",
       "4          1.0          1.0\n",
       "5          0.0          0.0\n",
       "6          1.0          1.0\n",
       "7          0.0          0.0\n",
       "8          0.0          0.0\n",
       "9          1.0          1.0\n",
       "10         1.0          1.0\n",
       "11         1.0          1.0\n",
       "12         1.0          1.0\n",
       "13         1.0          1.0\n",
       "14         0.0          0.0\n",
       "15         0.0          0.0\n",
       "16         1.0          1.0\n",
       "17         1.0          1.0\n",
       "18         0.0          0.0\n",
       "19         0.0          0.0\n",
       "20         1.0          1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = { \"oe_encoded\": oe_encoded, \n",
    "         \"ohe_encoded\": ohe_encoded}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b71e80-fe7e-446d-b54c-a88d06fc48c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In what scenarios it's OK to break the golden rule?\n",
    "- What are possible ways to deal with categorical columns with large number of categories? \n",
    "- In what scenarios you'll not include a feature in your model even if it's a good predictor? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a054f9-d9e3-4885-b697-e8d3821b0cfd",
   "metadata": {},
   "source": [
    "- What's the problem with calling `fit_transform` on the test data in the context of `CountVectorizer`?\n",
    "- Do we need to scale after applying bag-of-words representation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12b0b8-58a9-48d6-a79d-e534cfafdff5",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization \n",
    "\n",
    "- What makes hyperparameter optimization a hard problem?\n",
    "- What are two different tools provided by sklearn for hyperparameter optimization?  \n",
    "- What is optimization bias?\n",
    "\n",
    "\n",
    "| **Method**        | Strengths/Weaknesses | **When to use?** |\n",
    "|------------------|--------------------------------|---------------------------|\n",
    "| Nested for loops |  |  | \n",
    "| Grid search  |  |  | \n",
    "| Random search  |  |  | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bd8da-ddc6-42e5-ac93-dd146732d6fa",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "- Understand different metrics used to evaluate machine learning models like accuracy, precision, recall, F1-score, and PR curve, ROC curves for classification; mean squared error, root mean-squared error, MAPE and r2 for regression. Be prepared to discuss why you would choose one metric over another based on the problem context.\n",
    "- Why accuracy is not always enough?\n",
    "- Why it's useful to get prediction probabilities? \n",
    "- In what scenarios do you care more about precision or recall? \n",
    "- What's the main difference between AP score and F1 score?\n",
    "- What are advantages of RMSE or MAPE over MSE? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11a3f7-0ec3-4306-a84e-43fe74869e20",
   "metadata": {},
   "source": [
    "**Classification Metrics**\n",
    "| **Metric**        | How to generate/calculate? | **When to use?** |\n",
    "|------------------|--------------------------------|---------------------------|\n",
    "| Accuracy  |  |  | \n",
    "| Precision              |  |  | \n",
    "| Recall          |  |  | \n",
    "| F1-score         |  |  | \n",
    "| AP score        |  |  | \n",
    "| AUC        |  |  | \n",
    "\n",
    "\n",
    "**Regression Metrics**\n",
    "| **Metric**        | How to generate/calculate? | **When to use?** |\n",
    "|------------------|--------------------------------|---------------------------|\n",
    "| MSE  |  |  | \n",
    "| RMSE              |  |  | \n",
    "| r2 score          |  |  | \n",
    "| MAPE         |  |  | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6c11b-ee26-4d37-87ea-2b6bd3560f60",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "\n",
    "- How does a random forest model inject randomness in the model?\n",
    "- What's the difference between random forests and gradient boosted trees?\n",
    "- Why do we need averaging or stacking? \n",
    "- What are the benefits of stacking over averaging?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe7d3b-ec86-4ec3-86b8-f7ef6d0b1b79",
   "metadata": {},
   "source": [
    "### Feature importances\n",
    "\n",
    "- What are the limitations of looking at simple correlations between features and targets? \n",
    "- How can you get feature importances or non-linear models?\n",
    "- What you might need to explain a single prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d0b8d-0e03-4eb6-8d34-0753b7065164",
   "metadata": {},
   "source": [
    "### Feature engineering and selection \n",
    "\n",
    "- What's the difference between feature engineering and feature selection?\n",
    "- Why do we need feature selection?\n",
    "- What are the three possible ways we looked at for feature selection? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3e184-c56a-4659-becf-b4e9392e52eb",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d964698-af74-466e-945d-56898aed2a5d",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbdf4b-f28a-4b4a-bd31-680c7762bb6d",
   "metadata": {},
   "source": [
    "### Clustering \n",
    "- Why clustering and what is the problem of clustering?\n",
    "- Compare and contrast different clustering methods.\n",
    "- What’s the difficulty in evaluation of clustering? How do we evaluate clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d2a82-59e8-4b05-9b6d-f3dcb7bd3081",
   "metadata": {},
   "source": [
    "|     Scenario           | Which clustering method? | \n",
    "|------------------------|--------------------------|\n",
    "| Well-separated spherical clusters  |  |\n",
    "| Large datasets    |  | \n",
    "| Flexibility with cluster shapes  |  | \n",
    "| Small to medium datasets  |  | \n",
    "| Prior knowlege on how many clusters   |  | \n",
    "| Clusters are roughly of equal size   |  | \n",
    "| Irregularly shaped clusters   |  | \n",
    "| Clusters with different densities  |  | \n",
    "| Datasets with hierarchical relationships  |  | \n",
    "| No prior knowledge on number of clusters  |  | \n",
    "| Noise and outliers   |  | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de36215-6cfc-4116-893a-96cc3516501c",
   "metadata": {},
   "source": [
    "- Which clustering method would you use in each of the scenarios below? Why?\n",
    "- How would you represent the data in each case? \n",
    "    - Scenario 1: Customer segmentation in retail\n",
    "    - Scenario 2: An environmental study aiming to identify clusters of a rare plant species\n",
    "    - Scenario 3: Clustering furniture items for inventory management and customer recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc8452-7854-460c-b521-41f020413756",
   "metadata": {},
   "source": [
    "- How to decide the number of clusters? \n",
    "- What’s the difficulty in evaluation of clustering? How do we evaluate clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4524b1-f7c3-430d-ae4d-83db069cd1ed",
   "metadata": {},
   "source": [
    "### Recommender systems \n",
    "- What’s the utility matrix?\n",
    "- How do we evaluate recommender systems?\n",
    "- What are the baseline models we talked about?\n",
    "    - Global average\n",
    "    - Per user average\n",
    "    - Per item average\n",
    "- Evaluation of recommender systems\n",
    "- Compare and contrast KNN Imputer and content-based filtering \n",
    "- Ethical issues associated with recommender systems "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c97a895-a117-4590-a73c-2b0347fdd5e1",
   "metadata": {},
   "source": [
    "### Introduction to NLP \n",
    "\n",
    "- Embeddings\n",
    "    - What are different document and word representations we talked about?\n",
    "    - Why do we care about creating different representations?\n",
    "    - What are pre-trained models? Why are the benefits of using them?\n",
    "- Topic modeling \n",
    "    - What is topic modeling? What are the inputs and outputs of topic modeling?\n",
    "    - How it's different from clustering documents using a clustering model, say KMeans?\n",
    "- Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603acd1-5faf-4e46-8d8d-2b8707668682",
   "metadata": {},
   "source": [
    "### Multiclass classification and computer vision \n",
    "- How is the Softmax function used by logistic regression in the context of multiclass classification? \n",
    "- What are the methods we saw to use pre-trained image classification models for our image classification tasks?\n",
    "    - Out of the box\n",
    "    - Using pre-trained models as feature extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776c325-532f-4f57-9dbe-1344a0ab5c23",
   "metadata": {},
   "source": [
    "How would you use pre-trained model in each case below? \n",
    "- Imagine you want to quickly develop a prototype for an app that can identify different cat breeds from photos. \n",
    "- Suppose you're working on a project to predict the city in Canada based on the photos of landmarks in the city, a task for which there's limited training data available.\n",
    "- Suppose you're developing a system to diagnose specific types of tumors from MRI scans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210c5a2-902e-4776-903a-a04cb65fa3b3",
   "metadata": {},
   "source": [
    "### Time series\n",
    "\n",
    "- When is time series analysis appropriate? \n",
    "    - Time series analysis is used when there is a temporal aspect in the data.\n",
    "- **Data splitting**: Data should be split based on time to avoid future data leaking into the training set.\n",
    "- **Essential questions for Exploratory Data Analysis (EDA)**:\n",
    "    - What is the frequency of data collection (e.g., hourly, daily)?\n",
    "    - How many time series are present within the dataset?\n",
    "    - Are there any gaps or missing values in the data?\n",
    "- **Feature engineering**\n",
    "    - Derived new features from the date/time column.\n",
    "    - Appropriately encoded features based on the chosen model.\n",
    "    - Created lag features to incorporate past values for prediction.\n",
    "- **Baseline model approach**: Employ a simple model, such as using today's target value to predict tomorrow's, as a starting point for comparison.\n",
    "- **Cross-Validation Method for Time Series**: In `sklearn`, use `TimeSeriesSplit` as the `cv` parameter in functions like `cross_validate` or `cross_val_score` for time-appropriate validation.\n",
    "- **Strategies for long-term forecasting**:\n",
    "    - Generate forecasts for sequential time steps by assuming the predictions for the previous steps are accurate. \n",
    "- **Trends** \n",
    "    - A 'days since' feature to capture the trend over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6da334-6203-46fc-bb02-f14a834ab83f",
   "metadata": {},
   "source": [
    "### Survival analysis \n",
    "- What is right-censored data?\n",
    "- What happens when we treat right-censored data the same as \"regular\" data?\n",
    "    - Predicting churn vs. no churn\n",
    "    - Predicting tenure\n",
    "        - Throw away people who haven't churned\n",
    "        - Assume everyone churns today\n",
    "- Survival analysis encompasses predicting both churn and tenure and deals with censoring and can make rich and useful predictions!\n",
    "    - We can get survival curves which show the probability of survival over time.\n",
    "    - KM model $\\rightarrow$ doesn't look at features\n",
    "    - CPH model $\\rightarrow$ like linear regression, does look at the features and provides coefficients associated with each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c556a-8819-4da0-9a93-139232fb20cc",
   "metadata": {},
   "source": [
    "### Communication \n",
    "- Why is communication important in ML and Data Science? \n",
    "- What are different principles of good explanation?\n",
    "- What to watch out for when producing or consuming visualizations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a17758-cff5-4a10-b41f-613e8aa819d1",
   "metadata": {},
   "source": [
    "### Ethics\n",
    "- Fairness, accountability, transparency \n",
    "- Representation bias, measurement bias, historical bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf43e4-62fd-4132-bf3e-93a48802684e",
   "metadata": {},
   "source": [
    "### Deployment (Not examinable) \n",
    "\n",
    "- Deploying a model as a web app\n",
    "- Deploying a model as a REST API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
