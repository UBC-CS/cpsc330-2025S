Search.setIndex({"alltitles": {"(Optional) Changing the data": [[37, "optional-changing-the-data"]], "(Optional) Evaluation": [[48, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[37, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[36, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[36, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[36, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[39, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[41, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[37, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[32, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[36, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[39, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[41, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[41, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[36, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[50, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[37, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[29, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[41, "id1"]], "(iClicker) Exercise 21.1": [[48, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[48, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[32, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[32, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[33, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[33, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[33, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[34, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[34, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[35, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[35, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[36, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[42, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[42, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[42, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[42, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[43, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[43, "id2"]], "16.3 Select all of the following statements which are True": [[43, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[50, "vs-340"]], "<font color='red'>Question 10</font>": [[59, "question-10"]], "<font color='red'>Question 1</font>": [[54, "question-1"], [55, "question-1"], [57, "question-1"], [58, "question-1"], [59, "question-1"], [60, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[55, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[54, "question-2"], [57, "question-2"], [58, "question-2"], [59, "question-2"], [60, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[55, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[54, "question-3"], [57, "question-3"], [58, "question-3"], [59, "question-3"], [60, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[55, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[54, "question-4"], [57, "question-4"], [58, "question-4"], [59, "question-4"], [60, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[55, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[57, "question-5"], [58, "question-5"], [59, "question-5"], [60, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[55, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[57, "question-6"], [58, "question-6"], [59, "question-6"], [60, "question-6"]], "<font color='red'>Question 7</font>": [[57, "question-7"], [59, "question-7"]], "<font color='red'>Question 8</font>": [[57, "question-8"], [59, "question-8"]], "<font color='red'>Question 9</font>": [[59, "question-9"]], "<font color='red'>Recap Questions</font>": [[54, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[56, "recap-comprehension-questions"]], "A few comments on PR curve": [[37, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[43, "a-few-comments-on-clustering-evaluation"]], "AP score": [[37, "ap-score"]], "AP vs. F1-score": [[37, "ap-vs-f1-score"]], "API on the localhost": [[50, "api-on-the-localhost"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[61, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[35, "accessing-learned-parameters"]], "Activity (~5 mins)": [[40, "activity-5-mins"], [40, "id3"]], "Activity: Context and word meaning": [[45, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[41, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[49, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[37, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[36, "advantages-of-randomizedsearchcv"], [36, "id1"]], "Alternative and more compact syntax: make_pipeline": [[33, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[30, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[39, "an-effective-strategy"]], "An example from a project": [[51, "an-example-from-a-project"]], "An example of a bootstrap samples": [[39, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[49, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[32, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[32, "analogy-based-models"]], "Announcements": [[35, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[51, null]], "Appendix B: Multi-class, meta-strategies": [[52, null]], "Applying feature transformations": [[38, "applying-feature-transformations"], [49, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[48, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[48, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[48, "approach-3-survival-analysis"]], "Approach from all angles": [[49, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[37, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[37, "area-under-the-curve-auc"]], "Assignments": [[61, "assignments"]], "Attention": [[30, null], [30, null], [30, null], [32, null]], "Attribution": [[49, "attribution"]], "Automated hyperparameter optimization": [[36, "automated-hyperparameter-optimization"], [36, "id3"]], "Averaging": [[39, "averaging"]], "Averaging simulation": [[59, "averaging-simulation"]], "Bad range for hyperparameters": [[36, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[34, "bag-of-words-bow-representation"]], "Bag-of-words model": [[51, "bag-of-words-model"]], "Baseline": [[37, "baseline"], [40, "baseline"]], "Baseline Approaches": [[44, "baseline-approaches"]], "Baselines": [[30, "baselines"], [39, "baselines"]], "Baselines [video]": [[30, "baselines-video"]], "Basic text preprocessing [video]": [[45, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[41, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[44, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[31, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[30, "big-picture-and-datasets"]], "Big picture and motivation": [[31, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Bottom-up explanations": [[49, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [30, "break-5-min"], [31, "break-5-min"], [32, "break-5-min"], [33, "break-5-min"], [34, "break-5-min"], [41, "break-5-min"], [45, "break-5-min"], [46, "break-5-min"], [48, "break-5-min"], [49, "break-5-min"]], "Break (~15 min)": [[50, "break-15-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a model": [[50, "building-a-model"]], "Building a supervise machine learning model": [[29, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[50, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[30, "building-decision-trees-with-sklearn"]], "Building user profiles": [[44, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[42, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[33, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[34, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[39, "catboost"]], "Categorical features": [[40, "categorical-features"]], "Categorical features [video]": [[33, "categorical-features-video"]], "Categorical features with only two possible categories": [[34, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[48, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[61, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[37, "changing-the-training-procedure"]], "Characters in this course?": [[29, "characters-in-this-course"]], "Choosing K [video]": [[42, "choosing-k-video"]], "Choosing n_neighbors": [[32, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Meeting 4B": [[22, null]], "Class Meeting 4C": [[23, null]], "Class Meeting 5A": [[24, null]], "Class Meeting 5B": [[25, null]], "Class Meeting 5C": [[26, null]], "Class Meeting 6A": [[27, null]], "Class Meeting 6B": [[28, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"], [22, "class-slides"], [23, "class-slides"], [24, "class-slides"], [26, "class-slides"], [27, "class-slides"], [28, "class-slides"]], "Class imbalance in training sets": [[37, "class-imbalance-in-training-sets"]], "Class meetings": [[61, "class-meetings"]], "Classification report": [[37, "classification-report"]], "Classification vs. Regression": [[30, "classification-vs-regression"]], "Clustering": [[53, "clustering"]], "Clustering Activity (~5 mins)": [[42, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[42, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[42, "clustering-input-and-possible-output"]], "Code of conduct": [[61, "code-of-conduct"]], "Coefficients and intercept": [[35, "coefficients-and-intercept"]], "ColumnTransformer example": [[34, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[34, "columntransformer-on-the-california-housing-dataset"], [56, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[34, "columntransformer-transformed-data"]], "Coming up \u2026": [[31, "coming-up"]], "Coming up:": [[32, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[42, "common-applications"]], "Common preprocessing techniques": [[33, "common-preprocessing-techniques"]], "Communication": [[53, "communication"]], "Completing the utility matrix with content-based filtering": [[44, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[35, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[49, "concepts-then-labels-not-the-other-way-around"]], "Conclusion & farewell": [[50, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[49, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[49, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix (video)": [[37, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[37, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[32, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[44, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[34, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[61, "course-learning-objectives"]], "Course co-ordinator": [[61, "course-co-ordinator"]], "Course description": [[61, "course-description"]], "Course review / conclusion (~20 min)": [[50, "course-review-conclusion-20-min"]], "Cox proportional hazards model": [[48, "cox-proportional-hazards-model"]], "Create X and y": [[30, "create-x-and-y"]], "Create a classifier object": [[30, "create-a-classifier-object"]], "Create a column transformer": [[34, "create-a-column-transformer"]], "Creating train_df and test_df": [[31, "creating-train-df-and-test-df"]], "Creating utility matrix": [[44, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[37, "cross-validation-with-different-metrics"]], "Cross-validation": [[47, "cross-validation"], [47, "id4"]], "Cross-validation [video]": [[31, "cross-validation-video"]], "Cross-validation to the rescue!!": [[31, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[31, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[32, "curse-of-dimensionality"]], "Customer churn": [[48, "customer-churn"]], "Customer segmentation": [[42, "customer-segmentation"]], "DBSCAN [video]": [[43, "dbscan-video"]], "DBSCAN introduction": [[43, "dbscan-introduction"]], "DBSCAN: failure cases": [[43, "dbscan-failure-cases"], [43, "id1"]], "Data": [[34, "data"], [35, "data"], [39, "data"], [40, "data"], [40, "id1"]], "Data Splitting [video]": [[31, "data-splitting-video"]], "Data and main approaches": [[44, "data-and-main-approaches"]], "Data exploration": [[42, "data-exploration"]], "Data splitting": [[55, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[46, "dataset"], [49, "dataset"]], "Dataset [video]": [[38, "dataset-video"]], "Dataset for demonstration": [[37, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[33, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[37, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[34, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[30, "decision-boundary"]], "Decision boundary for max_depth=1": [[30, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[30, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[30, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[32, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[35, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[30, "decision-tree-algorithm"]], "Decision tree feature importances": [[40, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[30, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[30, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[30, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[30, "decision-trees-video"]], "Decision trees with continuous features": [[30, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[39, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[30, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[49, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[37, "decreasing-the-threshold"]], "Deep learning": [[47, "deep-learning"]], "Deep learning software": [[46, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of creating a new web service": [[50, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[41, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[47, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[50, "demo-deploying-moment-classification-model"]], "Dendrogram": [[43, "dendrogram"]], "Deploying the API on a server (not covered)": [[50, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[53, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[50, "difference-between-statistics-and-machine-learning"]], "Different models": [[40, "different-models"]], "Different range for hyperparameters yields better results!": [[36, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[38, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[32, "dimensions-in-ml-problems"]], "Discussion": [[50, "discussion"]], "Discussion question": [[45, "discussion-question"]], "Discussion questions:": [[49, "discussion-questions"]], "Distance between feature vectors": [[32, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[34, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[39, "do-we-have-class-imbalance"], [40, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[40, "do-we-have-correlated-features"]], "Document clustering": [[42, "document-clustering"]], "Domain-specific transformations": [[41, "domain-specific-transformations"]], "Dummy classifier": [[51, "dummy-classifier"]], "DummyClassifier": [[30, "dummyclassifier"], [47, "dummyclassifier"], [48, "dummyclassifier"]], "DummyClassifier baseline": [[39, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[30, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[30, "dummyregressor"], [38, "dummyregressor"]], "EDA": [[33, "eda"], [37, "eda"], [38, "eda"]], "EDA: Exploratory Data Analysis": [[55, "eda-exploratory-data-analysis"]], "Encoding text data": [[34, "encoding-text-data"]], "Encoding time as a number": [[47, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[47, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[53, "ensembles"]], "Equally good": [[49, "equally-good"]], "Ethics": [[53, "ethics"]], "Euclidean distance": [[32, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[43, "evaluating-dbscan-clusters"]], "Evaluation": [[44, "evaluation"], [44, "id3"]], "Evaluation metrics": [[53, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[37, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[37, "evalution-metrics-overview"]], "Examining the preprocessed data": [[38, "examining-the-preprocessed-data"], [49, "examining-the-preprocessed-data"]], "Example": [[35, "example"], [39, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[29, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[42, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[30, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[30, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[29, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[29, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[40, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[41, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[29, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[42, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[30, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[30, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[37, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[33, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[29, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[44, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[44, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[30, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[30, "exercise-2-4"]], "Exercise 8.2": [[36, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[54, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[36, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[40, "explaining-a-prediction"]], "Explanation 1": [[49, "explanation-1"]], "Explanation 2": [[49, "explanation-2"]], "Exploratory data analysis": [[47, "exploratory-data-analysis"], [60, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[34, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[47, "extracting-date-and-time-information"]], "F1-score": [[37, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[41, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[47, "feature-engineering"]], "Feature engineering and selection": [[53, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[47, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[47, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[41, "feature-engineering-motivation"]], "Feature importances": [[40, "feature-importances"], [53, "feature-importances"]], "Feature importances in linear models": [[40, "feature-importances-in-linear-models"], [40, "id2"]], "Feature interactions and feature crosses": [[41, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[38, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[41, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[33, "feature-transformations-and-the-golden-rule"]], "Feature types": [[38, "feature-types"], [38, "id1"], [49, "feature-types"]], "Feature vectors": [[32, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[36, "final-comments-and-summary"], [44, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[30, "final-comments-summary-and-reflection"], [42, "final-comments-summary-and-reflection"], [43, "final-comments-summary-and-reflection"]], "Final exam": [[61, "final-exam"]], "Final exam preparation: guiding questions": [[53, null]], "Final note": [[55, "final-note"]], "Final remarks": [[47, "final-remarks"]], "Finding the distances to a query point": [[32, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[32, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[47, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[47, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[44, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "GB better than RF": [[49, "gb-better-than-rf"]], "Garbage in, garbage out.": [[41, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[41, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[39, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[32, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[41, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[31, "generalization-video"]], "Generalization: Fundamental goal of ML": [[31, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[35, "generalizing-to-more-features"]], "Generalizing to unseen data": [[31, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[32, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[44, "global-average-baseline"]], "Golden rule violation: Example 1": [[31, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[31, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[39, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[39, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[61, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[37, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[31, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[43, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[35, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[31, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[40, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[39, "how-do-they-work"]], "How do we carry out feature selection?": [[41, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[30, "how-does-fit-work"], [30, "id2"]], "How does it work?": [[43, "how-does-it-work"], [49, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[35, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[30, "how-does-predict-work"]], "How to approximate generalization error?": [[31, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[33, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[32, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[31, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[35, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[53, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[36, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[42, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[32, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[36, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[34, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[46, "imagenet"]], "Import": [[51, "import"]], "Importance of scaling": [[35, "importance-of-scaling"]], "Important hyperparameters": [[39, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[34, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[42, "important-points-to-remember"]], "Imports": [[29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [49, "imports"], [50, "imports"], [53, "imports"], [54, "imports"], [55, "imports"], [60, "imports"]], "Imports and LO": [[36, "imports-and-lo"], [38, "imports-and-lo"], [46, "imports-and-lo"], [47, "imports-and-lo"]], "Imports and LOs": [[37, "imports-and-los"], [50, "imports-and-los"]], "Imports and learning outcomes": [[42, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[30, "imports-announcements-los"]], "Imports, Announcements, and LO": [[34, "imports-announcements-and-lo"], [35, "imports-announcements-and-lo"]], "Imports, LOs": [[31, "imports-los"], [33, "imports-los"], [40, "imports-los"]], "Imports, announcements, LOs": [[39, "imports-announcements-los"]], "Imports, announcements, and LOs": [[32, "imports-announcements-and-los"]], "Imputation": [[33, "imputation"]], "Imputation and scaling [video]": [[33, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[34, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[37, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[42, "inertia"]], "Initial analysis, EDA, preprocessing": [[50, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[42, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[39, "inject-randomness-in-the-classifier-construction"]], "Input data": [[29, "input-data"]], "Input features X and target y": [[29, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[49, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[37, "interim-summary"], [40, "interim-summary"], [41, "interim-summary"], [47, "interim-summary"]], "Interpretation of coefficients": [[35, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[35, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[40, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[43, "introduction"], [53, "introduction"]], "Introduction to NLP": [[53, "introduction-to-nlp"]], "Introduction to computer vision": [[46, "introduction-to-computer-vision"]], "Introduction to neural networks": [[46, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[42, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[51, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[37, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[34, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[49, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[41, "is-relevance-clearly-defined"], [41, "id2"], [41, "id3"], [41, "id4"], [41, "id5"], [41, "id6"], [41, "id7"]], "K-Means algorithm": [[42, "k-means-algorithm"]], "K-Means clustering [video]": [[42, "k-means-clustering-video"]], "K-Means example": [[42, "k-means-example"]], "K-Means limitations": [[43, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[43, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[43, "k-means-recap"]], "K-Means: failure case 1": [[43, "k-means-failure-case-1"]], "K-Means: failure case 2": [[43, "k-means-failure-case-2"]], "K-Means: failure case 3": [[43, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[48, "kaplan-meier-survival-curve"]], "Key point": [[40, "key-point"]], "LDA topics in social media": [[45, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[42, "labeled-vs-unlabeled-data"]], "Lag-based features": [[47, "lag-based-features"], [47, "id5"], [60, "lag-based-features"]], "Land acknowledgement": [[61, "land-acknowledgement"]], "Large datasets solve many of these problems": [[36, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[35, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[45, "learning-objectives"], [46, "learning-objectives"], [47, "learning-objectives"], [48, "learning-objectives"], [49, "learning-objectives"], [50, "learning-objectives"]], "Learning outcomes": [[29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [38, "learning-outcomes"], [40, "learning-outcomes"], [41, "learning-outcomes"], [42, "learning-outcomes"], [43, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[44, "learning-outcomes"]], "Least confident cases": [[35, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[38, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[39, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[40, null]], "Lecture 13": [[22, "lecture-13"]], "Lecture 13: Feature engineering and feature selection": [[41, null]], "Lecture 14": [[23, "lecture-14"]], "Lecture 14: K-Means Clustering": [[42, null]], "Lecture 15": [[23, "lecture-15"]], "Lecture 15: More Clustering": [[43, null]], "Lecture 16": [[24, "lecture-16"]], "Lecture 16: Recommender Systems": [[44, null]], "Lecture 17": [[24, "lecture-17"]], "Lecture 17: Introduction to natural language processing": [[45, null]], "Lecture 18": [[26, "lecture-18"]], "Lecture 18: Multi-class classification and introduction to computer vision": [[46, null]], "Lecture 19": [[26, "lecture-19"]], "Lecture 19: Time series": [[47, null]], "Lecture 1: Course Introduction": [[29, null]], "Lecture 20": [[27, "lecture-20"]], "Lecture 20: Survival analysis": [[48, null]], "Lecture 21": [[27, "lecture-21"]], "Lecture 21: Communication": [[49, null]], "Lecture 22 - Ethics": [[28, "lecture-22-ethics"]], "Lecture 23 - Deployment": [[28, "lecture-23-deployment"]], "Lecture 23: Deployment and conclusion": [[50, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[30, null]], "Lecture 3: Machine Learning Fundamentals": [[31, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[32, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[33, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[34, null]], "Lecture 7: Linear Models": [[35, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[36, null]], "Lecture 9: Classification metrics": [[37, null]], "Lecture learning objectives": [[39, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[43, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[61, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[33, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[34, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[32, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[33, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[40, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[37, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[38, "let-s-separate-x-and-y"], [40, "let-s-separate-x-and-y"], [49, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[38, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[33, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[39, "lightgbm"]], "Limitations of linear models": [[35, "limitations-of-linear-models"]], "Linear SVM": [[35, "linear-svm"]], "Linear models [video]": [[35, "linear-models-video"]], "Linear regression": [[35, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Loading our saved model": [[50, "loading-our-saved-model"]], "Logistic regression [video]": [[35, "logistic-regression-video"]], "Logistic regression intuition": [[35, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[35, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[46, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[47, "logisticregression"], [48, "logisticregression"]], "MAPE": [[38, "mape"]], "ML and decision-making (5 min)": [[49, "ml-and-decision-making-5-min"]], "ML fairness activity": [[58, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[37, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[53, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[29, "machine-learning-workflow"], [37, "machine-learning-workflow"]], "Magnitude of the coefficients": [[35, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[35, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[35, "main-hyperparameters"]], "Main issues in ML-related communication": [[49, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[36, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[42, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[42, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[38, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[29, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[42, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[42, "method-2-the-silhouette-method"]], "Midterms": [[61, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[44, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[38, "model-building"], [50, "model-building"]], "Model complexity and training error": [[31, "model-complexity-and-training-error"]], "Model deployment": [[50, "model-deployment"], [50, "id1"]], "Model interpretability beyond linear models": [[40, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[29, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[58, "model-training-and-evaluation"]], "Model transparency and interpretation": [[50, "model-transparency-and-interpretation"]], "Model-based selection": [[41, "model-based-selection"]], "More comments on tackling class imbalance": [[38, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[43, "more-details-on-dbscan"]], "More on feature transformations": [[34, "more-on-feature-transformations"]], "More on k-NNs [video]": [[32, "more-on-k-nns-video"]], "More terminology [video]": [[30, "more-terminology-video"]], "More than one ordinal columns?": [[34, "more-than-one-ordinal-columns"]], "Most confident cases": [[35, "most-confident-cases"]], "Motivating example": [[35, "motivating-example"]], "Motivation": [[36, "motivation"], [47, "motivation"], [49, "motivation"]], "Motivation [video]": [[39, "motivation-video"]], "Motivation and big picture [video]": [[33, "motivation-and-big-picture-video"]], "Motivation and context": [[45, "motivation-and-context"]], "Motivation and distances [video]": [[32, "motivation-and-distances-video"]], "Movie features": [[44, "movie-features"]], "Multi-class classification": [[46, "multi-class-classification"]], "Multiclass classification and computer vision": [[53, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[34, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[49, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[31, null], [31, null], [47, null]], "Number of trees and fundamental trade-off": [[39, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[34, "ohe-with-many-categories"]], "Object detection": [[46, "object-detection"]], "Observations": [[37, "observations"]], "One Vs. One approach": [[52, "one-vs-one-approach"]], "One Vs. One prediction": [[52, "one-vs-one-prediction"]], "One vs. Rest": [[52, "one-vs-rest"]], "One-hot encoding (OHE)": [[33, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[47, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[47, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[34, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[37, "operating-point"]], "Optimization bias of hyper-parameter learning": [[36, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[36, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[36, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[36, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[36, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[33, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[40, "ordinal-features"]], "Other applications": [[42, "other-applications"]], "Other approaches / what did we not cover?": [[48, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[45, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[38, "other-possible-preprocessing"]], "Other software package": [[47, "other-software-package"]], "Other tools for preprocessing": [[45, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[45, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[32, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[41, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[31, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[54, "outline"], [55, "outline"], [56, "outline"], [57, "outline"], [58, "outline"], [59, "outline"], [60, "outline"]], "Over confident cases": [[35, "over-confident-cases"]], "Overfitting": [[31, "overfitting"]], "Overfitting of the validation data": [[36, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[36, "overfitting-of-the-validation-error"]], "Oversampling": [[37, "oversampling"]], "Overview": [[32, "overview"]], "POSIX time feature": [[47, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[37, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[30, "parameters"]], "Parameters and hyperparameters: Summary": [[30, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[47, "parsing-datetimes"], [60, "parsing-datetimes"]], "Part 1": [[53, "part-1"]], "Part 2": [[53, "part-2"]], "Passing Requirements": [[61, "passing-requirements"]], "Pipelines": [[33, "pipelines"]], "Playground": [[32, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[30, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 13 Videos": [[22, "pre-lecture-13-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[37, "precision"]], "Precision and recall: toy example": [[37, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[37, "precision-recall-f1-score-video"]], "Precision-recall curve": [[37, "precision-recall-curve"], [37, "id1"]], "Precision/Recall tradeoff": [[37, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[29, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[35, "predicting-probability-scores-video"]], "Predicting with learned weights": [[35, "predicting-with-learned-weights"]], "Prediction": [[48, "prediction"]], "Prediction of linear regression": [[35, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[35, "prediction-with-learned-parameters"]], "Predictions": [[46, "predictions"]], "Preferences in LogisticRegression": [[49, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[34, "preprocessing"], [47, "preprocessing"], [53, "preprocessing"], [58, "preprocessing"], [60, "preprocessing"]], "Preprocessing the targets?": [[34, "preprocessing-the-targets"]], "Prevalence of ML": [[29, "prevalence-of-ml"]], "Principles of effective communication": [[49, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[49, "principles-of-good-explanations-15-min"]], "Problem formulation": [[44, "problem-formulation"]], "Problem: Different transformations on different columns": [[33, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[36, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[31, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[32, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[53, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[32, "question"]], "Question for you": [[43, "question-for-you"]], "Questions for class discussion": [[44, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[36, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[32, "quick-recap"]], "RF better than GB": [[49, "rf-better-than-gb"]], "RFE algorithm": [[41, "rfe-algorithm"]], "R^2 (not in detail)": [[38, "r-2-not-in-detail"]], "Random forest feature importances": [[40, "random-forest-feature-importances"]], "Random forests": [[39, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[39, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[39, "randomforestclassifier"], [48, "randomforestclassifier"]], "Randomized hyperparameter search": [[36, "randomized-hyperparameter-search"]], "Range of C": [[36, "range-of-c"]], "Raw scores": [[35, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[30, "reading-the-data"], [46, "reading-the-data"]], "Real boundary between Canada and USA": [[30, "real-boundary-between-canada-and-usa"], [54, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[37, "recall"]], "Recap": [[48, "recap"], [49, "recap"]], "Recap and motivation [video]": [[43, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[30, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[37, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[50, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommender systems": [[53, "recommender-systems"]], "Recommender systems intro and motivation": [[44, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[44, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[41, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[48, "references"]], "Registration": [[61, "registration"]], "Regression scoring functions": [[38, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[32, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[32, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[32, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[39, "relevant-papers"]], "Relevant papers and resources": [[37, "relevant-papers-and-resources"]], "Relevant resources": [[41, "relevant-resources"]], "Reminder": [[44, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[50, "render-set-up-i-already-did-these"]], "Report format": [[7, "report-format"]], "Requirements (I already did these)": [[50, "requirements-i-already-did-these"]], "Resources": [[42, "resources"], [43, "resources"], [44, "resources"]], "Reuse your running examples": [[49, "reuse-your-running-examples"]], "Ridge": [[35, "ridge"]], "Ridge on the California housing dataset": [[35, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[38, "ridgecv"]], "Root mean squared error or RMSE": [[38, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[40, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[40, "shap-plots"]], "SMOTE idea": [[37, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[37, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[32, "svm-regressor"]], "Saving the model": [[50, "saving-the-model"]], "Saving time and scaling products": [[29, "saving-time-and-scaling-products"]], "Scaling": [[33, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[33, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[61, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[32, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[47, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[29, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Sending a request to the API": [[50, "sending-a-request-to-the-api"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[46, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[35, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[42, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[32, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[51, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[31, "simple-train-test-split"]], "SimpleFeature correlations": [[40, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[39, "some-important-hyperparameters"]], "Some key takeaways": [[50, "some-key-takeaways"]], "Some quotes on feature engineering": [[41, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[30, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[36, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[34, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[39, "stacking"], [59, "stacking"]], "Step 1": [[56, "step-1"]], "Step 2": [[56, "step-2"]], "Step 3": [[56, "step-3"]], "Step 4": [[56, "step-4"]], "Step 5": [[56, "step-5"]], "Steps to train a classifier using sklearn": [[30, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[37, "stratified-splits"]], "Strengths and weaknesses": [[39, "strengths-and-weaknesses"]], "Strengths of linear models": [[35, "strengths-of-linear-models"]], "Study tips": [[53, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[29, "summary"], [32, "summary"], [39, "summary"], [45, "summary"], [46, "summary"], [48, "summary"]], "Summary and reflection": [[31, "summary-and-reflection"]], "Summary of linear models": [[35, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[31, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[43, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[44, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[42, "supervised-learning"]], "Supervised learning (Reminder)": [[30, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[30, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[29, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[32, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[32, "support-vectors"]], "Survival analysis": [[53, "survival-analysis"]], "Survival plots": [[48, "survival-plots"]], "Syllabus": [[1, "syllabus"], [61, null]], "TAs": [[61, "tas"]], "Tabular data": [[30, "tabular-data"]], "Take-home message": [[43, "take-home-message"]], "Teaching Team": [[61, "teaching-team"]], "Terminology": [[46, "terminology"]], "Terminology [video]": [[30, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[39, "the-netflix-prize"]], "The __ syntax": [[36, "the-syntax"]], "The best features may be dependent on the model you use.": [[41, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[59, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[31, "the-golden-rule"]], "The random forests classifier": [[39, "the-random-forests-classifier"]], "The sigmoid function": [[35, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[31, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[42, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[49, "things-to-watch-out-for"]], "Time series": [[53, "time-series"]], "Time series analysis on a more complicated dataset": [[60, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[48, "time-to-event-and-censoring"]], "Tokenization": [[45, "tokenization"]], "Topic modeling": [[45, "topic-modeling"]], "Topic modeling motivation": [[45, "topic-modeling-motivation"]], "Topic modeling pipeline": [[45, "topic-modeling-pipeline"]], "Topic modeling toy example": [[45, "topic-modeling-toy-example"]], "Toy datasets": [[30, "toy-datasets"]], "Traditional time series approaches": [[47, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[47, "train-test-split-for-temporal-data"]], "Train/test splits": [[47, "train-test-splits"]], "Train/validation/test split": [[31, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[29, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[35, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[31, "training-error-vs-generalization-error"]], "Training models with transformed data": [[34, "training-models-with-transformed-data"]], "Training on the full corpus": [[50, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[49, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[46, "transfer-learning"]], "Transformations on the toy data": [[34, "transformations-on-the-toy-data"]], "Transforming the targets": [[38, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[40, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[39, "tree-based-ensemble-models"]], "Tree-based models": [[39, "tree-based-models"]], "Try out this moment predictor": [[50, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[38, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[54, null]], "Tutorial 2": [[55, null]], "Tutorial 3": [[56, null]], "Tutorial 4": [[57, null]], "Tutorial 5": [[58, null]], "Tutorial 6": [[59, null]], "Tutorial 7": [[60, null]], "Types of censoring": [[48, "types-of-censoring"]], "Types of errors": [[31, "types-of-errors"]], "Types of machine learning": [[29, "types-of-machine-learning"], [42, "types-of-machine-learning"]], "Types of problems involving time series": [[47, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[48, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[31, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[31, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[37, "undersampling"]], "Understanding the problem": [[50, "understanding-the-problem"]], "Unequally spaced time points": [[47, "unequally-spaced-time-points"]], "Unsupervised learning": [[42, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[61, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[52, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[37, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[42, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[38, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[46, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[46, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[38, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[34, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[36, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[49, "visualizing-your-results"]], "Warning": [[30, null]], "Warnings about feature selection": [[41, "warnings-about-feature-selection"], [41, "id8"]], "Weaknesses": [[39, "weaknesses"]], "Web app on a real server": [[50, "web-app-on-a-real-server"]], "Web app on local server": [[50, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[33, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[33, "what-are-the-options"]], "What are we exactly learning?": [[35, "what-are-we-exactly-learning"]], "What did we cover?": [[44, "what-did-we-cover"], [50, "what-did-we-cover"]], "What did we learn today?": [[31, "what-did-we-learn-today"], [33, "what-did-we-learn-today"], [34, "what-did-we-learn-today"], [37, "what-did-we-learn-today"], [38, "what-did-we-learn-today"], [49, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[49, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[49, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[34, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[45, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[44, "what-is-a-recommender-system"]], "What is clustering?": [[42, "what-is-clustering"]], "What is deployment?": [[50, "what-is-deployment"]], "What is feature engineering?": [[41, "what-is-feature-engineering"]], "What is feature selection?": [[41, "what-is-feature-selection"]], "What is grid search?": [[49, "what-is-grid-search"]], "What is model interpretability?": [[40, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[29, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[37, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[39, "what-kind-of-estimators-can-we-combine"]], "What next?": [[50, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[49, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[42, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[33, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[49, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[33, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[36, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[39, "which-model-should-i-use"]], "Which type of error is more important?": [[37, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[36, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[40, "why-do-we-want-this-information"]], "Why feature selection?": [[41, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[29, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[40, "why-model-transparency-interpretability"]], "Why neural networks?": [[46, "why-neural-networks"], [46, "id1"]], "Why not neural networks?": [[46, "why-not-neural-networks"], [46, "id2"]], "Why should I use it?": [[49, "why-should-i-use-it"]], "Why should we care about effective communication?": [[49, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[44, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[34, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[45, "word-embeddings"]], "Word vectors with spaCy": [[45, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[30, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[39, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[37, "class-weight-balanced"]], "cross_val_score": [[31, "cross-val-score"]], "cross_validate": [[31, "cross-validate"]], "fit and transform paradigm for transformers": [[33, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[30, "fit-the-classifier"]], "fit, predict , and score summary": [[30, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[61, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[38, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[38, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[39, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[39, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[41, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[46, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[30, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[30, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[30, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[31, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[31, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[37, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[37, "iclicker-exercise-9-2"]], "iClicker question": [[49, "iclicker-question"]], "k-Nearest Neighbours (k-NNs) [video]": [[32, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[44, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[36, "n-iter"]], "n_jobs=-1": [[36, "n-jobs-1"]], "pandas_profiler": [[38, "pandas-profiler"]], "predict the target of given examples": [[30, "predict-the-target-of-given-examples"]], "predict_proba": [[35, "predict-proba"]], "random_state argument": [[31, "random-state-argument"]], "score your model": [[30, "score-your-model"]], "sklearn API summary: estimators": [[33, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[33, "sklearn-api-summary-transformers"]], "sklearn set_config": [[34, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[34, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[40, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[40, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[51, "spacy"]], "test score vs. cross-validation score": [[31, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[31, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[31, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[37, "questions-for-group-discussion"], [58, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[29, "questions-for-you"], [30, "questions-for-you"], [30, "id1"], [30, "id3"], [31, "questions-for-you"], [31, "id1"], [32, "questions-for-you"], [32, "id1"], [33, "questions-for-you"], [33, "id1"], [33, "id2"], [34, "questions-for-you"], [34, "id1"], [35, "questions-for-you"], [35, "id1"], [35, "id2"], [36, "questions-for-you"], [36, "id2"], [37, "questions-for-you"], [37, "id2"], [38, "questions-for-you"], [38, "id2"], [39, "questions-for-you"], [39, "id1"], [39, "id2"], [41, "questions-for-you"], [42, "questions-for-you"], [42, "id2"], [43, "questions-for-you"], [43, "id3"], [44, "questions-for-you"], [44, "id1"], [44, "id2"], [46, "questions-for-you"], [47, "questions-for-you"], [47, "id1"], [47, "id2"], [47, "id3"], [48, "questions-for-you"], [48, "id1"], [48, "id2"], [48, "id3"], [48, "id4"], [49, "questions-for-you"], [49, "id1"], [50, "questions-for-you"], [50, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[29, "eva-s-questions"], [31, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/classes/class4B", "lectures/classes/class4C", "lectures/classes/class5A", "lectures/classes/class5B", "lectures/classes/class5C", "lectures/classes/class6A", "lectures/classes/class6B", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/21_communication", "lectures/notes/23_deployment-conclusion", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/classes/class4B.md", "lectures/classes/class4C.md", "lectures/classes/class5A.md", "lectures/classes/class5B.md", "lectures/classes/class5C.md", "lectures/classes/class6A.md", "lectures/classes/class6B.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/21_communication.ipynb", "lectures/notes/23_deployment-conclusion.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 35, 36, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "0": [0, 1, 7, 8, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "00": [10, 29, 30, 32, 34, 35, 36, 37, 40, 43, 44, 47, 48, 49, 60, 61], "000": [29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 45, 46, 48, 51], "0000": [33, 35, 37, 51], "00000": [36, 47, 60], "000000": [30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48, 60], "00000000e": 40, "000000e": 36, "000001": 38, "00000e": 32, "000010": 38, "000011": 37, "000021": 33, "000036": 37, "000057": 33, "000065": 36, "000067": 36, "000077": 36, "000087": 35, "000089": 35, "0001": [35, 37, 38, 48, 49], "000100": [33, 38], "000108": 35, "000113": 37, "000114": 36, "000117": 38, "000130": 35, "000136": 46, "000137": 36, "000145": 36, "000146": 35, "000147": 36, "000149": 33, "000150": 35, "000151": 36, "000155": [33, 37], "000159": 36, "000163": 36, "000166": [35, 36], "000177": [33, 47], "000180": 33, "000181": 36, "000182": 35, "000183": 35, "000187": 35, "000188": 33, "000190": 47, "000192": 47, "000194": 35, "000195": 33, "000198": 37, "000201": 36, "000206": 36, "000208": 33, "000210": 36, "000212": 41, "000213": 35, "000218": 35, "000221": 38, "000226": 38, "000227": 37, "000231": 33, "000232": 46, "000234": [32, 36], "000235": [33, 37], "000240": 33, "000245": 36, "000247": 46, "000255": 35, "000256": 47, "000259": 33, "000260": 33, "000271": 47, "000273": 46, "000274": 46, "000281": 35, "000283": 35, "000285": 35, "000286": 36, "000289": 33, "000294": 36, "000312": 37, "000332": 38, "000336": 46, "000339": 36, "000348": 36, "000353": 36, "000354": 36, "000363": 46, "000366": 37, "000370": 36, "000371": 35, "000373": 38, "000378": 35, "00038": 36, "000397": 38, "000399": 46, "000433": 38, "000435": 46, "000437": 46, "000452": 33, "000459": 35, "000471": 47, "000472": 46, "000489": 36, "000492": 37, "000498": 47, "0005": 49, "000503": 36, "000508": 36, "000520": 38, "000575": 47, "00058": 36, "000580": 32, "000630": 37, "000633": 32, "000637": 46, "000647": 32, "000650": 32, "000651": 32, "000652": 38, "000655": 32, "000661": 32, "000671": 32, "000678": 36, "000713": 38, "000726": 37, "000737": 47, "000747": 36, "000748": 33, "000752": 32, "000758": 46, "000765": 33, "000774": 33, "000786": 37, "000787": 32, "00079": 36, "000794": 32, "000795": 32, "000797": 32, "000803": 38, "000829": 32, "000831": 32, "000832": 38, "000867": 33, "000869": 47, "000873": 32, "000889": 32, "000891": 37, "000917": 36, "000927": 37, "000936": 32, "000945": 41, "000960": 46, "000964": 41, "000976": 36, "000977": 32, "000982": 36, "001": [29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 46, 48, 49, 51], "0010": 35, "00100": 36, "001000": [36, 38], "001002": 31, "001006": 31, "001010": 31, "001011": [32, 38], "001014": 31, "001016": 31, "001017": 31, "001026": 31, "001027": 31, "001029": 31, "001038": 31, "001040": 37, "001043": 33, "001057": [31, 36], "001060": 33, "001063": 31, "001064": 46, "001068": 40, "001071": 31, "001078": 31, "001086": 31, "001087": 41, "001103": 31, "001111": 31, "001139": 32, "001149": 31, "001155": 41, "001162": [36, 41], "001174": 31, "001205": 37, "001220": 35, "001224": 32, "001226": 46, "001236": 36, "001239": 37, "001266": 38, "001279": 41, "001286": 37, "001294": 31, "001299": 31, "001305": 31, "001307": 31, "001315": 31, "001317": 31, "001322": 31, "001323": 31, "001325": 32, "001329": 31, "001337": 31, "001338": 35, "001347": 36, "001352": 31, "001361": 35, "001362": 35, "001365": 32, "001371": 34, "001390": 31, "001391": 31, "001392": 32, "001400": 34, "001406": 38, "001407": 31, "001412": 36, "001414": 32, "001422": 38, "001423": 36, "001429": 31, "001433": 38, "001441": 31, "001448": 34, "001453": 31, "00146": 36, "001466": 34, "001467": 36, "001492": 36, "001495": 32, "001563": 34, "001566": 38, "001585": 36, "001586": 32, "001591": 34, "001594": 36, "001595": 32, "001600": 32, "001604": 34, "001606": 34, "001608": 36, "001616": 36, "001620": 36, "001629": 36, "001641": 46, "001645": 35, "001647": 34, "001679": 36, "001682": 36, "001693": 41, "001699": 31, "0017": 37, "001700": 37, "001710": 35, "001715": 34, "001740": 38, "001769": 36, "001773": 32, "001776": 31, "001790": 38, "001792": 36, "001847": 41, "001850": 35, "001877": 32, "001894": 38, "001900": 32, "001920": 34, "001922": 34, "001933": 38, "001949": 41, "001952": 32, "001968": 31, "001994": 41, "002": [31, 35, 39, 40, 48], "002003": 36, "002022": 34, "002030": 32, "002045": 36, "002057": [33, 34], "002083": 32, "002096": 46, "002105": 36, "002116": 34, "002118": 32, "002123": 36, "002143": 31, "002146": 36, "002158": 41, "002159": 36, "002197": 36, "002221": 38, "002321": 35, "00234": 36, "002355": 41, "002385": 38, "002441": 41, "002460": 46, "002525": 46, "002561": 36, "002646": 41, "002664": 41, "002675": 36, "002682": 46, "002690": 33, "002692": 36, "002704": 36, "002711": 46, "002746": 38, "002783": 36, "002788": 34, "002789": 34, "002807": 34, "002835": 36, "002858": 34, "002867": 41, "002889": 37, "0029": 48, "002910": 34, "002934": 35, "002940": 46, "002948": 32, "002962": 46, "002986": 46, "002999": 36, "003": [36, 39], "003013": 34, "003014": 36, "003015": 36, "003027": 36, "003038": 36, "003083": 36, "003086": 34, "003115": 34, "003124": 38, "003133": 38, "003146": 34, "003148": 35, "003166": [33, 41], "003181": 33, "003183": 41, "003185": 48, "003186": 34, "003188": [33, 34], "003194": 35, "003212": 33, "003242": 46, "003257": 46, "003273": 31, "003283": 46, "003288": 38, "003300": 33, "00332": 36, "003324": 33, "003365": 34, "003401": 41, "003421": 36, "003423": 41, "003427": 41, "003472": 36, "003477": 46, "003479": 36, "003483": 36, "003493": 41, "003528": 36, "003529": 36, "003547": 38, "003563": 36, "003633": 36, "003647": 46, "00369": 36, "003748": 36, "003757": 36, "003785": 38, "003885": 36, "003919": 36, "003919287722401839": 36, "00392157": 46, "003923": 34, "003924": 41, "003933": 36, "003998": 36, "004": [32, 36, 39, 40, 46], "004057": 36, "004065": 47, "004082": 47, "004121": 38, "004143": 38, "004264": 31, "004293": 36, "004305": 36, "004337": 36, "00435173": 42, "004352": 42, "004398": 40, "004402": 36, "004466": 36, "004496": 36, "004521": 38, "004529": 40, "004556": 36, "004574": 38, "004602": 38, "00461": 36, "004714": 36, "004723": 40, "004761": 40, "004770": 33, "004801": [33, 34], "004807": 34, "004826": 38, "004829": 38, "004854": 38, "004884": 46, "004919": 36, "004934": 37, "004952": 36, "004959": 36, "00496": 36, "005": [29, 39, 40, 48, 49], "005067": 33, "005074": 46, "005093": 33, "005098": 38, "005114": 38, "005126": 36, "005151": 36, "005157": 33, "005167": 38, "005196": 36, "005241": 38, "00525962": 33, "005269": 38, "005288": 34, "005335": 36, "005336": 38, "005387": 37, "005423": 36, "005426": 36, "00543825": 33, "005440": 46, "005478": 40, "00548": 36, "005538": 38, "005579": 38, "005641": 38, "005674": 38, "005699": 31, "005708": 36, "00573": 36, "005734": 36, "005735": 36, "005767": 36, "005809": 47, "005834": 36, "005836": 33, "005888": 33, "006": [39, 40, 48], "006012": 36, "006046": 38, "006055": 36, "006067": 38, "006106": 36, "006110": [32, 36, 38], "006236": 38, "006244": 36, "006435": 36, "006452": 35, "006476": 38, "006505": 46, "006531": 31, "006545": 36, "006546893270012566": 35, "006557": 35, "006578": [33, 34], "006652": 36, "006667": 36, "00667": 36, "006744": 38, "006805": 31, "006861": 36, "006904": 36, "00691": 36, "006973": 33, "007": [33, 39, 40, 48, 51], "007068": 41, "00715": 36, "00720988e": 40, "007228": 38, "007291": 34, "007316": 31, "007361": 37, "007362": 36, "007434": 40, "007458": [33, 34], "007517": 38, "007544": 36, "007563": 36, "007588": 42, "00758803": 42, "00759438": 40, "007655": 36, "007666": 37, "00767": 36, "007737": 38, "007776": 38, "007818": 36, "007938": 31, "007986": 38, "008": [39, 40, 51], "008040": 47, "008120": 38, "008153": 36, "008167": [33, 34], "00830586": 34, "008306": 34, "008322e": 48, "008333": 34, "008346": 38, "008377": 36, "008472": 38, "008577": 46, "008581": 38, "008606": 38, "008617": 38, "008667": 36, "00871": 36, "008735": 32, "008785": 38, "009": [34, 39, 48], "009059": 31, "009063": 36, "009082": 36, "009090": 38, "009132": 36, "009140": 38, "009297": 36, "009305": 36, "009339": 38, "009422": 31, "009512": 36, "009514e": 38, "009664": 38, "009692": 46, "009724": 41, "01": [32, 33, 35, 36, 37, 38, 40, 46, 47, 48, 49, 52, 60], "010": [29, 35, 36, 48, 51], "0100": 35, "01000": 36, "010000": [33, 36, 38], "010027": 35, "010183": [33, 34], "0102": [32, 36], "010208": 41, "010294": 31, "010650": 31, "010679": 31, "010688": 41, "010715": 36, "010750": 41, "011": [29, 34, 46, 48], "011210": 41, "011234": 37, "011248": 38, "011252": 41, "011269e": 38, "011287": 41, "011332": 48, "011336": 32, "011440": 38, "011617": 36, "011678": 37, "011767": 38, "011773": 39, "012": [33, 34, 39, 40, 46, 48, 51], "012019": 31, "012030": 41, "012232": 38, "012240": 41, "012252": 36, "012616": 36, "012624": 38, "012707": 37, "012758": 38, "013031": 38, "01311996071": 38, "013120": 40, "013157": 36, "013161": 36, "013433": 32, "013629": 36, "013706928443177698": 36, "013707": 36, "013863": 36, "013888": 36, "014": [31, 33, 39, 40, 48], "014030": 38, "014081e": 38, "014305": 38, "01432486e": 40, "014481": 36, "014503": 36, "014650": 48, "014730": 34, "01473536": 32, "014758": 48, "015": [29, 33, 34, 39, 48, 51], "015003": 36, "015039": 37, "015056": 36, "015165": 38, "015372": 36, "015724": 41, "015755": 36, "015819": 36, "016263": 36, "016372": 36, "01647": 36, "016525": [38, 40, 49], "016555": 35, "016587": 37, "016598": 36, "016602": 36, "016607": 36, "016676": 42, "016688": [33, 41], "016693": 38, "016807": 35, "016815": 36, "016918": 37, "016944": 32, "017": [34, 46], "017185": 36, "017226": 38, "017308": 36, "017427": 36, "017610": 40, "017696": 40, "017737": 40, "017741": 40, "017829": [47, 60], "017837": 36, "01784": 36, "017927": 36, "017959e": 38, "017972": 33, "018": 39, "018014": 40, "018046": 37, "018077": 36, "018178": 32, "018243": 36, "018310": 32, "018434": [47, 60], "018459e": 38, "018487": 35, "0185": 35, "018505": 36, "018507e": 38, "018558": 36, "018581": 38, "018653": 36, "018745": 29, "018789": 36, "018846": 36, "018854": 37, "019": 39, "019012": 36, "019163": 36, "019381838999846482": 36, "019382": 36, "019396": 36, "019444": 34, "019446": 36, "019531": 37, "019556": 48, "0195598": 35, "019574": 36, "019839": 36, "02": [32, 33, 34, 35, 36, 38, 40, 41, 47, 48, 56, 60], "02000e": 32, "020123": 38, "020403": 36, "020414": 36, "020641": 40, "020648": 38, "020653": 31, "020833": 44, "020862": 38, "020873": 33, "021": [39, 51], "021043": 37, "021100": 33, "021281": 36, "021305": 32, "021345": 36, "021523": 37, "021603": 46, "021721": 36, "021746": 36, "021813": 37, "021862": 36, "021900": [32, 36], "022039": 37, "022331": 40, "022433": 36, "022629": 36, "022686": 36, "022848": 31, "022866": 37, "023": [39, 46], "023086": 48, "023105": [47, 60], "023305": 38, "023366": 41, "023367": 37, "023511": 36, "023554": 38, "023636": 37, "023666": 36, "023810": 51, "024": 39, "024028": 36, "024122": 36, "024291": 47, "024351e": 38, "024390": 41, "02446630e": 40, "024540": 33, "025": [33, 37], "025381": [40, 49], "025391": [33, 34], "025396": 36, "025489": 40, "025689": 36, "025910": 32, "025998": [33, 34], "026": 48, "0261": [32, 36], "026620": 36, "026777": 36, "02677733855112973": 36, "026793": [38, 40, 49], "026972": 38, "027070": 38, "027112": [47, 60], "027321": 41, "027484": 38, "027578": 38, "028023": 37, "028337": 36, "028351": 36, "028420": 38, "028672": 41, "028772": 38, "029137": 37, "029146": 37, "029164": [47, 60], "029198": 36, "029264": 38, "029409": 38, "029475": 38, "029909": 31, "029950e": 38, "02d": 47, "03": [35, 36, 38, 40, 46, 47, 48, 51, 60], "030": 40, "03017665e": 40, "030200": 33, "030343": 38, "030349": 38, "030408": 32, "03049217": 32, "0305": 32, "030739733331869412": 35, "030786": 38, "030805": 38, "031": 34, "031070": 38, "031385": 32, "031483": 38, "031564": 33, "031794": 38, "031863": 38, "031994": 38, "032140": 38, "032280": 37, "032324": 36, "032404": 36, "032566": 34, "03256625": 34, "032656": 32, "032874": 32, "033165": 38, "033222": 48, "033267": 47, "033279": 40, "033305": 46, "033322": 38, "033459": 32, "0335": 36, "033723": 38, "033739": 38, "033780": 48, "033833": 37, "0339": 33, "034071": 37, "03411038e": 40, "034132": 38, "0344": [32, 36], "034894": 40, "034977": 38, "034979e": 38, "035": 46, "0351": 33, "03516073": 40, "035161": 40, "035223": 38, "035230": [47, 60], "035722": 38, "036": [33, 39, 46], "036136": 41, "0362": 33, "036646": 38, "036749": 37, "036764": 37, "036886": 39, "0370": 33, "0373": 33, "037414": [47, 60], "037785": 37, "0378": [33, 48], "038102": 35, "038609": 38, "038707": 40, "038948": 38, "039": 46, "039498": 35, "039741": 32, "0399": 33, "04": [33, 34, 36, 38, 40, 47, 48, 56, 60], "040": 39, "040129": 48, "040497": 37, "040698e": 38, "040954": 48, "040984": 47, "041": [39, 46], "041031": 37, "04108378": 35, "041084": 35, "041129": 32, "041201": 37, "041488": 38, "041704": 40, "041769": 38, "042081": 40, "042382": 41, "042743": 38, "042957": [33, 34], "043": 36, "043257": 34, "043319": 40, "043509": 36, "0437": [30, 31, 32, 54], "043890": 32, "044": [32, 36], "044029": [33, 34], "044166": 35, "044253": 40, "044313": 33, "044409": 38, "044614": 36, "044873": 31, "045": [30, 46], "045267": 47, "045280": 37, "045304": 32, "045415": 33, "045481": [47, 60], "046": 46, "04600e": 32, "046020": 32, "046116": 36, "046193e": 38, "046216": 36, "046638": 34, "0468": 48, "0469": 33, "046945": 36, "04709519e": 40, "0474": 35, "047567": 38, "04774884": 42, "047749": 42, "048": [31, 34], "048378": 31, "04861878": 42, "048630": 47, "048860": 33, "048889": 38, "049": [34, 46], "05": [32, 33, 36, 37, 38, 43, 47, 48, 49, 60], "050": [29, 46], "050110e": 38, "050132": [33, 34], "051": 46, "051269": [33, 34], "05137470e": 40, "051392": 46, "051472": 32, "051620": 33, "051824": 38, "051925": 36, "052": 33, "052349": 33, "052607": 37, "052790": 37, "052819": 37, "05290827e": 40, "053156": 42, "05350962": 52, "0537": 36, "053763": 31, "053918": 36, "054054": 37, "054461": 37, "054653": 34, "05465323": 34, "054669": [38, 40, 49], "054784": 34, "05478443": 34, "055": [31, 33, 34], "055100": 36, "055915e": 38, "05598498": 34, "055985": 34, "056": 46, "056478": [33, 34], "056703": 37, "057": [33, 46], "057003": 32, "057082": 38, "057254": 48, "057296": 37, "057331": 38, "057646": 32, "057729": 37, "057732e": 48, "057793": [33, 34], "057910": [33, 34], "058": 39, "0580": [31, 35], "058176": 49, "058298": 38, "058311": 37, "059": [29, 33], "059077": 37, "0591": 33, "059242": [33, 34], "059360": 46, "059588": 36, "059863": 32, "06": [33, 36, 38, 43, 46, 47, 48, 52, 60], "060": 46, "060477": 38, "060543": 41, "061100": 33, "061206": 37, "061241": 32, "061312": 38, "061313": 46, "061937": 32, "062": [29, 32, 36], "062043": 36, "062449": 48, "062658e": 38, "062723": 31, "062792": 32, "063004": 41, "063110": [33, 34], "063173": 40, "064": [36, 40], "06405": 36, "064050": 36, "064200": 32, "064307": 41, "064452": 32, "065": 46, "065169": 36, "065199": 37, "065449": 38, "065463": 37, "066166": 48, "066251": 31, "066605": 36, "066667": 33, "0667579112160865": 35, "066810": 48, "066944": 36, "067119": 33, "067120": 31, "06797961": 38, "067991": 33, "068": 29, "068214": [35, 36], "068291": 46, "068498": 36, "068775": 36, "068891": 36, "069150": 40, "06915047": 40, "069188": 48, "0694": [32, 36], "069530": 32, "07": [36, 38, 41, 47, 48, 60], "070081": 36, "070195": 36, "070850": 37, "070898": 36, "070907": 31, "070929": 37, "071": 46, "071330": [47, 60], "071541": [33, 34], "071654": 41, "07174469222": 38, "071745": 40, "071975": 41, "072": 39, "072043": 36, "072243": 40, "0723": 33, "072396": 36, "07245741": 38, "072595": 36, "072707": 31, "073016": 49, "073058": 33, "073233": 35, "073366": 33, "074": [33, 39], "0741": 32, "074141": 32, "07418": 36, "074327": 39, "074418": 46, "074475": 33, "074719": 34, "07471942": 34, "074853": 49, "075000": 44, "075170": 47, "075453": 48, "075467": 48, "075747": 36, "076104": 38, "0762": 33, "076284": 42, "07639": 36, "076533": 38, "076798": 32, "077": [39, 46], "077204": 40, "077761": 48, "077803": 36, "078": [35, 39], "0780": [30, 31, 54], "078052": 37, "07808506982896266": 38, "078243": 36, "078387": 48, "078552": 36, "078740": 36, "07877994e": 52, "078880": 34, "079": 36, "079282": 36, "079377": 48, "0794": [32, 36], "079471e": 38, "079852e": 38, "08": [33, 36, 38, 41, 43, 46, 47, 48, 60], "080": 46, "08002986030": 34, "080084": 36, "080165": 36, "080319": 34, "08031924": 34, "080694": 40, "080734": 31, "0808": 36, "081": 29, "08116": 36, "081167": 48, "081292": 47, "08151507e": 40, "081837": 48, "082": 33, "082100": 36, "082251": 35, "082265e": 48, "082749": 32, "082835": 40, "082949": 32, "083": [32, 36, 39], "083123": [33, 34], "083338": 31, "083545": 37, "083615": 36, "083813": [33, 34], "084288": 36, "084490": 49, "084746": [33, 34], "085150": 47, "085415": [40, 49], "085477": 37, "085508": 38, "085546": 38, "085550": 38, "085551": 38, "085693": 36, "085698": 38, "08613": 36, "086461": 41, "086932": 31, "087": 34, "087128": 36, "087668": 36, "087996e": 36, "088": 46, "0880": 33, "088543": 36, "088948": 32, "089294": 36, "089313": 36, "089485": 31, "09": [31, 34, 36, 38, 47, 48, 60], "090000": 37, "09009799": 38, "090231": 40, "090376e": 38, "090453": 37, "090473": 36, "09058097218": 29, "090785": 38, "091": 46, "091243": 36, "091625": 41, "091819": 31, "092": 39, "092072": 36, "092123": 36, "0922": [32, 36], "092204": 31, "09245358900622544": 36, "092454": 36, "092604": 31, "092660": 48, "092670": 36, "092729": 36, "092930": 34, "093051": 36, "0931": 36, "093228": 41, "093350": 49, "093390": 32, "09345386": 34, "093454": 34, "093624": 31, "093787": 36, "093893": 36, "094": 29, "094290": 48, "09430199": 34, "094302": 34, "094581": 34, "094586": 37, "094725": 36, "094863": 36, "095018": 36, "09503409246217484": 38, "095177": 36, "095345": 36, "09573445": 36, "096462": 38, "096692": 33, "096722": 36, "096858": 36, "096927": 37, "096960": 38, "096990": 31, "096997": 46, "097": 46, "09706504": 46, "097088": 48, "097184": 36, "097293": [33, 34], "097516": 33, "097707": 36, "097763": 36, "098": [35, 46], "098152": 36, "098307": 38, "098326": [32, 46], "098559": 36, "098629e": 36, "098663": 36, "0989147678053208": 35, "098915": 35, "098950": 36, "098966": 33, "099": 39, "099230": 40, "099240": [33, 34], "099454": 36, "099558": [33, 34], "099685": 38, "099723": 33, "099729": 36, "099749": [47, 60], "099802": 36, "099869": 36, "0x1227a36e0": 8, "0x1577111f0": 36, "0x16888d4c0": 36, "0x168921100": 36, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 40, 45, 47, 50, 51, 52, 61], "10": [4, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 60, 61], "100": [30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 57, 60], "1000": [31, 32, 34, 35, 36, 37, 38, 40, 41, 46, 47, 48, 49, 51, 52, 57, 58], "10000": [30, 34, 35, 36, 38, 47, 60], "100000": [32, 34, 35, 36, 38, 47, 60], "1000000": 36, "100103": 47, "100105": 36, "100139": 34, "100146": 47, "100248": 32, "100275": 41, "1004": 32, "1005": [47, 60], "1006": [47, 60], "1007": [47, 60], "1008": [47, 60], "100882": 37, "1009": [47, 60], "10092665203438746": 38, "101": [9, 10, 42, 46, 48], "1010": [47, 60], "1012": [47, 60], "101259": 38, "1014": [36, 46], "1015": [46, 47, 60], "1016": [46, 47], "101688": 36, "1017": [46, 47, 60], "101796": 38, "1018": [46, 47, 60], "101810": 31, "101832": 36, "101894": 37, "1019": [46, 47, 60], "102": [37, 38, 59], "1020": [36, 41, 46, 47, 60], "102044": 41, "1021": [46, 47, 60], "102135": 37, "1022": [46, 47, 60], "1023": [46, 47, 60], "1024": [34, 46, 47], "102435": [32, 38], "102474": 34, "10247431": 34, "1025": [47, 60], "10254": 47, "1026": [35, 47], "1027": [47, 60], "10273": 38, "10274": 37, "1028": [47, 60], "1029": [47, 60], "103": 48, "103023": 36, "1031": 47, "103219": 41, "103222": 46, "1034": 41, "103439": 34, "1039": [47, 60], "104": [32, 33, 39, 42, 46], "1040": 33, "104070": 38, "1041": [38, 40, 47, 51, 60], "10416666666666667": 44, "1042": 36, "1044": 29, "104596": 36, "104643": 38, "105": 39, "1050": 30, "105080": 41, "105089": 34, "10513": 47, "1053": 51, "105314": 47, "10556679": 42, "105656": 40, "10584063": 46, "106000": 33, "106023": 38, "106112": 47, "106180": 47, "106319": 47, "106322": 47, "106424": 47, "106452": 32, "10645223": 32, "10653": [47, 60], "106705": 47, "106764": 36, "1068": 51, "106816": 47, "1069": 51, "106996": 36, "107": 39, "1070": 41, "107050": 47, "107292": 47, "1075": 51, "107502": [47, 60], "1076": 34, "107718": 36, "10781": [39, 40], "107917": [47, 60], "10793260e": 46, "107947": 38, "107985": 38, "107991": 37, "108": 29, "1080": 29, "10800": 29, "1085": 35, "10868": 47, "108681": 32, "1089": 38, "10910": 47, "10931": 34, "109526": 37, "1099": 38, "10_000": 48, "10th": [36, 37, 39, 40, 58], "10x": 37, "11": [1, 10, 11, 19, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 51, 53, 55, 60, 61], "110": [35, 46], "110316": [47, 60], "110319": [47, 60], "1104": 32, "11057": 47, "1106": 41, "110645": 38, "110915e": 38, "111": [33, 36, 37, 38, 48, 58], "11121453": 42, "111215": 42, "111220": 47, "111438": 41, "111543": 38, "112": 32, "1122": [38, 40, 51], "1123": [36, 51], "112441": 36, "112490": 36, "112527": 40, "112848": 38, "11331": 51, "11336331e": 40, "113600": [33, 34, 56], "1138": 41, "113837": 38, "1139": [38, 40, 49], "113949e": 48, "114": 33, "1140": [29, 38, 40, 49], "114000": [33, 41], "114079": 36, "114214": 36, "114507": 46, "11457": [38, 40, 49], "114766": 40, "114836": 41, "114966": 40, "115": 34, "1150": 29, "115083": 33, "115089": 47, "11509": 38, "115090": 47, "115091": 47, "115092": 47, "115183": 36, "115276": 48, "115401": 38, "115406": 32, "115428": [47, 60], "115956": 35, "116": 33, "116145": 41, "116167": 35, "116443": 41, "116497": 38, "11664": 51, "11693": 38, "117": [33, 34, 35, 41, 56], "117058": 35, "117379": 36, "117380": 33, "117412": 38, "117528": 41, "11758": [47, 60], "117612": 46, "117712": 47, "117816": 33, "117899e": 38, "1179": 33, "118": [33, 34, 35, 38, 40, 41, 49], "1180": 30, "118182": [33, 34], "118347": 38, "118450": 37, "118563": 41, "11886432": 36, "118874": 38, "118934": 37, "11898": 37, "119": [33, 34, 35, 41, 47, 56, 60], "1190": 33, "119049": [47, 60], "11909976": 42, "119100": 42, "119400": 33, "119570": 41, "119911": [47, 60], "11th": [37, 39, 40, 58], "12": [10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61], "120": [32, 33, 35, 38, 39, 46, 47, 52], "1204": 32, "120769e": 38, "121": [29, 33, 34, 35, 36, 39, 41, 47], "1210": 36, "121056e": 38, "121084e": 38, "121351": 40, "12138": 33, "1214": 38, "121438": 48, "12150684": 35, "121531": 37, "121599": 40, "121628": 32, "1217": 48, "12178": 41, "121846": 40, "121985": 38, "122": [29, 30, 31, 33, 34, 41, 46, 54, 59], "1220": [29, 33, 36], "1222": 36, "122307": [33, 34], "122331": 38, "12266": 45, "122668": 36, "123": [4, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58], "123367": 38, "1235387316046016": 36, "123539": 36, "124": 33, "1240": 29, "1241": [38, 41], "1243": 33, "12436984": 34, "124370": 34, "1247": 36, "12498": 40, "124982": 41, "125": [8, 38], "1250": [33, 34, 56], "12508": [38, 40, 49], "125440e": 38, "125476": 32, "125523": [47, 60], "1256": 52, "125617": [47, 60], "125644": 38, "1258": 48, "126": 41, "126238": 41, "126398": [33, 34], "126488": 42, "12649": 33, "126500": 33, "126563": 36, "126808": [33, 34], "127": [31, 33, 35, 36, 50], "127086": 33, "127087": 48, "1271": 39, "127107": 40, "127226": 34, "127242": 38, "1273": 40, "127326": 38, "1274": 41, "127418": 38, "127439": 38, "127441": 38, "127614": 38, "12761659": 38, "127878": 32, "1279": 38, "128": 51, "1280": [33, 36, 38], "1281": 38, "128188": [33, 34], "128384": 38, "128528": 38, "128820": 47, "128828": 47, "128829": 47, "128830": 47, "128984": 38, "129": [32, 35, 41, 48, 59], "1290": [33, 34], "12906": 29, "129257": 38, "12927": 29, "129300": [33, 34, 56], "129459": 41, "129600": 38, "129900": 37, "129904": 38, "129985": 33, "12th": [37, 39, 40, 58], "13": [8, 10, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 47, 48, 51, 53, 56, 60], "130": [29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 49, 54, 56], "1300": [38, 40, 49], "1302": 37, "130395": [47, 60], "1304": [32, 48, 49], "130432": [47, 60], "1306": 50, "130690e": 38, "1307": 38, "131": [33, 39, 47, 48], "131000": 38, "13107": 47, "131275": 37, "1313": 38, "1314": [38, 40, 49], "131607": [38, 40, 49], "131773": 48, "1319796954314723": 39, "132": 48, "1320": 41, "1321": 29, "132158": 38, "132292": 41, "13229595e": 40, "13255": 47, "132875": [33, 34], "132886": 47, "133": [36, 48], "133000": 38, "133210": 36, "133270": 38, "133337": 38, "133562": 48, "13392236": 46, "134": [30, 31, 34, 35, 54], "1340": 30, "134061": 41, "13407": 40, "134287": 37, "1346": [33, 38, 40, 41, 48, 51], "134615": 35, "134658": 33, "1347": 51, "134894": [47, 60], "135": [47, 48, 60], "135134": [47, 60], "135197": [47, 60], "13521135": 40, "135299": 41, "135305": [33, 34], "135384": 38, "135422": 38, "1357": 29, "136": [33, 34], "1360": 30, "13665": [33, 34, 56], "136714": 37, "1370": [29, 32, 36, 48], "13704": [38, 40, 49], "1372": 49, "137410": 42, "137500": [33, 34, 56], "1378": 38, "138": 51, "1380": 29, "138103": 46, "1383": 36, "138503": 41, "138528": 35, "138876": 48, "1389": [33, 38, 40], "139": [33, 51], "1390": 29, "139297": 37, "139317": 37, "139322": 37, "139349": 37, "13941": 37, "139554": 37, "1396": 36, "1397": 36, "14": [10, 24, 25, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 43, 44, 46, 47, 48, 53, 60], "140": 33, "140185": 41, "1404": [32, 48], "1405": 41, "1406": [33, 38, 40], "140641": [47, 60], "140953": [47, 60], "141": [33, 35], "141232": [47, 60], "14159265358979323": 8, "14160": 37, "141851": [47, 60], "142": 39, "142193": [47, 60], "142199": [47, 60], "1423": 37, "142398": [47, 60], "142467": 31, "1427": 49, "142806": [47, 60], "142857": 34, "14289": [33, 34, 56], "143": [36, 37], "143693": [47, 60], "143803": 41, "1438387200": 47, "1438398000": 47, "1438408800": 47, "1438419600": 47, "1438430400": 47, "1438441200": 47, "1438452000": 47, "1438462800": 47, "1438473600": 47, "1438484400": 47, "143975": [47, 60], "144": [29, 36], "144000": [38, 40, 49], "1441": 51, "144199": [47, 60], "144686": 40, "14471": [33, 34, 56], "144729": 47, "144730": 47, "144731": 47, "144732": 47, "144733": [47, 60], "144750": 32, "14485": 38, "145": [47, 60], "1452": 41, "145425": 38, "145454": [47, 60], "145455": [47, 60], "145456": [47, 60], "145457": [47, 60], "145458": [47, 60], "145459": [47, 60], "145460": [47, 60], "1457": [33, 34, 48, 56], "14579": 41, "1458": [33, 34, 56], "145833": 44, "146": [29, 39, 49], "1460": [38, 48], "1465": [33, 34, 56], "146656": [47, 60], "1467": 41, "146767": [37, 40], "146809": 37, "146830": 37, "14690": 34, "147": [40, 49], "147166": [39, 40], "14716638": 40, "147641": 38, "1477": 51, "147737": 46, "147893": 33, "147898": 37, "148": [32, 36, 40, 52], "14813": 47, "148141": 39, "148343": 38, "148349": 48, "14841": 37, "149": 48, "14970": 33, "149788": 40, "149822": [33, 34], "14999": 33, "15": [8, 10, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 47, 48, 51, 53, 54, 58, 60], "150": [32, 36, 38, 46, 49], "150000": [37, 44], "150115": 36, "15026771": 38, "150395": 32, "1504": 32, "1505": 33, "150mb": 37, "150p": 29, "151357": 41, "1514": 50, "152": 47, "1520": 36, "152401": 37, "152859": 37, "1530": 29, "1534": 33, "15377": [33, 41], "1540": 29, "154076": [37, 40], "154105": 41, "15429": 47, "154386": [33, 34], "1545": 41, "154795": [38, 40, 49], "154842": 48, "155": [29, 36], "15500": 38, "155178e": 38, "15559528e": 40, "155624": 38, "156": [33, 36, 37], "1562": 36, "156311e": 38, "1564": 36, "15661": 47, "157": [29, 36, 46], "157008": 38, "157157": 51, "157234": 41, "15725": [33, 41], "15775": 47, "1578": 40, "15795": [37, 40], "158": 36, "1580": 29, "1582": 40, "158867": [47, 60], "158982": 38, "159": 36, "1590": [32, 36], "15915": 47, "15992": 40, "16": [10, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 47, 48, 50, 51, 53, 54, 60], "160": [31, 32, 35, 36, 38, 40], "160000": [38, 40, 49], "160258": 31, "160282": 41, "1604": 32, "160506": 37, "160634": 46, "16063983": 34, "160640": 34, "160727": 40, "160729": [47, 60], "161": 33, "1610243052583638": 35, "16111330565237164": 35, "1613": 33, "16153": 47, "16157": 47, "16160": 47, "161606": [33, 34], "161782": 37, "1619": 36, "161931": [38, 40, 49], "162": 29, "162000": 38, "162007": 51, "162214": 49, "162330": 37, "162667": [37, 40], "1627": 41, "162904": 48, "1631": 36, "163195": [33, 34], "163397": [33, 34], "1634": [33, 34, 36, 56], "16358": 47, "164": [41, 46], "1645": 35, "16460": 41, "164679": 37, "165": [35, 38], "1650": [32, 36], "16507": [35, 41], "16508": [35, 41], "16509": [35, 41], "16510": [35, 41], "16511": [35, 41], "16512": [35, 41], "165198e": 38, "1652": [31, 35], "16533": 47, "165485": 40, "165617": 47, "165811": 36, "16630": 41, "166631": [33, 34], "167": 31, "167214": 32, "167241": 51, "16736": 45, "167600": 41, "167620": 46, "168": 38, "1680": 30, "168151": 46, "168196": [33, 34], "168244": 40, "1687": 36, "169": [31, 35, 41], "1690": [29, 30], "169269e": 48, "169421": 36, "169693": 32, "169748": 35, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 25, 30, 32, 33, 34, 35, 36, 37, 38, 41, 47, 48, 53, 56, 60], "170": [33, 43], "170100": [33, 34, 56], "170277": [39, 40], "1704": 32, "17054987": 46, "170670": 38, "170931": 46, "171": [29, 46], "17144": 47, "171468": [38, 40, 49], "1715": 36, "171657": 31, "171899": 48, "1720": 33, "17205": 47, "172792": 37, "173": [32, 36], "173025": 36, "17393037": 8, "1739787032867638": 36, "173979": 36, "174": [29, 32, 36], "174590": 37, "174766": 41, "1750": [33, 50], "175000": [38, 40, 49], "17518": 47, "176": 33, "1766": 38, "176924": 48, "177": 41, "17730": [33, 41], "177709": 48, "178": [29, 38], "178494": 38, "17896": 47, "179": [39, 48], "179080": 37, "179123": 32, "179300": 33, "179730": 36, "17973005068132514": 36, "179802": 38, "18": [10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 44, 47, 48, 49, 51, 53, 56, 60], "180": [36, 38, 46], "1800": [29, 30, 32, 36], "18000": 47, "180000": 30, "180279e": 38, "180388": 32, "1804": 32, "180900": 41, "18096": 47, "181": 48, "18113": 47, "18116": 47, "1813": 36, "182": [47, 48], "18201414": 40, "18245": 47, "182639": 38, "182648": 38, "18311": 47, "18313": 47, "18317085": 8, "183179": 48, "183423": 32, "183471e": 38, "18365": 34, "18391": [33, 34], "184": [47, 48], "1840": 29, "184405": 40, "1847": 34, "185": 48, "185155": 40, "185175": 48, "18533": 47, "1854": 36, "185707": [32, 36], "18571": [33, 34], "18572": [33, 34], "18573": [33, 34], "18574": [33, 34], "18575": [33, 34], "18576": [33, 34], "1858": 41, "185868": 41, "185975": 40, "18597545": 40, "186024": 29, "186814": 37, "186899": 37, "187": [31, 35, 39], "1870": 36, "187000": 33, "1872": 38, "1875": 35, "187503": 47, "187663": 32, "187700": 33, "188": [29, 31, 35], "1880": 36, "1886": 35, "1887": [37, 40], "18955": 47, "189981": 38, "19": [8, 10, 29, 30, 31, 32, 34, 36, 37, 38, 41, 44, 48, 51, 53, 60], "190": [31, 38, 41], "19000e": 32, "1901": 29, "190319": 41, "19032": 47, "1904": 32, "190617": [33, 34], "191": [31, 33], "1911": 41, "191169": [38, 40], "191204": 41, "191250": 31, "191396": 32, "191700": 41, "1918": 34, "191k": 40, "1920": 29, "19213263": 34, "192133": 34, "19266": 47, "1927": 51, "1928": 51, "193": 46, "1930": 29, "193021": 37, "193122": 37, "193247": 41, "1933": 30, "193346": 40, "193427": 36, "19365": 47, "193704": [47, 60], "19380": 47, "1940": 34, "194002": 32, "194034": [47, 60], "194040": 33, "19422": 40, "1945": 38, "1946": [29, 38], "194710": 38, "19485": 33, "194985": 38, "195": 33, "1950": 38, "1951": 30, "195228": 34, "1953": [36, 38], "19536": 37, "1954": 45, "1955": 30, "195564": 41, "1957": 45, "1959": 29, "19591": 41, "1960": 30, "1963": 36, "196385": 40, "1965": 30, "196599": 38, "1966": 38, "196717": 46, "196739": 47, "1968": 29, "1970": [35, 38, 47], "1972": 38, "197649": 41, "1977": [29, 48], "19777": [39, 40], "19781": 47, "198": [46, 51], "198127": 38, "1984": 38, "1985": 38, "198629": 46, "198645": 48, "1987": [29, 30], "1989": 29, "198924": [33, 34], "199": [29, 32, 37], "1990": [32, 35, 36], "1991": [30, 39], "1992": [47, 51], "1993": 38, "199364": 37, "1994": 29, "199412": 48, "199413": [32, 36], "19966": [33, 34, 41], "1997": [35, 36], "199771": 40, "1_000_000_000": 36, "1d": 46, "1e": [36, 38, 57], "1e3": [36, 57], "1e4": 36, "1h": [33, 34, 41], "1st": [8, 37, 39, 40, 47, 58], "1stflrsf": [38, 40, 49], "1v": 52, "1v2": 52, "1v3": 52, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 39, 40, 41, 45, 46, 47, 50, 51, 52, 61], "20": [4, 8, 10, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 47, 51, 52, 53, 55, 56, 60, 61], "200": [29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 46, 49, 54, 55, 56, 57, 58], "2000": [32, 36, 37, 38, 39, 40, 41, 46, 50, 52, 57], "200000": [36, 47, 60], "200326e": 38, "2004": 38, "200475": 37, "2006": [38, 40, 49], "2007": [38, 40, 47, 49, 60], "2008": [38, 40, 47, 49, 60], "200876": 34, "20087625": 34, "2009": [38, 40, 47, 49], "200978": 32, "200k": 58, "201": [32, 61], "2010": [38, 40, 47], "20113": [33, 34, 56], "2012": [8, 33, 36], "2013": [45, 47, 60], "201332": 43, "2014": [29, 39, 47], "2015": [46, 47, 60], "20150630": [47, 60], "2016": [8, 46, 47], "20160101": 47, "2017": [40, 47, 60], "201810": 37, "201862": 41, "202": [32, 34], "2020": 51, "2022": 47, "2023": [10, 47], "2024": [0, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 56, 57, 58, 59, 60], "20248": 33, "2024w1": 46, "2025": [1, 49, 50], "2025_2026": 49, "2025s1": [0, 11, 49], "20274": 47, "202839": 37, "203": 32, "20310": 47, "20311": 41, "20319": 47, "203265": 40, "20334": 47, "203421": 38, "203500": 33, "20357847293371892": 35, "204": [30, 31, 32, 36, 54], "204167": 31, "2043": 48, "204302": [47, 60], "20433": 41, "204583": 31, "2046": 34, "204600": [32, 36], "204692": 38, "204734": 37, "20485": 47, "205": [30, 31, 32, 51, 54], "205000": [33, 34, 38, 40, 49, 56], "205059": 41, "20509": 47, "20514": 47, "205144": 41, "205323": [47, 60], "205479": 35, "205597": 38, "20564": 47, "206": [30, 31, 32, 36, 37, 50, 54], "206041": 40, "206073": 37, "206099": 36, "20620": 47, "206292": 33, "20639": 41, "2064": 33, "20640": [35, 41], "206724": 48, "20683258": 35, "20694": 47, "207": [30, 31, 32, 33, 36, 46, 54], "207039e": 38, "2071": 41, "207814e": 38, "20794": 47, "208": [30, 31, 32, 35, 36, 54], "209": [29, 30, 31, 32, 36, 54], "209221": 49, "209583": 31, "209746": 37, "209903": 41, "20analysi": 48, "20assumpt": 48, "20hazard": 48, "20intro": 48, "20learn": 46, "20lifelin": 48, "20with": 48, "21": [10, 29, 30, 32, 33, 34, 37, 38, 41, 42, 44, 47, 51, 60], "210": 36, "210001": 37, "210240": 36, "210272": 41, "210591": [33, 34], "210779": 47, "21086181023099526": 35, "211": 36, "2110": 33, "211250": 31, "211343": 41, "211544": 37, "211892": [33, 34], "212": [31, 36], "212385": 40, "212581": 41, "21274": 47, "212870": 38, "212975": 38, "213": [36, 46, 47], "2130": 29, "21353": 47, "21382972": 39, "21389": 47, "2139": [33, 34, 56], "214": [29, 34, 36], "21405": 47, "2144": 36, "214740": 33, "214769": 46, "214821": 47, "214852": 37, "215": 36, "215245": 38, "21530": 47, "215412": 38, "21549": 47, "21571": 47, "21581": 47, "215865": 40, "21596": 47, "216": 36, "21603": 47, "21605": 47, "216123": 48, "21613": 30, "21616484": 52, "21617": 47, "216346": 40, "21634631": 40, "216585": 33, "216596": [47, 60], "21668": 47, "21670": 47, "216718": 37, "216728": 33, "21694": 47, "21697": 47, "217": 50, "2170": 30, "217334": 34, "21733442": 34, "21767954": 40, "21768": [40, 47], "217680": [39, 40], "21774": 47, "218207": [33, 34], "21847": 47, "21872": [38, 40, 49], "218760": 40, "218830": 33, "219": 41, "2190": 33, "2192": 36, "219512": 41, "219700": 41, "219845e": 38, "22": [10, 32, 33, 34, 36, 37, 38, 39, 40, 41, 47, 48, 51, 52, 56, 60, 61], "220": 31, "22001": 40, "220392": 48, "22057": 47, "2206": 48, "22078": 47, "2210": 29, "22114": 47, "221329": 38, "221348": [47, 60], "2214": 51, "22154": 47, "221622": [33, 34], "22168237": 52, "221900": 30, "22219": 47, "22221894": 38, "222222": 33, "22225": 47, "222307": 33, "222500": 31, "22260": 47, "222647": [38, 40, 49], "2229": 35, "222963e": 38, "22305705": 39, "22320": 47, "223333": 31, "223460": 48, "223750": 31, "223804": 40, "224": [36, 46], "22452": 47, "2246468746": 31, "224662": 38, "22471154513694713": 35, "224865": [38, 40], "225": 46, "225301e": 38, "2254": 33, "22550": 47, "226": 36, "226415": 33, "226789": 48, "2268": 39, "22697768": 34, "226978": 34, "2270": 36, "227143": 33, "2272": [37, 50], "227304": 47, "22741": 41, "227559": [38, 40, 49], "227836": 37, "22788": 47, "22811601": 35, "22826": 47, "228329": 37, "2285": 47, "228603": 38, "228750": 31, "229": 46, "229000": 33, "22910": 47, "229102": 40, "2293467570951035": 39, "2295": 47, "229583": 31, "229718": 40, "22974": 45, "23": [10, 32, 33, 34, 35, 36, 37, 38, 41, 47, 48, 56, 60], "230": [32, 36], "2300": 29, "23011": 40, "2305": 40, "2307": [31, 35], "2309": 47, "23091772": 39, "2310": 47, "2311": 47, "2312": 47, "2313": 47, "23175": 47, "231815": 40, "232143": 34, "232751": 48, "23290": 47, "233": 30, "234": 48, "234040": 37, "234436": 48, "235": 41, "235096": [33, 34], "235152": 32, "235417": 31, "235706": 41, "236": [32, 36, 48], "236096": 46, "236174": 41, "236210": 42, "23621041": 42, "23640124": 35, "236456": 33, "23654": [37, 40], "236960": 36, "237": [37, 48], "237895": 37, "237935": 40, "238": [37, 48], "238192": [37, 40], "2389": 34, "239": 48, "23902": 47, "23941": 47, "239944e": 38, "24": [1, 11, 29, 32, 33, 37, 38, 39, 40, 41, 46, 47, 48, 60], "240": 48, "2401": 41, "240893": 41, "241": 48, "241489": 48, "241620": 37, "24182": 47, "242015": [39, 40], "242083": 31, "242169": 37, "242381": 47, "24295676": 34, "242957": 34, "242996": [33, 34], "243": 47, "243243": 38, "2435": 41, "2436": 41, "24395": [39, 40], "24397122221206388": 47, "244": 47, "244592": 32, "2447": 39, "244814": 48, "245": 47, "2451": 36, "245329": 38, "245521": 37, "245686": 37, "246": 47, "246332": 38, "246646": 36, "246646103936": 36, "246653": 36, "247": 47, "247119": 47, "247439": 42, "24743939": 42, "247690828913": 36, "247691": 36, "248": 47, "248328": 39, "248333": 31, "2484": 29, "248457": [38, 40, 49], "248609": 38, "248664": 41, "2488": 32, "248999": 48, "249": 51, "2496": [31, 35], "249601e": 38, "249618e": 38, "249720": 32, "24h": [37, 50], "25": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61], "2500": [8, 51], "250000": [33, 37, 38], "25031": 47, "25037": 47, "2506": [30, 31, 54], "250900": 38, "251093": 36, "251158e": 38, "2516": 39, "25176": 47, "251769": 46, "252": 50, "252042": 41, "25214": 47, "252160": 32, "252859": 40, "2530": 29, "2533": [31, 35], "253312": [33, 34], "253432": 40, "253724": 32, "253914": 38, "254380": 48, "254443": 37, "255": 33, "2551": 51, "255134": 46, "2556": 39, "255751": 41, "255889": [47, 60], "256": [29, 46], "25622": 47, "256263": [39, 40], "256333": 33, "256437": 41, "25658": 41, "256813": 32, "257": 30, "2570": [29, 30], "257024": 36, "257103": 37, "2574": 41, "2580": 29, "258225": 47, "25823": 37, "258387": 40, "258427": 32, "258886": 37, "259": [38, 41], "25904": 47, "2590575478171884": 35, "259286": 32, "259500": 33, "26": [8, 10, 29, 32, 33, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 60], "2600": [33, 34, 56], "260258": 41, "26048": 40, "260572": 38, "26063": 47, "260890": [38, 40, 49], "261035": 38, "261953": [47, 60], "262": [38, 40, 48, 49], "262079e": 38, "262156e": 38, "262269e": 38, "2623": 38, "262361": 41, "262500": 38, "263": 38, "2630": 33, "26307": 45, "263541": 48, "263600": 33, "26370005": 35, "263736": 48, "263742e": 38, "26376": 47, "264195": 48, "264283e": 38, "26447953": 34, "264480": 34, "265": 39, "265273": 35, "266120": [47, 60], "266135": [33, 34], "2670": 36, "267612e": 38, "268": 36, "2683": 37, "26831": 47, "2691": [30, 31, 54], "26919": 41, "269689": 37, "269880": 32, "269972": [38, 40, 49], "27": [8, 32, 34, 36, 37, 38, 47, 48, 60], "270093": 36, "270093376167": 36, "27021": 47, "270270": 44, "27048": 37, "2705": 36, "271037": 41, "271287": 47, "271500": 41, "271738e": 38, "2720": 30, "27206": 47, "27263": 40, "272667": [33, 34], "2730": 33, "273382": [33, 34], "273606": [33, 34], "273890": 46, "273962": 41, "274": [33, 34, 47, 56], "274404": 33, "275008": [47, 60], "27502379069": 38, "275290": 37, "275352": 32, "275410": 35, "2759": 40, "276": 33, "27638": 47, "27652": 37, "276687": 38, "27676": [37, 50], "27678": [37, 50], "276943e": 38, "27697": [37, 50], "2770": 36, "27705": [37, 50], "27715": [37, 50], "277381": 32, "2777": 48, "278441": [47, 60], "278634": 37, "27874871715903093": 35, "278755": 34, "27875502": 34, "2788": [31, 35], "2794": 35, "28": [10, 32, 33, 34, 35, 36, 37, 38, 41, 42, 47, 48, 60], "280": [33, 41, 51], "2800": 8, "280028": 41, "280310": [33, 34], "2806": 36, "280618": 37, "2807": 48, "280801": 48, "281": 33, "28122025543": 38, "281583": 38, "2817": 40, "2820": 36, "282021e": 38, "2822": 40, "282600": 48, "283119e": 38, "28327": 47, "283421": 38, "2836": 40, "28362": 47, "283857": 32, "283921": 33, "284": [41, 47], "2845": 48, "2846": 51, "2847": 51, "285": [33, 34, 47, 56], "285263": 40, "28526302": 40, "285467": [38, 40, 49], "28571429": 30, "286": [31, 32, 36, 47], "286000": 36, "286200": 41, "286416": 34, "2865025": 52, "286821": 32, "287": 47, "287031": [47, 60], "287079e": 38, "287344": [33, 34], "287500": 41, "288": 47, "288002": [47, 60], "288462": 35, "28854": 47, "28868": 37, "289": 47, "2890": [32, 36], "28953": 47, "289541": [38, 40, 49], "289799": 32, "29": [8, 32, 33, 37, 38, 47, 48, 51, 60], "290": 47, "290002": 37, "290424": 38, "29045704": 38, "290961e": 38, "291": [35, 47], "291667": 44, "292": 47, "292587": 48, "293": 47, "29324459": 46, "293663": 37, "294": [33, 45], "294251": 34, "2948": [33, 34, 56], "294855": 40, "2953863599856862": 35, "295397": 37, "29545": 38, "296": [33, 51], "296601": 41, "29691": 47, "297": 35, "29802": [37, 40], "298561": 48, "298612": [47, 60], "29881": 47, "298813": 37, "299": 46, "299164": 41, "2d": 46, "2d454e5fd9a5": 48, "2e": 10, "2f": [31, 36, 44, 47], "2nd": 35, "2ndflrsf": [38, 40, 49], "2v": 52, "2v3": 52, "3": [7, 8, 10, 11, 14, 16, 17, 18, 32, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 61], "30": [4, 10, 29, 31, 32, 35, 37, 38, 39, 40, 41, 47, 48, 49, 51, 60, 61], "300": [32, 43, 45, 49, 52], "3000": 46, "300000": [33, 34, 47, 60], "300464": 41, "300837": 37, "301": 48, "3010": 41, "301200": 36, "3014": 41, "30146": 47, "301563": 38, "30167": 47, "301784": 48, "301838": 49, "3019": [30, 31, 35, 54], "301952": 41, "302": [38, 40, 49], "302131": 38, "30279": 47, "302801": 48, "302844": 48, "303": [38, 40, 49], "303000": 33, "303004": 41, "303030": 35, "303109": 34, "303790": 36, "3038": 51, "3038344082": 40, "303916": 32, "304": 32, "3040": 47, "3041": 47, "3042": 47, "3043": 47, "3044": 47, "304784": 38, "305": 29, "30504657": 42, "305047": 42, "30530902": 32, "305346": 32, "305674": 41, "3057": [31, 35], "30573": 41, "306": 51, "306500": 32, "306564": 46, "307": 33, "3075": 51, "307516": 46, "307521": 35, "308120": 33, "30815": 38, "308216": 46, "308220": 37, "308448": 32, "3089": 36, "309": 41, "3092": [30, 31, 54], "309249": 46, "309859": 35, "31": [10, 29, 32, 33, 34, 35, 37, 38, 39, 40, 42, 47, 48, 51, 56, 60], "310": 61, "310000": 33, "31000e": 32, "310284": 40, "310405": 37, "311": 33, "3110": 33, "311151": 48, "31127015": 40, "311310": 29, "311769": 41, "31196406381465247": 35, "3120": 33, "3125": 33, "312500": 44, "312501": [38, 40, 49], "312696": 51, "3129": 51, "31297381": 34, "312974": 34, "31298589e": 46, "313": [34, 38], "3130": 51, "31384": 37, "314": 33, "3140": 33, "314000": 36, "31449687e": 40, "31454": 41, "314582": 40, "314840": 41, "314929": [47, 60], "315134": [47, 60], "315630": 37, "316164": 41, "316230": 41, "316363": 32, "316395e": 38, "316426": 41, "316552": 34, "31655231": 34, "316798": 41, "317": [33, 40, 50], "317277": 41, "317761": 37, "318": [33, 50], "3180": 36, "3180174485124284": 33, "318937": [33, 34], "319": [30, 33, 50], "31908384": 46, "319630": 48, "31984311": 38, "31st": 47, "32": [8, 32, 33, 34, 35, 36, 38, 42, 47, 48, 56, 60], "320": [33, 50], "320155": 37, "320430": 38, "32064171": 39, "321": [40, 50], "32127053": 38, "322": [41, 50], "32240": [39, 40], "32247597e": 40, "322755": 32, "323045": [33, 34], "32323": 29, "32397724e": 40, "324": 50, "3245": 29, "3252": 41, "325319": 41, "32561": 37, "326": [33, 41], "326730": 37, "326741e": 48, "326933": [32, 36], "327188": 37, "3272": 48, "327283": 38, "32734": 41, "3274": 48, "327408": 37, "328": 41, "328077e": 38, "328799": 37, "328953": 32, "3298721": 46, "3299": 51, "33": [8, 29, 32, 33, 34, 35, 36, 37, 38, 41, 47, 48, 60], "330": [9, 10, 11, 29, 30, 46, 47, 49, 51, 61], "33000e": 32, "330346": 48, "3310": 33, "332125": 37, "332130": 38, "332671": 40, "3327": 47, "332710": 38, "332746": 48, "332791": 48, "332824": 38, "3330": 33, "33308783": 34, "333088": 34, "333139": 37, "333333": [30, 33, 36, 44], "3333333333333333": [44, 46], "333340": 32, "3334": 51, "334": 41, "334411": 32, "334576": 38, "335": 39, "335309": 38, "3355": [33, 34, 56], "3356700488_183566145b": 46, "33590": 47, "336389": 40, "33641142": 40, "3364114233677307": 40, "336411423367732": 40, "336735": 36, "336826": 34, "33682642": 34, "33683087": 35, "336831": 35, "337034": 41, "33726089": 38, "338": [32, 36], "33888659": 8, "339": 37, "339368": 48, "339889": 48, "34": [29, 32, 33, 34, 35, 37, 38, 41, 47, 48, 56], "340": [3, 10, 30, 39, 41, 46, 47, 48], "34000e": 32, "340988": 37, "341109": 38, "341300": 41, "341571": 48, "34161762": [38, 40], "341712": [47, 60], "34182": 40, "3420": 33, "342200": 41, "342605e": 38, "3436": [47, 60], "3437": 51, "3438": 51, "344": 33, "3442": 48, "34426571": 38, "34441": 38, "345": 40, "345136": 32, "345386e": 38, "3454": [48, 51], "3455": 51, "345831": 29, "346": [33, 34, 56], "346850": 37, "34691": 47, "347523": 36, "348": [33, 41], "34806": 38, "348569": 49, "34900": 38, "35": [32, 33, 35, 37, 38, 39, 40, 47, 48, 51, 55, 59, 60], "350": 29, "3500": 55, "350000": 33, "351351": 44, "351366": 37, "3515": 48, "3517": 51, "351821": 48, "351883": 49, "3520": 48, "3521": 29, "352100": 41, "352930": [33, 34], "353": 46, "35375221": 52, "353961": 36, "354114": [38, 40, 49], "354604": 37, "3547": 41, "354759e": 38, "356689": [39, 40], "35671794": 40, "357": 33, "357500": [33, 34], "3576": 29, "3577": 51, "357823": 29, "358": [29, 36], "358032": 40, "3582": [48, 51], "358264": [38, 40, 49], "3583": 51, "358333": 32, "358500": 41, "358913": 34, "3589134": 34, "359": [32, 36], "3590": 36, "359784": 36, "359887": 42, "359992": 32, "35p": 29, "36": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 60], "360": 34, "360172": 37, "360918": [47, 60], "361": 48, "361718": 37, "362": [48, 51], "362009": 47, "362185e": 38, "362553": 41, "36269995": 34, "362700": 34, "363": 48, "363192": 32, "363913": 37, "364": [47, 48], "364352": 35, "365": 47, "36525": 40, "365420": 51, "365603": 35, "365623": 32, "366": [34, 47, 48], "366005": 37, "3663": 48, "366626": 32, "367": 47, "367329e": 48, "367423": 36, "368": [47, 51], "3681": 40, "368304": 35, "3684": 48, "368922": 43, "369": 38, "369875": 32, "369896": 46, "37": [33, 34, 35, 38, 41, 47, 48, 51, 56, 60], "37050406": 8, "370643": 37, "371": [41, 47, 60], "3717": 40, "371722": 40, "372": 33, "372706": [47, 60], "372763": [38, 40, 49], "373031": 32, "373275": [47, 60], "373656": 47, "374": 33, "374584": 46, "37546": 40, "376": [33, 38], "376089": 38, "37647072": 39, "3768": 51, "3769": 51, "377032": 38, "377619": 36, "377619120792": 36, "37797291": 34, "377973": 34, "378159": 38, "378764": 32, "378971e": 38, "37906": 37, "379416e": 38, "379875e": 38, "38": [8, 32, 33, 35, 37, 38, 41, 47, 48, 60], "3803": 48, "380436": 34, "38043616": 34, "380495": 32, "380504": [33, 34], "380643": 32, "381190": 41, "3814": 34, "381416e": 48, "381428": [38, 40, 49], "381676": 32, "38192364": 42, "381924": 42, "382558": 37, "383": [33, 41], "384111": 51, "384127": 32, "384613e": 36, "3851": 37, "3856": 32, "385639": 42, "386": 36, "386071e": 38, "386530": [40, 49], "387": 36, "388023": 37, "388169": 41, "38853": 38, "3889": 34, "389": [36, 41], "389065": 40, "389349": 41, "389736": [33, 34], "39": [32, 36, 37, 38, 42, 47, 59, 60], "390428669205": 36, "390429": 36, "390725": 38, "39095422e": 40, "391": 33, "3912": 48, "39163": 37, "391996": 46, "392": [29, 48], "392082": 40, "392221": 35, "392385": 48, "392612": 38, "392893": [32, 36], "393": [30, 34], "3932": 48, "39375": 47, "394113e": 38, "394920": 33, "395282e": 38, "395686e": 38, "395688": 48, "395697e": 38, "396": [33, 48], "396266": 46, "396752e": 38, "396991": [33, 34], "397": 48, "398": 41, "398495": [47, 60], "39896994": 34, "398970": 34, "399": 33, "3990": [30, 31, 54], "3991": 38, "39931": 40, "399827": 37, "3blue1brown": 46, "3d": [41, 46], "3f": [30, 31, 32, 33, 37, 38, 44, 45, 51], "3h": 47, "3m": 46, "3rd": 45, "3ssnporch": [38, 40, 49], "3v": 52, "4": [0, 1, 8, 9, 10, 14, 16, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 61], "40": [8, 29, 32, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 49, 55, 60, 61], "400": [30, 33, 36, 49, 57], "40000": [46, 47, 60], "400000": [36, 47, 60], "400047": 48, "400157": 41, "400164": 46, "400649628005": 36, "400650": 36, "401": [32, 36], "401102": 47, "401541": 37, "401623": 38, "401830": 40, "401895": 36, "402": 29, "402808": 40, "404": [32, 41], "405": 39, "405227e": 38, "405415": 32, "405650": 38, "406": 46, "406202": 36, "40689": 41, "407": 37, "407234": 46, "40725012": 46, "407510": 37, "40756124": 39, "407862": 48, "4084": 48, "40_000": 46, "40b5a809b05a": 48, "41": [32, 33, 37, 38, 40, 41, 42, 44, 47, 48, 60], "410": 33, "410240": [37, 40], "410599": 41, "411412": 38, "41150573": 38, "412": [29, 32, 36], "412500": 41, "413050": 46, "413718": 48, "413796": 38, "413958": 37, "414": 51, "4143": 48, "4151": 39, "4153": 41, "4158382658": 33, "416": 40, "4165": 39, "4169": 48, "418031": 32, "418069": 36, "41901484361": 36, "419015": 36, "419355": 35, "4195": 40, "4197": [30, 31, 35, 54], "419973": 37, "42": [29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 52, 54, 55, 58, 59], "420": 36, "420000": 29, "4203": 45, "42060": 41, "421": 46, "42104086": 40, "421215": 42, "42121526": 42, "421875": 35, "422": 38, "4234": 40, "4236": 40, "4238": 37, "423852": 37, "424222": 38, "424337e": 38, "425": 39, "425365": 48, "42541681": 52, "425419": 38, "426067": 33, "426410": 32, "427": 48, "4276": 50, "428": 48, "429": [38, 40, 49], "429217": 37, "429634": 48, "43": [32, 35, 36, 37, 38, 47, 48], "430": [36, 38, 40, 48, 49], "430323": 33, "430571": 37, "430704": 42, "4307043": 42, "430868": 35, "431": [31, 48], "4310": [32, 33, 36], "431137": 35, "4314": 37, "432": 48, "433": 48, "433514": [47, 60], "433814": 48, "434": [32, 35, 36, 48], "43445": 41, "435": 48, "435186": 32, "435489": 37, "435792": 36, "436": 48, "436492": 38, "43697758253484614": 35, "437": 51, "4372": 42, "437367": [33, 34], "4375": [41, 44], "437500": 44, "437684": 47, "438": 44, "438231": 46, "438275": 34, "43827545": 34, "43833466": 38, "438592": [40, 49], "438906": 40, "439": 33, "4390": [32, 36], "439209": 37, "439360": 33, "439779": 37, "44": [31, 32, 33, 35, 37, 38, 41, 45, 47, 48, 51, 60], "440": [36, 47], "441": 38, "441404": 46, "441445": 41, "442377e": 38, "442806": 32, "4430": 48, "44311": 41, "4432": 41, "443317": 32, "443419": [38, 40, 49], "444297": 41, "444444": 33, "4448": 41, "445": 36, "445111e": 38, "445124e": 38, "44586935": 39, "44586935141902073": 39, "446216": 41, "446284e": 38, "446869": 41, "447": [33, 40], "447461": [47, 60], "447517": 40, "4482": 29, "4484": 32, "448757": 48, "449": 51, "449666": 32, "44966612": 32, "45": [8, 30, 31, 32, 35, 37, 38, 45, 47, 48, 50, 54, 60, 61], "450000": 44, "450132": [47, 60], "450739": 38, "450822": 41, "451888": 37, "452600": 41, "453367": 41, "4537": 48, "454427": [33, 34], "454677": 42, "45467725": 42, "454788": [40, 49], "454966": 37, "455": 34, "4552": 40, "45555535": 40, "45587": [47, 60], "45588": [47, 60], "45589": [47, 60], "45590": [47, 60], "45591": [47, 60], "456": 46, "456419": 41, "45653693": 34, "456537": 34, "456904786": 51, "457435": [47, 60], "45756": 51, "458": 33, "458333": 44, "458524": 48, "459": 38, "4591": 33, "459214e": 38, "459873": 48, "45a": [47, 60], "45am": [47, 60], "46": [8, 30, 31, 32, 33, 34, 35, 37, 38, 47, 48, 49, 51, 54, 56, 60], "460047": 48, "46019608e": 40, "46021": 51, "46075": 51, "4608": [30, 31, 54], "460950": 42, "461": [33, 36], "462060": 48, "462545": 40, "462963": 35, "46299": 51, "463": 37, "463582": 39, "464104e": 38, "465279e": 38, "46530779": 34, "465308": 34, "466246": 46, "4664": 29, "46729488": 38, "467379": 40, "467628": 41, "468": [32, 36, 40], "468232": [47, 60], "4687": 41, "46880": 51, "469": [33, 37], "469383": 37, "4695": 37, "469571": 41, "47": [10, 29, 30, 31, 32, 33, 35, 36, 38, 41], "470": [33, 51], "4700": 36, "470060": 38, "470666": 38, "471032": 40, "472": 51, "47232": 45, "47242662": 52, "4726": 48, "472603": 38, "472790": 37, "473691": 32, "474": 37, "474552": 32, "47491": 37, "475099": 40, "476": 30, "4760": 36, "47606": 41, "476092": [38, 40, 49], "476406": 40, "476412": 42, "47641249": 42, "477": 36, "477291": 41, "47799": 51, "478060": [47, 60], "479109": 32, "479132": 41, "48": [30, 31, 32, 35, 37, 38, 44, 47, 48, 54, 60], "480": 38, "4800": 29, "480249": 32, "48073598": 42, "4809": 36, "481": 33, "4810": 50, "4813": [31, 35], "481514": 38, "481793": 33, "481893": 37, "481960": 37, "4822": 48, "483751": 32, "48390": 51, "48407": 51, "484937": 35, "485": 46, "48535": 51, "4854": 40, "486": 40, "4861": [33, 34, 56], "486266": 33, "487": 33, "48721": 51, "4879": 51, "488": 33, "488753": [47, 60], "489130": 35, "49": [32, 35, 37, 38, 41, 47, 48, 59, 60], "490": [41, 52], "490000": 33, "490033": 38, "490568": 36, "491217": 37, "491366": [40, 49], "491379": [33, 41], "492": [33, 37], "492270": 34, "493": [30, 31, 33], "493544": 33, "493921": 34, "494": [32, 33, 36], "4943": 36, "49575": 37, "496": 41, "496213": 38, "496757": 40, "497386": 32, "497787": 38, "498": [37, 50], "498133e": 38, "498562": 32, "499900": 33, "4f": [32, 34, 37, 45], "4m": 46, "4th": [37, 39, 40, 58], "4x": 61, "5": [4, 10, 29, 35, 36, 38, 39, 43, 44, 47, 50, 51, 52, 53, 54, 61], "50": [10, 29, 32, 33, 34, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 57, 58, 60, 61], "500": [29, 33, 37, 39, 40, 41, 58], "5000": [29, 30, 50], "50000": [47, 60], "500000": [33, 34, 37, 38, 43, 47, 51, 60], "500000e": 36, "500001": 33, "5002": 38, "500625": 32, "50062e": 32, "500924": [33, 34], "501": [33, 51], "501071": 46, "501250": 32, "501304e": 38, "501875": 32, "5024752475247525": 36, "502500": 32, "502985": 37, "503000": 33, "503090": 37, "503125": 32, "503750": 32, "504": [32, 41], "504231": 48, "504375": 32, "504429": 34, "504644": 36, "50475372e": 40, "504fde4fcf8": 48, "505335": 37, "505592e": 38, "505625": 32, "5057": 38, "50596432e": 52, "506023": 39, "506035e": 38, "506079e": 38, "506084e": 38, "506211": [33, 36], "506410": 35, "506875": 32, "507130": 36, "507359": [33, 36], "507500": 32, "50774": 36, "507740": 33, "50775": 36, "507750": 36, "507752": [33, 36], "507995": 35, "508": [33, 38], "508125": 32, "508133": [33, 36], "508371": 36, "50884": 41, "50899": 36, "509000": 29, "509001": 38, "509317": [33, 36], "509930": [47, 60], "50k": [37, 39, 40, 58], "51": [32, 33, 34, 36, 37, 38, 40, 42, 47, 48, 49, 56, 60], "510000": [30, 32, 36], "5106": 51, "510836": 36, "5109": 40, "511": 9, "5112": 30, "51137414e": 40, "51143": 41, "51150": 37, "511620e": 38, "5118": 40, "512": 46, "5120": 29, "512000": [32, 36], "51226051": 42, "512319": 33, "512408": [38, 40, 49], "512897": 32, "512x640": 46, "513": 33, "513678": 48, "514155": [33, 34, 38], "514598e": 38, "5146": 35, "515000": 32, "51503393": 34, "515034": 34, "515351e": 38, "5156": [33, 41], "515848": 41, "516394": 41, "517346": 37, "519029": 37, "52": [32, 33, 35, 37, 38, 41, 47, 48, 51, 60], "52061": 47, "5208": 30, "520857": 37, "5209": 38, "5212": 38, "521284e": 38, "521567e": 38, "521578e": 38, "521743e": 38, "522": 38, "522563e": 38, "5238095238095238": 30, "52398": 41, "524": [30, 44], "524364": 48, "5253": 40, "525554": 41, "525757": 32, "526078": [33, 34], "526214": 40, "526596": 41, "526602": 38, "5274": 48, "527500": 33, "528": 38, "5282": 48, "528403": 32, "52881619": 32, "529210": 37, "529388e": 38, "5294": 39, "529412": 33, "53": [35, 38, 47], "530052": 36, "530978": 37, "531": 49, "531116e": 38, "531353": 46, "5315": 36, "532034": 38, "533454": 46, "533498": 32, "534": 51, "534114": 36, "534342": 41, "535": [33, 41], "535014": 33, "53520104": 32, "535604": 33, "535622": 41, "536362": 42, "53636249": 42, "537267": 33, "538000": 30, "538702": 32, "538816": 37, "5390": [37, 40], "5391": [33, 41], "539116": [47, 60], "539376": 48, "539459": 51, "54": [38, 47, 48, 59, 60], "540": 47, "540000": 33, "540359": 41, "541117": 38, "541488": 41, "54152": 37, "541667": 34, "541795": 37, "542": 49, "54240": 37, "542624": 40, "542873": [33, 34], "543297": 36, "543351": 40, "544": 36, "544462": 40, "545": [38, 51], "546": 33, "5461": 38, "546473": 35, "546610": 32, "54676006e": 40, "547": [36, 38, 40], "547993": 37, "548831": 40, "549": 51, "549682": 37, "5498": 32, "55": [30, 31, 32, 35, 37, 38, 39, 40, 47, 48, 49, 54], "55000": 36, "550000": [33, 34, 36], "550004": 39, "550616": 37, "55101": 47, "5513": 36, "5514": [39, 40], "5515": 48, "551579e": 38, "551862e": 38, "551975": 38, "552": [33, 38], "552721": 39, "553965": 40, "553979": 37, "5540": 48, "5541306485809793": 39, "55413065": 39, "554180": [47, 60], "554621": 41, "5551": 35, "555740": 32, "5566": [33, 34, 56], "557197": 46, "557242": 37, "557739": 38, "558": [38, 40, 41, 49], "558564": 37, "55862988e": 40, "55873324": 46, "5588": 29, "558824": 37, "558889": 38, "559": [36, 38, 40, 49], "56": [32, 34, 37, 38, 47, 48, 59, 60], "560225": 33, "560768": 38, "561": [10, 32, 36, 40, 41], "561467": [33, 34], "561602": 40, "561645e": 38, "562112": 33, "563": 10, "5630224174651539": 35, "563314": [38, 40, 49], "563467": 33, "5644": 38, "564483": 41, "56499": 45, "565": 41, "5650": 30, "565062": 48, "56521734": 8, "565679": 37, "565746": 48, "565888": 33, "566": 33, "566092": 33, "566222": 46, "5667": 37, "567724": 46, "567856e": 38, "568": 46, "568009": 32, "56804591": 38, "568663": 38, "5690201394302518": 40, "56902014": 40, "569375": 32, "5694": 41, "57": [32, 33, 34, 37, 38, 40, 47, 48, 49, 56, 60], "57000": 48, "570015": 38, "570449": 37, "570473": 41, "5707": 48, "570739": 41, "571": [42, 52], "571500": 41, "571901e": 38, "571969": 41, "572": 10, "572105": 32, "572549": 33, "572962": 48, "573": 52, "573050": 37, "573129": [38, 40, 49], "5732": [37, 50], "573542": 41, "573818": 37, "57415": [47, 60], "574260": 41, "575000": 44, "57510": 41, "575907": 41, "576": 33, "57640869": 34, "576409": 34, "578523": 35, "578654": 37, "5789": 38, "579091": 41, "579432": 35, "579559e": 38, "579660": 39, "5798": 39, "57994": 37, "58": [30, 31, 32, 35, 38, 47, 48, 54], "580": 46, "580539e": 38, "581": 40, "58137177": 34, "581372": 34, "5814": 29, "581687": 41, "581787": 48, "582": [29, 39], "582090": 37, "582469": 38, "58387198": 42, "583872": 42, "584": 33, "584615": [33, 41], "585": 33, "585513": 35, "5857": 48, "586095": [33, 34], "587773": 37, "588": [32, 36], "588125": 32, "588235": 35, "588307": 33, "589286": 51, "59": [1, 32, 38, 47, 48], "59049": 37, "59050": 37, "590618": 41, "59082668": 34, "590827": 34, "5915": 34, "592": 51, "592401": 29, "59243876": 39, "59300": 41, "5931": 38, "593370": 38, "593508": 42, "5938": 33, "594": 33, "594595": 32, "594982": 37, "594995": 37, "5950": 33, "595427": 46, "595569e": 38, "596088e": 38, "596151": 41, "596810": 32, "596864": 38, "5970": 39, "59700": 37, "597015": 35, "59708": 37, "597326": 37, "597555": 29, "597924": [38, 40, 49], "598": 33, "59810": 37, "598100": 35, "598149": [38, 40, 49], "598750": 32, "599": 51, "599492": 35, "599860": 32, "599894": [47, 60], "5fin": 38, "5th": [37, 39, 40, 58], "5unf": 38, "6": [8, 10, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 61], "60": [8, 29, 33, 37, 38, 40, 41, 42, 44, 45, 47, 48, 49], "600": [33, 35, 45], "60000": [47, 60], "600000": [31, 32, 36, 47, 60], "600193": 37, "60023631": 38, "600k": 38, "601": 36, "601042": 29, "601504": 35, "601712": 37, "601790": 35, "602": [33, 34, 56], "602000": 33, "602649": 32, "6028": 37, "602941": 37, "602954": 39, "60319915": 52, "603684e": 36, "603970": 48, "604": 32, "6040": [32, 36], "604000": 30, "604032": 37, "60429913": 38, "604320": 35, "60455": [47, 60], "604619": 35, "604797": 35, "6048": 47, "604807": 48, "60495488": 32, "605060": 37, "6051": [33, 34, 56], "605100": 35, "605101": 35, "605102": 35, "605263": 32, "605625": 32, "605696": 35, "606": 33, "606061": 35, "606557": 35, "606567": 35, "606811": 36, "606875": 32, "606902": 35, "607062": [47, 60], "608050": 35, "608125": 32, "6082": 33, "608468": 35, "608532": 46, "608565": 48, "60860": 33, "609": 33, "6092": 29, "609375": 32, "60943": 37, "60k": 38, "61": [32, 34, 35, 37, 38, 42, 47, 48], "61029914": 38, "610407": 37, "610931": 43, "611": 34, "611007": 46, "611178": [47, 60], "612349": 34, "61234944": 34, "6124": 48, "612546": 37, "612621": 35, "612755": 32, "613507": 35, "613738": 36, "613738418384": 36, "614": 33, "61420598": 34, "614206": 34, "614567": 41, "615": 33, "6154": 41, "615730": 39, "616": 36, "616099": 36, "6168": 30, "617342": 48, "617431": 43, "6176": 37, "617647": 37, "618": 33, "618012": 36, "619": 51, "61912405": 40, "62": [32, 36, 37, 38, 47, 48, 60], "622255": 33, "622454": 36, "622500": 32, "6226": 41, "622612": 37, "622709": 35, "623000": 33, "62320": 47, "62352928": 39, "624049": 38, "6241": 29, "624375": 32, "624450e": 38, "624615": 38, "6250": 33, "625387": 36, "6257": 48, "626206": 38, "62657": 47, "626875": 32, "62688064": 40, "627": 48, "6273": 36, "6275": [30, 31, 54], "627722": 40, "627966": 33, "628032": 41, "628139": 37, "62873917": 40, "629792e": 38, "63": [32, 36, 37, 38, 47, 48, 51, 60], "6303": [33, 34, 56], "6306": [33, 41], "631899": 48, "632": 51, "6320": 35, "6322": 41, "632353": 37, "632786": [47, 60], "63316788": 52, "63358": 45, "63362": 38, "634397": 35, "634490": 34, "634686": 37, "635": 33, "635200": 41, "635239": [33, 34], "635648": 35, "636": [29, 33, 34, 48, 56], "636364": 51, "636410": 39, "636849e": 38, "637": 46, "637982": 32, "638169": 40, "6389": [33, 41], "6391518364256": 48, "6392": 41, "639754": 38, "64": [11, 32, 35, 38, 46, 47, 48], "640": [36, 46, 51], "6400": 33, "640000": [37, 51], "640266": [33, 34], "640x480": 32, "641216": 47, "641538": 48, "641873": 38, "642676": 47, "642965": 37, "643": 36, "6431": 41, "643311e": 38, "644106": 37, "64417243": 46, "64454": 37, "644770": 43, "645519": 37, "6458": [30, 31, 54], "645963": 36, "646050": 40, "6464": 48, "646617": 49, "647796": 41, "648": [32, 33, 36], "6480": 39, "648195": 37, "648550": 46, "649658": 40, "64994": [47, 60], "65": [30, 34, 38, 48], "650": 37, "65000": 36, "650000": 36, "65000e": 32, "65013704": 42, "65125032": 52, "6513": 40, "651446": 47, "65243": 38, "652487": 41, "6526853": 38, "652828": 36, "652986": 41, "653": 33, "653205": 36, "653205232272": 36, "654": 33, "65424895": 38, "656297e": 38, "656349": 32, "656827": 37, "657675": 41, "658047": 35, "658645": 35, "659056": 38, "66": [30, 31, 33, 35, 37, 38, 46, 47, 54, 60], "660171": 32, "6604": [33, 34, 56], "660714": 34, "66214339": 32, "66221": 47, "662450": 37, "662541e": 38, "662745": 33, "662879": 39, "66368": 40, "663680": [38, 40, 49], "6637": 48, "6638": 48, "663822": 40, "6639": 48, "6641": 48, "6642": 48, "664207": 37, "6643": 48, "6644": 48, "6645": 48, "664707": 35, "66473": [47, 60], "665": 33, "665351e": 38, "665625": 32, "665882": 39, "666": [33, 34], "666166": [47, 60], "6666666666666666": 46, "666667": [31, 33, 44], "666754": 46, "667450": 47, "668787": 32, "6688": 29, "669614": 37, "669725": 37, "669805e": 38, "67": [30, 31, 34, 35, 37, 38, 47, 48], "670344": 32, "67186503136": 38, "673277": 36, "6744": 40, "674490": 36, "674721": 39, "675000": 29, "67501": 47, "67512181": 38, "67562658": 34, "675627": 34, "675676": 44, "675814": 32, "676": 49, "676250": 32, "676373": 37, "67672595": 38, "677": 33, "6772": 48, "677268": 48, "677579": 32, "677601": 36, "677629": 32, "678": [32, 36], "678689": 35, "679478": 33, "679877": [38, 40, 49], "68": [30, 31, 32, 34, 37, 38, 40, 42, 43, 47, 48, 52, 60], "680000": 29, "680657": 33, "681223": 32, "683015": 39, "683171": 37, "68323": 36, "68339": [47, 60], "684211": 32, "684447": 33, "684960": [33, 34], "685103e": 38, "68523": 47, "685786": 39, "6858": 35, "686": 33, "686348e": 38, "687": 38, "687055": 37, "687307": 36, "687500": 31, "688": 36, "6880359361853475": 35, "688135": 36, "689338": [38, 40, 49], "69": [30, 31, 32, 34, 38, 42, 47, 48, 60], "690": 51, "69027185e": 40, "690402": 36, "690778": 40, "691241": 37, "691640": 32, "691877": 36, "691924": 42, "69192445": 42, "692308": 33, "693": 33, "693498": 36, "693590": 34, "6938": [29, 47], "693890": 47, "693898": 47, "693936": 34, "69393613": 34, "69411": 41, "694155": 32, "694334": 39, "6950": 40, "695532": 33, "696034e": 38, "6962": 33, "6963": 40, "696373": 33, "696429": 37, "696712": 47, "696859": 36, "696875": 32, "696970": 35, "69698010e": 40, "697": [33, 41], "697248": 37, "6973": 33, "698": 33, "698167": [47, 60], "698206": 38, "698384608345687": 36, "698385": 36, "6984": 41, "698857": 36, "699224": 32, "699706": 46, "699901396097971": 43, "6th": [37, 39, 40, 58], "6x6": 57, "7": [10, 11, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 61], "70": [30, 31, 34, 37, 38, 42, 43, 47, 48, 49, 60], "70000": [47, 60], "700000": [47, 60], "700855": 37, "701128": [47, 60], "701173": 36, "701186e": 38, "70162085e": 40, "7017": 48, "701863": 36, "702703": 32, "703406": 48, "704": [32, 33, 38], "704099": 34, "7042": 48, "7043": 48, "7046136400143138": 35, "70472": 41, "704969": 36, "705000": 33, "705511": 36, "70560276": 34, "705603": 34, "70568": 38, "705696": 32, "705882": [31, 36], "70588235": 31, "705898": 41, "706": 34, "706128": 32, "706444": 37, "706783": 34, "70678332": 34, "706966": 47, "707681": 32, "707712": 48, "707899": 42, "70789903": 42, "70799": 36, "708": [33, 34, 36, 39, 56], "708075": 36, "708527": 33, "708978": 36, "709185": 32, "70978": 41, "709874": 36, "709880": 36, "709893": 47, "7099": 41, "71": [29, 30, 31, 34, 35, 37, 38, 42, 47, 48, 60], "710000": 33, "710031": 40, "710526": 32, "710896": 37, "71096": 41, "711": [34, 36], "711077": 33, "711086": 36, "711717": 36, "711754": [33, 34], "711852": 41, "71199006": 38, "712": 33, "712074": 36, "71219761": 34, "712198": 34, "712324": 36, "712402": 39, "7129": 36, "713": 34, "71327467": 38, "714": 46, "714077": [33, 34], "714286": 36, "714402": 37, "715072": 46, "71517": 36, "7153": 48, "715424": 36, "715728": 37, "715992": 46, "716157": 37, "716655": 36, "716657": 36, "716792": 37, "716985": 32, "717289": 36, "717391": 36, "717829": 33, "718242": 36, "718266": 36, "718524": 47, "71866979": 38, "718750": 32, "7188": 34, "719": [29, 33, 41], "719056": 39, "719427e": 38, "719500": 32, "719747": 37, "72": [30, 31, 32, 37, 38, 47, 48, 54, 57], "720357": [47, 60], "72036": 47, "720497": 36, "720859": 33, "720893": 48, "720904": 47, "7210": 30, "721006": 36, "721008": 36, "7212512828409691": 35, "721616": 36, "721705": 33, "7218": [30, 31, 54], "721818": 41, "721921": 33, "722": 33, "722241": 36, "722249": 36, "723": 33, "72338": 45, "72345029": 38, "723602": 36, "723613": 32, "7242": 30, "724458": 36, "724539": [47, 60], "724891": 37, "725": [35, 36], "7250894": 52, "726": [33, 37, 41], "726412": [33, 34], "726474": 46, "726573": 36, "726583": 36, "726634": 37, "7266666666666667": 52, "726788": 38, "727014": 47, "727198": 36, "727273": 32, "727554": 36, "7277854625841886": 48, "727821": 36, "7278214718381631": 36, "727829": 36, "728": [33, 37], "728235": [33, 34], "7283": 37, "728324": 37, "728777": 32, "729": 36, "729109": 51, "729143": 37, "7292": 41, "729814": 36, "73": [30, 31, 34, 35, 36, 37, 38, 43, 47, 48], "730383": 37, "731498": 48, "7315": 35, "7315558717766282": 36, "731572": 35, "731583": 32, "7328": 33, "732919": 36, "733102": [33, 34], "733333": [31, 33, 34], "733746": 36, "734": [36, 38, 48], "734011": 36, "734385": 37, "734816": 47, "735": 38, "735043": 37, "735261": 36, "7352614272253524": 36, "735879": 36, "736285": 37, "736498": 36, "736900": 33, "7379": 30, "738": [33, 38], "738564": 47, "738701": [33, 34], "738715": 48, "738839": 35, "738977": 36, "739": 51, "739264": [33, 41], "7395977155164125": 36, "739598": 36, "739938": 36, "74": [30, 31, 33, 34, 35, 36, 37, 38, 43, 56], "740542": 29, "740844": 36, "741": 48, "741037": [47, 60], "741250": 32, "741463": 36, "7418": 40, "741935": 51, "742084": 36, "742088": 36, "742703": 36, "742981": 37, "743": [32, 33, 36, 48, 51], "743133": 32, "743135": 37, "743321": 36, "743323": 36, "743324": 36, "743391": 32, "743555": 40, "7436": [30, 31, 54], "743917": [33, 34], "7440": 29, "744201": 37, "744565": 36, "745": 39, "745178": 36, "746114": 39, "746328": 32, "747": 29, "74720920774": 38, "74798624e": 40, "748510": 37, "748725": 48, "748749e": 36, "748797": 35, "749118": 40, "75": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 47, 48, 49, 56, 60], "750": 29, "7500": 38, "750000": 38, "7503": 30, "7504": 51, "751": 51, "7524": 47, "753286": [33, 34], "754": 33, "754165": 51, "754386": 37, "754874": 41, "755": 48, "755000": 38, "7551": 36, "755364": 32, "755418": 36, "755477": 32, "756": 48, "7562": 29, "75625": [47, 60], "757": 37, "7574257425742574": 36, "75745416": 42, "757545": 38, "757591": 47, "757932": 48, "757985": [39, 40], "758": [39, 40, 48], "758062e": 38, "75826": [39, 40], "758514": 36, "7588186": 46, "759561": 42, "75956122": 42, "7599": 35, "76": [31, 33, 35, 36, 37, 38, 40, 41, 48], "760": 48, "760262": 36, "760678": 47, "76161": 36, "761945e": 38, "762": [31, 48], "7620": 29, "762093e": 38, "76270194": 40, "763": 33, "7639": 30, "764052": 41, "76470588": 31, "764706": [31, 32, 36], "765": 37, "765591": 37, "765601": 38, "766317e": 38, "766423": 38, "766430": 32, "767": [38, 40, 49], "767742": 35, "767802": 36, "767819": 47, "767852": 32, "768": [33, 34, 38, 40, 49, 56], "768176": 48, "768279": 49, "768512": 37, "76908228": 39, "769231": 33, "77": [30, 31, 34, 35, 37, 38, 43, 47, 48, 53, 59], "770": 30, "7706532429048965": 39, "770833": 44, "770898": 36, "771": 33, "771969": 32, "772532": 37, "773017": [38, 40, 49], "7736": 36, "773851": 47, "774261": 47, "774844": 34, "77484447": 34, "7750553478074826": 47, "775270": 38, "7752884548630529": 35, "775311": 40, "77536150e": 40, "7758": 36, "776": 36, "7763": [33, 41], "776427": 48, "77694295": 39, "77709": 36, "777934": 32, "778": 51, "7781845435415525": 47, "779": [33, 41], "779271": 41, "78": [29, 30, 31, 33, 34, 37, 38, 41, 42, 47, 48, 53], "7800": 36, "780000": 39, "780296": 38, "780298": 38, "780316": 38, "780497": 38, "78058051e": 40, "780864": 37, "781": 33, "781004": 32, "781531": 37, "7816": 38, "782183": 38, "782219": 32, "7827": 37, "783282": 36, "783582": 32, "783784": 44, "783789": 32, "784424": 35, "784573": 41, "785": 34, "785105": 38, "785108": 38, "785134": 38, "785399": 38, "785483": [47, 60], "785714": 33, "786115": 41, "78617028": 39, "786555": 38, "787": 33, "787574": 38, "787879": [32, 35], "787933": 38, "788": 31, "788374": 46, "7887": 40, "7891381897690047": 35, "789436": 33, "789657": [47, 60], "79": [30, 31, 33, 34, 35, 37, 38, 47, 48, 54], "790": 37, "790000": 33, "79041": 38, "790721": 49, "790731": 35, "791017": 48, "791467": 33, "792": 52, "792023": [40, 49], "79250": 33, "792577": 38, "792603": 32, "792828": 38, "793": 41, "793243": 33, "79378": 37, "7938": 34, "794": 48, "794118": 32, "794236": 33, "794820": 33, "795": [32, 36], "79500e": 32, "7951": 36, "7951559890417761": 38, "795902": [47, 60], "796": 33, "7964215270662811": 35, "797": 33, "797355": [33, 34], "7978563117812038": 33, "798": 33, "7982": 32, "7986546": 38, "799983": 32, "79998417": 52, "7f688092391a": 46, "7pm": 41, "7th": [37, 39, 40, 58], "8": [9, 10, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 55, 60], "80": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 47, 48, 49, 53, 60], "800": [29, 31, 36, 45, 57], "800000": [36, 47, 60], "8001": 35, "800190": 32, "80062924": 32, "800k": 49, "801219e": 38, "801666": 37, "801863": 32, "802502": 41, "802902": 38, "802987": 32, "803": [32, 33, 51], "803617": 37, "804": [32, 48, 51], "804818": [33, 34], "80482065": 34, "804821": 34, "805198": 38, "805342": 47, "805970": [32, 35], "806": 34, "8062": 30, "806899": 46, "8076": 38, "807684": 32, "807735": 37, "8078": 29, "808": 48, "8080": 30, "808208": 37, "808958": 32, "809": 33, "8098": 48, "81": [30, 31, 32, 34, 35, 36, 37, 38, 40, 42, 47, 48, 49, 60], "810073": [38, 40], "810098": 41, "810368": 32, "81071706": 36, "810811": 44, "8112": 29, "812272": 38, "812363": 38, "812500": 31, "812593": 46, "812875": 48, "813": 33, "813586": 37, "815669": 37, "8162831858407079": 50, "816717791411044": 48, "817": 39, "817034": 51, "817558": [33, 34], "8180": 33, "818041": 48, "818868": 33, "819152": 32, "819213": 48, "8195": 35, "819549": 32, "819584": 32, "81970188": 34, "819702": 34, "82": [30, 34, 36, 37, 43, 47, 48, 60], "820": 32, "820033": 38, "820143": 35, "82025568e": 40, "820564": 38, "821040": 40, "821807": 38, "8219": 33, "8221": 34, "8225": 51, "82273995": 34, "822740": 34, "823511": 37, "823529": [31, 32, 35], "82352941": 31, "823543": 41, "824849": 37, "824884": 38, "825": 33, "825123": 41, "8253": 32, "825306": 36, "825470": 48, "825697": 38, "826142": 38, "826203": 35, "826216": 38, "826513": [47, 60], "826553": 38, "82670": [47, 60], "826739": 38, "826758": 38, "826760": 38, "827039": 35, "827068": 35, "827130": 37, "827261": 38, "827842": 35, "827907": 36, "8280229354283182": 38, "82804": 36, "828332": [38, 40, 49], "828358": 32, "828405": 47, "828682": 36, "828891": 36, "828976": 36, "83": [30, 31, 34, 36, 37, 43, 44, 45, 47, 48, 53, 60], "830382": 37, "830712e": 38, "831135": 32, "831611": [38, 40], "831989": 36, "832": 33, "832320": 35, "832370": 37, "832866": 38, "833": [32, 36], "83320": 47, "8334": 40, "8340": 32, "834109": 36, "834356e": 38, "83437": 38, "834455": 32, "8356": 40, "835651": 36, "835749": [38, 40], "83603": [38, 40], "8361313": 38, "836189": 32, "836735": 37, "836878e": 38, "836880e": 38, "837022e": 38, "837838": 32, "837848": 32, "838": [32, 36], "83848729e": 46, "83876": 36, "8388866943476283": 35, "838951": 38, "8389756947416362": 35, "839225": 38, "84": [30, 31, 34, 47, 48, 51, 52, 53], "840": 33, "84002795": 34, "840028": 34, "840074": 31, "840183": 38, "840492": [38, 40, 49], "84062193": 40, "841": 38, "841208": 36, "841886": 36, "841983": 36, "842": 33, "842028": 37, "842064": 48, "842105": 32, "843": 39, "843281": 40, "843284": [32, 35], "843842": [33, 34], "843992": [38, 40], "844409": 34, "84440919": 34, "844921": 42, "845": 36, "846154": [33, 51], "8462": 41, "846260e": 38, "846650": 38, "84679073": 32, "84698489": 46, "847178": 37, "847287": 36, "8475": 47, "84772": 37, "847799": 36, "847808": 37, "8478316682480326": 47, "848": [39, 40], "8481": 51, "84893192": 36, "849": [39, 40], "849102e": 38, "849438e": 38, "849612": 36, "85": [30, 31, 34, 37, 38, 39, 40, 41, 47, 48, 53, 60], "850": [29, 39, 40], "8502": 36, "850283": [47, 60], "850503": 36, "850746": 32, "851460": 38, "851852": 35, "852": [48, 51], "852053": 36, "852104": 38, "852941": 35, "853125": 32, "853399": 37, "854129": 38, "854167": 44, "854500": 48, "8546143543902771": 48, "854744525547446": 48, "854749": 47, "85545875": 32, "85597188": 34, "855972": 34, "856": 36, "856175": 33, "856589": 36, "857": 38, "857874": 36, "858": 35, "8580": [33, 34, 56], "858209": [32, 35], "858915": 36, "859": 39, "859318": 38, "859439": 42, "85943906": 42, "859455": 48, "85969": 36, "859799": 36, "86": [30, 32, 34, 35, 36, 37, 41, 47, 48], "860": [37, 40], "86000e": 32, "8601643854446082": 38, "860677": 37, "861": 33, "86102": [47, 60], "861157": 49, "861348": 36, "862432": 38, "862552": 33, "8625888648969532": 48, "86267067": 34, "862671": 34, "862997": 41, "863014": 35, "863889": 47, "863941": 38, "864": 39, "86400": [47, 60], "8641864337292489": 48, "864205": 40, "865562": 48, "8661": 51, "866110": 35, "866667": [31, 37], "866980": 38, "867434": 46, "867558": 41, "868003": 38, "868281": 38, "868305": 38, "868308": 38, "869077": 34, "86907725": 34, "869094": 36, "8691": 34, "869531": 32, "869964": 36, "87": [30, 33, 34, 37, 47, 48], "870": [39, 40], "870503": 46, "871": [36, 39], "871094": 47, "8711": 37, "872": [39, 40], "872093": 36, "872603": 46, "872722908439952": 40, "8727229084399575": 40, "872961060": 38, "8729610607986": 38, "873": 39, "8731": [38, 40, 49], "873103": 32, "873182": 47, "873356": 32, "873643": 36, "873704": 38, "874062": 34, "87406235": 34, "874305": 47, "874516": 36, "874532": 38, "874767e": 38, "875": 37, "8750": [33, 41], "875000": 31, "876065": 36, "876540": 48, "876574": [33, 34], "877046": 41, "877390": 40, "877519": 36, "877551": 37, "878183": 32, "87844893": 38, "87849316": 35, "879": 33, "87907": 36, "879938": 36, "88": [30, 31, 33, 34, 35, 37, 41, 48, 51, 56], "880": 41, "880348": 36, "880831": [47, 60], "881395": 36, "881720": 37, "883138": 36, "884586": 36, "885": [29, 34], "885044": [38, 40, 49], "885968": 48, "886047": 36, "886759": 35, "887": 39, "887017": 37, "887159": [47, 60], "8873": 37, "887324": 37, "887343": 32, "887597": 36, "887701": 37, "8878117": 34, "887812": 34, "888": [36, 39, 40], "888066": 40, "888372": 36, "888513": 37, "888811": 36, "888889": [33, 35], "888961": 40, "889086": 38, "889147": 36, "889429": 47, "889921": 47, "89": [30, 31, 34, 37, 43, 47, 48, 53, 60], "890": 39, "890457": 38, "890933": 48, "891001": 37, "891557": 36, "892476": 37, "892477": 32, "892491": 33, "89270": 41, "892733": 47, "892961": 41, "893000": 33, "893260": 34, "8937442459553657": 40, "894": 33, "894587": 49, "895": 39, "895349": 36, "895541": 38, "89572": [47, 60], "895833": 37, "895963": 35, "897010": [33, 34], "89706451e": 40, "897674": 36, "898": 40, "898016": 36, "898703e": 38, "899": [33, 34, 36, 39, 56], "8994": 40, "8997": 38, "899969": [47, 60], "8m": 46, "8th": [37, 39, 40, 58], "9": [4, 10, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 60, 61], "90": [8, 29, 30, 31, 32, 34, 37, 38, 43, 44, 47, 48, 53], "900": [34, 36, 37], "90000": [47, 60], "900000": [31, 47, 60], "900662": 31, "901085": 35, "9010852321946792": 35, "901262": 47, "90159483": 42, "901595": 42, "902401": 36, "903101": 36, "904": [32, 36], "90403853": 34, "904039": 34, "904226": 32, "9047619047619048": 30, "904902": 46, "905": [32, 33], "905327": 47, "906667": 31, "90669": 41, "906865": 31, "907": 48, "907143": 51, "907595": 47, "908": 33, "908140": [33, 34], "908215": 38, "909091": 33, "90982": 41, "91": [30, 31, 33, 34, 36, 37, 41, 42, 47, 53, 60], "910": 30, "9100": 47, "910018": 38, "910174": 38, "9103": 47, "910456e": 38, "91063776": 40, "910714": 51, "910843": 38, "911615": 38, "911846": 38, "912": 33, "912395": 40, "913333": 31, "913767": 38, "913849": 38, "914003": 40, "914451894267": 38, "914585": 40, "91515735": 38, "915714e": 38, "915952": 38, "916254": 32, "916722": 40, "917526": 37, "917837": 37, "918": 39, "918124": 37, "918191": 46, "9182": 47, "919198": 40, "9196": 29, "92": [30, 31, 34, 37, 43, 46, 47, 48, 53], "920000": 31, "9203": 36, "920305": 41, "920462": 40, "92120500e": 52, "921422": 48, "921438": 38, "921850": 38, "92195464": 40, "921955": 40, "922": 34, "923077": 37, "923283": [33, 34], "923432": 40, "924485": 41, "9245": [31, 35], "925272e": 38, "925288e": 38, "925593": 32, "925768": 37, "926657": 38, "926733e": 38, "926829": 37, "928": 36, "92809": 41, "92852376": 32, "929": 36, "9295": 36, "93": [30, 31, 34, 35, 36, 42, 47, 48, 53], "930000": 33, "930123": 32, "930561": 32, "931439e": 38, "931786": 35, "932": 33, "932070": 48, "932124": 32, "932143": 51, "93279": 47, "9336": 33, "934205": 32, "934269": [33, 34], "934783": 37, "9351": 41, "935512": 48, "935802": 32, "93665": [47, 60], "937429": 49, "9375": 31, "937500": [31, 34], "93788": 45, "938": 37, "9383": [32, 35], "93869659": 34, "938697": 34, "939006": 37, "9391": 38, "939394": [32, 35], "94": [30, 31, 33, 34, 35, 36, 37, 38, 47, 53, 56], "9401": 47, "9406": [30, 31, 54], "941": 48, "941176": [31, 34], "94117647": 31, "943609": 41, "944": 29, "944092": 37, "944354": 34, "946783": 32, "947": [33, 36, 51], "9471": 36, "948482": 48, "94888": 37, "949": 33, "9490": 33, "9492": 38, "94933723": 38, "94959681": 34, "949597": 34, "95": [30, 31, 34, 37, 43, 47, 48, 49], "950000": 33, "950088": 41, "9505": 40, "950564": 41, "9506": 40, "950696": 48, "950733": 32, "951294": 38, "951574": 41, "951644": 41, "951669": 41, "951696": 32, "953": 39, "9530973451327434": 50, "95511263": 32, "955113": 32, "9558": 47, "956": 33, "956966": 41, "957075": 41, "9573": 47, "9576": 29, "957886": 46, "957919": 32, "957987": 32, "9583333333333334": 46, "958393": [33, 41], "95886206e": 46, "959": 33, "959139": 40, "959402e": 38, "959870": 37, "959873": 48, "96": [30, 34, 35, 36, 37, 41, 47], "960": 35, "961106": 37, "961109802000133": 43, "961404": [33, 34], "961498": [38, 40, 49], "961771": 35, "961898": 35, "962776": 37, "96319": 47, "96320": 47, "96321": 47, "96322": 47, "96323": 47, "96325": 47, "963689": 41, "96554": 41, "9661": 38, "966131": [33, 34], "9664": [30, 31, 54], "966491": 37, "967102": 37, "967907": 37, "968": 33, "968233": 41, "96834506": 32, "968493": 48, "968514e": 38, "96875": 46, "969048e": 38, "9691": 38, "9692602666681306": 35, "96965253": 40, "969653": 40, "97": [30, 31, 34, 35, 36, 40, 43, 47, 48], "970518": 37, "970683": 41, "971": 34, "97203586": 34, "972036": 34, "97217": 47, "972198": 36, "97223953": 34, "972240": 34, "972440": 37, "97253": 47, "9730": 34, "973225": 37, "973280": 34, "97328024": 34, "973482e": 36, "973750": 32, "974": 33, "974480": 41, "9748": 35, "974801e": 38, "975895": 47, "976": [33, 37, 39], "977": [33, 47, 60], "977278": 41, "9773": [30, 31, 32, 54], "978": 35, "9781449369880": 47, "9781789957211": 46, "97823755": 35, "978738": 41, "979": [39, 40], "979562": 48, "98": [30, 33, 34, 35, 38, 40, 42, 45, 47, 48, 49], "980": [47, 60], "98007": 29, "98028": 30, "98045": 29, "98052": 29, "98055": 29, "980634": 48, "98072": 29, "98074": 30, "98075": 29, "9808": 35, "98107": 29, "98112": 29, "98116": 29, "981195": 47, "98125": 30, "98136": 30, "981735": 35, "98178": 30, "982": 34, "982184": 36, "982570": 48, "983": 46, "9837": [31, 35], "984": 36, "984653": 35, "984664": 38, "985283": 36, "9854": [30, 31, 35, 54], "985457": 48, "985816": 31, "986047": 36, "9862": 51, "986207": 36, "987": [36, 46], "987062": 38, "987597": 36, "9876": [39, 40], "987681": 41, "988": 41, "9881": [30, 31, 54], "988381": 36, "988841": 36, "988901": 38, "989": 30, "989147": 36, "989156": 36, "989443": 48, "989922": 36, "989973": 35, "99": [30, 31, 33, 34, 36, 37, 47, 58, 60], "990631": [47, 60], "990754": 47, "9912": [32, 35], "9915": [47, 60], "991966": 48, "992": [31, 36], "992254": 36, "99240562": 40, "992406": 36, "9926": 34, "992857": 31, "992908": 31, "993023": 36, "993029": 36, "993065": 48, "9931": [30, 31, 54], "9934531067299874": 35, "993666": 40, "993969": [38, 40, 49], "994": 29, "994266": 36, "994574": 36, "994764": 47, "995": [41, 46], "9950": 41, "9951": [30, 31, 54], "99515": 47, "995434": 38, "996588e": 38, "996765": 40, "996788": 48, "996820": 48, "996899": 36, "99744241e": 40, "9977957422135844": 40, "998": [37, 48, 51], "9983": 37, "998302": 37, "99845": 36, "998451": 36, "999": [35, 51], "99907": 36, "999122": 37, "999147": 37, "999172": 37, "999183": 37, "999185": 37, "999192": 37, "999210": 37, "999214": 37, "999221": 37, "999223": 37, "999225": 36, "999254": 37, "999298": 37, "999317": 37, "99931882": 38, "999335": 37, "999535": 36, "999577": 47, "999622": 33, "9am": 41, "9th": [37, 39, 40, 58], "A": [0, 8, 9, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 52, 53, 60, 61], "AND": [0, 38], "AS": 0, "And": [29, 30, 36, 38, 45, 47, 48, 49, 54, 55], "As": [4, 31, 34, 36, 38, 39, 40, 44, 47, 48, 49, 50, 52, 55, 57, 59, 61], "At": [4, 29, 31, 35, 37, 39, 41, 42, 46, 47], "BE": [0, 45], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 32, 40, 49, 50, 53, 55], "Being": 46, "But": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 55, 57, 59, 60, 61], "By": [29, 31, 32, 34, 37, 39, 42, 45, 46, 48, 49, 55, 57, 61], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58, 59, 60, 61], "IN": [0, 31, 35], "IT": 35, "If": [4, 5, 6, 7, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61], "In": [6, 7, 8, 9, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61], "Ines": 51, "It": [2, 4, 7, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 57, 59, 61], "Its": 48, "NEAR": [33, 34, 41, 56], "NO": 0, "NOT": [0, 8, 34, 35], "No": [0, 29, 30, 38, 39, 40, 41, 43, 47, 48, 49, 50, 53, 60], "Not": [37, 38, 39, 40, 41, 42, 44, 47, 48, 58], "OF": 0, "OR": [0, 8, 38], "Of": [9, 34, 36], "On": [4, 7, 29, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 48, 49, 51], "One": [5, 8, 16, 30, 31, 34, 35, 36, 37, 40, 42, 43, 48, 53, 58, 60], "Or": [32, 34, 36, 49, 55], "Such": [6, 44, 47], "THE": [0, 31], "TO": [0, 45], "That": [30, 31, 33, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 58], "The": [0, 1, 2, 5, 7, 8, 10, 29, 30, 32, 33, 34, 37, 38, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61], "Their": 5, "Then": [30, 35, 39, 42, 47, 50, 58], "There": [2, 5, 8, 9, 10, 11, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 61], "These": [4, 11, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 44, 47, 49, 59, 61], "To": [8, 11, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 43, 45, 46, 47, 49, 50, 51, 55, 57, 59, 60, 61], "WITH": 0, "Will": [37, 48, 51, 53, 58], "With": [0, 29, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 46, 48, 52, 55, 61], "_": [39, 46, 48, 51], "__call__": 34, "__class__": [35, 47], "__finalize__": 48, "__getitem__": [31, 33], "__init__": 51, "__name__": [35, 47], "_arg": 51, "_array_api": 51, "_astype_nansaf": 48, "_c": 51, "_california_housing_dataset": 35, "_call_func_on_transform": 34, "_callback": 51, "_column_transform": 34, "_constructor_from_mgr": 48, "_context": 51, "_data": 36, "_distn_infrastructur": 36, "_encod": 34, "_get_default_devic": 51, "_get_sequential_output": 34, "_i": 46, "_logist": 52, "_mgr": 48, "_modified_open": 50, "_proba": 39, "_pseudo_sync_runn": 51, "_run": 51, "_run_cel": 51, "_run_cod": 51, "_run_module_as_main": 51, "_run_onc": 51, "_score": 34, "_scorer": 34, "_set_output": 34, "_temp": 51, "_time_fit_was_cal": 48, "_transform": 34, "_transform_on": 34, "_valid": 34, "ab": [35, 37, 38, 40], "abbrevi": 45, "abil": [29, 34, 36, 40, 45, 47, 55], "abl": [8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 55, 57, 61], "about": [2, 4, 7, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61], "abov": [0, 5, 8, 11, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 52, 55, 57, 60, 61], "absenc": [34, 40, 44], "absolut": [35, 37, 38, 40, 42, 51, 61], "abspath": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60], "academ": [7, 41, 50], "accept": [5, 8, 37, 38, 45, 50], "accept_spars": 34, "access": [10, 11, 31, 33, 36, 39, 42, 44, 45, 47, 49, 50, 57], "accessori": 47, "accident": [32, 33, 50], "accommod": 7, "accompani": [7, 29, 30], "accomplish": 50, "accord": [35, 37, 38, 41, 44, 48, 57, 58, 59, 61], "account": [7, 10, 31, 37, 41, 44, 48, 50, 53, 58], "accur": [29, 31, 39, 40, 41, 44, 48, 49, 53, 54], "accuraci": [30, 31, 32, 33, 36, 37, 39, 40, 41, 43, 46, 48, 49, 51, 53, 54, 58, 59, 61], "accuracy_scor": 37, "acdm": [37, 39, 40, 58], "acf": 47, "achiev": [8, 32, 37, 50, 57, 59, 60], "acinonyx": [29, 46], "acoust": [32, 33, 36, 57], "acquir": 61, "acquisit": 44, "across": [29, 30, 31, 33, 37, 40, 46, 61], "act": [35, 61], "action": [0, 29, 39, 40, 42, 44, 45, 48, 61], "activ": [4, 11, 29, 36, 51, 53, 61], "actor": [44, 45], "actual": [7, 29, 35, 37, 39, 40, 42, 44, 45, 47, 48, 49, 57, 59], "ad": [34, 35, 36, 37, 39, 40, 41, 43, 45, 46, 48, 51, 57, 60], "adapt": [0, 33, 34, 37, 39, 45, 47, 49, 51], "add": [7, 8, 11, 33, 34, 37, 38, 39, 40, 41, 43, 45, 47, 48, 51, 56, 58, 59, 60], "add_pip": 51, "addit": [0, 4, 38, 44, 49, 58, 61], "addition": [54, 55, 61], "address": [18, 43, 50, 58], "adelaid": [47, 60], "adio": 49, "adj": 51, "adject": 45, "adjust": [32, 36, 43, 47, 55], "adm": [37, 39, 40], "admin": 61, "administr": 1, "admit": 31, "adopt": [6, 44], "adp": [45, 51], "adult": [37, 39, 40, 58], "adult_df_larg": [39, 40], "adv": 45, "advanc": [34, 36, 42, 43, 44, 45, 46, 54, 61], "advantag": [33, 34, 35, 39, 43, 44, 45, 53, 61], "advic": 48, "advis": 29, "advisor": 61, "af": 40, "affect": [11, 32, 33, 35, 36, 37, 42, 47, 48, 50, 51, 55], "affix": 45, "aft": 50, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 37, 38, 40, 42, 43, 46, 47, 48, 49, 50, 51, 53, 59, 60, 61], "ag": [29, 35, 37, 38, 39, 40, 41, 44, 58, 59], "again": [11, 30, 31, 33, 43, 44, 45, 46, 48, 50, 55, 58, 59, 60], "against": [44, 47, 57], "agenc": 51, "agent": 10, "agglomerativeclust": 43, "aggress": 45, "agnost": 40, "ago": [46, 47], "agre": 55, "agreement": [48, 61], "ahead": [49, 58], "ai": [7, 9, 37, 41, 46, 58], "aight": 29, "aim": 53, "airplan": 49, "airport": [37, 50], "aka": [35, 48], "al": [39, 45], "alamine_aminotransferas": 29, "alan": 10, "alaska": 35, "album": 36, "albumin": 29, "albumin_and_globulin_ratio": 29, "alburi": [47, 60], "alexand": 49, "alexnet": 46, "algebra": [44, 45], "algorithm": [2, 15, 29, 31, 33, 34, 37, 38, 39, 40, 43, 45, 46, 49, 50, 54, 55, 56, 58, 61], "align": [8, 29, 30, 31], "align_kei": 48, "aliv": 50, "alkaline_phosphotas": 29, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 31, 32, 34, 36, 38, 39, 40, 41, 45, 46, 47, 48, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61], "all_cap": 51, "all_featur": [47, 60], "allei": [38, 40, 49], "allen": 51, "alley_grvl": 38, "alley_miss": 38, "alley_pav": 38, "alloc": [8, 45, 46], "allow": [5, 7, 11, 31, 33, 36, 37, 41, 45, 47, 48, 50, 54, 55, 57, 60, 61], "allpub": [38, 40, 49], "almost": [35, 36, 38, 41, 43, 44, 45, 58], "along": [7, 30, 34, 37, 46, 47, 49, 54], "alpha": [32, 33, 47, 55, 60], "alpha_": 38, "alphabet": 35, "alphago": [29, 42], "alq": [38, 40, 49], "alreadi": [4, 8, 11, 37, 38, 40, 42, 47, 48, 49, 51, 54, 57, 60, 61], "also": [2, 4, 5, 7, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "altar": 46, "altern": [8, 36, 42, 49, 57, 61], "although": [31, 39, 42, 44, 48], "alwai": [29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 51, 53, 54, 55, 57, 61], "am": [33, 42, 49, 51], "amatriain": 44, "amazon": [29, 42, 44, 51], "ambigu": 45, "amer": 37, "america": 34, "american": 42, "aml": 33, "among": [29, 30, 36, 37, 39, 40, 44, 59], "amongst": 51, "amount": [4, 29, 31, 35, 36, 37, 38, 40, 42, 46, 47, 48, 50, 57, 60], "amp": [39, 40], "amplifi": [37, 45, 58], "amuel": 33, "an": [0, 2, 4, 6, 7, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 56, 57, 59, 60, 61], "anaconda": [11, 40, 51], "analogi": [15, 43, 45, 49], "analysi": [2, 9, 10, 30, 37, 38, 42, 43, 45, 49, 58, 61], "analyt": 47, "analyz": [37, 41, 47, 48, 49, 60, 61], "anatinu": 46, "anca": 61, "ancestor": 41, "ancestr": 61, "ancuta": 61, "andrea": [9, 10], "andrew": [9, 10, 36, 41], "anemon": 46, "angel": [48, 51], "ani": [0, 11, 30, 31, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 61], "anim": [37, 46], "animal_fac": 46, "anneal": 41, "annot": [40, 42], "announc": 7, "annoyingli": 38, "annual": 51, "anomali": [37, 38, 42], "anonym": 47, "anoth": [8, 11, 30, 32, 35, 36, 37, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 53, 54, 56, 59, 60], "answer": [4, 6, 7, 29, 30, 31, 36, 39, 42, 44, 45, 47, 49, 52, 54, 55, 58, 59, 60, 61], "anteat": 46, "anti": 48, "anymor": [38, 42, 44, 55], "anyon": [49, 50], "anyth": [0, 31, 34, 37, 44, 45, 48, 50, 57], "anytim": 61, "anywher": 34, "ap": [53, 61], "ap_lr": 37, "ap_svc": 37, "apart": [32, 43], "apeendixa": 41, "api": [37, 45, 47, 53], "app": [30, 51, 53], "appeal": 45, "appear": [2, 7, 34, 39, 50, 55, 59, 61], "append": [4, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 54, 55, 56, 57, 58, 59], "appendix_b": 45, "appendixb": 46, "appli": [0, 2, 6, 9, 10, 29, 30, 31, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 61], "applic": [0, 5, 29, 34, 36, 37, 38, 40, 41, 45, 48, 50, 51, 53, 58, 61], "appreci": [42, 61], "approach": [10, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 53, 55, 60, 61], "appropri": [0, 4, 11, 30, 31, 34, 37, 38, 42, 43, 47, 48, 50, 53, 61], "approv": [37, 58, 61], "approx": [32, 40], "approxim": [30, 36, 41, 50], "april": 47, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 36, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "arang": [8, 31, 32, 35, 36, 37, 38, 55, 57], "arbitrari": [40, 42, 43, 47], "architectur": 46, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "area": [36, 38, 39, 41, 42, 49, 57], "aren": [7, 38, 41, 42, 46, 47, 51, 60], "arena": 41, "arg": [31, 34, 50, 51], "argh": 48, "argmin": [31, 32, 37, 42], "argsort": [40, 45], "argu": [42, 45, 57], "argument": [8, 30, 34, 36, 37, 38, 40, 49, 51, 53, 56], "arima": 47, "arima_model": 47, "aris": [0, 29, 45], "aristotl": 32, "arithmet": 8, "around": [7, 32, 34, 37, 38, 47, 48, 54], "aroundn": 29, "arr": 48, "arr1": 8, "arr2": 8, "arrai": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 57], "array_equ": 8, "arriv": 41, "art": 49, "arthur": 29, "articl": [10, 30, 31, 33, 37, 42, 44, 45, 46, 49], "articul": [49, 53], "artifici": [10, 45], "artist": [32, 33, 36, 57], "as_fram": [32, 55], "ascend": [8, 34, 35, 36, 38, 39, 40, 41, 47, 48, 53, 59], "ased": 43, "asi": 51, "asia": 34, "asid": [4, 31, 39, 55], "ask": [3, 7, 11, 29, 30, 31, 32, 34, 37, 41, 42, 44, 45, 48, 49, 51, 54, 61], "asleep": 35, "aspartate_aminotransferas": 29, "aspect": [35, 40, 41, 43, 44, 48, 49, 53], "assault": 61, "assert": [7, 34, 37, 39, 40, 58], "assess": [6, 10, 29, 30, 31, 33, 37, 40, 42, 49, 61], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 53, 54, 56, 58, 60], "assist": 29, "assoc": [37, 39, 40, 58], "associ": [0, 29, 31, 32, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 53, 59, 61], "assum": [29, 30, 34, 35, 37, 38, 43, 44, 45, 47, 49, 53, 58], "assumpt": 48, "asterisk": 36, "astyp": [8, 47, 48, 60], "astype_arrai": 48, "astype_array_saf": 48, "async_": 51, "async_help": 51, "asyncio": 51, "asyncio_loop": 51, "atabak": 61, "atratu": 46, "attack": 30, "attempt": [31, 57, 58], "attend": 61, "attent": [6, 45, 50], "attic": 38, "attract": 45, "attribut": [0, 1, 29, 30, 32, 33, 35, 36, 41, 42, 45, 46, 57, 59], "attrit": 48, "auc": [48, 50, 53, 58, 61], "audienc": [49, 50, 58, 61], "audio": [46, 61], "audit": [50, 61], "auditor": 61, "augment": 37, "august": 47, "australia": [47, 60], "authent": 42, "author": [0, 45, 61], "auto": [29, 36, 37, 41, 42, 49], "autocorrel": 47, "autom": [30, 38, 45, 49], "automat": [33, 34, 38, 41, 45, 47, 48, 49, 60], "autoregress": 35, "autumn": 47, "autumn_month": 47, "aux": 51, "av": [38, 40, 49], "avail": [0, 1, 7, 9, 10, 11, 31, 34, 36, 37, 38, 43, 44, 45, 46, 47, 48, 53, 58, 59, 60, 61], "avebedrm": 35, "aveoccup": 35, "averag": [31, 32, 34, 35, 36, 38, 40, 42, 43, 45, 48, 50, 51, 53, 55, 61], "average_precis": 37, "average_precision_scor": 37, "average_word_length": 51, "averaging_model": [39, 59], "averaging_model_ndt": 39, "averoom": 35, "avg": [37, 44, 47], "avg_sent_emb": 45, "avocado": 49, "avoid": [7, 8, 30, 33, 37, 38, 43, 47, 48, 49, 50, 52, 53, 55, 58, 61], "aw": 50, "awai": [4, 6, 30, 35, 42, 44, 46, 48, 49, 50, 53], "await": 51, "awar": [34, 48, 49, 61], "award": 61, "awesom": 9, "ax": [31, 32, 35, 37, 42, 43, 46, 48, 49, 55, 58], "axi": [7, 8, 29, 30, 31, 33, 34, 35, 40, 42, 43, 45, 46, 47, 49, 60], "axvlin": 42, "az": 51, "b": [8, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49], "b3": [33, 40], "babe": 29, "babi": [41, 45], "bachelor": [37, 39, 40, 58], "back": [8, 33, 36, 45, 53], "backdrop": 47, "background": [30, 49, 50, 61], "bad": [8, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 46, 47], "badgeryscreek": 47, "bag": [41, 45, 46, 53, 57], "bai": [33, 34, 41], "baidu": 31, "bal_scor": 37, "balanc": [6, 32, 39, 42, 44, 52, 58, 59], "ballarat": [47, 60], "balust": 46, "balustrad": 46, "bambi": 44, "banist": 46, "bank": [37, 40, 47, 48, 58], "bannist": 46, "bar": [37, 38, 40, 46, 47, 48, 49, 50, 60], "baranski": 51, "barbu": 61, "barri": 35, "base": [5, 8, 11, 15, 30, 31, 33, 34, 35, 36, 37, 38, 40, 42, 43, 45, 48, 49, 50, 51, 53, 54, 57, 58, 59, 61], "base_ev": 51, "base_scor": 39, "base_valu": 40, "baseblockmanag": 48, "baselin": [14, 48, 50, 53, 54, 56, 57, 60], "baseline_hazard_": 48, "bash": 5, "basi": [30, 32], "basic": [2, 8, 30, 36, 41, 44, 46, 48, 51, 59, 60], "batch": [45, 46], "batch_siz": 46, "batch_t": 46, "bath": 29, "bathroom": [29, 30, 35], "bayesian": 36, "bayesopt": 36, "beagl": [29, 46], "bear": 46, "beat": [39, 48], "beauti": [44, 45, 49], "becam": 46, "becaus": [7, 8, 10, 11, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 58, 60, 61], "becom": [4, 31, 32, 35, 36, 37, 40, 41, 42, 45], "bed": [37, 50], "bedroom": [29, 30, 35], "bedroomabvgr": [38, 40, 49], "bedrooms_per_household": [33, 34, 56], "beef": 45, "been": [4, 6, 10, 29, 30, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 61], "befor": [4, 10, 11, 29, 30, 31, 32, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 54, 55, 57, 58, 59, 60], "begin": [30, 35, 41, 44, 47, 48, 53], "beginn": 46, "behav": [36, 40], "behavior": [31, 33, 37, 44, 50], "behaviour": [34, 58, 59], "behind": [29, 35, 61], "being": [4, 29, 31, 33, 37, 38, 39, 40, 43, 45, 48, 49, 55, 61], "belief": 49, "believ": [36, 40, 47], "bell": 46, "belong": [30, 35, 43, 54], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61], "bench": 46, "benchmark": 46, "bendigo": [47, 60], "benefici": [34, 49], "benefit": [4, 32, 39, 43, 45, 49, 53], "bengio": 36, "ber": 45, "bergstra": 36, "berri": 45, "bertop": 45, "best": [2, 30, 31, 32, 36, 37, 38, 39, 40, 42, 43, 44, 48, 49, 50, 54, 55, 57, 59], "best_alpha": 38, "best_depth": 31, "best_estimator_": [36, 38], "best_n_neighbour": 32, "best_param": [36, 49], "best_paramet": 36, "best_params_": [36, 38, 49, 57], "best_scor": 36, "best_score_": [36, 38, 57], "best_svr": 49, "bestalpha_coeff": 38, "better": [6, 29, 30, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 53, 54, 55, 56, 57, 58, 59, 61], "between": [2, 8, 11, 29, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 55, 61], "bewar": 45, "beyond": [31, 36, 41, 49], "bia": [35, 37, 40, 48, 50, 53, 58], "bias": [37, 40, 45, 48, 58, 61], "bicycl": [30, 47], "big": [7, 32, 34, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 55], "bigalpha_coeff": 38, "bigger": [32, 34, 35, 38, 40, 43, 45, 46, 47], "biggest": [38, 41, 60], "bike": 47, "bill": 46, "billboard": 47, "billion": 38, "billionth": 47, "bin": [33, 36, 38, 41, 47, 48, 49, 51, 54], "binar": [30, 34], "binari": [30, 33, 34, 35, 46, 48, 49, 52, 53, 58], "binary_feat": 34, "binary_featur": [37, 39, 40, 58, 59], "binary_transform": [37, 39, 40, 58, 59], "bincount": [37, 39, 58], "bind": [32, 55], "binomi": 36, "biolog": 41, "biologi": 34, "bit": [11, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 48, 49, 57, 58, 60], "black": [32, 40, 42, 46, 47, 60], "bld": 51, "bldgtype": [38, 40, 49], "bldgtype_1fam": 38, "bldgtype_2fmcon": 38, "bldgtype_duplex": 38, "bldgtype_twnh": 38, "bldgtype_twnhs": 38, "blei": 45, "blend": 45, "blindli": [37, 38], "blob": 52, "block": [35, 48], "blog": [45, 47], "bloomberg": [9, 10], "blq": [38, 40, 49], "blue": [30, 32, 36, 37, 40, 41, 42, 47], "bmatrix": [41, 44], "board": 4, "boathous": 46, "bob_dylan": 45, "bodi": 51, "boggl": 39, "bold": 49, "bond": [37, 50], "bonu": 39, "book": [1, 9, 37, 38, 44, 45, 47, 49, 61], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "bool": [38, 47], "boom": 51, "boost": [19, 20, 45, 50, 53], "booster": 39, "bootstrap": [11, 49], "border": [30, 35, 43, 45, 52, 54], "bore": 35, "boston": 35, "both": [2, 6, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 61], "bother": 40, "bottom": 43, "bought": 44, "bound": [41, 48], "boundari": [31, 43, 45, 49, 50, 55], "bow_df": 34, "box": [9, 40, 53], "boxplot": 40, "boyc": 30, "br": 45, "bracket": 8, "brain": [41, 46], "branch": [30, 43, 45, 48], "brand": 49, "break": [37, 53, 55], "breakwat": 46, "breath": 53, "breathtak": 45, "breed": 53, "breiman": 39, "brief": [4, 35, 39], "briefli": [29, 37, 39, 41], "bring": [6, 40, 43, 50, 51, 53], "british": [1, 45], "british_columbia": 45, "broad": [32, 55], "broadcast": 45, "broader": [2, 39, 45], "broadli": [30, 32, 35, 37, 39, 42, 43, 45], "broken": 49, "brownle": 41, "browser": 11, "brush": 46, "bsmtcond": [38, 40, 49], "bsmtexposur": [38, 40, 49], "bsmtfinsf1": [38, 40, 49], "bsmtfinsf2": [38, 40, 49], "bsmtfintype1": [38, 40, 49], "bsmtfintype2": [38, 40, 49], "bsmtfullbath": [38, 40, 49], "bsmthalfbath": [38, 40, 49], "bsmtqual": [38, 40, 49], "bsmtunfsf": [38, 40, 49], "btw": 40, "bubbl": [44, 46], "bucket": [41, 51], "budget": [36, 44], "bug": [4, 8], "bui": [44, 50], "build": [0, 2, 11, 31, 33, 34, 39, 41, 42, 45, 47, 49, 52, 55, 60, 61], "built": [8, 29, 30, 31, 35, 36, 40, 47, 49, 50, 60], "builtin": 50, "bullshit": [10, 48], "bulwark": 46, "bunch": [8, 11, 30, 38, 39, 46, 48, 49, 50, 55], "bundl": [7, 11], "bureau": 35, "busi": [37, 42, 48, 51], "bustl": 47, "butterfli": 43, "buzz": 29, "bypass": 61, "c": [0, 5, 8, 9, 10, 11, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 55, 57, 61], "c1": 43, "c2": 43, "c_1": 42, "c_2": 42, "c_3": 42, "c_log": [32, 55], "c_widget": [32, 55], "ca": [5, 9, 51, 61], "ca_transform": 34, "cache_s": 49, "cal_hous": 35, "calcul": [7, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 51, 52, 53, 55, 58, 60], "calibr": 50, "california": [33, 41], "california_h": 41, "californian": 33, "call": [8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 59, 60], "callback": 39, "caller": 50, "calm": 53, "came": 47, "camera": 34, "campu": [41, 61], "can": [4, 6, 7, 10, 11, 29, 30, 32, 34, 35, 36, 37, 38, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "canada": [5, 31, 32, 34, 35, 45, 49, 51, 53], "canada_usa_c": [30, 31, 32, 35, 54], "canadian": 45, "canadien": 45, "canberra": [47, 60], "cancel": 61, "cancer": [29, 41], "candid": [36, 39, 45, 55], "cannot": [0, 8, 31, 32, 36, 37, 39, 40, 41, 43, 47, 48, 49, 51, 61], "canva": [1, 7, 10], "capabl": 9, "capit": [37, 39, 40, 58], "caption": [7, 46], "captiv": 45, "captur": [31, 33, 35, 39, 41, 43, 44, 45, 47, 48, 53, 61], "car": [29, 45, 46, 50], "card": [29, 30, 37, 48, 49, 58], "care": [5, 7, 31, 33, 36, 37, 38, 40, 41, 42, 47, 48, 53, 57, 59, 60], "carefulli": [1, 37, 38, 58, 61], "carpentri": 5, "carri": [30, 31, 32, 34, 36, 37, 38, 39, 42, 44, 45, 47, 50, 51, 55, 57, 60], "caruana": 40, "case": [6, 11, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 60, 61], "cash": 29, "cast": [36, 44, 51], "castl": 46, "cat": [29, 37, 39, 45, 46, 51, 53], "catamount": [29, 46], "catboost": [40, 49, 53, 61], "catboostclassifi": 39, "catboostregressor": 39, "catch": [37, 61], "categor": [30, 36, 37, 38, 39, 41, 42, 44, 45, 48, 49, 53, 55, 56, 58, 60], "categori": [32, 33, 37, 38, 39, 40, 41, 42, 46, 49, 53, 58], "categorical_feat": [34, 36, 53, 57], "categorical_featur": [34, 37, 38, 39, 40, 47, 48, 49, 58, 59, 60], "categorical_transform": [34, 37, 38, 39, 40, 47, 49, 58, 59, 60], "categories_": [33, 34], "cater": 42, "caus": [37, 40, 41, 44, 48, 57], "causal": [40, 41], "caution": 47, "cbar": 35, "cbtf": [10, 61], "cc": [0, 1], "cc_df": [37, 58], "cconj": 45, "ccp_alpha": 49, "cell": [7, 8, 29, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 48, 49, 50, 51, 54, 55, 57, 59], "cell_nam": 51, "censor": [10, 49, 50, 53, 61], "censu": [35, 37, 39, 40, 58], "census_df": [37, 58], "cent": 38, "center": [32, 42, 43, 46, 52], "centercrop": 46, "centers_idx": 42, "central": 5, "centralair": [38, 40, 49], "centralair_i": 38, "centralair_n": 38, "centric": [49, 61], "centroid": [42, 43], "centroids_idx": 42, "centroids_idx_init": 42, "centuri": 45, "certain": [11, 32, 35, 36, 37, 40, 41, 42, 45, 48, 49, 58], "certainli": 54, "certainti": 37, "cezannec": 46, "chage": 57, "chain": 34, "challeng": [6, 31, 41, 42, 44, 46, 47, 50, 53, 59, 61], "chanc": [30, 31, 36, 37, 38, 41, 42, 48, 49, 50, 58], "chang": [0, 5, 7, 8, 11, 30, 31, 32, 33, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 54, 55, 57, 58, 59, 60, 61], "channel": [1, 11, 46], "chapter": 10, "charact": [34, 37, 45], "characterist": [30, 31, 35, 57], "charg": [0, 29, 48], "charl": 35, "charm": 45, "chart": [40, 47, 48, 49, 60], "chat": 61, "chatgpt": 45, "che210d": 9, "cheaper": 41, "cheat": 9, "check": [4, 7, 10, 11, 29, 30, 31, 33, 35, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 55, 58, 59, 60], "check_assumpt": 48, "check_invers": 34, "checklist": 53, "checkmark": 44, "checkout": 36, "cheetah": [29, 46], "cherri": 49, "chest": 31, "chestpaintyp": 59, "chetah": [29, 46], "chi": 48, "chicago": 51, "chicken": 42, "child": [37, 40], "children": 44, "chines": 45, "chn": 8, "choic": [2, 36, 38, 39, 40, 42, 43, 44, 47, 51, 55, 56, 57], "cholesterol": 59, "choos": [29, 36, 37, 39, 43, 49, 50, 53, 55], "chop": [36, 45, 49], "choreograph": 51, "chose": 49, "chosen": [31, 36, 37, 48, 49, 53, 59], "chrbv": 48, "christin": 51, "christma": 51, "chunki": 42, "churn": [49, 53], "ciml": 10, "cinematographi": 45, "cinereu": 46, "circl": [32, 37], "circumst": 7, "citat": 7, "cite": 48, "citi": [30, 31, 32, 47, 49, 53, 54], "citibik": 47, "cities_df": [32, 35], "citizen": 48, "cityscap": 47, "civ": [37, 39, 40], "clai": 40, "claim": [0, 36, 37], "clarif": 42, "clarifi": 53, "clariti": 61, "class": [4, 5, 11, 29, 30, 31, 32, 33, 34, 35, 41, 42, 47, 48, 49, 50, 54, 55, 58, 59, 60], "class_attend": [30, 31, 53], "class_attendance_enc": 34, "class_attendance_level": 34, "class_label": 37, "class_labels_fil": 29, "class_nam": [30, 32, 39, 46], "class_sep": 37, "class_weight": [39, 49, 58], "classes_": [35, 37, 39, 40, 46, 52], "classic": [32, 46, 52], "classif": [2, 10, 31, 32, 33, 34, 35, 38, 39, 40, 41, 44, 45, 47, 48, 49, 52, 54, 55, 57, 58, 59, 61], "classifi": [31, 32, 33, 34, 36, 37, 40, 46, 49, 52, 54, 56, 58, 59], "classification_df": [30, 31], "classification_report": [37, 46, 58], "classifiers_ndt": 39, "classify_imag": [29, 46], "classmat": [6, 55, 56, 57, 58, 59, 60, 61], "classroom": 10, "clean": [2, 29, 43, 49, 60, 61], "clean_text": 45, "cleaned_hm": [37, 50], "cleaner": [37, 40], "clear": [7, 37, 42, 50, 55, 61], "clearli": [4, 6, 7, 36, 39, 40, 47], "cleric": [37, 39, 40], "clever": 49, "clf": [29, 30, 32, 35, 46], "cli": 45, "click": [5, 7, 10, 37, 44, 49, 50], "client": [44, 50], "clinic": 30, "clip": 29, "clone": [5, 7, 11], "close": [2, 31, 32, 35, 36, 37, 42, 43, 45, 47, 51, 52, 55, 61], "close_default_lr": 37, "close_zero_svm": 37, "closer": [32, 33, 35, 44, 54, 57, 61], "closest": [32, 33, 37, 42, 43, 45, 47], "cloth": 47, "cloud": [29, 30, 34, 35, 36, 38, 39, 51], "cloud3pm": [47, 60], "cloud9am": [47, 60], "clust_label": 42, "cluster": [2, 10, 44, 45, 47, 50, 61], "cluster_cent": 42, "cluster_centers_": 42, "cluster_std": [43, 46], "clutter": 30, "cm": [32, 35, 37, 40, 44, 55, 58], "cmap": [33, 36, 37, 40, 46, 57], "cmn": 38, "cmp": 48, "cnn": [46, 47], "co": [34, 45], "coast": 46, "cockpit": 49, "code": [4, 7, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60], "code_ast": 51, "code_obj": 51, "codecademi": 9, "coef": [47, 48, 51, 60], "coef0": 49, "coef_": [35, 38, 39, 40, 41, 44, 46, 47, 48, 51, 52, 59], "coef_df": [35, 40], "coef_nonzero": 47, "coeff": 35, "coeff_df": 47, "coeffici": [38, 39, 41, 44, 46, 47, 48, 49, 51, 52, 53, 59, 60], "coefs_df": 41, "coher": 42, "col": [30, 34, 35, 44, 47, 53], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 33, "colinear": 40, "collabor": [5, 44, 61], "collaps": 40, "colleagu": [8, 9], "collect": [29, 30, 33, 34, 37, 39, 40, 41, 44, 45, 46, 47, 48, 50, 53, 59, 61], "colleg": [37, 39, 40, 58], "collinear": 41, "color": [19, 23, 24, 25, 26, 27, 28, 35, 40, 41, 42, 43, 47, 49], "color_continuous_scal": 41, "color_threshold": 43, "colorbar": [33, 35], "colour": [34, 35, 36, 40, 42, 43, 46], "colsample_bylevel": 39, "colsample_bynod": 39, "colsample_bytre": 39, "columbia": [1, 9, 45], "column": [7, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "column_nam": 34, "column_stack": 41, "columntranform": 56, "columntransform": [10, 16, 17, 33, 36, 37, 38, 39, 40, 41, 47, 48, 49, 51, 57, 58, 59, 60], "columntransformer__countvectorizer__max_featur": [36, 57], "columntransformercolumntransform": [34, 36, 38, 39, 41, 51], "columntransformerifittedcolumntransform": [34, 38, 49], "columntransformerinot": [34, 39], "com": [0, 5, 8, 9, 11, 29, 30, 34, 35, 37, 38, 39, 46, 47, 48, 50, 51, 58], "comat": 45, "combin": [30, 33, 34, 36, 37, 41, 44, 46, 47, 48, 49, 54, 55, 57, 59], "come": [11, 29, 30, 33, 34, 37, 41, 44, 45, 46, 47, 48, 49, 54], "comedi": 44, "comfort": 5, "command": [4, 11, 37, 45, 50], "comment": [8, 9, 60], "commerci": 0, "commit": [7, 37, 61], "common": [1, 8, 30, 31, 32, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 50, 52, 55, 61], "commonli": [30, 33, 36, 37, 42, 48], "commun": [2, 10, 11, 34, 36, 38, 50, 61], "commut": 8, "comp_dict": 37, "compact": [36, 41], "compani": [37, 42, 44, 45, 48, 51, 58], "compar": [8, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 52, 53, 57, 58, 59, 60, 61], "comparison": [43, 46, 48, 53], "compassion": 61, "compat": [8, 40, 51], "compatibitl": 8, "compel": 47, "compet": 51, "competit": [39, 46, 52], "compil": 51, "complain": [6, 51], "complaint": [6, 61], "complement": 45, "complet": [1, 6, 7, 29, 33, 36, 39, 40, 41, 43, 45, 48, 49, 54, 55, 58, 59, 61], "complex": [30, 32, 35, 36, 38, 39, 40, 41, 43, 45, 46, 47, 50, 55, 61], "compli": 0, "complic": [4, 30, 31, 36, 38, 41], "compon": [34, 37, 44, 47, 49, 61], "components_": 45, "compos": [32, 34, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 51, 56, 57, 58, 59, 60], "composit": 34, "compound": [45, 46, 48, 51], "comprehend": 45, "comprehens": [42, 53, 61], "compress": [34, 42], "compris": [29, 30, 42], "comput": [7, 9, 10, 11, 29, 34, 36, 37, 39, 40, 41, 42, 43, 45, 47, 49, 50, 52, 58, 59, 61], "computation": 41, "compute_class_weight": 37, "computer_programm": 45, "coms4995": 33, "con": [42, 46, 49], "concat": [29, 32, 33, 34, 35, 40], "concaten": [34, 45], "concav": 41, "concensu": 31, "concentr": [36, 53], "concept": [10, 30, 31, 40, 41, 42, 47, 53, 55, 61], "conceptu": [39, 49], "concern": [4, 34, 39, 61], "concess": 7, "concis": [30, 50], "conclus": 49, "concord": 48, "concordance_index": 48, "concordance_index_": 48, "concret": [29, 49], "conda": [29, 37, 38, 39, 40, 42, 45, 48, 51], "condit": [0, 29, 30, 34, 41, 45, 48, 61], "condition1": [38, 40, 49], "condition1_arteri": 38, "condition1_feedr": 38, "condition1_norm": 38, "condition1_posa": 38, "condition1_posn": 38, "condition1_rra": 38, "condition1_rran": 38, "condition1_rrn": 38, "condition1_rrnn": 38, "condition2": [38, 40, 49], "condition2_arteri": 38, "condition2_feedr": 38, "condition2_norm": 38, "condition2_posa": 38, "condition2_posn": [38, 40], "condition2_rra": 38, "condition2_rran": 38, "condition2_rrnn": 38, "conditional_aft": 48, "confid": [29, 31, 40, 48, 50, 53, 55, 58, 59], "confidenti": 37, "config": [11, 51], "configur": [36, 38, 39], "confirm": 11, "conflict": [11, 43, 61], "confound": 41, "confus": [8, 18, 32, 34, 38, 42, 50, 55, 58], "confusion_matrix": [37, 46, 48], "confusionmatrixdisplai": [37, 58], "congrat": 34, "conjunct": 41, "connect": [0, 30, 43, 44, 50], "connot": 45, "conort": 41, "consciou": 61, "consecut": 47, "consequ": [7, 29, 34, 37, 44, 49, 58], "consid": [4, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 53, 55, 61], "consider": [2, 37, 39, 42, 44, 48, 49, 50, 61], "consist": [6, 7, 30, 31, 33, 42, 50], "constant": [30, 37, 38, 39, 40, 47, 48, 49, 58, 60], "constitu": 39, "constitut": [45, 61], "construct": 44, "constructor": [30, 33], "consult": [32, 55, 61], "consum": [29, 41, 42, 44, 50, 53], "consumpt": 47, "contact": [29, 61], "contain": [8, 11, 19, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 44, 45, 46, 50, 51, 52, 61], "container": 50, "content": [1, 4, 11, 42, 45, 46, 50, 53, 61], "contest": 6, "context": [30, 33, 35, 36, 37, 39, 40, 41, 43, 44, 46, 47, 49, 53, 55, 61], "contextu": 61, "contin": 34, "conting": 43, "continu": [15, 34, 36, 38, 39, 41, 45, 47, 49, 60], "contract": [0, 48], "contract_month": 48, "contract_on": 48, "contract_two": 48, "contrast": [53, 61], "contribut": [32, 35, 40, 46, 59, 61], "control": [5, 8, 30, 31, 32, 34, 35, 38, 39, 46, 61], "convei": 61, "conveni": [8, 36, 37, 42, 45, 47, 48, 49, 50], "converg": 42, "convers": [37, 38, 40, 45, 50, 57], "convert": [29, 33, 34, 35, 39, 40, 41, 45, 47, 48, 60], "convinc": [34, 49], "convolut": [41, 46], "convolutional_neural_network": 46, "cooccurrencematrix": 45, "cook": 42, "cool": 46, "coolwarm": 35, "coordin": 61, "copi": [0, 7, 8, 11, 30, 36, 39, 40, 42, 44, 46, 47, 48, 59, 60, 61], "copy_arrai": 51, "copyright": 0, "cor": 40, "coral": 46, "core": [9, 31, 33, 34, 36, 37, 38, 41, 43, 44, 47, 48, 50, 51, 53, 60, 61], "corefer": 45, "corei": 50, "corgi": [29, 46], "coro": 51, "corona_nlp_test": 51, "coronapocalyps": 51, "coronaviru": 51, "corpor": [5, 51], "corpora": [34, 45], "corpu": [34, 37, 45], "corr": 40, "corr_df": 40, "correct": [7, 29, 30, 31, 32, 37, 39, 40, 48, 49, 54, 55, 59], "correctli": [10, 11, 30, 31, 37], "correl": [47, 53], "correspond": [10, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 42, 44, 47, 55, 57], "cosin": 45, "cosine_similar": 45, "cost": [8, 29, 46, 49, 61], "cost_rep": 8, "costli": 37, "cot": 46, "cote": 46, "could": [6, 8, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 44, 45, 47, 48, 49, 50, 55, 57, 58, 60, 61], "count": [8, 30, 33, 34, 37, 38, 41, 45, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61], "counter": 37, "counti": 55, "countri": [31, 32, 34, 35, 37, 39, 40, 58, 61], "country_columbia": 40, "country_dominican": 40, "country_guatemala": 40, "country_hondura": 40, "country_hong": 40, "country_hungari": 40, "country_india": 40, "country_iran": 40, "country_miss": [39, 40], "country_puerto": 40, "country_scotland": 40, "country_south": 40, "country_taiwan": 40, "country_thailand": 40, "country_trinadad": [39, 40], "country_unit": [39, 40], "country_vietnam": [39, 40], "country_yugoslavia": [39, 40], "countvector": [29, 35, 36, 37, 45, 50, 51, 53, 57], "countvectorizercountvector": [34, 36, 51], "countvectorizeroriginaltweet": 51, "countvectorizersong_titl": 36, "coupl": [4, 30, 36, 43, 51, 60], "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 51, 53, 54, 55, 57], "coursera": [9, 10], "coursework": 61, "court": 45, "covari": [30, 48], "cover": [8, 37, 39, 42, 46, 47, 61], "coverag": 37, "covid": 51, "covid2019": 51, "cow": 49, "cox": 61, "coxph_fitt": 48, "coxphfitt": 48, "cph": [48, 49, 53], "cph_param": 48, "cpp": 51, "cpsc": [9, 10, 11, 29, 30, 39, 41, 45, 46, 47, 49, 50, 51, 61], "cpsc330": [0, 11, 29, 30, 31, 34, 36, 40, 45, 46, 48, 49, 50, 51, 61], "cpsc330env": 11, "cpu": [36, 46, 51], "craft": [32, 37, 39, 40, 42, 55], "crash": [10, 50, 51], "crate": 46, "crazi": 50, "creat": [8, 9, 11, 29, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "create_lag_df": 47, "create_lag_featur": [47, 60], "create_y_from_r": 44, "creativ": 1, "credenc": 49, "credit": [0, 30, 37, 39, 45, 47, 48, 49, 58], "creditcard": [37, 58], "crime": 35, "crimin": 40, "criteria": [30, 43], "criterion": [43, 49], "critic": [49, 61], "cross": [15, 30, 32, 34, 36, 38, 39, 40, 42, 44, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60], "cross_val": 39, "cross_val_predict": [37, 39, 48], "cross_val_scor": [33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 56, 57, 58, 59, 60], "cross_valid": [32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60], "cross_validate_std": 31, "crowd": [39, 43], "crown": 61, "crucial": [29, 31, 35, 40, 42, 43, 44, 45], "crude": 45, "cs189": 9, "cs189_ch7": 9, "csrc": 51, "css": 50, "csv": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "ct": 34, "cuda": 46, "cui": 61, "cuisin": 50, "cultiv": 61, "cultur": [46, 61], "cupi": 51, "curios": 29, "curiou": [29, 55], "curl": 50, "current": [39, 45, 46, 47, 48, 49, 50, 51], "curriculum": 61, "curs": 49, "curv": [7, 8, 42, 49, 53, 55, 61], "custom": [5, 8, 29, 30, 34, 37, 38, 44, 50, 51, 53], "custom_plot_tre": [30, 31, 39, 40], "customerid": 48, "customiz": 51, "cut": 43, "cv": [31, 34, 37, 38, 39, 40, 41, 47, 48, 49, 50, 53, 55, 57], "cv_feat": 51, "cv_results_": [36, 38, 57], "cv_score": [31, 38], "cv_train_scor": 55, "cv_valid_scor": 55, "cycl": 8, "cyclic": 47, "cycling_data": 8, "cygnu": 46, "d": [4, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 58, 59, 60], "d1b": 61, "d1c": 61, "d1e": 61, "d1f": 61, "d3": 42, "da": 29, "dabeaz": 9, "dad": 41, "dai": [4, 8, 10, 41, 46, 48, 49, 53, 60, 61], "daili": [48, 53], "dall": 47, "damag": [0, 37], "dan": 45, "danceabl": [32, 33, 36, 57], "dark": 51, "darker": 36, "dashboard": [32, 55], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 43, 45, 48, 52, 53, 54, 56, 57, 58, 59, 61], "data_dict": 35, "data_dir": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60], "data_to_wrap": 34, "data_transform": 46, "data_transforms_bw": 46, "data_url": [37, 58], "datacamp": 9, "datafram": [29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 55, 56, 57, 59, 60], "dataload": 46, "dataloaders_bw": 46, "datapoint": 35, "dataquest": 9, "dataset": [8, 18, 29, 31, 32, 39, 40, 41, 42, 43, 48, 50, 51, 52, 53, 55, 57, 58, 61], "dataset2": 42, "dataset_s": 46, "dataviz": 49, "date": [7, 11, 29, 30, 44, 48, 50, 51, 53, 55, 60, 61], "date_rang": 47, "dates_rain": [47, 60], "datetim": 48, "datetime64": [47, 60], "datetimeindex": 47, "daughter": [37, 50], "daum\u00e9": 10, "daunt": 44, "dave": 45, "david": [10, 45, 49], "day_nam": [47, 60], "daylight": [47, 60], "dayofweek": 47, "days_sinc": 47, "dbscan": [50, 61], "dc": [47, 48, 51], "dcc": 35, "dd": [47, 60], "de": [45, 47], "deactiv": 11, "deadlin": 61, "deal": [0, 31, 32, 33, 38, 45, 48, 49, 53, 56], "death": 61, "debat": [8, 40], "debbi": 51, "debug": [4, 40], "decad": 46, "decemb": [47, 60], "decid": [8, 30, 32, 35, 39, 40, 41, 42, 43, 45, 47, 48, 53], "decis": [2, 6, 10, 14, 31, 33, 36, 37, 39, 41, 46, 52, 53, 54, 56, 59, 61], "decision_boundari": 52, "decision_funct": 37, "decisiontreeclassifi": [31, 32, 33, 34, 35, 36, 40, 54, 55, 56, 57, 59], "decisiontreeclassifierdecisiontreeclassifi": 39, "decisiontreeregressor": [30, 38, 54, 55], "deck": 9, "declar": 61, "decomposit": [43, 44, 45], "decor": 51, "decreas": [31, 35, 36, 39, 40, 42, 55], "deduct": 7, "deem": 6, "deep": [2, 9, 36, 40, 41, 45, 48, 50], "deepen": [53, 61], "deeper": [2, 36, 37, 38, 40], "deepexplain": 40, "def": [31, 32, 33, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 50, 51, 55, 57, 60], "defalut": 57, "default": [5, 11, 30, 31, 34, 35, 36, 37, 38, 39, 42, 43, 46, 47, 48, 49, 50, 52, 57, 58, 61], "default_threshold": 37, "defaultdict": 44, "defin": [30, 32, 33, 34, 37, 39, 40, 42, 43, 44, 47, 50, 60], "definit": [8, 32, 40, 42, 45, 47, 52, 53, 54], "degre": 37, "degrees_freedom": 48, "degrees_of_freedom": 48, "del": 39, "delai": [10, 11, 41], "deleg": 45, "delet": [4, 7, 33, 49], "delgado": 39, "delight": 45, "deliver": 7, "delv": [45, 61], "demo": [10, 39, 49, 61], "demograph": [30, 44], "demonstr": [30, 31, 33, 35, 36, 38, 39, 42, 44, 45, 46], "denomin": [38, 51], "denot": [30, 44], "dens": [43, 45], "densenet": 46, "densenet121": 46, "densenet121_weight": 46, "densiti": [40, 43, 53], "dep": 45, "department": 61, "departur": 41, "depend": [2, 8, 11, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 43, 45, 47, 48, 49, 59], "dependence_plot": 40, "dependents_no": 48, "dependents_y": 48, "deploi": [31, 37, 44, 49, 53], "deploy": [40, 47, 61], "deprec": [31, 33, 37, 38, 48, 52], "deprecationwarn": [39, 48], "depth": [10, 30, 31, 36, 39, 43, 54, 55], "dequ": [39, 40, 59], "deriv": [0, 30, 35, 37, 44, 48, 53, 58], "descend": [8, 43, 46, 53], "descent": 47, "descr": 35, "describ": [8, 29, 30, 31, 32, 33, 35, 37, 38, 44, 45, 47, 50, 55, 58, 60, 61], "descript": [38, 48, 51], "deserv": 6, "design": [30, 40, 43, 46, 49, 57, 61], "desir": [37, 45, 48, 56], "desk": 61, "despit": [41, 45], "det": [45, 51], "detach": 46, "detail": [7, 32, 34, 39, 46, 50, 61], "detect": [29, 30, 37, 38, 42, 43, 47, 50, 58], "determin": [32, 42, 43, 45, 48, 49, 55, 59, 61], "detriment": [37, 44, 58], "dev": [31, 52], "develop": [9, 10, 29, 31, 33, 34, 36, 37, 38, 39, 45, 46, 49, 50, 51, 53, 61], "devianc": 48, "deviat": [6, 31, 33, 39, 40], "devic": [39, 46, 51], "deviceprotect": 48, "deviceprotection_no": 48, "deviceprotection_y": 48, "df": [29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 46, 47, 48, 49, 50, 51, 54, 60], "df_concat": 29, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 47, "df_locat": [47, 60], "di": 48, "diagnos": [31, 40, 53], "diagnosi": 37, "diagnost": [48, 50], "diagon": [32, 37, 40], "diagram": [34, 36, 39, 40], "dialogu": 45, "dict": [37, 44], "dict_kei": 39, "dictionari": [8, 33, 36, 37, 39, 40, 50], "did": [6, 30, 32, 40, 42, 45, 47, 51, 55, 57, 58, 59, 61], "didn": [36, 39, 40, 43, 47, 48, 50], "die": 51, "diet": 30, "diff": [47, 60], "differ": [2, 5, 7, 8, 10, 11, 29, 30, 31, 32, 34, 35, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 57, 58, 59, 60, 61], "differenti": [29, 30, 61], "difficult": [4, 6, 7, 37, 41, 42, 49], "difficulti": [42, 53], "dig": [37, 38], "digit": [47, 49], "dilemma": 44, "dim": 46, "dimens": [8, 35, 41], "dimension": [2, 8, 35, 36, 37, 39, 41, 42, 45], "dine": 50, "direct": [35, 40, 41, 43, 45, 51], "direct_bilirubin": 29, "directli": [8, 10, 34, 38, 46, 48, 50, 61], "director": 44, "directori": [11, 30, 31, 33], "dirichlet": [45, 46], "disabl": 45, "disadvantag": [36, 39, 43, 44, 56], "disast": 29, "discard": [41, 45], "disciplin": [37, 41], "disclos": [51, 61], "discourag": 8, "discours": 44, "discov": [41, 42], "discoveri": 29, "discret": [30, 41, 61], "discrete_scatt": [30, 31, 32, 35, 42, 43, 46, 52, 54, 55], "discretization_feat": 41, "discrimin": 39, "discuss": [1, 4, 31, 32, 33, 35, 40, 41, 42, 43, 47, 53, 55, 56, 57, 59, 60, 61], "diseas": [30, 37, 48], "dislik": 49, "dispatch": 51, "dispatch_queu": 51, "dispatch_shel": 51, "displaci": [45, 51], "displai": [7, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 43, 44, 46, 47, 48, 54, 55, 56, 57, 58, 60], "display_heatmap": [36, 57], "display_label": [37, 58], "disput": 45, "disrespect": 4, "dissemin": 50, "dist": [32, 42, 43], "distanc": [8, 33, 41, 43, 44, 45], "distinct": [37, 41, 47, 49], "distinguish": [30, 32, 34, 37, 55], "distract": 61, "distribut": [0, 11, 31, 37, 40, 41, 43, 45, 46, 47, 57, 60, 61], "district": [33, 35], "districtdatalab": 42, "disturb": 29, "dive": 40, "divers": [39, 42, 44, 47, 61], "divid": [35, 37, 39, 40, 47, 55], "divis": 40, "divorc": [39, 40], "dktal": 48, "dlwqn": 48, "dmp": 61, "do": [0, 4, 5, 6, 7, 8, 10, 11, 29, 30, 31, 32, 35, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "do_execut": 51, "doc": [8, 9, 40, 45, 46, 50, 51, 61], "docker": 50, "doctor": [37, 39, 40, 58], "document": [0, 1, 7, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 51, 53, 57, 58, 59, 61], "document_top": 45, "documentari": 44, "doe": [5, 8, 11, 29, 31, 32, 33, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 53, 55, 57, 59, 60, 61], "doesn": [7, 8, 31, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 53], "dog": [37, 46], "dolist": 50, "dollar": [4, 35, 38, 49], "dolli": 51, "domain": [0, 29, 40, 42, 45], "domin": [33, 38, 46], "domingo": [10, 31, 41], "don": [4, 29, 31, 34, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52], "done": [5, 11, 31, 34, 36, 37, 46, 47, 49, 53, 56, 58], "dont": 51, "door": 46, "dot": [32, 35, 37, 39, 40, 41, 43, 45], "dot_product": 45, "doubl": 36, "down": [31, 37, 40, 48, 49, 55, 59, 61], "downfal": 44, "downgrad": 51, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 35, 37, 38, 40, 45, 46, 49, 51, 55, 59], "downright": 49, "dpi": 41, "dr": [45, 61], "draft": 10, "drag": 7, "drama": 44, "drastic": 37, "draw": [35, 36, 45, 49], "drawback": [40, 44, 61], "drawn": 39, "dream": 46, "drink": 49, "drinker": 45, "drive": [29, 40], "driven": [11, 36, 37], "drop": [7, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 47, 48, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61], "drop_dupl": [32, 36], "drop_feat": [34, 53], "drop_featur": [37, 38, 39, 40, 47, 48, 49, 51, 58, 60], "dropdown": [19, 23, 24, 25, 26, 27, 28], "dropdrop": [34, 38, 39, 49, 51], "drope": 33, "dropna": [37, 47, 50, 60], "dropoff": 42, "drug": [29, 50], "dsci": [9, 10, 40, 49, 52], "dsl": 48, "dt": 55, "dt88trtd17lf726d55bq16c40000gr": 51, "dt_best": 55, "dt_pipe": 36, "dtype": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 58, 59, 60], "dual": 37, "duan": 61, "duck": [46, 49], "duckbil": 46, "due": [7, 35, 39, 41, 44, 61], "dummi": [30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 54, 56, 57, 58, 59, 60], "dummy_clf": [30, 54], "dummy_scor": 32, "dummy_valid_accuraci": 32, "dummyclassifi": [31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 46, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60], "dummyregressor": [34, 39, 40, 41, 49, 50, 51, 56, 59], "dump": 50, "dun": 29, "dunno": 29, "duplex": 38, "duplic": 8, "durat": [7, 41, 47, 48], "duration_col": 48, "duration_m": [32, 33, 36], "dure": [4, 8, 10, 29, 30, 32, 34, 35, 36, 39, 40, 41, 44, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61], "dwell": 38, "e": [6, 7, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 60, 61], "e737c5242822": 48, "e_": 31, "each": [7, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61], "eager": 50, "earli": [40, 48, 49], "earlier": [33, 39, 41, 47, 48], "early_stopping_round": 39, "earn": 61, "earnest": 61, "easi": [7, 32, 33, 35, 39, 40, 41, 42, 43, 45, 49, 51], "easier": [5, 7, 37, 40, 41, 44, 49], "easiest": [40, 48, 51], "easili": [39, 41, 47, 49, 50, 54, 60], "echidna": 46, "econom": [34, 47], "ecosystem": 46, "ed": 1, "eda": [31, 45, 48, 53, 60], "edg": [30, 36], "edgecolor": [36, 47, 60], "edit": [36, 45], "edu": 9, "educ": [37, 39, 40, 44, 58], "education_level": [37, 39, 40, 58], "effect": [32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 53, 55, 58], "effici": 36, "effort": [4, 11, 36, 41, 42, 44, 46, 61], "egg": 42, "eghbal": 61, "either": [4, 30, 31, 32, 34, 37, 40, 42, 43, 45, 46, 47, 55, 57], "elast": 48, "elbow": 43, "elect": 45, "electr": [38, 40, 49], "electrical_fusea": 38, "electrical_fusef": 38, "electrical_fusep": 38, "electrical_miss": 38, "electrical_mix": 38, "electrical_sbrkr": 38, "electron": [48, 61], "eleg": [33, 49], "elegantli": 45, "element": [0, 9, 10, 31, 34, 45, 54], "eli5": 40, "elif": [30, 47, 48], "elimin": 61, "els": [30, 34, 37, 46, 47, 48, 51, 58], "email": [29, 31, 37, 61], "emb": [7, 32, 37, 42, 43], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 46, 50, 53, 61], "emoji": 51, "emoticon": [41, 42], "emp": 40, "empathi": 45, "emphas": 61, "emphasi": [50, 61], "emploi": [47, 48, 50, 53], "employ": 44, "employe": 30, "empti": [35, 45, 46, 47, 60], "en": [47, 48, 49, 51, 60], "en_core_web_lr": 45, "en_core_web_md": [45, 51], "enabl": [11, 44, 45, 47], "enable_categor": 39, "enable_halving_search_cv": 36, "enc": [33, 34, 47], "enclosedporch": [38, 40, 49], "encod": [16, 17, 29, 31, 36, 37, 38, 40, 44, 48, 53, 56, 58, 60], "encompass": [48, 49, 53], "encount": [34, 36], "encourag": [11, 61], "end": [4, 8, 29, 31, 32, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 50, 55, 61], "endors": 0, "endpoint": 48, "energi": [32, 33, 36, 47, 57], "engag": 61, "engin": [9, 10, 34, 37, 38, 42, 44, 45, 48, 50, 60, 61], "england": 51, "english": [29, 33, 36, 37, 45, 46, 50, 51, 57], "enhanc": 61, "enjoi": [10, 35], "enjoy_class": 34, "enjoy_cours": [34, 53], "enjoy_course_enc": 34, "enjoy_the_mo": [37, 50], "enough": [7, 32, 34, 37, 38, 39, 42, 44, 53, 57, 58, 60], "ensembl": [10, 19, 20, 38, 40, 41, 43, 44, 47, 48, 49, 50, 51, 59, 60, 61], "ensiti": 43, "ensur": [7, 33, 39, 47, 60, 61], "ent": [45, 51], "enter": [34, 48, 49, 57], "enterpris": 5, "entertain": 45, "enthusiast": [29, 49], "entir": [4, 8, 31, 38, 46, 47, 49, 50, 51, 59, 61], "entiti": [41, 44, 45, 51], "entitl": 34, "entlebuch": [29, 46], "entri": [32, 33, 34, 35, 37, 38, 41, 44, 47, 48, 60], "entropi": [30, 49], "enumer": 39, "env": [11, 30, 31, 34, 36, 40, 48, 50, 51, 52], "environ": [3, 5, 8, 29, 33, 34, 36, 37, 38, 39, 40, 41, 45, 46, 48, 49, 51, 61], "environemnt": 11, "environment": 53, "ep": [30, 31, 32, 35, 43, 54], "epoch": 47, "epsilon": [43, 49], "equal": [8, 32, 34, 37, 38, 39, 40, 43, 44, 47, 53, 60, 61], "equat": [4, 35], "equip": [32, 48, 61], "equival": [8, 37, 39, 58], "err": 45, "errno": 50, "error": [4, 6, 7, 8, 11, 30, 32, 34, 35, 39, 40, 41, 45, 48, 49, 50, 51, 53, 55, 59, 61], "error_": 31, "erupt": 29, "erythrocebu": [29, 46], "es": [47, 60], "escap": 49, "eskimo": 37, "esl": 10, "especi": [2, 30, 32, 36, 37, 39, 41, 44, 47], "essenti": [48, 53], "estat": 30, "estim": [31, 32, 34, 35, 36, 41, 42, 48, 49, 50, 53, 59], "estimators_": 39, "et": [39, 45], "etc": [2, 7, 8, 30, 41, 46, 47, 48, 49, 50, 51, 61], "ethic": [10, 50, 61], "euclidean": [42, 43, 45], "euclidean_dist": [32, 33, 42, 43, 45], "ev": 51, "eva": 44, "eva_model": 44, "eval": 46, "eval_metr": [39, 40], "eval_on_featur": 47, "evalu": [8, 10, 30, 31, 36, 38, 40, 42, 47, 49, 50, 55, 59, 61], "evapor": [47, 60], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 35, 36, 37, 41, 42, 43, 44, 47, 48, 49, 51, 53, 55, 56, 58, 61], "event": [0, 37, 38, 51, 61], "event_col": 48, "event_observ": 48, "ever": [30, 52], "everi": [8, 30, 31, 39, 43, 47, 55], "everydai": [8, 45], "everyon": [6, 40, 49, 53], "everyth": [34, 37, 44, 47, 50, 59], "everywher": 47, "evict": 51, "evo": 50, "evocarshar": 50, "evok": 45, "ex": [38, 40, 49], "ex1_idx": 40, "ex2_idx": 40, "exact": [4, 48], "exactli": [7, 29, 31, 40, 55, 57], "exagger": 49, "exam": [6, 10, 49, 50], "examin": [31, 32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52, 58, 60], "exampl": [0, 4, 5, 6, 7, 8, 11, 38, 43, 44, 46, 47, 50, 52, 53, 54, 55, 57, 58, 60, 61], "example1": 30, "example2": 30, "exceedingli": 55, "excel": [34, 35, 38, 40, 48, 53, 56], "except": [0, 7, 8, 31, 47, 48, 60, 61], "exception": 4, "exchang": [37, 53], "excit": 44, "exec": 51, "execut": [4, 7, 42, 50], "execute_request": 51, "exercis": [7, 9, 10, 45, 50, 51, 55, 56, 57, 58, 59, 60, 61], "exerciseangina": 59, "exhaust": 57, "exist": [8, 37, 41, 48, 50, 58], "exp": [35, 48, 49], "expand": [10, 30, 61], "expect": [1, 4, 7, 8, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 55, 58, 60, 61], "expected_valu": 40, "expenditur": 47, "expens": [29, 37, 38, 41, 42, 44], "experi": [29, 36, 44, 45, 50, 61], "experienc": 61, "experiment": [36, 50], "expert": [29, 30, 31, 36, 40, 41, 58], "explain": [4, 7, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 58, 59, 61], "explan": [4, 31, 32, 53, 58], "explanatori": 30, "explicit": [37, 48], "explicitli": [8, 29, 50], "exploit": 6, "explor": [30, 31, 34, 36, 37, 40, 41, 44, 45, 46, 50, 55, 57], "exploratori": [38, 48, 50, 53], "explos": 51, "expm1": [38, 49], "expon": 36, "exponenti": 36, "export_graphviz": [30, 54], "exposur": 44, "express": [0, 8, 34, 35, 41, 45, 49], "extend": [45, 46, 52, 61], "extend_block": 48, "extens": [32, 37, 40, 42, 43, 45, 47, 55, 61], "extent": [42, 45], "extercond": [38, 40, 49], "exterior": 40, "exterior1st": [38, 40, 49], "exterior1st_asbshng": 38, "exterior1st_asphshn": 38, "exterior1st_brkcomm": 38, "exterior1st_brkfac": 38, "exterior1st_cblock": 38, "exterior1st_cemntbd": 38, "exterior1st_hdboard": 38, "exterior1st_imstucc": [38, 40], "exterior1st_metalsd": 38, "exterior1st_plywood": 38, "exterior1st_ston": 38, "exterior1st_stucco": 38, "exterior1st_vinylsd": 38, "exterior1st_wd": 38, "exterior1st_wdsh": 38, "exterior2nd": [38, 40, 49], "exterior2nd_asbshng": 38, "exterior2nd_asphshn": 38, "exterior2nd_brk": 38, "exterior2nd_brkfac": 38, "exterior2nd_cblock": 38, "exterior2nd_cmentbd": 38, "exterior2nd_hdboard": 38, "exterior2nd_imstucc": 38, "exterior2nd_metalsd": 38, "exterior2nd_oth": 38, "exterior2nd_plywood": 38, "exterior2nd_ston": 38, "exterior2nd_stucco": 38, "exterior2nd_vinylsd": 38, "exterior2nd_wd": 38, "exterqu": [38, 40, 49], "extra": [4, 42, 47, 50, 60, 61], "extract": [41, 42, 44, 45, 46, 51, 60, 61], "extractor": 53, "extrapol": [47, 48], "extratreesclassifi": 39, "extrem": [6, 34, 37, 39, 40, 44, 48, 51], "ey": 51, "f": [8, 11, 29, 30, 31, 32, 33, 34, 37, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 55, 59, 60, 61], "f1": [18, 38, 53, 61], "f1_score": 37, "f403": 51, "fa": [38, 40, 49], "face": [29, 30, 32, 44, 46], "facebook": [44, 45, 61], "facial": 32, "facil": 61, "facilit": [8, 61], "fact": [29, 36, 37, 39, 46, 47, 48, 49, 60], "factor": [30, 36, 40, 41, 43, 44, 48], "fail": [7, 8, 10, 11, 31, 33, 34, 41, 43, 45, 48, 49, 51], "failur": [7, 29, 48, 59, 61], "fair": [6, 31, 33, 38, 40, 42, 50, 53, 61], "fairli": [31, 36, 37, 40, 50, 58], "fake": 32, "fall": [32, 42, 45, 47], "fals": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 53, 58, 59, 60], "famili": [29, 36, 37, 38, 39, 40, 42, 50, 61], "familiar": [8, 11, 30, 33, 49, 55, 60, 61], "famou": [9, 10, 46], "fanci": [4, 29, 36], "fancier": 41, "far": [30, 32, 33, 34, 35, 37, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 55, 57, 59], "farm": 37, "farthest": 30, "fashion": [39, 45], "fast": [31, 32, 35, 39, 40, 45, 48, 50, 61], "faster": [29, 36, 39, 41, 46], "fastest": 39, "fastingb": 59, "fasttext": 45, "favour": 50, "favourit": 45, "fc": 35, "fcluster": 43, "fd": 50, "feat": [36, 47, 51], "feat1": 42, "feat2": 42, "feat_nam": [47, 51], "feat_vec": 44, "featur": [10, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 31, 37, 39, 42, 43, 45, 48, 50, 52, 55, 56, 57, 58, 59, 61], "feature_extract": [29, 34, 35, 36, 37, 45, 50, 51, 57], "feature_importances_": 41, "feature_nam": [30, 31, 35, 39, 40, 41, 45], "feature_names_out": 34, "feature_select": 41, "feature_typ": 39, "features_lag": 47, "features_nonzero": 47, "features_poli": 47, "februari": 47, "feder": [37, 40, 47], "feedback": [30, 53], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 42, 53], "feli": [29, 46], "fell": 35, "femal": [37, 39, 40, 48, 58], "female_cm": [37, 58], "female_pr": [37, 58], "fenc": [38, 40, 46, 49], "fernandez": 39, "fetch_california_h": 35, "few": [8, 10, 29, 35, 38, 39, 41, 44, 46, 47, 48, 50, 54, 59], "fewer": [11, 39, 41, 43], "fewest": 59, "feynman": 49, "fiber": 48, "fiction": 51, "field": [2, 4, 29, 34, 45, 46, 47, 50, 61], "fig": [31, 32, 35, 37, 41, 42, 43, 46, 55, 58], "figsiz": [30, 31, 32, 33, 35, 37, 40, 41, 42, 43, 46, 47, 48, 49, 55, 58], "figur": [4, 8, 11, 29, 30, 32, 36, 38, 40, 41, 42, 43, 46, 47, 48, 49, 55], "file": [0, 1, 4, 5, 7, 8, 11, 19, 25, 30, 34, 37, 40, 46, 48, 50, 51, 58, 60], "filenam": 46, "filenotfounderror": 50, "fill": [32, 35, 36, 44, 50, 55, 59, 61], "fill_diagon": 32, "fill_valu": [37, 38, 39, 40, 47, 49, 58, 60], "film": [45, 51], "filter": [4, 29, 31, 42, 47, 53, 60, 61], "filterwarn": [32, 48, 59], "final": [6, 7, 10, 31, 33, 39, 41, 49, 50, 54, 56, 59], "final_estim": 39, "final_estimator_": [39, 59], "financ": [46, 47], "find": [7, 8, 10, 29, 30, 33, 36, 38, 39, 40, 42, 43, 44, 45, 49, 51, 52, 57, 58, 61], "fine": [7, 33, 34, 37, 44, 46, 47, 50, 59], "finish": [25, 29, 38], "fira": [0, 1, 61], "firasm": [37, 49, 58], "fireplac": [38, 40, 49], "fireplacequ": [38, 40, 49], "first": [4, 8, 10, 30, 32, 34, 35, 36, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 57, 58, 59, 61], "first_dai": 47, "first_day_retail": 47, "firth": 45, "fish": [37, 40], "fist": 47, "fit": [0, 29, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60], "fit_intercept": 37, "fit_predict": 43, "fit_resampl": 37, "fit_tim": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 51], "fit_transform": [33, 34, 37, 39, 40, 41, 43, 44, 45, 47, 53, 58], "fittedcolumntransform": [34, 39], "fittedpipelin": [34, 36, 38], "fittedvotingclassifi": 39, "fitter": 48, "five": 36, "fix": [33, 34, 39, 48, 50, 52, 55, 61], "flag": 48, "flagstaff": 51, "flaki": 37, "flashcard": 53, "flask": 50, "flat": 43, "flatten": [39, 40, 43, 47, 59], "flatten_train": 46, "flatten_transform": 46, "flatten_valid": 46, "flaw": [31, 33], "flawless": 35, "flexibl": [7, 29, 41, 46, 53, 61], "flibbertigibbet": 45, "flickr_cat_000002": 46, "flight": 41, "flip": [10, 31, 37, 38], "flip_i": 37, "float": [8, 38, 41, 48, 51], "float32": [45, 46], "float64": [30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 47, 48, 60], "floatlogslid": [32, 55], "floatslid": [32, 37, 42, 43, 55], "floor": [29, 30], "flower": [32, 37, 50, 55], "fmt": 36, "fn": 37, "fnlwgt": [37, 39, 40, 58], "focu": [10, 29, 33, 34, 35, 40, 43, 44, 45, 47, 53, 55, 56, 57, 58, 59, 61], "focus": [29, 35, 42, 45, 53, 60], "fold": [31, 33, 34, 36, 37, 38, 39, 50, 55], "folder": [5, 6, 31, 33, 40, 50, 51], "folk": [48, 50, 61], "follow": [0, 5, 6, 7, 8, 11, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 61], "font": [29, 30, 31, 42, 43, 44, 47, 48, 49], "font_scal": 40, "fontsiz": [30, 31, 32, 37, 39, 40, 42, 46, 49, 54, 55], "food": [42, 45, 46, 61], "foot": [38, 40], "footag": 35, "footstal": 46, "forc": [37, 40, 55], "force_plot": 40, "forecast": [30, 48, 49, 53, 60, 61], "forest": [37, 38, 46, 47, 48, 50, 53, 59, 61], "forev": 47, "forg": [11, 37, 38, 39, 40, 45, 48, 51], "forget": [30, 34, 39, 59], "form": [10, 34, 37, 41, 43, 44, 45, 48, 49, 50, 53], "formal": 61, "format": [0, 10, 30, 37, 43, 45, 47, 48, 60], "former": 48, "formul": [4, 36], "formula": [35, 38, 46, 52], "forum": [6, 7], "forward": [48, 50], "found": [7, 10, 31, 34, 36, 38, 42, 44, 45, 51, 53, 57, 59, 61], "foundat": [9, 10, 37, 38, 40, 49, 61], "foundation_brktil": 38, "foundation_cblock": 38, "foundation_pconc": 38, "foundation_slab": 38, "foundation_ston": 38, "foundation_wood": 38, "fountain": 46, "four": [30, 31, 41, 43, 50, 53], "fourth": 43, "foxhound": [29, 46], "foyer": 38, "fp": 37, "fpr": 37, "fpr_lr": 37, "fpr_svc": 37, "frac": [30, 35, 37, 38, 42, 45, 46], "fractal": 41, "fraction": [34, 37, 44], "fragment": 55, "frame": [33, 34, 37, 38, 41, 47, 48, 49, 50, 60], "framework": [30, 36], "fraud": [30, 37, 38, 42, 47, 58], "fraudul": [30, 37, 49, 58], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 38, 45, 48], "freedom": [0, 51], "french": 33, "freq": [47, 60], "frequenc": [34, 45, 47, 48, 53, 60], "frequent": [30, 33, 44, 45, 48], "fresh": 44, "fri": [10, 47], "fridai": [10, 61], "friend": [30, 31, 37, 40, 43, 44, 50, 53, 61], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "from_block": 48, "from_estim": [37, 58], "front": 61, "frozen": 51, "fruit": 45, "frustrat": [4, 6, 36], "full": [36, 39, 46, 47, 48, 61], "fullbath": [38, 40, 49], "fulli": 43, "fun": [37, 45, 46], "func": [8, 34, 35, 38, 49], "function": [2, 29, 30, 31, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 60], "functiontransform": [34, 48], "fund": 51, "fundament": [2, 9, 10, 15, 33, 35, 36, 38, 41, 46, 48, 61], "funni": [29, 39, 51], "furnish": 0, "furnitur": 53, "further": [37, 39, 41, 42, 46, 48, 50, 55, 57, 58], "furthermor": 49, "futur": [31, 33, 36, 38, 48, 53, 57, 60, 61], "futurewarn": [31, 33, 38, 40, 52], "fyi": 48, "g": [6, 7, 8, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 60, 61], "g26r0dcx4b35vf3nk31216hc0000gr": [33, 40], "gain": [6, 30, 37, 39, 40, 58, 61], "game": [30, 40], "gamma": [35, 36, 39, 49, 55, 57], "gamma_log": [32, 55], "gamma_widget": [32, 55], "gap": [31, 47, 48, 49, 53, 55], "garagearea": [38, 40, 49], "garagecar": [38, 40, 49], "garagecond": [38, 40, 49], "garagefinish": [38, 40, 49], "garagefinish_fin": 38, "garagefinish_miss": 38, "garagefinish_rfn": 38, "garagefinish_unf": 38, "garagequ": [38, 40, 49], "garagetyp": [38, 40, 49], "garagetype_2typ": 38, "garagetype_attchd": 38, "garagetype_bas": 38, "garagetype_builtin": 38, "garagetype_carport": 38, "garagetype_detchd": 38, "garagetype_miss": 38, "garageyrblt": [38, 40, 49], "garlic": 42, "gauss": 45, "gaussian": 43, "gaussianmixtur": 43, "gave": [44, 47], "gbr": 8, "gca": [42, 43, 48], "gd": [29, 38, 40, 49], "gdprv": [38, 40, 49], "gdwo": [38, 40, 49], "gelbart": [0, 1, 30, 45, 57], "gender": [29, 34, 37, 45, 47, 48, 58], "gender_femal": 48, "gender_mal": 48, "gener": [7, 9, 15, 30, 33, 34, 36, 37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 57, 58, 60, 61], "genet": 41, "genom": 41, "genr": 44, "gensim": 45, "gentl": 61, "geograph": [35, 50], "geometr": 30, "georg": 45, "geq": 35, "ger": 8, "german": 45, "get": [4, 5, 6, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61], "get_avg_word_length": 51, "get_cmap": 33, "get_depth": 55, "get_dummi": 33, "get_featur": 46, "get_feature_names_out": [33, 34, 37, 38, 39, 40, 41, 45, 47, 48, 49, 51, 58, 60], "get_length_in_word": 51, "get_lr_data_per_us": 44, "get_permutation_import": 40, "get_relative_length": 51, "get_season": 47, "get_senti": 51, "get_stat": 44, "get_text": 49, "get_user_profil": 44, "getattr": 48, "gif": [42, 43], "gift": 51, "gini": [30, 40, 49], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 29, 33, 34, 36, 37, 38, 39, 40, 41, 46, 49, 50, 51, 57, 58], "githubusercont": 8, "gitlf": 37, "giulia": [0, 1], "give": [0, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 55, 58], "given": [0, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 60], "gladwel": 42, "glass": 49, "glob": [29, 46], "global": [33, 37, 39, 42, 45, 53], "glove": [45, 61], "glq": [38, 40, 49], "gmail": [29, 42], "go": [5, 7, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60], "goal": [2, 32, 33, 36, 37, 42, 43, 44, 45, 50, 51, 57, 59, 60, 61], "goe": [2, 31, 32, 34, 37, 39, 40, 43, 44, 46, 49, 50], "gold": 8, "goldcoast": 47, "golden": [32, 50, 53, 55], "good": [9, 11, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60], "googl": [4, 10, 29, 30, 39, 40, 41, 42, 45, 49, 51], "google_news_vector": 45, "got": [32, 35, 36, 37, 38, 46], "gotten": [48, 59], "gov": [37, 39, 40], "govern": [45, 61], "gpe": 45, "gpt": [44, 45], "gpu": [39, 45, 46], "grad": [37, 39, 40, 58], "grade": [3, 7, 10, 29, 31, 34, 36, 49, 53, 55, 56, 57, 58, 59, 60], "grader": 6, "grades_df": 53, "gradescop": [1, 6, 10, 61], "gradient": [19, 20, 50, 53], "gradientboostingclassifi": 39, "gradientboostingregressor": [39, 49], "gradientexplain": 40, "grading_concern": 6, "graduat": 46, "grai": 46, "grain": [35, 40], "gram": 45, "grammat": 45, "grandma": 41, "grandmoth": [37, 50], "grant": 0, "granular": 43, "graph": [10, 46, 47], "graphic": 46, "graphviz": [30, 54], "grasp": [53, 61], "grayscal": 46, "great": [29, 30, 32, 34, 35, 40, 41, 45, 46, 47, 49, 51], "greater": [11, 41, 42], "greater_is_bett": 38, "greedili": 43, "green": [32, 36, 42, 49, 52], "grei": 61, "grid": [35, 38, 47, 48, 53, 57, 60], "grid_result": 49, "grid_search": [36, 49, 57], "gridsearchcv": [32, 39, 40, 57, 59], "gridsearchcvifittedgridsearchcv": 36, "grinberg": 50, "grip": 45, "grlivarea": [38, 40, 49], "groak": 45, "groceri": [46, 51], "groin": 46, "ground": [31, 41, 43, 44, 61], "ground_truth_categori": [37, 50], "group": [7, 30, 32, 34, 35, 39, 41, 53, 55, 56, 59, 61], "groupbi": [47, 60], "grow": [36, 39, 41], "grow_polici": 39, "growth": [47, 48], "groyn": 46, "grv": 38, "gsc": 49, "gt": [34, 35, 36, 37, 38, 39], "gtl": 40, "guarante": [36, 37, 39, 42, 46], "guenon": 46, "guess": [32, 33, 45, 51], "guid": [7, 9, 10, 41, 46, 50, 61], "guidanc": 40, "guidelin": [40, 41, 50], "guido": 10, "h": [37, 39, 40, 42, 45, 46, 48, 50, 51, 58], "ha": [2, 5, 6, 10, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 58, 59, 60, 61], "habit": [34, 49, 50], "hacki": [46, 52], "had": [29, 33, 34, 35, 37, 44, 46, 47, 48, 50], "hadn": 48, "hal": 10, "half": [6, 10, 30, 35, 41, 43], "halfbath": [38, 40, 49], "halvingrandomsearchcv": 36, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 36, "ham": 29, "hand": [4, 9, 37, 44, 58, 61], "handi": 37, "handl": [39, 40, 43, 48, 50, 51, 52, 53, 55, 61], "handle_unknow": 34, "handle_unknown": [33, 34, 36, 37, 38, 39, 40, 47, 48, 49, 53, 57, 58, 59, 60], "handler": [37, 40], "handrail": 46, "handwritten": [37, 49], "hang": 37, "happen": [4, 6, 29, 32, 34, 36, 39, 40, 41, 44, 47, 48, 49, 53, 60, 61], "happi": [37, 42, 48], "happier": [50, 61], "happydb": [37, 50], "hard": [8, 29, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 59], "hardli": 44, "hardwar": 46, "harmon": 37, "harri": 45, "has_cupi": 51, "has_emoji": 51, "has_rais": 51, "hasn": [4, 44, 48], "hassl": [8, 40, 47], "hat": [35, 38, 39], "have": [0, 4, 6, 7, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61], "haven": [31, 48, 49, 50, 53], "haylei": 30, "hazard": 61, "hc_truncation_toy_demo": 43, "hdbscan": 43, "he": [31, 34, 61], "head": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60], "header": 50, "headlin": [45, 49], "health": 45, "healthcar": 40, "healthi": [45, 49], "heard": 31, "heart": [30, 51, 59], "heart_df": 59, "heartdiseas": 59, "heat": [36, 38, 40, 49, 57], "heating_floor": 38, "heating_gasa": 38, "heating_gasw": 38, "heating_grav": 38, "heating_othw": [38, 40], "heating_wal": 38, "heatingqc": [38, 40, 49], "heatmap": 40, "heavi": [39, 51], "heavili": [44, 46, 47, 58], "heeren": 45, "height": [30, 31, 37, 45, 51, 54], "hell": 51, "help": [3, 7, 11, 29, 31, 33, 34, 36, 37, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 56, 60, 61], "henc": [5, 37, 38, 40, 42], "her": [29, 44, 45], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61], "herebi": 0, "herself": 51, "herta": 32, "hesist": 49, "hesit": 49, "heurist": [30, 36], "hi": [45, 55], "hidden": [41, 46, 49], "hide": [8, 46, 49], "hier_label": 43, "hier_labels1": 43, "hier_labels2": 43, "hierarch": [53, 61], "hierarchi": [30, 43], "high": [6, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 61], "high_corr": 40, "higher": [30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 55, 57, 58], "highest": [39, 40, 44, 45, 46, 49, 52, 55, 58], "highland": 51, "highli": [10, 11, 33, 40, 44], "highlight": [4, 46, 49, 53], "highwai": 35, "hinder": 61, "hindi": 33, "hint": [40, 55], "hist": [33, 36, 38, 41, 48], "histgradientboostingclassifi": 39, "histgradientboostingregressor": 39, "histogram": 48, "histor": 53, "histori": [35, 44, 47, 61], "hit": [29, 36], "hitter": 51, "hl": [38, 40, 49], "hmid": [37, 50], "hmmm": 48, "hockei": 45, "hold": [49, 50, 57], "holder": 0, "holdout": 37, "holi": 49, "holidai": [10, 44, 61], "home": [30, 35, 37, 46, 50], "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 32, 35, 36, 45, 50, 53, 61], "honest": 49, "honour": 61, "hood": [31, 50], "hope": [31, 49, 50], "hopefulli": [50, 57], "hopeless": 41, "hopelessli": 32, "horizont": [30, 34], "host": [5, 48, 50], "hot": [16, 31, 34, 40, 53, 60], "hound": [29, 46], "hour": [4, 11, 37, 39, 40, 41, 44, 47, 50, 53, 58, 61], "hourli": [48, 53], "hous": [18, 38, 40, 41, 48, 49, 55], "houseag": 35, "household": [33, 34, 35, 41, 56], "housestyl": [38, 40, 49], "housestyle_1": 38, "housestyle_1stori": 38, "housestyle_2": 38, "housestyle_2stori": 38, "housestyle_sfoy": 38, "housestyle_slvl": 38, "housing_df": [30, 33, 34, 41, 55, 56], "housing_median_ag": [33, 34, 41, 56], "houston": 51, "how": [0, 3, 8, 11, 29, 34, 36, 37, 38, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61], "howard": 42, "howev": [2, 8, 33, 34, 37, 38, 40, 42, 44, 47, 48, 50, 52, 55, 58], "hsjcy": 48, "hstack": 47, "html": [7, 9, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 48, 49, 50, 51, 54, 56, 58], "http": [0, 5, 8, 9, 11, 29, 30, 31, 33, 34, 35, 37, 38, 39, 46, 47, 48, 49, 50, 51, 58, 61], "hug": 44, "huge": [34, 38, 45, 46, 47, 48, 60], "human": [0, 29, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 58], "humidity3pm": [47, 60], "humidity3pm_lag1": [47, 60], "humidity9am": [47, 60], "hummu": [42, 45], "humour": [10, 45], "hundr": 35, "hurrai": 59, "hurrican": 29, "husband": [37, 39, 40], "hussar": [29, 46], "hw": 29, "hw1": [4, 10, 54], "hw2": [10, 32, 33, 57], "hw3": 10, "hw4": 10, "hw5": [10, 61], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 44, "hyper": 49, "hyperband": 36, "hyperopt": 36, "hyperparamet": [10, 31, 37, 43, 44, 45, 46, 49, 50, 57], "hyperparameter_": 49, "hyperparamt": [31, 36, 48], "hyperparlan": 35, "hyperplan": 35, "hypothesi": [45, 48, 50], "hypothet": [35, 42], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 35, 38, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "i1": 39, "i2": 39, "ia": 51, "ibm": 51, "ic": 45, "icc": 61, "iclick": 10, "id": [29, 30, 38, 40, 44, 49, 55], "idea": [8, 30, 31, 33, 36, 40, 42, 43, 44, 45, 46, 47, 48, 50, 53, 55, 60], "ideal": [4, 37, 39, 41, 44, 48, 50], "ident": [45, 46, 51], "identif": [29, 51], "identifi": [30, 31, 32, 33, 36, 37, 38, 42, 43, 45, 46, 47, 49, 50, 53, 58, 60, 61], "idf": 34, "idx": 46, "idxmax": 32, "if_binari": [34, 37, 39, 40, 53, 56, 58, 59], "ifram": [31, 37], "igloo": 45, "ignor": [30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 47, 48, 49, 53, 57, 58, 59, 60], "ignore_index": 8, "ii": 37, "iii": 10, "ij": [35, 44], "ik": 39, "ill": 61, "illus": [37, 58], "illustr": [43, 47], "iloc": [8, 30, 31, 32, 33, 34, 39, 40, 45, 47, 51, 54, 59, 60], "im": 51, "imag": [7, 31, 37, 40, 41, 42, 43, 47, 49, 53, 58, 61], "image_dataset": 46, "image_datasets_bw": 46, "image_s": 46, "imagefold": 46, "imagenet": 52, "imagenet1k_v1": 46, "imagenet_class": [29, 46], "imagin": [29, 30, 31, 33, 35, 37, 40, 41, 42, 45, 48, 49, 50, 53, 54, 58], "imaginari": [31, 45], "imbal": [18, 42, 48, 58], "imbalanc": [37, 38, 52], "imblearn": 37, "img": [29, 46], "img_classifi": 29, "img_path": 29, "img_t": 46, "immedi": [40, 44, 61], "imp": [33, 34, 47], "impact": [7, 34, 35, 39, 40, 43, 47, 49, 55, 60, 61], "implement": [2, 4, 29, 33, 37, 38, 39, 41, 43, 44, 45, 48, 49, 50, 52], "impli": [0, 48], "implic": [33, 50, 53, 61], "implicit": 45, "import": [8, 10, 21, 22, 23, 24, 25, 26, 27, 28, 52, 56, 57, 58, 59, 61], "importance_typ": 39, "importances_mean": 40, "impos": 33, "imposs": 42, "impress": 40, "improv": [36, 37, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 53, 57, 61], "impur": [30, 39], "imput": [16, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60], "imread": 46, "imshow": [29, 46], "inbox": 31, "inc": [40, 45], "incept": [44, 46], "inception": 46, "incl": 38, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 30, 33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61], "include_bia": [41, 47], "incom": [31, 35, 37, 39, 40, 58], "incomplet": 48, "inconsist": 34, "incorpor": [36, 38, 41, 48, 50, 53], "incorrect": [48, 49], "incorrectli": [29, 37], "increament": 50, "increas": [8, 31, 32, 34, 35, 39, 40, 41, 42, 43, 46, 55, 57], "increasingli": 29, "incred": 46, "increment": 50, "inde": 40, "independ": [8, 9, 30, 36, 38, 39, 41, 47, 61], "index": [29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 55, 58, 59, 60], "index_col": [8, 32, 33, 36, 37, 44, 50, 57], "india": 45, "indian": 37, "indian_liver_pati": 29, "indic": [0, 34, 42, 44, 45, 46, 47, 48], "indirectli": 49, "individu": [39, 40, 42, 44, 45, 48, 50, 59, 61], "industri": [39, 41, 45, 46], "inequ": [37, 58], "inertia_": 42, "inertia_valu": 42, "inf": [32, 48], "infeas": 36, "infer": [30, 45, 46, 47, 50, 54], "infin": [32, 49], "infinit": 36, "inflamm": 9, "inflat": 40, "inflect": [42, 45], "influenc": [30, 31, 36, 40, 42, 44, 48, 55], "info": [1, 3, 8, 33, 34, 37, 38, 41, 45, 47, 48, 55, 59, 60], "inform": [1, 4, 7, 11, 30, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 55, 58, 59, 60, 61], "inhabit": 61, "inher": [37, 47, 48, 58], "initi": [43, 46, 51], "initj": 40, "inject": [41, 44, 53], "ink": 49, "inland": [33, 34, 41, 56], "inlin": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 49, 54, 55, 57, 58, 59], "inner": [34, 36, 45], "inplac": [8, 29, 30, 36], "input": [8, 30, 33, 35, 39, 40, 43, 45, 46, 47, 50, 51, 53, 60], "input_img": 46, "inputs_bw": 46, "insid": [9, 34, 37], "insight": [2, 32, 37, 40, 42, 61], "inspct": 37, "inspect": [40, 43], "inspir": [30, 37, 39], "instal": [29, 32, 37, 38, 39, 40, 42, 45, 46, 48, 50, 51], "instanc": [29, 30, 31, 34, 35, 37, 42, 43, 44, 45, 46, 47, 52], "instanti": [36, 55], "instead": [5, 8, 11, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 55, 57, 58, 59], "institut": 51, "instruct": [3, 4, 5, 11, 32, 49, 50, 61], "instructor": [4, 6, 29, 49, 50, 61], "instrument": [32, 33, 36, 57], "int": [33, 34, 37, 39, 40, 45, 47, 51, 58, 59, 60], "int32": [32, 42, 43, 47], "int64": [30, 32, 34, 37, 38, 44, 47, 48, 50, 51], "integ": [8, 31, 33, 36, 39, 40, 47], "integr": [50, 61], "intellig": [10, 45], "intend": [0, 49], "intens": 45, "inter": 51, "interact": [9, 32, 36, 37, 40, 42, 43, 44, 47, 50, 51, 55], "interaction_constraint": 39, "interaction_onli": [41, 47], "interactive_plot": [32, 55], "interactiveshel": [50, 51], "intercept": [40, 46, 52], "intercept_": [35, 39, 46, 52], "intercept_sc": 37, "interest": [2, 29, 31, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 55, 57, 59, 60], "interfac": [39, 50], "intermedi": [43, 46], "intern": [0, 1, 30, 46, 47, 48, 51], "internet": [48, 49, 50], "internetservic": 48, "internetservice_dsl": 48, "internetservice_fib": 48, "internetservice_no": 48, "internship": 29, "interpret": [10, 11, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 58, 61], "interv": [47, 48, 53, 57, 61], "interweb": 50, "intrins": 47, "intro": [10, 19, 20, 45, 46], "introduc": [34, 37, 48], "introduct": [9, 10, 11, 13, 16, 47, 48, 55, 61], "intslid": [32, 55], "intuit": [32, 33, 34, 36, 38, 40, 42, 43, 48, 51, 61], "invalid": [36, 49], "inventori": 53, "invers": [35, 38], "inverse_func": [38, 49], "investig": [32, 40, 55], "involv": [2, 4, 36, 38, 39, 43, 45, 46], "io": [9, 33, 46, 48, 51], "io_loop": 51, "io_open": 50, "ipkernel": 51, "ipykernel": 51, "ipykernel_19402": 40, "ipykernel_32469": 33, "ipykernel_79734": 31, "ipykernel_86208": 51, "ipykernel_launch": 51, "ipynb": [7, 8], "ipython": [29, 30, 31, 32, 33, 34, 35, 37, 45, 50, 51, 54, 56, 58], "ipywidget": [32, 55], "ir1": [38, 40, 49], "ir2": [38, 40, 49], "iri": [32, 55], "iris_df": [32, 55], "irregular": 61, "irregularli": 53, "irrelev": [32, 41, 45], "irrelevant_po": 45, "irrespect": [31, 35, 61], "is_avail": 46, "is_leap_year": [47, 60], "is_stop": 45, "is_year_end": [47, 60], "isinst": 48, "island": [33, 34], "isn": [31, 32, 37, 38, 39, 49], "isnul": 33, "isol": [11, 37, 38, 40, 49], "issu": [4, 6, 7, 39, 44, 48, 53, 57, 61], "issubclass": 48, "isupp": 51, "itali": 45, "item": [29, 39, 40, 42, 44, 45, 46, 48, 53, 59], "item_inverse_mapp": 44, "item_kei": 44, "item_mapp": 44, "iter": [36, 41, 42, 43, 46, 50], "iterable_with_config": 34, "iterrow": 44, "its": [8, 29, 31, 32, 34, 35, 37, 40, 42, 43, 45, 46, 47, 48, 51, 52, 55, 57, 60, 61], "itself": [7, 37, 39, 43], "j": [8, 35, 40, 41, 42, 44, 46], "j6": 51, "jackin": 36, "jackpot": 34, "jaguar": [29, 46], "jam": 36, "jame": [45, 48, 51], "jan": 1, "januari": 47, "japan": 45, "jargon": 30, "jason": [10, 41], "javascript": 40, "jellyfish": 46, "jennif": 51, "jerri": 44, "jet": 33, "jetti": 46, "jieba": 45, "jim": 44, "jmlr": 36, "job": [34, 47, 48, 60], "joblib": [34, 50], "john": 39, "join": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61], "jointli": 47, "joke": [29, 44], "jolen": 51, "joseph": 61, "journal": 45, "journei": [10, 43, 61], "jpg": 46, "json": 50, "ju": 29, "jubatu": [29, 46], "judg": 41, "judgment": 49, "juic": 45, "juli": 47, "jun": 61, "june": [10, 47], "junh": 61, "jupyt": [1, 7, 8, 9, 11, 29, 33, 34, 36, 37, 38, 39, 40, 41, 46, 49, 50, 51], "jupyter_notebook": 48, "jupyterlab": 40, "jurafski": 45, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53, 55, 59, 60, 61], "justic": [40, 61], "justif": 59, "k": [7, 10, 15, 31, 35, 37, 38, 39, 41, 45, 46, 48, 50, 51, 52, 55, 61], "k_neighbor": 37, "k_valu": 32, "kaggl": [30, 33, 37, 38, 39, 40, 41, 46, 49, 58, 59], "kaggler": 41, "kangaroo": 46, "kaplan": 61, "kaplanmeierfitt": 48, "kb": [34, 38, 48], "kbinsdiscret": 41, "kbinsdiscretizer__latitude_0": 41, "kbinsdiscretizer__latitude_1": 41, "kbinsdiscretizer__latitude_2": 41, "kbinsdiscretizer__latitude_3": 41, "kbinsdiscretizer__latitude_4": 41, "kbinsdiscretizer__latitude_5": 41, "kbinsdiscretizer__latitude_6": 41, "kbinsdiscretizer__latitude_7": 41, "kbinsdiscretizer__latitude_8": 41, "kbinsdiscretizer__latitude_9": 41, "kbinsdiscretizer__longitude_11": 41, "kbinsdiscretizer__longitude_12": 41, "kbinsdiscretizer__longitude_13": 41, "kbinsdiscretizer__longitude_14": 41, "kbinsdiscretizer__longitude_15": 41, "kbinsdiscretizer__longitude_16": 41, "kbinsdiscretizer__longitude_17": 41, "kbinsdiscretizer__longitude_18": 41, "kbinsdiscretizer__longitude_19": 41, "kbinsdiscretizerkbinsdiscret": 41, "kc_house_data": [29, 30, 55], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 37, 39, 40, 41, 42, 44, 45, 48, 50, 55, 56, 61], "keep_empty_featur": 44, "kei": [9, 30, 31, 32, 33, 36, 37, 38, 39, 44, 45, 48, 57, 59, 61], "kelbowvisu": 42, "kellei": 35, "kelli": 61, "kept": 31, "kera": 40, "kernel": [7, 10, 15, 33, 35, 36, 40, 41, 49, 55], "kernelapp": 51, "kernelbas": 51, "kernelexplain": 40, "keyword": [4, 36, 51], "kfold": 37, "kick": 45, "kilian": 40, "kill": 48, "kimia": 61, "kind": [0, 29, 30, 31, 33, 34, 35, 37, 38, 40, 42, 43, 44, 46, 47, 48, 50, 52, 60], "king": [44, 45, 55], "kitchenabvgr": [38, 40, 49], "kitchenqu": [38, 40, 49], "kk": 42, "km": [48, 49, 53], "km_label": 42, "kmean": [42, 43, 53], "kmf": 48, "kmqfw": 48, "kneighborregressor": 33, "kneighborsclassifi": [33, 34, 35, 41, 55, 56], "kneighborsregressor": [33, 34, 35, 56], "kneighborsregressorkneighborsregressor": [33, 34], "knew": 42, "knn": [2, 15, 31, 32, 33, 34, 35, 40, 41, 44, 46, 50, 52, 53, 59], "knn1": 32, "knn100": 32, "knn_pipe": 34, "knn_scale": 33, "knn_unscal": 33, "knn_valid_accuraci": 32, "knnimput": 44, "knob": [30, 49], "know": [8, 10, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61], "knowledg": [8, 30, 34, 36, 41, 42, 45, 49, 53], "knowleg": 53, "known": [44, 45, 48], "koala": 46, "kolhatkar": [0, 1, 45], "kr9rkqfj4w78h49djkz8yy9r0000gp": 31, "ksatr": 48, "kvarada": [11, 30, 31, 34, 36, 40, 46, 48, 52], "kvarada01": 11, "kwarg": [31, 33, 34, 48, 50, 51], "l": 11, "l1": [10, 48], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 37, "l2": [10, 37, 45, 48], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "la": 49, "lab": [11, 30, 31, 42, 44], "lab1": [30, 31, 34, 53], "lab2": [30, 31, 34, 53], "lab3": [30, 31, 34, 53], "lab4": [30, 31, 34, 53], "label": [7, 8, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 56], "label_": [45, 51], "label_encod": [39, 40], "label_n_clust": 43, "labelencod": [39, 40], "labels": [37, 42], "labels_": [42, 43], "lack": [31, 44, 49], "lag": [48, 53], "lag_df": 47, "lakeshor": 46, "lakesid": 46, "lambda": [8, 30, 35, 43, 46, 47, 48, 51], "land": 48, "landcontour": [38, 40, 49], "landcontour_bnk": [38, 49], "landcontour_hl": [38, 49], "landcontour_low": [38, 49], "landcontour_lvl": [38, 49], "landmark": 53, "landown": 51, "landscap": [42, 45], "landslop": [38, 40, 49], "landslope_gtl": [38, 40, 49], "landslope_mod": [38, 40, 49], "landslope_sev": [38, 40, 49], "languag": [2, 9, 33, 34, 44, 46, 50, 51], "language_enc": 33, "language_english": 33, "language_french": 33, "language_hindi": 33, "language_mandarin": 33, "language_spanish": 33, "language_vietnames": 33, "laptop": [29, 50], "lar": 29, "larg": [29, 31, 32, 33, 35, 37, 38, 42, 43, 45, 46, 50, 53, 55, 58], "larger": [30, 31, 32, 33, 35, 36, 38, 39, 40, 42, 43, 48], "largest": 38, "larvatu": [29, 46], "last": [8, 25, 28, 30, 31, 32, 33, 34, 37, 40, 44, 46, 47, 48, 50, 51, 55, 57, 59, 60, 61], "last_row": 8, "lastp": 43, "lat": [29, 30], "late": [37, 61], "latent": [44, 45, 46], "latentdirichletalloc": 45, "later": [11, 30, 34, 37, 46, 47, 50, 55], "latest": [34, 40, 48], "latex": [4, 7], "latin": [29, 37, 58], "latitud": [31, 32, 33, 34, 35, 41, 56], "latitude_0": 41, "latitude_1": 41, "latitude_10": 41, "latitude_11": 41, "latitude_12": 41, "latitude_13": 41, "latitude_14": 41, "latitude_15": 41, "latitude_16": 41, "latitude_17": 41, "latitude_18": 41, "latitude_19": 41, "latitude_2": 41, "latitude_3": 41, "latitude_4": 41, "latitude_5": 41, "latitude_6": 41, "latitude_7": 41, "latitude_8": 41, "latitude_9": 41, "latter": 38, "launch_inst": 51, "launch_new_inst": 51, "lauvagrand": 51, "law": 45, "lawsuit": 45, "layer": 46, "layout": [32, 55], "lazi": 32, "lbfg": 37, "lda": 46, "ldot": 36, "lead": [8, 10, 31, 35, 38, 43, 44, 45, 48, 49], "leaf": [30, 43], "leak": [33, 48, 53], "leakag": 53, "leaner": 31, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "learner": [31, 32, 39], "learning_method": 45, "learning_r": 39, "learnxinyminut": 9, "least": [4, 10, 31, 32, 37, 38, 40, 41, 42, 43, 49, 59, 60, 61], "least_confident_i": 35, "least_confident_x": 35, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 43, 46, 48, 49, 52], "lec11": 19, "lec16": 25, "lec17": 25, "lectur": [5, 7, 8, 11, 19, 25, 53, 58], "lecun": 40, "lee": 40, "left": [7, 29, 36, 37, 38, 42, 43, 45, 47, 48, 49, 61], "legal": [0, 45], "legend": [7, 8, 32, 35, 37, 38, 41, 42, 46, 47, 48, 49, 52], "legendari": 51, "leisur": [37, 50], "lemma": 45, "lemma_": 45, "lemmat": 45, "lemon": 42, "len": [31, 33, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 49, 51], "length": [30, 31, 32, 35, 38, 40, 42, 43, 45, 47, 48, 51, 55, 60], "leo": 39, "leopard": [29, 46], "leq": [41, 42], "less": [5, 6, 10, 29, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 48, 49, 53, 55, 58], "lesson": [9, 33, 51], "lesssim": 31, "let": [29, 30, 31, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "letter": [35, 51], "lev": 38, "level": [32, 35, 37, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 58, 61], "leverag": [40, 44], "lewi": 51, "lexic": 45, "lexicon": 51, "lg": [19, 23, 24, 25, 26, 27, 28], "lgbm": [39, 40, 53, 61], "lgbmclassifi": [29, 39, 40, 59], "lgbmclassifierifittedlgbmclassifi": [29, 40], "lgbmclassifierlgbmclassifi": 39, "lgbmregressor": [29, 39], "li": 35, "liabil": 0, "liabl": 0, "liao": 29, "lib": [30, 31, 34, 36, 40, 48, 50, 51, 52], "librari": [4, 8, 11, 31, 37, 40, 41, 45, 46, 47, 49, 51, 55], "licensor": 0, "life": [30, 35, 42, 44, 49, 50, 54, 61], "lifelin": [48, 61], "lifetim": 48, "lighter": 36, "lightgbm": [29, 40, 50, 59], "lightweight": 45, "like": [2, 4, 7, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61], "likelihood": 48, "likewis": 7, "lime": 40, "limit": [0, 29, 30, 31, 34, 39, 40, 49, 50, 51, 53, 54, 57, 61], "linalg": 45, "line": [4, 8, 11, 30, 34, 35, 36, 37, 38, 42, 45, 46, 47, 48, 49, 50, 51, 55, 57], "line2d": 8, "linear": [10, 17, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 39, 41, 43, 44, 46, 47, 48, 49, 50, 52, 53], "linear_model": [29, 35, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 58, 59, 60], "linear_svc": 35, "linearli": [35, 41, 47], "linearregress": [35, 38, 41, 48, 51], "linestyl": [42, 47, 60], "linewidth": [47, 49], "linger": 32, "lingual": 45, "linguist": 34, "link": [0, 4, 5, 7, 10, 29, 30, 34, 35, 38, 39, 43, 48, 49, 50], "linkag": 43, "linkage_arrai": 43, "linkage_typ": 43, "linkedin": 44, "linspac": [35, 36, 38, 41, 49, 57], "lion": 44, "list": [4, 7, 8, 11, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 59, 61], "listedcolormap": 35, "liter": 51, "literatur": 39, "littl": [8, 37, 46, 49, 50], "live": [10, 11, 32, 33, 34, 36, 42, 48, 49, 50, 57], "liver": 30, "livestream": 61, "ll": [6, 7, 10, 11, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 60, 61], "llazx": 48, "llm": 10, "lo": 51, "load": [8, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 49, 51, 55, 56, 58], "load_breast_canc": 41, "load_citibik": 47, "load_digit": 49, "load_iri": [32, 55], "loan": [37, 58], "loc": [8, 32, 35, 37, 40, 44, 47, 48, 49, 60], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 37, 39, 40, 41, 46, 51], "locat": [8, 34, 42, 44, 45, 47, 51, 59, 60, 61], "location_katherin": 47, "location_mountginini": 47, "location_townsvil": 47, "location_witchcliff": 47, "location_wollongong": 47, "lock": 31, "log": [32, 38, 39, 48, 49, 50, 55, 59, 61], "log10": 38, "log1p": [38, 49], "log2": 48, "log_likelihood_ratio_test": 48, "log_loss": 49, "logarithm": [32, 55], "logic": 41, "logical_xor": 41, "login": 44, "logisit": 46, "logist": [17, 39, 40, 47, 48, 49, 50, 51, 52, 53, 58, 59, 60], "logisticregress": [29, 35, 38, 39, 40, 41, 45, 46, 50, 51, 52, 58, 59, 60], "logisticregressionifittedlogisticregress": 46, "logisticregressionlogisticregress": [37, 39, 46, 51], "logloss": 40, "lognorm": 36, "logspac": [36, 57], "loguniform": [36, 57], "lol": 34, "london": 51, "lone": 43, "long": [0, 29, 30, 35, 37, 39, 43, 44, 48, 50, 53, 61], "longer": [7, 36, 37, 46, 48, 49, 50], "longest": 30, "longitud": [31, 32, 33, 34, 35, 41, 56], "longitude_0": 41, "longitude_1": 41, "longitude_10": 41, "longitude_11": 41, "longitude_12": 41, "longitude_13": 41, "longitude_14": 41, "longitude_15": 41, "longitude_16": 41, "longitude_17": 41, "longitude_18": 41, "longitude_19": 41, "longitude_2": 41, "longitude_3": 41, "longitude_4": 41, "longitude_5": 41, "longitude_6": 41, "longitude_7": 41, "longitude_8": 41, "longitude_9": 41, "look": [1, 11, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59], "lookatm": 29, "loop": [36, 39, 47, 52, 53], "loos": [43, 50], "lose": [6, 34], "loss": [2, 37, 38, 39, 40, 45, 48, 58], "lot": [5, 9, 29, 30, 32, 34, 35, 36, 37, 38, 40, 41, 43, 46, 47, 48, 49, 50, 57, 61], "lotarea": [38, 40, 49], "lotconfig": [38, 40, 49], "lotconfig_corn": 38, "lotconfig_culdsac": 38, "lotconfig_fr2": 38, "lotconfig_fr3": 38, "lotconfig_insid": 38, "lotfrontag": [38, 40, 49], "lotshap": [38, 40, 49], "lotshape_ir1": 38, "lotshape_ir2": 38, "lotshape_ir3": 38, "lotshape_reg": 38, "loud": [32, 33, 36, 53, 57], "loui": 47, "lourenzutti": 36, "love": [50, 51], "low": [6, 31, 32, 36, 37, 38, 40, 41, 42, 43, 48, 49, 50], "lower": [31, 32, 37, 38, 40, 42, 44, 45, 48, 49, 57, 61], "lowercas": [33, 34], "lowest": [55, 61], "lowqualfinsf": [38, 40, 49], "lr": [35, 37, 38, 40, 46, 47, 48, 51, 52], "lr_1": 41, "lr_2": 41, "lr_3": 41, "lr_coef": [40, 47, 48, 60], "lr_coefs_landslop": 40, "lr_flatten_pip": 46, "lr_item": 44, "lr_pipe": [38, 40, 47], "lr_pred": [37, 38], "lr_scale": 40, "lr_schedul": 46, "lr_x": 44, "lr_y": 44, "ls15hb": 29, "lstm": 47, "lt": [31, 33, 34, 36, 37, 38, 39, 40, 41, 48], "ltorgo": 35, "luck": 50, "lucki": [32, 36], "luckili": [57, 59], "lundberg": 40, "luster": 43, "lvert": 45, "lvl": [38, 40, 49], "lwq": [38, 40, 49], "lynx": [29, 46], "l\u00e9cuyer": 45, "m": [11, 29, 31, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "m_neighbor": 37, "ma": 36, "macaqu": [29, 46], "macbook": 11, "machin": [2, 9, 10, 11, 13, 14, 15, 33, 34, 36, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 53, 55, 60, 61], "machine_learn": 49, "mackworth": 10, "made": [0, 6, 7, 8, 29, 30, 37, 39, 40, 44, 45, 46, 47, 49, 50, 57], "magazin": 45, "magnitud": [36, 38, 40, 45, 47, 60], "maguir": 44, "mahsa": 61, "mai": [0, 7, 8, 10, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61], "mail": 48, "main": [8, 11, 30, 32, 34, 39, 42, 43, 53, 61], "mainland": 35, "maintain": [39, 44, 49, 53], "mainten": 39, "maj1": [38, 40, 49], "maj2": [38, 40, 49], "major": [2, 31, 32, 33, 34, 45, 53, 54, 59], "major_biologi": 34, "major_comput": 34, "major_econom": 34, "major_linguist": 34, "major_mathemat": 34, "major_mechan": 34, "major_phys": 34, "major_psychologi": 34, "make": [2, 4, 5, 6, 7, 11, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 58, 59, 60, 61], "make_blob": [32, 42, 43, 46, 52], "make_circl": 43, "make_classif": [32, 37], "make_column_transform": [36, 37, 38, 39, 40, 41, 47, 48, 49, 51, 56, 57, 58, 59, 60], "make_forg": 32, "make_grid": 46, "make_imb_pipelin": 37, "make_moon": 43, "make_num_tree_plot": 39, "make_pipelin": [29, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60], "make_scor": [38, 41, 51], "maker": 49, "malcolm": [42, 44], "malcom": 42, "male": [37, 39, 40, 48, 58], "male_cm": [37, 58], "male_pr": [37, 58], "mall": 51, "man": [44, 45], "manag": [5, 47, 48, 49, 53, 61], "mandarin": 33, "mango": 45, "mani": [2, 5, 8, 10, 29, 30, 31, 32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 57, 59, 60, 61], "manipul": 49, "manner": [0, 39], "manual": [11, 29, 34, 37, 41, 42, 43, 45, 57], "manufactur": 46, "map": [10, 30, 31, 34, 36, 44, 57], "mape": [50, 53], "mape_scor": 38, "mapper": 44, "march": 47, "marit": [37, 39, 40, 58], "mark": [6, 7, 36, 37, 43, 61], "marker": [32, 35, 42], "markers": [35, 37], "market": [29, 42, 46, 47, 49, 50], "marri": [37, 39, 40], "martin": 45, "mask": 36, "massiv": [34, 36], "master": [8, 36, 37, 39, 40, 45, 58], "masvnrarea": [38, 40, 49], "masvnrtyp": [38, 40, 49], "masvnrtype_brkcmn": 38, "masvnrtype_brkfac": [38, 49], "masvnrtype_miss": [38, 49], "masvnrtype_ston": [38, 49], "match": [34, 35, 37, 39, 40, 47, 59, 60], "materi": [8, 11, 19, 29, 30, 31, 32, 42, 45, 48, 53, 61], "matern": 41, "math": [2, 42, 44, 48], "mathcal": 32, "mathemat": [2, 34, 39, 50, 53], "mathematician": 45, "mathia": 51, "matlab": 8, "matplotlib": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60], "matplotlibdeprecationwarn": 40, "matric": [32, 37, 44, 58], "matrix": [18, 34, 43, 45, 50, 53, 58], "matter": [33, 34, 37, 39, 43, 49, 53], "max": [8, 31, 33, 35, 36, 37, 38, 39, 42, 43, 47, 60], "max_bin": 39, "max_cat_threshold": 39, "max_cat_to_onehot": 39, "max_clust": 43, "max_colwidth": [29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 54, 55, 56, 57, 58], "max_delta_step": 39, "max_depth": [31, 32, 36, 39, 40, 49, 54, 55], "max_depth_widget": [32, 55], "max_df": 34, "max_displai": 40, "max_featur": [29, 34, 36, 39, 49, 57], "max_it": [29, 37, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 52, 58], "max_leaf_nod": [30, 49], "max_leav": 39, "max_opt": [32, 37, 42, 43], "max_row": 48, "max_sampl": 49, "maxclust": 43, "maxent": 52, "maxhr": 59, "maxim": [29, 37, 38, 42], "maximum": [30, 33, 38, 39, 42, 43, 55, 61], "maxosx": 11, "maxtemp": [47, 60], "may": 10, "mayb": [37, 40, 47, 49, 61], "maybe_coerce_valu": 48, "mb": [33, 34, 37, 41, 47, 48, 60], "md": [11, 30, 45], "me": [8, 29, 36, 49, 50, 51], "mean": [5, 6, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 46, 47, 48, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61], "mean_absolute_error": 50, "mean_absolute_percentage_error": 38, "mean_cv_error": 31, "mean_cv_scor": [32, 35, 36], "mean_fit_tim": [36, 38], "mean_scor": [31, 33, 36, 51], "mean_score_tim": [36, 38], "mean_squared_error": [38, 41, 51], "mean_std_cross_val_scor": [31, 33, 34, 39, 40, 48, 51], "mean_test_neg_mean_squared_error": 38, "mean_test_scor": [36, 38, 57], "mean_train_error": 31, "mean_train_neg_mean_squared_error": 38, "mean_train_scor": [32, 35, 36, 38], "meaning": [32, 34, 37, 40, 42, 45, 56, 61], "meaningless": 43, "measur": [0, 29, 30, 31, 32, 37, 38, 40, 42, 43, 44, 45, 47, 48, 49, 50, 53, 55, 59, 60], "mechan": [34, 53], "medal": 8, "media": 49, "median": [30, 33, 34, 35, 38, 40, 41, 47, 48, 49, 60], "median_house_valu": [33, 34, 41, 56], "median_incom": [33, 34, 41, 56], "mediat": 49, "medic": [37, 42, 61], "medinc": 35, "medit": [37, 50], "medium": [0, 32, 48, 53], "meet": 45, "meier": 61, "melbourneairport": [47, 60], "member": [35, 39, 61], "membership": [34, 42, 43], "memori": [8, 33, 34, 37, 38, 39, 41, 46, 47, 48, 53, 60], "mental": 49, "mention": [0, 4, 35, 48, 49], "menu": [11, 50], "merchant": 0, "merg": [0, 5, 11, 43], "meshgrid": 41, "mess": [44, 48], "messag": [4, 6, 11, 31, 34], "messi": [41, 45], "met": 61, "meta": 39, "metacademi": 10, "method": [2, 30, 32, 33, 35, 37, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 59, 60, 61], "methodologi": [33, 47], "metric": [10, 32, 34, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 58, 59, 61], "mexico": 37, "mglearn": [30, 31, 32, 33, 34, 35, 36, 37, 42, 45, 46, 47, 52, 54, 55, 57, 58], "mi": [29, 36, 37, 49], "microsoft": 51, "midnight": 47, "midterm": [6, 10], "might": [6, 10, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 55, 61], "miguel": 50, "mike": [0, 1, 9, 30, 50, 57], "mikolov": 45, "milk": 45, "mill": 39, "millennia": 61, "million": 46, "min": [10, 35, 38, 43, 47, 60], "min1": [38, 40, 49], "min2": [38, 40, 49], "min_child_weight": 39, "min_df": 34, "min_impurity_decreas": 49, "min_impurity_split": 49, "min_sampl": 43, "min_samples_leaf": [30, 49], "min_samples_split": [30, 49], "min_token_len": 45, "min_token_length": 45, "min_weight_fraction_leaf": 49, "mind": [31, 33, 34, 39, 40, 44, 48, 49, 53, 61], "mine": 10, "minibatchkmean": 43, "miniconda": 11, "miniconda3": [11, 50, 51], "miniforge3": [30, 31, 34, 36, 40, 48, 52], "minim": [5, 30, 38, 42, 43, 49], "minimum": [8, 31, 33, 43, 45], "minmaxscal": [33, 34, 49], "minor": [6, 48], "mintemp": [47, 60], "minut": [4, 30, 41, 48, 53], "miracl": 51, "miscalcul": 10, "miscfeatur": [38, 40, 49], "miscfeature_gar2": 38, "miscfeature_miss": 38, "miscfeature_othr": 38, "miscfeature_sh": 38, "miscfeature_tenc": 38, "misclassifi": 58, "misconduct": 61, "miscval": [38, 40, 49], "mislead": [31, 37], "miss": [11, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 47, 48, 49, 53, 55, 57, 58, 60, 61], "mistak": [33, 39, 48, 49, 55], "mit": [0, 1], "mitig": [44, 61], "mitlp": 48, "mitt": 45, "mitten": 45, "mix": [38, 49, 50], "mixtur": [43, 45, 46], "ml": [2, 9, 10, 14, 15, 30, 33, 39, 43, 45, 46, 50, 61], "ml_experi": [30, 31, 34, 53], "mlpclassifi": 46, "mlpregressor": 46, "mm": [47, 60], "mmsto": 29, "mn": [38, 40, 49], "mnprv": [38, 40, 49], "mnww": [38, 40, 49], "mobil": [34, 46], "mobilenet": 46, "mod": [38, 40, 49], "mode": [32, 33, 36, 57], "model": [2, 10, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 42, 43, 44, 47, 49, 52, 54, 57, 60, 61], "model_nam": 44, "model_select": [29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60], "modern": [10, 32, 45, 49], "modif": 48, "modifi": [0, 11, 37, 48, 50, 61], "modul": [9, 10, 30, 31, 37, 51], "moe": 36, "mole": 46, "mom": 41, "moment": [37, 57, 59, 61], "moment_predictor": 50, "mon": [10, 47], "mondai": [10, 47, 61], "monei": [8, 48], "monitor": 45, "monkei": [29, 46], "monotone_constraint": 39, "montani": 51, "month": [31, 34, 38, 48, 60], "month_nam": [47, 60], "monthli": 48, "monthlycharg": 48, "montreal": [45, 51], "moon": 43, "moosvi": [0, 1, 45, 61], "moral": [0, 42], "more": [1, 2, 5, 6, 8, 10, 11, 14, 31, 36, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61], "morn": 29, "morpholog": 45, "moskowitz": 42, "mosold": [38, 40, 49], "mosold_1": 38, "mosold_10": 38, "mosold_11": 38, "mosold_12": 38, "mosold_2": 38, "mosold_3": 38, "mosold_4": 38, "mosold_5": 38, "mosold_6": 38, "mosold_7": 38, "mosold_8": 38, "mosold_9": 38, "most": [7, 8, 11, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 59, 61], "most_confident_i": 35, "most_confident_x": 35, "most_frequ": [30, 32, 33, 37, 38, 40, 49, 54], "most_similar": 45, "mostli": [8, 34, 47], "motiv": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34], "mountginini": 47, "move": [7, 12, 35, 40, 41, 54, 59, 61], "movi": [35, 45, 51], "movie_feats_df": 44, "movie_id": 44, "movie_nam": 44, "movies_rated_by_pat": 44, "movies_to_pr": 44, "movieto": 51, "mpimg": 46, "mri": 53, "mrtssm448usn": 47, "mse": [30, 44, 50, 53], "msg": [34, 48], "mssubclass": [38, 40, 49], "mssubclass_120": 38, "mssubclass_160": 38, "mssubclass_180": 38, "mssubclass_190": 38, "mssubclass_20": 38, "mssubclass_30": 38, "mssubclass_40": 38, "mssubclass_45": 38, "mssubclass_50": 38, "mssubclass_60": 38, "mssubclass_70": 38, "mssubclass_75": 38, "mssubclass_80": 38, "mssubclass_85": 38, "mssubclass_90": 38, "mszone": [38, 40, 49], "mszoning_c": [38, 40], "mszoning_fv": 38, "mszoning_rh": 38, "mszoning_rl": 38, "mszoning_rm": 38, "much": [4, 5, 8, 30, 31, 32, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 57, 61], "mueller": 10, "multi": [38, 40, 42, 45, 47, 50], "multi_class": [37, 52], "multi_strategi": 39, "multiclass": [46, 50, 52], "multicoliniar": 40, "multicultur": 45, "multilevel": 38, "multimod": 42, "multinomi": 52, "multipl": [7, 8, 31, 35, 36, 39, 40, 45, 46, 47, 48, 60], "multiplelin": 48, "multiplelines_no": 48, "multiplelines_y": 48, "multipli": [35, 36, 37, 39, 41, 48], "music": [44, 51], "musqueam": 61, "must": [0, 6, 7, 8, 30, 31, 33, 40, 43, 45, 48, 51, 61], "mutual": 43, "mwf": 61, "my": [6, 11, 29, 36, 37, 42, 45, 49, 50, 51, 61], "my_heatmap": [36, 57], "my_map": 38, "mypreprocessor": 45, "myself": [30, 49], "m\u00fcller": 9, "n": [10, 30, 32, 35, 36, 38, 39, 40, 41, 43, 44, 45, 47, 49, 51, 52, 55, 60], "n_bin": 41, "n_class": [32, 37, 58], "n_cluster": [42, 43], "n_clusters_per_class": 37, "n_compon": 45, "n_constitu": 39, "n_estim": [41, 47, 48, 49], "n_estimators_valu": 49, "n_exampl": 42, "n_feat": 32, "n_featur": [32, 37, 42, 57], "n_features_to_select": 41, "n_inform": 37, "n_init": 42, "n_iter": 57, "n_job": [34, 37, 38, 39, 49, 57], "n_neighbor": [44, 55], "n_neighbors_selector": 32, "n_neighbors_widget": [32, 55], "n_redund": 37, "n_rental": 47, "n_rentalsin3hour": 47, "n_rentalsin6hour": 47, "n_repeat": 40, "n_resourc": 36, "n_sampl": [32, 37, 42, 43, 46, 52, 58], "n_split": 47, "n_threshold": 37, "n_topic": 45, "n_train": 47, "n_word": [45, 51], "na": [38, 40, 49], "nafter": 45, "nah": 34, "naiv": 43, "name": [4, 5, 6, 7, 8, 11, 30, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 55, 59, 60, 61], "named_estimators_": 39, "named_step": [35, 37, 38, 39, 40, 41, 47, 49, 51, 60], "named_transformers_": [34, 37, 38, 39, 40, 41, 47, 48, 49, 51, 58, 60], "nan": [33, 34, 37, 38, 39, 40, 41, 44, 47, 48, 49, 51, 53, 58, 60], "nanmean": 44, "nanosecond": 47, "narr": 45, "narrow": [44, 49], "nasali": [29, 46], "nation": 61, "nativ": [37, 39, 40, 46, 52, 58], "natur": [2, 29, 34, 37, 39, 41, 46, 50, 52, 61], "navig": [7, 11, 50], "nbsp": [29, 33, 34, 36, 38, 39, 40, 41, 46], "nbviewer": [29, 33, 34, 36, 37, 38, 39, 40, 41, 46, 49, 51], "nc": 1, "ncol": 35, "ndarrai": [8, 34], "ndate": 51, "ndframe": [41, 48], "ndim": 8, "ne": [47, 60], "nearbi": [32, 42], "nearest": [15, 37, 43, 55], "necessari": [0, 7, 30, 36, 53, 56], "necessarili": [31, 38, 39, 44, 50], "necvq": 48, "need": [5, 7, 8, 11, 29, 30, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61], "neg": [30, 31, 32, 35, 38, 39, 40, 45, 47, 48, 51, 55, 58], "neg_mean_absolute_percentage_error": 38, "neg_mean_squared_error": [38, 49], "neg_root_mean_square_error": 38, "neg_root_mean_squared_error": 38, "neigh": 32, "neighbor": [32, 33, 34, 35, 37, 41, 43, 55, 56], "neighborhood": [35, 38, 40, 49], "neighborhood_blmngtn": 38, "neighborhood_bluest": 38, "neighborhood_brdal": 38, "neighborhood_brksid": 38, "neighborhood_clearcr": 38, "neighborhood_collgcr": 38, "neighborhood_crawfor": 38, "neighborhood_edward": 38, "neighborhood_gilbert": 38, "neighborhood_idotrr": 38, "neighborhood_meadowv": 38, "neighborhood_mitchel": 38, "neighborhood_nam": 38, "neighborhood_noridg": [38, 40], "neighborhood_npkvil": 38, "neighborhood_nridght": [38, 40], "neighborhood_nwam": 38, "neighborhood_oldtown": [38, 40], "neighborhood_sawy": [38, 40], "neighborhood_sawyerw": [38, 40], "neighborhood_somerst": [38, 40], "neighborhood_stonebr": [38, 40], "neighborhood_swisu": [38, 40], "neighborhood_timb": [38, 40], "neighborhood_veenk": [38, 40], "neighbour": [15, 31, 40, 42, 43, 45, 55], "neighbourhood": [35, 41, 43, 56], "neither": [31, 34, 44], "neq": [40, 44], "ner": 45, "nervou": 30, "nest": [36, 53], "net": [46, 48], "netflix": [44, 51], "network": [10, 29, 34, 39, 41, 42, 44, 47, 50, 61], "neu": 51, "neural": [10, 41, 47, 61], "neutral": 51, "never": [37, 39, 40, 44, 46, 48], "new": [10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 56, 57, 59, 60], "new_cent": 42, "new_column": [38, 40, 47, 48, 49, 60], "new_data": 48, "new_df": [47, 60], "new_exampl": [30, 42], "new_feature_nam": [47, 60], "new_text": 49, "new_valu": 48, "newaxi": 8, "newcastl": 51, "newer": 38, "newli": [33, 38, 41, 43], "newsgroup": 45, "newswir": 45, "next": [11, 30, 31, 32, 33, 34, 37, 38, 39, 45, 46, 47, 49, 56, 57, 58, 59, 61], "nfeat": 32, "nfeats_accuraci": 32, "ng": [9, 10, 36, 41], "ngram": 41, "ngram_rang": 34, "nhqxu": 48, "nice": [4, 36, 37, 39, 40, 43, 46, 48, 49, 50], "nicki": 36, "night": [37, 47, 50], "nightmar": 49, "niki": 61, "nlemma": 45, "nlp": [34, 46, 51], "nltk": [45, 51], "nltk_data": 51, "nmax": 49, "nn": [10, 33, 46, 51, 55], "nne": [47, 60], "nnw": [47, 60], "nnz": 34, "no_grad": 46, "nobodi": 29, "node": [30, 39, 43, 46, 54], "nois": [43, 53, 55], "non": [1, 8, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 43, 44, 46, 47, 48, 50, 53, 58, 60, 61], "noncommerci": 1, "none": [10, 26, 27, 28, 31, 33, 34, 35, 36, 37, 39, 41, 43, 47, 48, 49, 51, 59], "noninfring": 0, "nonzero": 34, "noqa": [36, 51], "nor": [7, 31, 34], "norg": [45, 51], "norm": [36, 45], "normal": [6, 37, 38, 39, 40, 42, 43, 45, 46, 47, 49, 51, 58, 59], "norvig": 10, "notat": 32, "note": [0, 3, 7, 9, 10, 11, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 50, 52, 53, 57, 58, 60, 61], "notebook": [5, 7, 9, 11, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 46, 49, 51, 56, 60], "notic": [0, 34, 35, 37, 38, 41], "notion": [32, 36, 42, 44], "notna": [47, 60], "noun": [45, 51], "nov": 47, "novel": 53, "novemb": 47, "novic": 9, "now": [8, 11, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 54, 55, 56, 57, 58, 59], "np": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60], "nperson": 51, "npie": 8, "npo": 45, "npr": [41, 45, 51, 53], "ntest": [32, 36, 55], "ntoken": 45, "ntree": 39, "null": [33, 34, 37, 38, 41, 47, 48, 60], "null_distribut": 48, "num": [37, 39, 40, 58], "num_output_channel": 46, "num_parallel_tre": 39, "num_sent": [37, 50], "num_work": 46, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 50, 53, 55, 57, 60, 61], "number_test": 36, "numer": [2, 30, 33, 34, 35, 37, 38, 39, 44, 45, 47, 48, 49, 55, 56, 58, 60], "numeric_feat": [34, 36, 41, 53, 57], "numeric_featur": [34, 37, 38, 39, 40, 47, 48, 49, 51, 58, 59, 60], "numeric_looking_column": 38, "numeric_transform": [34, 37, 38, 39, 40, 47, 49, 58, 59, 60], "numpi": [9, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60], "numpy_dtyp": 48, "nutrit": 45, "nw": [47, 60], "nwith": 32, "ny": 51, "nyt": 49, "o": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "obelisk": 46, "object": [31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 51, 53, 54, 55, 57, 58, 60], "observ": [29, 30, 31, 32, 39, 40, 42, 43, 47, 48, 55, 58, 59, 60], "obtain": [0, 35, 42, 43, 44, 48, 55, 57], "obviou": [43, 45], "occasion": 37, "occup": [37, 39, 40, 58], "occupation_farm": 40, "occupation_miss": 40, "occupation_priv": 40, "occupi": 61, "occur": [8, 30, 31, 34, 45, 48], "occurr": [45, 48], "ocean": [33, 34, 41, 56], "ocean_proxim": [33, 34, 41, 56], "ocean_proximity_": [33, 34], "ocean_proximity_inland": [33, 34], "ocean_proximity_island": [33, 34], "ocean_proximity_near": [33, 34], "oct": 35, "octob": 47, "oe": [34, 53], "oe_encod": 53, "off": [25, 35, 36, 37, 38, 41, 42, 45, 46, 48, 49, 53, 57, 61], "off_shelf": 59, "offens": 4, "offer": [8, 39, 44, 45, 48, 61], "offic": [4, 11, 53, 61], "offici": [45, 61], "offlin": 44, "offset": 35, "often": [8, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55], "ogunrind": 29, "oh": [40, 41, 46, 47, 48, 50, 53, 57, 60], "ohe_column": [38, 40, 49], "ohe_enc": 34, "ohe_encod": 53, "ohe_feature_nam": [40, 47, 60], "ohehotencod": 34, "ois": 43, "ok": [29, 32, 38, 47, 48, 50, 53, 60], "okai": [42, 50], "ola": 45, "old": [9, 39, 40], "old_cent": 42, "older": 38, "oldpeak": 59, "olymp": 8, "omit": 40, "omw": 45, "onc": [6, 7, 8, 11, 30, 31, 33, 34, 36, 41, 43, 44, 45, 46, 50, 57, 58, 59, 61], "onca": [29, 46], "one": [6, 8, 9, 11, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 57, 58, 59, 60, 61], "one_c": 32, "one_ex_preprocess": 40, "one_ex_preprocessed_perturb": 40, "one_exampl": 40, "one_example_perturb": 40, "onehot": [34, 41], "onehotencod": [33, 35, 36, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 56, 57, 58, 59, 60], "onehotencoder__major_biologi": 34, "onehotencoder__major_comput": 34, "onehotencoder__major_econom": 34, "onehotencoder__major_linguist": 34, "onehotencoder__major_mathemat": 34, "onehotencoder__major_mechan": 34, "onehotencoder__major_phys": 34, "onehotencoder__major_psychologi": 34, "onehotencoderonehotencod": [34, 36, 38, 39, 49], "ones": [8, 29, 32, 33, 39, 40, 42, 44, 45, 55, 59], "onevsoneclassifi": 52, "onevsrestclassifi": 52, "onli": [2, 4, 8, 11, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 55, 56, 58, 61], "onlin": [3, 5, 7, 11, 30, 45, 61], "onlinebackup": 48, "onlinebackup_no": 48, "onlinebackup_y": 48, "onlinesecur": 48, "onlinesecurity_no": 48, "onlinesecurity_y": 48, "onrend": 50, "ontonot": 45, "oob_scor": 49, "op": 37, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 46, 50, 61], "openporchsf": [38, 40, 49], "oper": [4, 8, 11, 34, 41, 45, 50], "operand": 8, "opinion": 39, "opportun": 44, "oppos": [38, 39], "opposit": [8, 38, 39, 40, 60], "opt": [11, 39, 50], "optic": 48, "optim": [2, 10, 30, 31, 32, 34, 37, 39, 40, 41, 42, 43, 46, 48, 49, 50, 57], "optimist": 36, "option": [7, 8, 10, 30, 38, 42, 45, 49, 57, 59, 60], "oracl": 10, "orang": 35, "order": [5, 7, 8, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 53], "ordering_ordinal_oth": [38, 40, 49], "ordering_ordinal_reg": [38, 40, 49], "ordin": [38, 53, 56], "ordinal_feat": 34, "ordinal_featur": [37, 39, 40, 58], "ordinal_features_oth": [38, 40, 49], "ordinal_features_reg": [38, 40, 49], "ordinal_transform": [37, 39, 40, 58], "ordinal_transformer_oth": [38, 40, 49], "ordinal_transformer_reg": [38, 40, 49], "ordinalencod": [33, 34, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 56, 58, 59, 60], "ordinalencoderordinalencod": [34, 38, 39, 49], "ordinari": 38, "oreilli": [46, 47], "org": [9, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 45, 46, 49, 51], "organ": [29, 30, 33, 45, 49, 50], "orgin": 8, "orig_featur": [47, 60], "orig_pr": 40, "orig_scor": 37, "origin": [33, 34, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 51, 55, 57, 60, 61], "original_hm": [37, 50], "originaltweet": 51, "ornithorhynchu": 46, "oscar": 35, "ostblom": 45, "other": [0, 1, 4, 5, 6, 7, 11, 30, 31, 33, 34, 35, 36, 37, 39, 40, 43, 44, 46, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61], "otherwis": [0, 7, 34], "ounc": [29, 46], "our": [5, 6, 8, 11, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 57, 58, 59, 60, 61], "ourselv": [30, 37, 46, 47], "out": [0, 4, 7, 8, 11, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 51, 53, 55, 57, 59, 60, 61], "out_col": [31, 33, 51], "out_step": 37, "outcom": 12, "outer": 51, "outlier": [38, 43, 50, 53], "outlook": 48, "output": [7, 8, 11, 29, 30, 31, 34, 35, 37, 39, 40, 45, 46, 47, 49, 50, 53, 59, 60, 61], "outsid": [7, 37, 39, 40, 44, 45, 47, 48], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 36, 38, 46, 47, 48, 49, 50, 53, 61], "over_confident_i": 35, "over_confident_x": 35, "over_sampl": 37, "overal": [11, 37, 40, 42, 45, 46, 49, 53, 58, 59, 61], "overallcond": [38, 40, 49], "overallqu": [38, 40, 49], "overconfid": [40, 41, 50], "overfit": [10, 32, 35, 38, 39, 41, 46, 50, 55, 57, 59, 61], "overflow": 7, "overhead": 34, "overlap": [2, 31, 42, 50], "overli": [32, 36, 55], "overload": [44, 48], "overpredict": 38, "oversample_pip": 37, "overshadow": 45, "overst": 49, "overus": 39, "overview": [42, 43, 44, 45], "overwhelm": 42, "overzeal": 6, "own": [4, 5, 8, 31, 33, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 60], "p": [35, 36, 43, 45, 48, 50], "p_i": 42, "p_value_threshold": 48, "pace": [35, 42, 45, 61], "packag": [5, 8, 30, 31, 34, 36, 37, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 61], "pad": 46, "page": [1, 4, 10, 29, 33, 34, 36, 37, 38, 39, 40, 41, 45, 46, 49, 51, 59, 61], "pai": [40, 50], "pain": [4, 46, 47, 49, 60], "pair": [43, 45, 52], "pairwis": [32, 43], "panda": [9, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "pane": [32, 55], "panel": [32, 37, 40, 42, 43, 55], "panic": 51, "panther": [29, 46], "panthera": [29, 46], "paper": [7, 40, 41, 45, 46, 48, 50, 51], "paperlessbil": 48, "paperlessbilling_no": 48, "paperlessbilling_y": 48, "paradigm": [29, 30, 42], "paradox": 44, "paragraph": 45, "parallel": [34, 36, 39], "param": [32, 34, 36, 38, 55], "param_columntransformer__countvectorizer__max_featur": 36, "param_dist": [36, 57], "param_distribut": [36, 57], "param_grid": [31, 32, 36, 38, 49, 57], "param_grid1": [36, 57], "param_grid2": [36, 57], "param_grid3": 36, "param_grid4": 36, "param_ridge__alpha": 38, "param_svc__c": 36, "param_svc__gamma": 36, "paramet": [32, 33, 34, 38, 39, 40, 42, 43, 45, 47, 48, 49, 51, 54, 55, 57, 58, 59, 60], "parametr": 43, "params_": 48, "params_str": 36, "paramter": 32, "pardu": [29, 46], "parent": [43, 51], "park": [41, 46, 50, 51], "pars": 45, "parse_d": [8, 47, 60], "parser": 45, "part": [4, 9, 10, 11, 33, 34, 35, 36, 37, 39, 40, 41, 43, 45, 47, 49, 50, 51, 59, 61], "part1": 44, "part2": 44, "parti": 45, "partial": [4, 48, 49], "particip": 61, "particular": [0, 9, 11, 33, 34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 55, 58], "particularli": [39, 44, 61], "partit": [34, 42, 43], "partner": [48, 61], "partner_no": 48, "partner_y": 48, "parton": 51, "pass": [8, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 55], "passthrough": [34, 36, 48, 51, 57, 59], "passthrough__ml_experi": 34, "passthrough_feat": [34, 36, 53, 57], "passthrough_featur": [48, 51, 59], "passthroughpassthrough": [34, 36, 51], "past": [30, 31, 39, 47, 48, 49, 53], "pat": 44, "pat_i": 44, "pat_model": 44, "pat_x": 44, "pata": [29, 46], "path": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "patial": 43, "patient": [30, 50, 59], "patio": 46, "patric": 40, "patrick": 61, "pattern": [29, 30, 31, 34, 36, 41, 42, 47, 49, 55, 60], "pave": [38, 40, 49], "paveddr": [38, 40, 49], "paveddrive_i": 38, "paveddrive_n": 38, "paveddrive_p": 38, "paymentmethod": 48, "paymentmethod_bank": 48, "paymentmethod_credit": 48, "paymentmethod_electron": 48, "paymentmethod_mail": 48, "pca": [37, 43, 44], "pcarter": 9, "pd": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "pdf": [7, 9, 19, 25], "peac": 45, "pedest": 46, "pedro": [10, 31, 41], "peek": 60, "peer": [50, 53, 61], "pembrok": [29, 46], "penal": [6, 48], "penalti": [37, 61], "peopl": [4, 30, 31, 33, 35, 37, 39, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 61], "per": [8, 35, 37, 38, 39, 40, 44, 46, 47, 49, 52, 53, 57, 58, 60], "perceiv": 6, "percent": 38, "percent_error": 38, "percentag": [30, 37, 44, 49], "perfect": [6, 30, 31, 37, 38, 40, 44, 48, 51], "perfectli": [2, 44, 45], "perform": [30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61], "performac": 31, "perhap": [38, 47, 52], "perimet": 41, "period": [45, 47, 48, 51, 61], "perm_sorted_idx": 40, "perman": 8, "permiss": [0, 61], "permit": [0, 33, 37, 61], "permut": 40, "persist": 44, "person": [0, 4, 6, 10, 29, 37, 42, 45, 46, 47, 48, 50, 51, 61], "perspect": [39, 44], "pertain": 5, "perthairport": [47, 60], "perturb": [40, 43], "perturbed_pr": 40, "peter": 10, "ph": 45, "pharma": 50, "phascolarcto": 46, "phase": 31, "phd": 45, "phdei": 48, "phenomenon": [44, 48, 55], "philippin": 51, "philosoph": 45, "phone": [29, 48, 61], "phoneservic": 48, "phoneservice_no": 48, "phoneservice_y": 48, "photo": [51, 53], "photograph": 61, "phrase": 45, "physic": [34, 47], "pi": 8, "pick": [30, 35, 37, 39, 40, 41, 42, 43, 46, 49, 50, 52, 54, 55, 57, 58, 59], "pictur": [39, 40, 43, 45, 47, 49], "pie": 8, "piec": [35, 48], "pil": [29, 46], "pin": 46, "pineappl": 45, "pip": [11, 40, 45, 46, 50, 51], "pipe": [33, 34, 35, 36, 37, 39, 45, 46, 51, 57, 58], "pipe_bestalpha": 38, "pipe_bigalpha": 38, "pipe_catboost": 39, "pipe_dt": [39, 40, 59], "pipe_forward": 41, "pipe_knn": 59, "pipe_lgbm": [39, 40, 59], "pipe_lr": [37, 39, 40, 50, 58, 59], "pipe_lr_all_feat": 41, "pipe_lr_balanc": [37, 58], "pipe_lr_model_bas": 41, "pipe_lr_weight": [37, 58], "pipe_rf": [39, 40, 59], "pipe_rf_demo": 39, "pipe_ridg": [35, 38], "pipe_sklearn_gb": 39, "pipe_sklearn_histgb": 39, "pipe_smallalpha": 38, "pipe_svc": 37, "pipe_svm": [36, 57], "pipe_xgb": [39, 40], "pipe_xor": 41, "pipelin": [2, 10, 16, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61], "pipeline__lab1": 34, "pipeline__lab2": 34, "pipeline__lab3": 34, "pipeline__lab4": 34, "pipeline__quiz1": 34, "pipeline__rooms_per_household": 41, "pipeline__university_year": 34, "pipelineifittedpipelin": [33, 34, 36, 37, 41, 46, 51], "pipelineinot": [34, 36, 38], "pipelinepipelin": 36, "pitch": 49, "pitfal": [47, 49], "pixel": 40, "pizza": 45, "pkg": 11, "place": [5, 45, 47, 61], "plagiar": 61, "plai": [30, 32, 36, 40, 43, 54, 55], "plain": 42, "plan": [11, 29, 38, 41, 48, 50, 51, 56, 59, 61], "plane": 35, "plant": 53, "plastic": 45, "platform": [4, 51], "platypu": 46, "player": [40, 46], "pleas": [1, 4, 7, 11, 29, 33, 34, 36, 37, 38, 39, 40, 41, 46, 49, 50, 51, 57, 61], "plinth": 46, "plot": [7, 30, 31, 32, 33, 35, 36, 37, 38, 41, 43, 44, 45, 46, 47, 49, 50, 55, 57, 58, 60], "plot_2d_scor": 35, "plot_2d_separ": [32, 35, 55], "plot_confusion_matrix": 37, "plot_confusion_matrix_exampl": 37, "plot_cross_valid": [31, 47], "plot_dbscan": 43, "plot_dbscan_with_label": 43, "plot_dendrogram_clust": 43, "plot_elbow": 42, "plot_example_dist": 42, "plot_fruit_tre": 30, "plot_grid_search_overview": 36, "plot_k_means_dbscan_comparison": 43, "plot_km_initi": 42, "plot_km_it": 42, "plot_km_iter": 42, "plot_kmean": 43, "plot_knn_clf": 32, "plot_knn_decision_boundari": 32, "plot_knn_regress": 32, "plot_lda_w_vector": 45, "plot_linkage_criteria": 43, "plot_logistic_regress": 35, "plot_logistic_regression_graph": 46, "plot_loss_diagram": 49, "plot_multiclass_lr_ovr": 52, "plot_original_clust": 43, "plot_partial_effects_on_outcom": 48, "plot_result": [32, 55], "plot_scal": 33, "plot_silhouette_dist": 42, "plot_single_hidden_layer_graph": 46, "plot_support_vector": 32, "plot_survival_funct": 48, "plot_svc_c": 32, "plot_svc_gamma": 32, "plot_time_spacing_distribut": [47, 60], "plot_train_test_point": 32, "plot_tree_decision_boundari": 31, "plot_tree_decision_boundary_and_tre": [30, 31, 54], "plot_two_hidden_layer_graph": 46, "plot_typ": 40, "plot_x_dendrogram": 43, "plotli": [41, 45], "plotting_funct": [30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 46, 49, 52, 54, 55, 56, 57, 58, 59], "plotting_functions_unsup": [42, 43, 44, 45], "plt": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "plu": [35, 46], "plural": 34, "pm": [1, 10, 47, 60, 61], "pmltt": 10, "pn": [32, 37, 42, 43, 55], "po": [31, 33, 35, 38, 40, 45, 49, 51], "pobox": 29, "point": [4, 10, 29, 30, 31, 33, 34, 35, 36, 38, 41, 43, 48, 49, 50, 52, 53, 55, 58, 61], "point_ind": 42, "point_index": 42, "pointless": 57, "polarity_scor": 51, "pole": 46, "polici": [3, 4, 7, 61], "polit": [44, 45, 46], "poly_transform": 47, "polynomialfeatur": [41, 47], "pomegran": 46, "pool": 10, "poolarea": [38, 40, 49], "poolqc": [38, 40, 49], "poor": [34, 38, 41, 53, 56], "poorli": [32, 38, 43, 47], "pope": 45, "popul": [33, 34, 35, 41, 47, 56], "popular": [8, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 51, 61], "population_per_household": [33, 34, 56], "port": 50, "porter": 45, "porterstemm": 45, "portion": [0, 31, 33, 36, 38, 40, 49, 59, 60, 61], "portug": [37, 40], "pos_": [45, 51], "pos_label": 38, "posit": [30, 31, 32, 33, 35, 38, 39, 40, 45, 47, 48, 51, 58], "posix": 48, "possess": 49, "possibl": [4, 5, 6, 8, 29, 30, 31, 33, 36, 37, 39, 40, 41, 43, 44, 45, 46, 48, 49, 53, 55, 56, 57, 58, 61], "possibli": [7, 45], "post": [4, 6, 8, 10, 45, 47, 50, 61], "postprocess": 46, "potenti": [32, 33, 42, 45, 49, 50, 61], "potteri": 45, "powder": 45, "power": [8, 31, 39, 44, 45, 46, 49], "pplicat": 43, "pr": 53, "practic": [0, 6, 9, 10, 31, 33, 41, 46, 49, 50, 53, 56, 57, 61], "practition": 49, "prairielearn": [10, 61], "pre": [10, 11, 19, 23, 24, 25, 26, 27, 28, 29, 39, 41, 45, 49, 50, 51, 53], "precipit": 50, "precis": [18, 38, 49, 50, 53, 58, 61], "precision_lr": 37, "precision_recall_curv": 37, "precision_scor": 37, "precision_svc": 37, "precisionrecallcurvedisplai": 37, "precisionrecalldisplai": 37, "pred": [37, 38, 44, 47, 48], "pred_df": [29, 44], "pred_dict": 29, "pred_g": 44, "pred_lin_reg": 44, "pred_train": 38, "pred_x": 44, "prediciton": 48, "predict": [2, 17, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61], "predict_expect": 48, "predict_for_usr": 44, "predict_proba": [37, 39, 40, 46, 52, 59], "predict_survival_funct": 48, "predicted_categori": [37, 50], "predicted_n_rent": 47, "predicted_quiz2": 30, "predicted_sal": 47, "predicted_target": 29, "predictor": [30, 53], "prefer": [29, 39, 42, 44, 57], "prefix": 8, "preliminari": [33, 41], "prepar": [33, 41, 46], "prepend": 11, "preprocess": [10, 16, 18, 31, 32, 35, 36, 37, 39, 40, 41, 43, 44, 46, 48, 51, 55, 56, 57, 59, 61], "preprocess_featur": [47, 60], "preprocessing_fin": 48, "preprocessing_notenur": 48, "preprocessor": [34, 36, 37, 38, 39, 40, 47, 48, 49, 51, 56, 57, 58, 59, 60], "preprocessor1": 41, "preprocessor2": 41, "preprocessor3": 41, "prereq": 50, "prerequisit": [2, 48, 61], "preschool": [37, 39, 40, 58], "presenc": [34, 40, 48], "present": [7, 31, 37, 44, 45, 46, 47, 48, 49, 50, 53, 55, 60], "preserv": [37, 42], "pressure3pm": [47, 60], "pressure9am": [47, 60], "pretend": [30, 31, 47], "pretrain": [45, 46, 51], "pretti": [30, 34, 35, 37, 39, 42, 45, 47, 48, 60], "prevent": [36, 45, 48, 61], "previou": [30, 38, 39, 42, 43, 47, 48, 49, 53, 57, 58, 60], "previous": [44, 46, 47], "price": [8, 18, 33, 35, 38, 40, 41, 48, 49, 55], "primari": [8, 19, 23, 24, 25, 26, 27, 28, 32], "primarili": [30, 40, 46, 50], "prime": 29, "principl": [9, 30, 53, 61], "print": [7, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 58, 60], "print_top": 45, "prior": [42, 47, 53], "priorit": [41, 53], "privaci": [0, 42, 50, 61], "privat": [7, 37, 39, 40], "privileg": 6, "prize": 34, "pro": [42, 46, 49], "prob": [35, 39], "proba": 46, "probabilist": 2, "probabl": [17, 29, 32, 33, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 53, 58, 59, 60], "problem": [4, 6, 10, 29, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 52, 53, 55, 57, 58, 59, 60, 61], "problemat": [37, 40, 48], "probosci": [29, 46], "proce": 61, "procedur": 39, "proceed": [31, 60], "process": [2, 5, 7, 30, 32, 33, 34, 36, 41, 42, 43, 46, 49, 50, 51, 55, 57, 61], "process_on": 51, "procfil": 50, "prod": [34, 36], "produc": [2, 7, 38, 40, 43, 48, 49, 53, 55], "product": [5, 36, 44, 45, 49], "prof": [37, 39, 40, 58], "profession": [44, 50], "profil": 38, "profile_df": 44, "profilereport": 38, "profit": 49, "program": [0, 4, 9, 11, 29, 45, 61], "programm": 45, "progress": 42, "project": [11, 33, 39, 41, 46, 49, 50, 53, 61], "promin": 45, "promis": [29, 45, 47, 50], "promot": 48, "prompt": [11, 61], "pron": [45, 51], "prone": 36, "proper": [46, 54], "properli": [7, 48, 49], "properti": [30, 38, 40, 41], "prophet": 47, "propn": 51, "proport": [30, 31, 34, 35, 37, 38, 39, 40, 49, 58, 61], "proportional_hazard_test": 48, "prostitut": 45, "protocol": 50, "prototyp": [50, 53], "prove": 37, "provid": [0, 5, 7, 11, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 53, 57, 58, 59, 60, 61], "provinc": [34, 45], "proxi": 31, "proxim": [35, 45, 61], "prune": 41, "psychologi": [34, 53], "pt": [35, 36, 46], "public": [0, 4, 7, 45, 51], "publish": [0, 10, 35, 45], "pud": 38, "pull": [11, 35, 45], "punct": [45, 51], "punctuat": [34, 45], "punish": 49, "punkt": 51, "punkt_tab": 51, "purchas": [29, 44, 50], "pure": [30, 47], "purpos": [0, 30, 31, 33, 44, 45, 47, 50, 53, 54, 55, 59, 61], "pursuit": 49, "push": [7, 40], "put": [7, 8, 11, 30, 31, 33, 34, 41, 42, 43, 44, 49, 50, 57], "px": [41, 45], "py": [30, 31, 33, 34, 36, 39, 40, 42, 43, 48, 49, 50, 51, 52], "pybind11": 51, "pybo": 36, "pydata": 41, "pyplot": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60], "pysurviv": 48, "python": [3, 4, 10, 29, 36, 38, 44, 45, 46, 47, 48, 49, 50, 51, 61], "python3": [9, 30, 31, 34, 36, 40, 48, 50, 51, 52], "pythonwarn": 38, "pytorch": [29, 46], "pytorch_1711403226120": 51, "pyviz": 37, "q": 10, "qualiti": [37, 40, 42, 43, 49], "quantifi": [37, 58], "queri": [33, 37, 39, 42, 44, 45, 47, 48, 58, 60, 61], "query_point": 32, "quest": 41, "question": [6, 7, 61], "queuepredictor": 50, "quick": [4, 45, 50, 61], "quickli": [30, 32, 33, 36, 43, 48, 53, 61], "quickstart": 9, "quirk": 31, "quit": [6, 29, 30, 33, 36, 37, 38, 40, 41, 43, 45, 46, 47, 48, 49, 51], "quiz": [1, 10, 45], "quiz1": [30, 31, 34, 53], "quiz2": [31, 34, 53], "quizz": 30, "r": [30, 34, 35, 37, 47, 49, 59, 61], "r1": 39, "r2": [38, 39, 53, 55], "r2_score": [38, 41, 51], "r4": 39, "race": [34, 37, 39, 40, 58, 61], "radial": 32, "radiu": [41, 43], "rail": 46, "rain": [47, 60], "rain_df": [47, 60], "rain_df_modifi": [47, 60], "rainfal": [47, 60], "rainfall_lag1": [47, 60], "rainfall_lag2": [47, 60], "rainfall_lag3": [47, 60], "raintodai": [47, 60], "raintoday_miss": [47, 60], "raintoday_no": [47, 60], "raintoday_y": [47, 60], "raintomorrow": [47, 60], "rais": [6, 34, 37, 47, 48, 50, 60], "rand": [8, 39], "randint": [36, 57], "randn": [35, 41], "random": [6, 8, 31, 32, 35, 37, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 57, 59, 61], "random_forest_data": 39, "random_search": [36, 57], "random_st": [29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59], "randomforestclassifi": [40, 41, 47, 49, 59, 60], "randomforestclassifierrandomforestclassifi": 39, "randomforestregressor": [38, 39, 40, 41, 47, 48, 49, 50, 51, 59], "randomhorizontalflip": 46, "randomizedsearchcv": [32, 39, 40, 49, 57, 59], "randomizedsearchcvifittedrandomizedsearchcv": 36, "randomli": [31, 35, 36, 37, 39, 48, 58], "randomoversampl": 37, "randomresizedcrop": 46, "randomst": [41, 43], "randomundersampl": 37, "rang": [4, 8, 31, 32, 33, 34, 35, 39, 42, 44, 45, 46, 47, 48, 49, 51, 57, 61], "rangeindex": [34, 41, 47, 48, 60], "rank": [37, 41, 44, 45, 48, 58], "rank_test_mape_scor": 38, "rank_test_neg_mean_squared_error": 38, "rank_test_scor": [36, 38], "ranking_": 41, "rare": [34, 37, 38, 42, 45, 53], "rate": [29, 35, 37, 39, 42, 48, 49, 53, 58], "rated_item": 44, "rather": [29, 34, 36, 37, 38, 39, 40, 42, 45, 46], "ratings_df": 44, "ratio": [37, 39, 45, 48], "ravel": [37, 53], "raw": [8, 34, 37, 40, 41, 45, 46, 49, 52, 58], "raw_model_output": 35, "raw_scor": 40, "rbf": [10, 15, 31, 33, 35, 36, 39, 40, 41, 49, 50, 53, 55, 57], "rcparam": [29, 30, 31, 37, 42, 43, 44, 46, 47, 48, 49, 54, 60], "re": [4, 7, 8, 11, 29, 30, 31, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 50, 51, 53, 54, 60], "reach": [6, 42, 61], "read": [1, 4, 7, 10, 32, 33, 34, 37, 38, 39, 40, 45, 47, 49, 50, 59, 60], "read_csv": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 61, "readi": [7, 31, 32, 33, 35], "readlin": 46, "readm": 48, "readthedoc": 48, "real": [31, 32, 33, 34, 35, 37, 40, 42, 43, 44, 45, 46, 49, 51, 53], "realdonaldtrump": 51, "realist": [33, 47, 50, 60], "realiti": [31, 38, 48], "realiz": 49, "realli": [8, 31, 35, 36, 39, 41, 43, 44, 46, 47, 48, 50], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 36, 37, 38, 40, 42, 44, 45, 47, 48, 49, 50, 53, 61], "rebuild": 51, "rec": [38, 40, 49], "recal": [18, 30, 31, 32, 33, 34, 35, 38, 42, 47, 50, 53, 58, 61], "recall_lr": 37, "recall_scor": 37, "recall_svc": 37, "receiv": [6, 7, 34, 43, 46, 47, 50], "recent": [8, 11, 29, 34, 41, 44, 45, 47, 48, 50, 51], "recip": 31, "recogn": [31, 43, 47, 49, 61], "recognit": [29, 30, 32, 37, 45, 61], "recommend": [2, 4, 8, 10, 11, 29, 31, 32, 36, 37, 42, 45, 46, 49, 50, 59, 61], "record": [30, 48], "recreat": 60, "rectangular": 42, "recurr": 47, "recurs": 61, "red": [30, 32, 37, 40, 41, 42, 47], "redbon": 36, "redefin": 48, "redistribut": 0, "reduc": [7, 8, 29, 32, 36, 37, 38, 39, 40, 41, 44, 45, 46, 52, 55, 58, 61], "reduct": [2, 37, 39, 41, 42], "redund": [35, 40], "ref": [37, 48, 58], "refer": [8, 30, 31, 32, 33, 34, 35, 37, 40, 42, 44, 45, 46, 55, 61], "referenc": 61, "referenti": 45, "refin": [32, 55], "refit": 38, "reflect": [32, 38, 40, 45, 55, 57, 61], "reflection_period": [37, 50], "reg": [30, 39, 59], "reg_model": 30, "regard": 61, "regardless": 7, "regex": 45, "regim": 50, "region": [30, 37, 43, 47, 50, 52, 57, 60], "region_data": [47, 60], "regist": [50, 61], "registri": 51, "regrad": 6, "regress": [2, 10, 17, 29, 33, 34, 40, 41, 44, 47, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61], "regression_df": 30, "regressor": [30, 33, 34, 38, 47, 59], "regular": [32, 34, 35, 39, 45, 47, 48, 49, 53], "regulatori": 40, "reinforc": [29, 42], "reject": [37, 58], "rel": [35, 40, 43, 45, 51, 52, 58], "rel_char_len": 51, "relabel": 42, "relat": [2, 6, 11, 29, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 51, 59, 61], "relationship": [37, 39, 40, 41, 45, 47, 49, 51, 53, 54, 55, 58, 60, 61], "relationship_husband": 40, "relationship_own": 40, "releas": [7, 10], "relev": [4, 8, 10, 30, 32, 33, 36, 40, 47, 61], "reli": [31, 32, 41, 43, 44, 47, 55], "reliabl": [29, 42], "religi": 45, "remain": [5, 38, 41, 44, 47, 49], "remaind": 6, "rememb": [7, 32, 34, 36, 37, 40, 41, 43, 46, 47, 48, 54, 55, 57, 60], "remind": 54, "remix": 0, "remov": [7, 33, 37, 39, 40, 41, 45, 46, 48, 52, 57, 58, 60], "renam": [29, 37, 40, 47, 50], "render": [4, 7, 29, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 49, 51], "rent": 47, "rental": [47, 50], "rentals_df": 47, "rentals_lag5": 47, "rentals_lag5_i": 47, "rentals_lag5_x": 47, "rentals_model": 47, "repair": [37, 39, 40], "repeat": [8, 41, 42, 43, 46, 50, 57, 58, 59], "repeatedli": 6, "rephras": 49, "replac": [29, 33, 37, 39, 40, 44, 48, 58], "replic": 50, "reply_cont": 51, "repo": [10, 37, 50], "report": [6, 30, 36, 38, 41, 47, 51, 58], "repositori": [0, 5, 10, 11, 35, 37, 50, 61], "repres": [30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 59], "represent": [29, 30, 33, 36, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51, 53], "reproduc": [4, 31, 36, 39, 50, 61], "republ": 40, "request": [6, 45, 61], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 53, 55, 60], "rerun": [29, 33, 34, 36, 37, 38, 39, 40, 41, 46, 49, 51], "res_mean": 31, "resampl": 37, "research": [29, 31, 36, 44, 45, 50], "reserv": [47, 61], "reset_index": 29, "reshap": [8, 35, 36, 46, 47, 57], "resid": 35, "residu": 39, "resiz": 46, "resnet": 46, "resolut": 45, "resolv": 61, "resort": 35, "resourc": [3, 5, 10, 30, 39, 40, 45, 46, 50, 53], "respect": [35, 36, 37, 39, 40, 57], "respons": [4, 7, 30, 42, 45, 49, 61], "rest": [35, 36, 46, 48, 50, 53, 60], "restart": [7, 11], "restaur": [44, 50], "restingbp": 59, "restingecg": 59, "restrict": [0, 38, 39, 45], "result": [2, 7, 8, 10, 11, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 51, 55, 57, 58, 59, 60, 61], "result_block": 48, "result_img": 46, "results_df": [31, 32, 35, 55], "results_dict": [31, 32, 33, 34, 36], "results_single_valid_df": 55, "retail": [51, 53], "retail_df": 47, "retail_df_test": 47, "retail_df_train": 47, "retail_lag_5": 47, "retail_model": 47, "retail_test_5": 47, "retail_test_5_pr": 47, "retail_train_5": 47, "retail_train_5_d": 47, "retail_train_5_i": 47, "retail_train_5_x": 47, "retent": 48, "retrain": [36, 50, 57], "return": [5, 8, 11, 30, 31, 32, 33, 34, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 55, 57, 60], "return_gener": 34, "return_predict": 50, "return_train_scor": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 51, 55, 57, 59], "reus": [37, 61], "revenu": 44, "revers": [34, 38], "review": [4, 10, 25, 35, 42, 49, 51, 53, 57, 58, 59, 61], "revisit": [37, 53], "revok": 0, "reward": [29, 34, 42], "rf": [47, 48], "rf_imp_df": 40, "rfe_cv": 41, "rfe_pip": 41, "rfecv": 41, "rgb": 29, "rich": [40, 45, 48, 49, 53], "richard": 49, "rico": 40, "rid": [11, 34, 39, 40, 45, 48], "ridg": [40, 41, 44, 47, 48, 49, 50, 51], "ridge__alpha": 38, "ridge_pr": 38, "ridge_tun": 38, "ridgecv": [41, 51], "ridgecv_pip": 38, "ridgeridg": [38, 41], "right": [0, 10, 29, 35, 36, 37, 38, 41, 42, 43, 44, 45, 49, 50, 53, 57, 58, 61], "rightarrow": [30, 32, 35, 37, 38, 39, 42, 43, 44, 45, 49, 50, 53], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 45, "rise": [41, 45], "risk": [10, 37, 41, 49, 55, 59], "river": 35, "rl": [38, 40, 49], "rmse": [44, 53], "rng": [41, 43], "rnn": 47, "ro": 37, "roast": 42, "robot": [44, 45], "robust": [29, 31, 32, 33, 36, 39, 43, 55, 57], "roc": [50, 53, 61], "roc_auc": 37, "roc_auc_scor": 37, "roc_curv": 37, "roc_lr": 37, "roc_svc": 37, "roccurvedisplai": 37, "rodolfo": 36, "rodr\u00edguez": 45, "roger": 41, "role": [35, 36, 40, 46], "roman": 44, "romanc": 44, "romant": 44, "ronald": 35, "roof": 40, "roofmatl": [38, 40, 49], "roofmatl_clytil": [38, 40], "roofmatl_compshg": [38, 40], "roofmatl_membran": 38, "roofmatl_met": 38, "roofmatl_rol": 38, "roofmatl_tar": 38, "roofmatl_wdshak": 38, "roofmatl_wdshngl": [38, 40], "roofstyl": [38, 40, 49], "roofstyle_flat": 38, "roofstyle_g": 38, "roofstyle_gambrel": 38, "roofstyle_hip": 38, "roofstyle_mansard": 38, "roofstyle_sh": 38, "room": [29, 30, 35, 38, 41, 51, 61], "rooms_per_household": [33, 34, 41, 56], "rooms_per_household_0": 41, "rooms_per_household_1": 41, "rooms_per_household_10": 41, "rooms_per_household_11": 41, "rooms_per_household_12": 41, "rooms_per_household_13": 41, "rooms_per_household_14": 41, "rooms_per_household_15": 41, "rooms_per_household_16": 41, "rooms_per_household_17": 41, "rooms_per_household_18": 41, "rooms_per_household_19": 41, "rooms_per_household_2": 41, "rooms_per_household_3": 41, "rooms_per_household_4": 41, "rooms_per_household_5": 41, "rooms_per_household_6": 41, "rooms_per_household_7": 41, "rooms_per_household_8": 41, "rooms_per_household_9": 41, "root": [11, 30, 32, 44, 46, 53], "rose": 45, "rostin": 61, "rotat": [47, 60], "rough": 4, "roughli": [5, 31, 45, 50, 53], "round": [8, 32, 33, 36, 37, 39, 43, 46, 55], "rout": [5, 30, 47], "row": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 59, 60, 61], "rry": 45, "rsh": 36, "ru": [8, 37], "rubric": 35, "rule": [1, 8, 29, 30, 32, 35, 37, 39, 45, 50, 53, 55, 58], "run": [4, 5, 7, 10, 11, 29, 31, 32, 34, 36, 37, 38, 40, 42, 43, 45, 46, 50, 51, 52, 54, 55, 57, 59], "run_ast_nod": 51, "run_cel": 51, "run_cell_async": 51, "run_cod": 51, "run_forev": 51, "runner": 51, "runpi": 51, "runtimewarn": 36, "rush": 41, "russel": 10, "rv": 36, "rv_continuous_frozen": 36, "rv_discrete_frozen": 36, "rvert_2": 45, "s1": [8, 45], "s19": 33, "s2": [8, 45], "s_lag": [47, 60], "sa": 1, "sabrina": 10, "sadli": 45, "safe": 33, "safeti": 46, "sai": [8, 30, 32, 33, 34, 37, 38, 39, 40, 45, 47, 49, 53, 58], "said": [31, 33, 35, 40, 43, 44, 45, 49], "sal": [38, 40, 49], "sale": [8, 37, 38, 47, 49, 55], "salecondit": [38, 40, 49], "salecondition_abnorml": 38, "salecondition_adjland": 38, "salecondition_alloca": 38, "salecondition_famili": 38, "salecondition_norm": 38, "salecondition_parti": 38, "salepric": [38, 40, 49], "sales_data": 47, "salesforc": 51, "saletyp": [38, 40, 49], "saletype_cod": 38, "saletype_con": 38, "saletype_conld": 38, "saletype_conli": 38, "saletype_conlw": 38, "saletype_cwd": 38, "saletype_new": 38, "saletype_oth": 38, "saletype_wd": 38, "salt": [35, 40], "sam": 44, "same": [6, 7, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 58, 60], "sampl": [30, 32, 33, 35, 36, 40, 43, 46, 47, 48, 49, 50, 54, 55, 58, 59, 60], "sample_df": [37, 50], "sample_text": 51, "sampling_strategi": 37, "samuel": 29, "sand": 46, "sandbar": 46, "saniti": [30, 48], "sarah": 10, "sat": 47, "satisfactori": 42, "satisfi": [42, 61], "satur": 49, "saturdai": [10, 47], "save": [7, 8, 34, 36, 40, 45, 46, 47, 49, 51, 56, 57, 60], "saw": [33, 35, 36, 37, 43, 53], "sb": 41, "scalabl": [29, 43], "scalar": 8, "scale": [16, 31, 32, 34, 36, 37, 38, 39, 41, 43, 46, 48, 49, 50, 53, 55, 56, 57], "scale_pos_weight": 39, "scaler": [33, 40, 41], "scan": 53, "scari": 50, "scatter": [33, 38, 40, 41], "scatter_3d": 41, "scatterplot": [41, 50], "scc": 45, "scenario": [31, 34, 39, 40, 41, 43, 47, 48, 50, 53, 61], "schafer": 50, "schedul": [48, 53], "schmidt": 36, "school": [29, 37, 39, 40, 44, 58], "scienc": [2, 9, 10, 11, 34, 42, 47, 49, 53, 55, 61], "scientif": [44, 45], "scientist": [9, 10, 43], "scikit": [9, 11, 16, 17, 30, 32, 35, 36, 37, 39, 42, 43, 46, 47, 49, 51, 52, 57, 58, 61], "scipi": [11, 36, 43, 45, 57], "scm": 5, "scope": [45, 47], "score": [17, 18, 29, 32, 33, 34, 39, 40, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61], "score_func": 38, "score_gb_test": 49, "score_gb_train": 49, "score_lr_print_coeff": [47, 60], "score_param": 34, "score_rf_test": 49, "score_rf_train": 49, "score_tim": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 51], "scorer": [34, 38], "scores_averag": 59, "scores_dict": 35, "scores_imag": 35, "scores_stack": 59, "scoring_method": 48, "scoring_metr": [39, 40, 51], "scotland": 45, "scott": 49, "scratch": [2, 46, 50], "screen": 7, "screennam": 51, "screenplai": 45, "screenporch": [38, 40, 49], "script": 11, "scroog": 51, "sd": [19, 23, 24, 25, 26, 27, 28], "sdng": 38, "se": [47, 48, 60], "sea": 46, "seaborn": [40, 41, 42, 43, 44], "seacoast": 46, "search": [4, 5, 11, 38, 45, 53, 57], "search_multi": 38, "seashor": 46, "season": 60, "season_autumn": 47, "season_fal": 47, "season_summ": 47, "season_wint": 47, "seat": [46, 61], "seattl": 51, "seawal": 46, "second": [4, 6, 30, 35, 39, 40, 43, 46, 47, 49], "secondari": 29, "secpompeo": 51, "section": [7, 11, 30, 31, 41, 59, 61], "secur": [40, 50, 61], "see": [1, 4, 6, 7, 8, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61], "seed": [35, 36, 42, 43, 50], "seem": [30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 47, 48, 51, 52, 55, 57, 58], "seemingli": [37, 58], "seen": [8, 29, 31, 32, 33, 34, 35, 41, 43, 44, 48, 53, 55, 57, 59], "sefa": 61, "segment": [37, 45, 46, 48, 50, 53, 61], "segmentspher": 50, "select": [5, 6, 10, 11, 31, 32, 33, 34, 35, 36, 37, 38, 39, 46, 47, 48, 49, 50, 61], "select_dtyp": 38, "select_knn": 41, "select_rf": 41, "select_svc": 41, "selectfrommodel": 41, "self": [29, 34, 48, 51, 61], "sell": [0, 8, 30, 49], "semant": [42, 43, 45, 61], "semest": 61, "semi": [10, 45], "semicolon": 8, "semilogx": 38, "send": [4, 29, 51], "senior": 48, "seniorcitizen": 48, "sens": [6, 31, 34, 35, 37, 38, 40, 41, 42, 44, 45, 47, 48, 50, 52], "sensibl": [7, 50], "sensit": [31, 33, 36, 37, 38, 42, 48], "sent": [29, 45], "sent_token": 45, "sentenc": [45, 49], "sentiment": [30, 35, 45, 51], "sentimentintensityanalyz": 51, "sepal": [32, 55], "separ": [30, 31, 33, 34, 35, 37, 41, 42, 44, 45, 47, 52, 53, 54, 55, 56, 57, 58], "septemb": 47, "sequenc": [31, 34, 46, 47, 49], "sequenti": [30, 39, 47, 48, 53], "sequentialfeatureselector": 41, "ser": [31, 33, 48], "seri": [2, 10, 31, 33, 34, 37, 41, 46, 48, 50, 51, 61], "serial": 39, "seriou": [6, 37, 44, 45, 48, 50, 61], "serv": [5, 30, 40, 61], "server": 5, "servic": [39, 40, 44, 48, 51], "session": [42, 53, 61], "set": [7, 8, 9, 10, 29, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 55, 56, 57, 58, 59, 60], "set_config": [36, 39], "set_index": [31, 32, 36, 37, 38], "set_opt": [29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 54, 55, 56, 57, 58], "set_properti": 29, "set_titl": [32, 35, 37, 46, 55, 58], "set_xlabel": [32, 35, 42, 55], "set_ylabel": [32, 35, 42, 55], "settl": [57, 58], "setup": [3, 7, 11, 54], "setup_default_warn": 51, "sev": [38, 40, 49], "sever": [11, 33, 35, 42, 43, 45, 46, 47, 52, 60, 61], "sex": [37, 39, 40, 41, 58, 59], "sexual": 61, "shadab": 61, "shadow": [19, 23, 24, 25, 26, 27, 28], "shaikh": 61, "shall": [0, 45], "shallow": 39, "shap": 50, "shape": [30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 58, 60], "shape_df": 31, "shape_dict": 31, "share": [0, 41, 50, 61], "sharealik": 1, "sharex": 33, "shashwat": 61, "she": [29, 44, 51], "shed": [38, 40, 49], "sheet": [9, 50, 53], "shelf": [39, 45, 57], "shell": [5, 9, 51], "shelv": 51, "shift": [47, 60], "shit": 51, "shng": 38, "shop": 44, "short": [10, 11, 31, 36, 39, 45, 61], "shorter": 48, "shorthand": 33, "shortli": 50, "shot": 41, "should": [5, 7, 8, 11, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61], "shouldn": [37, 39, 55], "show": [4, 7, 11, 29, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 53, 55, 57, 59, 60], "show_plot": 48, "showcas": 45, "shown": [7, 11, 29, 30, 32, 37, 39, 42, 43, 47, 49], "shrink": [36, 41, 49], "shuffl": [31, 46, 47, 60], "si": 29, "sibl": 41, "sick": [42, 51], "sid": 51, "side": [6, 46, 49], "sift": 44, "sigma": 46, "sign": [4, 38, 40, 46, 55, 57, 59, 61], "signal": [31, 45], "signific": [33, 46, 49, 61], "significantli": [34, 37, 44], "sigoptsearchcv": 36, "silhouett": 43, "silhouettevisu": [42, 43], "sim": 40, "sim_word": 45, "simard": 40, "similar": [10, 11, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 49, 52], "similarity_": 45, "similarli": [40, 42, 48], "simp": 47, "simpl": [10, 30, 32, 33, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 53, 54, 58], "simplefilt": [39, 40], "simpleimput": [33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 56, 57, 58, 59, 60], "simpleimputersimpleimput": [33, 34, 38, 39, 41, 49], "simpler": [35, 36, 50, 55], "simplest": 34, "simpli": [33, 41, 42], "simplic": [30, 34, 44], "simplist": [32, 40, 55], "simul": 41, "sin": 8, "sinc": [5, 35, 38, 40, 41, 42, 44, 46, 47, 48, 49, 52, 53, 54, 60], "singl": [8, 32, 33, 35, 36, 37, 39, 40, 43, 47, 48, 53, 54, 55, 57, 58], "sit": 61, "site": [5, 30, 31, 34, 36, 40, 48, 50, 51, 52, 61], "situat": [6, 29, 37, 39, 42, 46, 48, 61], "six": [31, 39, 47, 50], "size": [29, 30, 31, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 59, 60, 61], "skeleton": 49, "skeptic": 49, "skew": 38, "skill": [39, 50, 61], "skin": 51, "skip": 58, "skipna": 48, "sklearn": [10, 29, 31, 32, 35, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "sklearn_gb": 39, "sklearn_histgb": 39, "sktime": 47, "skyblu": [47, 60], "skyscrap": 47, "slate": 60, "slice": 8, "slide": [9, 10, 19, 25, 33, 46, 61], "slightli": [34, 35, 37, 39, 48], "slipper": 49, "slope": 35, "sloppi": 33, "slot": 61, "slow": [32, 39, 41, 46], "slower": [39, 42], "slowest": 59, "sm": [29, 34], "smac": 36, "small": [11, 31, 32, 34, 36, 38, 39, 40, 41, 42, 44, 46, 48, 53, 55, 57, 59], "small_citi": 32, "small_train_df": 32, "smallalpha_coeff": 38, "smaller": [32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 55, 57], "smallest": [35, 38, 42, 43], "smart": [42, 49, 51], "smile": 51, "smooth": [32, 55], "smoothli": 11, "smote_pip": 37, "sms_df": 29, "sn": [40, 42, 43], "snake": [35, 46], "snake_length": 35, "snakes_df": 35, "snbf": 39, "snippet": 7, "snow": [29, 46], "snp": 41, "so": [0, 4, 5, 7, 8, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61], "social": [42, 43, 44, 47], "societ": 61, "societi": [37, 45, 58], "sofist": 55, "soft": [35, 39, 59], "softmax": 53, "softwar": [1, 5, 11, 48], "solar": 44, "sold": [8, 38], "sole": [37, 43], "solidifi": 53, "solut": [29, 30, 31, 39, 42, 48, 49, 50, 51, 53, 61], "solv": [4, 29, 30, 32, 41, 45, 49, 50, 55, 61], "solver": 37, "some": [4, 6, 7, 8, 11, 29, 31, 32, 33, 34, 35, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61], "someon": [29, 30, 31, 41, 48, 49], "someth": [4, 7, 11, 30, 34, 37, 38, 39, 40, 42, 47, 48, 49, 50, 53, 61], "sometim": [6, 30, 31, 34, 35, 36, 39, 40, 45, 49, 50], "somewhat": 38, "somewher": [29, 38], "song": [32, 33, 44, 51, 57], "song_titl": [32, 33, 36, 57], "soo": 61, "soon": [29, 32, 33, 47, 50], "sopha": 29, "sophist": [36, 40, 45], "sort": [5, 10, 30, 31, 33, 40, 44, 45, 46, 47, 50, 60], "sort_index": [8, 36, 38, 47, 60], "sort_valu": [33, 34, 35, 36, 38, 39, 40, 41, 47, 48, 51, 59, 60], "sound": [40, 41], "soundtrack": 45, "sourc": [11, 29, 30, 31, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 51, 54, 57, 61], "south": 34, "space": [32, 35, 36, 41, 42, 43, 45, 51, 60, 61], "spaci": 41, "spacy_download": 45, "spacymoji": 51, "spam": [31, 37, 42], "spam_predict": 29, "span": [45, 47], "spanish": 33, "spars": [32, 35, 39, 44, 45, 53], "sparse_output": [33, 34, 37, 38, 39, 40, 47, 48, 49, 53, 58, 59, 60], "spatial": 35, "speak": [5, 50], "spearmint": 36, "speci": [32, 53, 55], "special": [29, 34, 44, 45, 46, 47, 48, 55, 61], "specialti": [37, 39, 40], "specif": [8, 30, 31, 36, 37, 40, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 57, 59, 61], "specifi": [8, 30, 31, 34, 36, 37, 42, 43, 46, 49, 50, 57, 59], "spectrogram": 41, "speech": [41, 45, 51], "speechi": [32, 33, 36, 57], "speed": [8, 30, 39, 46, 50], "spell": 29, "spend": [29, 33, 41, 49, 51, 61], "spent": [6, 33, 41], "spheric": [43, 53], "spici": 42, "spini": 46, "spit": 46, "split": [15, 30, 32, 34, 35, 36, 38, 39, 41, 44, 45, 48, 50, 51, 53, 58, 59, 60, 61], "split0_test_r2": 38, "split0_test_scor": 36, "split0_train_neg_mean_squared_error": 38, "split0_train_scor": 36, "split1_test_r2": 38, "split1_test_scor": 36, "split1_train_neg_mean_squared_error": 38, "split1_train_scor": 36, "split2_test_r2": 38, "split2_test_scor": 36, "split2_train_neg_mean_squared_error": 38, "split2_train_scor": 36, "split3_test_r2": 38, "split3_test_scor": 36, "split3_train_neg_mean_squared_error": 38, "split3_train_scor": 36, "split4_test_scor": 36, "split4_train_neg_mean_squared_error": 38, "split4_train_scor": 36, "spoken": 34, "sport": [45, 46, 47], "spot": [37, 38, 50, 55], "spotifi": [32, 44, 57], "spotify_df": [32, 33, 36, 57], "spotlight": [5, 11], "spous": [37, 39, 40], "spread": 43, "spring_month": 47, "sqft": 40, "sqft_abov": [29, 30], "sqft_basement": [29, 30], "sqft_live": [29, 30], "sqft_living15": [29, 30], "sqft_lot": [29, 30], "sqft_lot15": [29, 30], "sqrt": [32, 38, 40, 44, 45], "squar": [8, 30, 32, 35, 40, 44, 48, 49, 51, 53, 61], "squash": [35, 46], "squeez": [8, 48], "src": [31, 37], "sse": [47, 60], "ssw": 47, "st": [47, 51], "st_slope": 59, "stabil": 11, "stabl": [31, 37, 39, 55], "stack": [7, 50, 53, 61], "stack_method": 59, "stacking_model": [39, 59], "stacking_model_tre": 39, "stackingclassifi": [39, 59], "stackingregressor": 39, "staff": 6, "stai": [37, 48], "stakehold": [49, 50, 61], "stale": 42, "stand": [32, 36, 45, 50], "standard": [4, 6, 31, 33, 36, 39, 40, 41, 45, 50], "standardscal": [34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 53, 56, 57, 58, 59, 60], "standardscalerstandardscal": [33, 34, 36, 37, 38, 39, 41, 46, 49, 51], "stanford": 45, "star": [32, 42, 44, 51], "start": [7, 8, 11, 30, 31, 32, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 60], "startswith": 40, "starttim": 47, "stat": [36, 48, 57], "state": [6, 8, 31, 37, 39, 40, 44, 50, 51, 58], "statement": [7, 31, 32, 33, 34, 35, 36, 37, 38, 41, 46, 48, 49], "static": 50, "station": 47, "statist": [9, 10, 30, 35, 40, 44, 45, 48, 61], "statistician": 32, "statlib": 35, "statsmodel": [47, 48], "statu": [37, 39, 40, 58], "status_marri": 40, "status_nev": 40, "std": [31, 32, 33, 37, 38, 46, 47, 51, 52, 60], "std_cv_error": 31, "std_cv_score": 32, "std_fit_tim": [36, 38], "std_score": [31, 33, 51], "std_score_tim": [36, 38], "std_test_neg_mean_squared_error": 38, "std_test_scor": [31, 36], "std_train_error": 31, "std_train_neg_mean_squared_error": 38, "std_train_scor": [31, 32, 36], "stdki": 48, "stem": 45, "step": [7, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 59, 61], "stereotyp": 45, "stick": 47, "still": [4, 11, 36, 37, 38, 39, 41, 42, 47, 48, 51, 55, 56, 57, 58], "stipul": 49, "stochast": [41, 42], "stock": [29, 47], "stop": [8, 42, 45, 46, 48, 55], "stop_word": [36, 37, 45, 50, 51, 57], "stopword": 45, "storag": 32, "store": [7, 8, 32, 33, 34, 36, 37, 39, 40, 43, 44, 46, 47, 48, 50, 51], "stori": [38, 39, 51], "storylin": 45, "str": [36, 40, 45, 47, 48, 51, 60], "straight": [48, 50], "straightforward": 40, "strain": 7, "strang": [40, 48], "strata": 48, "strategi": [30, 32, 33, 34, 37, 38, 40, 42, 44, 47, 48, 49, 50, 53, 54, 58, 60], "stratif": 48, "stratifi": 48, "stratifiedkfold": [31, 37], "stream": [48, 51], "streamingmovi": 48, "streamingmovies_no": 48, "streamingmovies_y": 48, "streamingtv": 48, "streamingtv_no": 48, "streamingtv_y": 48, "street": [38, 40, 49], "street_grvl": 38, "street_pav": 38, "strength": [45, 53], "stress": 42, "strftime": [47, 48], "string": [8, 11, 32, 37, 38, 39, 40, 45, 47, 48, 55, 59], "strip": [40, 46], "strong": [39, 48, 53], "stronger": 39, "strongli": 39, "structur": [8, 42, 45, 46], "struggl": [42, 47], "stuart": [10, 39], "stuck": [4, 8], "student": [4, 5, 6, 7, 29, 30, 35, 37, 38, 40, 41, 42, 43, 44, 46, 50, 51, 61], "studi": [29, 34, 41, 45, 48], "stuff": [32, 46, 48], "stump": [30, 31, 32, 39, 54], "stupid": 51, "style": [29, 38, 41, 42, 44, 45, 46, 49, 50, 51], "sub": [36, 42, 45, 48, 49, 50, 53], "subdirectori": [40, 50], "subgroup": 48, "subject": [0, 48, 61], "sublicens": 0, "submiss": [3, 61], "submit": [8, 10, 50, 61], "subplot": [31, 32, 35, 37, 42, 46, 48, 49, 55, 58], "subplot_kw": 31, "subprocess": 38, "subscrib": 48, "subscript": [47, 48], "subset": [30, 31, 36, 39, 46, 47, 52, 55], "substanc": 49, "substanti": 0, "substitut": 0, "subtl": 45, "subtleti": [31, 38], "subtract": [32, 37, 40], "suburb": 51, "subword": 45, "succe": [41, 61], "success": [5, 8, 11, 29, 37, 39, 44, 45, 46, 47, 50], "successfulli": [11, 29, 51], "sudo": 5, "suei": 36, "suffer": 36, "suffici": [7, 45], "suggest": [0, 10, 30, 44, 48], "suicid": 45, "suit": 44, "suitabl": [11, 29, 42, 44, 50, 53, 59, 61], "sum": [8, 32, 33, 34, 35, 39, 40, 42, 46, 51], "sum_": [32, 38, 42, 45, 46], "sum_i": [40, 45], "sum_prob_ex1_class_0": 39, "sum_prob_ex1_class_1": 39, "summar": [10, 29, 35, 37, 38, 42, 45, 50], "summari": [0, 52, 53, 55], "summary_plot": 40, "summat": [39, 49], "summer": [1, 44, 47], "summer_month": 47, "sun": [45, 47], "sundai": 47, "sundial": 46, "sunshin": [47, 60], "super": [34, 51, 53], "superfici": 32, "superior": 61, "supermarket": 51, "supervis": [33, 34, 36, 37, 38, 41, 43, 45, 47, 48, 53, 60, 61], "suppli": 61, "support": [11, 15, 30, 33, 37, 39, 40, 41, 43, 45, 49, 51, 52, 55, 61], "support_": [32, 41], "suppos": [29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 49, 53, 54], "suppress": 8, "suprem": 45, "sure": [4, 7, 8, 11, 31, 32, 34, 37, 38, 39, 40, 43, 46, 47, 49, 50, 55, 58, 59, 60, 61], "surgeri": 48, "suri": 61, "surpris": [40, 44], "surprisingli": [34, 35], "surround": [4, 49, 61], "survei": 42, "surviv": [2, 10, 49, 50, 61], "survival_function_": 48, "suscept": [43, 50], "suspect": 36, "svc": [32, 33, 34, 35, 36, 39, 40, 41, 46, 51, 55, 56, 57, 59], "svc__c": [36, 57], "svc__gamma": [36, 57], "svc_pipe": 36, "svc_pred": 37, "svcsvc": [34, 36, 37], "svm": [10, 31, 33, 34, 36, 39, 40, 41, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 59], "svm_estim": 37, "svr": [32, 34, 40, 49], "svr_c_pipe": 34, "svr_pipe": 34, "sw": [47, 60], "swai": 29, "swamp": 32, "swan": 46, "swcarpentri": 9, "sweep": 37, "sweet": 51, "switch": [40, 42, 47, 48, 49, 60], "sy": [29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59], "sydnei": 47, "syllabu": [3, 7, 10, 12], "symbol": 30, "symmetri": 41, "sync": [5, 49], "synonym": 45, "syntact": 45, "syntax": [4, 8, 29, 41, 48], "syntaxwarn": 49, "synthet": [41, 52], "system": [2, 4, 5, 6, 10, 11, 29, 31, 32, 34, 37, 40, 42, 47, 49, 50, 58, 61], "systemat": [30, 34, 36, 40, 45], "t": [4, 5, 7, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 59, 60, 61], "ta": [7, 29, 38, 40, 49, 50, 54, 55, 56, 57, 58, 59, 60], "tabbi": [29, 46], "tabl": [7, 59], "tabular": [8, 29, 46, 47], "tackl": [31, 33, 37, 43, 55], "taco": 41, "tag": [4, 45, 51], "tail": [8, 47], "tailor": [42, 49, 50, 61], "take": [2, 4, 5, 6, 11, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61], "taken": [47, 52, 57, 61], "talk": [30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 61], "tall": 45, "target": [31, 32, 33, 35, 36, 37, 39, 40, 41, 44, 46, 47, 48, 49, 50, 53, 55, 56, 57, 58, 59, 60], "target_column": [39, 40, 48, 59], "target_nam": 37, "target_names_toi": 37, "tariff": 45, "task": [33, 34, 35, 36, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 57, 60, 61], "tast": [42, 44], "taught": [34, 45, 61], "tax": 49, "tba": 10, "tbd": [19, 61], "teach": [4, 29, 33, 45, 49, 53], "team": [4, 8, 29, 39, 40, 45, 59], "tech": [32, 37, 40], "technic": [49, 50, 61], "techniqu": [10, 32, 36, 41, 44, 46, 48, 50, 52, 53, 61], "technolog": 0, "technologi": 45, "techsupport": 48, "techsupport_no": 48, "techsupport_y": 48, "ted": 42, "tediou": 43, "telco": 48, "telecom": 48, "telephon": 45, "tell": [31, 32, 33, 35, 37, 40, 41, 44, 45, 47, 48, 49, 50, 55, 57, 60], "temp3pm": [47, 60], "temp9am": [47, 60], "temperatur": 30, "templat": 50, "tempo": [32, 33, 36, 57], "tempor": [48, 53, 60], "tend": [31, 32, 35, 39, 41, 44, 47, 48, 61], "tendenc": 31, "tensor": 46, "tensor_numpi": 51, "tensorflow": [11, 40, 46], "tent": 61, "tenur": [48, 49, 53], "tenure_lm": 48, "tenure_predict": 48, "term": [0, 2, 28, 30, 32, 34, 35, 37, 40, 41, 44, 45, 48, 49, 50, 53], "termin": [5, 11, 30, 42, 50], "terminologi": [14, 31, 37, 53, 54], "terrac": 46, "terribl": [38, 44], "territori": 61, "tesoro": 36, "test": [1, 7, 8, 11, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 43, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 61], "test_accuraci": 37, "test_average_precis": 37, "test_df": [29, 33, 34, 35, 37, 38, 39, 40, 41, 47, 48, 49, 50, 51, 56, 58, 59, 60], "test_df_churn": 48, "test_df_nan": [37, 39, 40, 58], "test_df_sort": 47, "test_df_surv": 48, "test_exampl": 39, "test_f1": 37, "test_format": 32, "test_g50k": 39, "test_imag": [29, 46], "test_l50k": 39, "test_mape_scor": 38, "test_nam": 48, "test_neg_mean_squared_error": 38, "test_neg_root_mean_square_error": 38, "test_point": [32, 52], "test_precis": 37, "test_r2": 38, "test_recal": 37, "test_roc_auc": 37, "test_sampl": 59, "test_scor": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 51, 55], "test_shap_valu": 40, "test_siz": [29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 49, 50, 51, 52, 55, 56, 57, 58, 59], "test_sklearn": 38, "test_statist": 48, "test_x": 48, "text": [7, 10, 16, 17, 29, 30, 35, 36, 37, 38, 39, 40, 41, 44, 46, 49, 50, 53, 57, 61], "text_feat": [36, 57], "text_featur": 51, "text_pp": 45, "textbook": [3, 9, 49], "textrm": 31, "textual": 61, "textur": 41, "tf": 34, "tfidfvector": 35, "th": [35, 44, 61], "than": [6, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 54, 55, 58, 59, 61], "thank": [29, 45, 55], "thankfulli": [47, 60], "thei": [7, 8, 10, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59, 60, 61], "theirs": 45, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 61], "theme": 45, "themselv": [42, 43, 45], "theoret": [33, 37, 39, 53], "theori": 40, "thepopbreak": 51, "therefor": 55, "thermostat": 30, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 25, 28, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "thick": 42, "thinc": 51, "thing": [5, 7, 8, 10, 30, 31, 32, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 55, 59, 60], "think": [4, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 42, 44, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 60, 61], "third": 43, "thk": 29, "thorough": [11, 59], "thoroughli": 53, "those": [5, 8, 11, 33, 38, 39, 40, 44, 48, 49, 50, 61], "though": [31, 34, 35, 42, 43, 44, 50, 51], "thought": [4, 32, 40, 48, 53], "thousand": [35, 43, 44], "threahold": 41, "threaten": 51, "three": [8, 30, 33, 35, 37, 39, 40, 41, 42, 43, 45, 46, 47, 52, 53, 58, 61], "thresh": 8, "threshold": [30, 35, 39, 41, 43, 45, 48], "thresholds_lr": 37, "thresholds_svc": 37, "through": [7, 11, 30, 37, 38, 41, 43, 44, 46, 49, 61], "throughout": [31, 49], "throw": [34, 46, 48, 49, 53], "thu": [6, 36, 47, 48], "thumb": [30, 51], "thursdai": 61, "ti": 34, "tick": 47, "tick_label": 40, "tick_param": 42, "tiger": [29, 46], "tight": [32, 43, 55], "tight_layout": [46, 49], "tightrop": [32, 55], "tile": 40, "till": [32, 45, 48], "timber": 45, "time": [2, 4, 8, 10, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 54, 55, 57, 58, 59, 61], "time_diff": [47, 60], "time_signatur": [32, 33, 36, 57], "timedelta": [47, 60], "timeit": [8, 52], "timelin": 49, "timeseri": [46, 47], "timeseriessplit": [47, 48, 53, 60], "timestamp": [47, 60], "timezon": [10, 48], "tinder": 44, "tini": [7, 31, 37, 43], "tip": 45, "tire": 51, "titan": 44, "titi": 29, "titl": [7, 31, 32, 35, 38, 41, 43, 46, 47, 48, 49, 55, 60], "tn": 37, "to_datetim": [47, 60], "to_html": [29, 30, 31], "to_notebook_ifram": 38, "to_numpi": [32, 44, 47], "to_str": [29, 46], "toarrai": [34, 40, 47], "tobago": [39, 40], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 44, 46, 47, 48, 50, 53, 59, 60], "todens": [40, 41], "togeth": [5, 8, 30, 32, 33, 34, 42, 45, 55, 61], "toi": [8, 31, 32, 41, 42, 43, 44, 47, 53], "toilet": [46, 51], "token": [7, 51, 61], "token_pattern": 34, "tol": [37, 41, 49], "told": [5, 61], "tolist": [29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 47, 48, 51, 60], "tomasbeuzen": 8, "tomorrow": [30, 47, 48, 53, 60], "ton": 36, "tone": 51, "too": [6, 7, 31, 32, 34, 36, 38, 39, 40, 47, 48, 49, 50, 55, 57, 60, 61], "took": 47, "tool": [7, 8, 10, 11, 34, 35, 37, 38, 40, 43, 44, 46, 47, 48, 50, 53, 61], "toolbox": [32, 39, 45], "toolkit": 45, "top": [30, 34, 36, 37, 43, 47, 49, 50, 60], "topic": [2, 8, 10, 30, 37, 38, 42, 44, 46, 50, 53, 61], "topic2vec": 45, "topics_per_chunk": 45, "topn": [29, 46], "torch": [46, 51], "torchvis": [29, 46], "tornado": 51, "toronto": [45, 49, 51], "tort": 0, "total": [8, 10, 30, 33, 34, 37, 38, 39, 40, 41, 45, 47, 48, 49, 60], "total_bedroom": [33, 34, 41, 56], "total_bilirubin": 29, "total_protien": 29, "total_room": [33, 34, 41, 56], "total_second": [47, 60], "totalbsmtsf": [38, 40, 49], "totalcharg": 48, "totem": 46, "totensor": 46, "toti": [0, 1, 45], "totrmsabvgrd": [38, 40, 49], "touch": 50, "toward": [35, 40, 45, 58, 61], "towardsdatasci": [46, 48], "town": 51, "townsvil": 47, "toy_clust": 45, "toy_clust_df": 42, "toy_df": [34, 45], "toy_lda_data": 45, "toy_movie_feat": 44, "toy_rat": 44, "toy_spam": 34, "toy_x": 45, "tp": 37, "tpot": 36, "tpr": 37, "tpr_lr": 37, "tpr_svc": 37, "tr_score": 55, "traceback": [4, 8, 34, 48, 50, 51], "track": [34, 50, 61], "trade": [35, 37, 41, 42, 53, 61], "tradeoff": [15, 32, 33, 35, 38, 41, 42, 46], "tradit": [29, 44, 46, 48, 61], "tradition": 61, "trail": 8, "train": [7, 32, 33, 36, 38, 39, 40, 41, 42, 44, 45, 48, 51, 52, 53, 54, 55, 56, 57, 59, 60], "train_accuraci": 37, "train_dataload": 46, "train_df": [29, 33, 34, 35, 37, 38, 39, 40, 41, 47, 48, 49, 50, 51, 56, 58, 59, 60], "train_df_churn": 48, "train_df_nan": [37, 39, 40, 58], "train_df_ord": [47, 60], "train_df_sort": 47, "train_df_surv": 48, "train_df_surv_not_churn": 48, "train_f1": 37, "train_flatten": 46, "train_for_usr": 44, "train_load": 46, "train_mape_scor": 38, "train_mat": 44, "train_mat_imp": 44, "train_neg_mean_squared_error": 38, "train_neg_root_mean_square_error": 38, "train_precis": 37, "train_r2": 38, "train_recal": 37, "train_scor": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 51, 55], "train_shap_valu": 40, "train_sklearn": 38, "train_test_split": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60], "train_x": 44, "traitlet": 51, "transact": [30, 37, 47, 49, 58], "transfer": [48, 50], "transfer_learning_tutori": 46, "transform": [0, 32, 36, 37, 39, 40, 43, 45, 46, 47, 48, 50, 51, 53, 55, 56, 60], "transformed_exampl": 39, "transformed_oh": 33, "transformedtargetregressor": [38, 41, 49, 51, 53], "transformedtargetregressortransformedtargetregressor": 38, "transformerdecod": 51, "transformerencod": 51, "translat": [9, 10, 29], "transpar": [37, 53], "transpos": [41, 46], "trasform": 33, "trash": 54, "traumat": 61, "treat": [8, 31, 33, 34, 37, 38, 44, 47, 48, 49, 53, 58, 60], "treati": 61, "treatment": 34, "tree": [2, 10, 14, 19, 20, 31, 32, 33, 34, 35, 36, 38, 41, 43, 46, 47, 48, 50, 52, 53, 54, 56, 57, 59], "tree1": 39, "tree2": 39, "tree3": 39, "tree_numeric_transform": 40, "treeexplain": 40, "trend": [48, 53, 61], "tri": [39, 40, 49, 52, 57, 58, 59], "trial": [36, 48], "triangl": [32, 42], "trick": [5, 38], "tricki": [34, 36, 40, 44], "trigger": [32, 51], "trigram": 45, "trivial": 43, "troubl": 11, "true": [8, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60], "truli": [38, 45], "truncat": 43, "truncate_mod": 43, "truncation_mod": 43, "trust": [29, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 49, 51], "trustworthi": [43, 59], "truth": [39, 41, 42, 43, 44, 47], "try": [4, 5, 8, 10, 11, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 57, 58, 59, 60, 61], "tsa": 47, "tscv": 47, "tslearn": 47, "tsunami": 29, "ttr": 38, "ttr_pipe": 38, "tue": 47, "tuesdai": [10, 41, 47, 60, 61], "tuggeranong": 47, "tumor": 53, "tune": [31, 36, 39, 43, 44, 46, 49, 50, 57, 59], "turn": [4, 31, 45, 46, 48, 56, 57, 61], "tusker": 46, "tutori": [4, 5, 9, 10, 11, 44, 46, 50, 53, 61], "tweak": [32, 55], "tweet": [45, 51], "tweetat": 51, "twice": [8, 31, 34, 35], "twinx": 49, "twist": 45, "twitter_allowed_char": 51, "two": [4, 6, 7, 8, 9, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 58, 61], "two_citi": 32, "two_song": 33, "two_songs_subset": 33, "tx": [35, 51], "tx_i": 49, "txt": [29, 46, 50], "typ": [38, 40, 49], "type": [4, 8, 11, 30, 32, 33, 34, 36, 39, 41, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 60, 61], "typeerror": 48, "typic": [2, 7, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 47, 49, 50, 57], "u": [4, 11, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 56, 57, 59, 60], "u6": 30, "u_1": 32, "u_2": 32, "u_i": 32, "u_n": 32, "ubc": [0, 4, 5, 8, 9, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 56, 57, 58, 59, 60, 61], "ubc_img": 46, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 38, "ultim": [4, 31, 49], "ultralyt": 46, "uluru": [47, 60], "umbrella": 44, "un": [38, 48], "unabl": [29, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 48, 49, 51, 61], "unambigu": 45, "unassign": [42, 43], "unbalanc": 58, "unbias": [37, 58], "unced": 61, "uncertain": [35, 59], "uncertain_indic": 59, "uncertainti": [35, 37, 49, 50], "unchang": 40, "uncia": [29, 46], "uncomfort": 44, "uncorrel": 40, "under": [0, 1, 7, 30, 31, 38, 46, 48, 50], "under_sampl": 37, "underestim": 48, "underfit": [32, 35, 36, 46, 55, 57], "underli": [2, 40, 41, 42], "underneath": 7, "underpredict": 38, "undersample_pip": 37, "understand": [0, 1, 4, 7, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 58, 61], "understood": 37, "unemploi": 48, "unexpect": [34, 35, 36, 45], "unexplain": 38, "unf": [38, 40, 49], "unfinish": 38, "unfortun": [6, 36, 40, 42, 43, 57], "uniform": [36, 37, 43, 57], "unimport": [36, 40], "uninstal": 11, "uninterpret": 40, "unintuit": 8, "union": 8, "uniqu": [33, 34, 37, 38, 39, 40, 44, 45, 47, 48, 58, 60], "unit": [35, 37, 38, 39, 40, 45, 46, 48, 51], "unitless": 38, "univers": [1, 9, 45], "university_year": [34, 53], "unix": [5, 47], "unknown": [6, 45, 53], "unlabel": [29, 31, 43], "unless": [7, 61], "unlik": [8, 31, 32, 34, 38, 40, 42, 43], "unlimit": 47, "unlucki": 31, "unmarri": [39, 40], "unnam": 29, "unoffici": 61, "unqualifi": [37, 58], "unreason": [6, 38], "unreli": 31, "unscal": 33, "unseen": [30, 41, 42, 46, 50, 55], "unsqueez": 46, "unstructur": 45, "unsupervis": [29, 44, 45, 46, 50, 61], "unsur": [7, 49], "until": [4, 30, 31, 36, 41, 42, 43, 48, 49, 50], "unus": 55, "unwieldi": [30, 33], "unzip": 40, "uoft": 45, "up": [7, 8, 29, 30, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 57, 61], "uparrow": 43, "upcom": 42, "updat": [10, 11, 32, 33, 34, 39, 42, 55], "update_cent": 42, "update_plot": [32, 55], "update_z": 42, "upgrad": [45, 51], "upload": 7, "upon": [0, 30, 31, 34, 37, 39, 40, 41, 42, 43, 45], "upper": [37, 48], "uppercas": 51, "upto": 47, "ur": 29, "urgent": [34, 45], "url": [4, 31, 37, 48, 50, 58], "us": [0, 2, 4, 5, 10, 11, 35, 36, 40, 43, 44, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60], "usa": [8, 31, 32, 35, 45], "usabl": 50, "usag": [33, 34, 37, 38, 41, 45, 47, 48, 60], "usec_": 48, "useless": [36, 40, 41], "user": [11, 29, 30, 31, 33, 34, 36, 39, 40, 42, 43, 46, 48, 49, 50, 51, 52, 53, 57], "user_global_n": 51, "user_id": 44, "user_inverse_mapp": 44, "user_kei": 44, "user_mapp": 44, "user_n": 51, "user_nam": 44, "usernam": 51, "userwarn": [30, 31, 34, 39, 40, 51], "usf": 34, "using_copy_on_writ": 48, "using_cow": 48, "usual": [10, 11, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 60, 61], "utc": [47, 48], "utcnow": 48, "util": [5, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 48, 49, 51, 53, 54, 55, 56, 57, 59], "utilities_allpub": 38, "utilities_nosewa": 38, "utility_mat": 44, "v": [3, 7, 10, 34, 35, 43, 45, 47, 48, 49, 53], "v1": [29, 37], "v10": 37, "v11": 37, "v12": 37, "v13": 37, "v14": 37, "v15": 37, "v16": 37, "v17": 37, "v18": 37, "v19": 37, "v2": [29, 37], "v20": 37, "v21": 37, "v22": 37, "v23": 37, "v24": 37, "v25": 37, "v26": 37, "v27": 37, "v28": 37, "v3": 37, "v4": 37, "v5": 37, "v6": 37, "v7": 37, "v8": 37, "v9": 37, "v_1": 32, "v_2": 32, "v_i": 32, "v_n": 32, "vacat": 35, "vaccin": [49, 51], "vader": 51, "vader_lexicon": 51, "vader_senti": 51, "vain": 36, "val": [44, 48], "valenc": [32, 33, 36, 51, 57], "valid": [10, 15, 30, 32, 34, 38, 39, 40, 41, 42, 44, 46, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60], "valid_dataload": 46, "valid_flatten": 46, "valid_load": 46, "valid_mat": 44, "valid_sample_df": 39, "valid_sample_i": 39, "valid_sample_x": 39, "valid_scor": 55, "valid_x": 44, "valu": [7, 8, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 60], "valuabl": [41, 43, 61], "value_count": [30, 34, 37, 39, 40, 47, 48, 50, 51, 58, 59, 60], "value_throttl": [32, 55], "valueerror": [8, 33, 34, 48, 50], "values_format": [37, 58], "vancouv": [45, 49], "vanilla": 35, "var": [31, 33, 40, 51, 57], "var_": 40, "varada": [0, 1], "vari": [30, 36, 39, 43, 48, 55, 61], "variabl": [7, 8, 30, 33, 34, 35, 36, 38, 40, 41, 47, 48, 49, 55, 60], "varianc": [38, 40, 43, 47, 55], "variant": [40, 43], "variat": [31, 35, 37, 38, 41], "varieti": [29, 39, 45], "variou": [29, 32, 38, 40, 46, 47, 48, 49, 50, 53, 55, 57, 61], "vault": 31, "ve": [7, 8, 29, 31, 32, 37, 38, 40, 44, 46, 47, 49, 50, 52, 60], "vec": [34, 45, 46], "vec1": 45, "vec1_i": 45, "vec2": 45, "vec2_i": 45, "vec8": 34, "vec8_binari": 34, "vec_binari": 34, "vecom": 36, "vector": [15, 30, 35, 37, 44, 46, 49, 55, 59], "verb": [45, 51], "verbos": [29, 37, 39, 40, 49], "veri": [2, 4, 5, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 60, 61], "verifi": 58, "versa": [38, 55, 58], "version": [4, 5, 7, 8, 11, 31, 33, 35, 36, 38, 40, 43, 45, 47, 48, 51, 52, 58, 60, 61], "versu": 9, "vert": 40, "vertic": [30, 37, 47], "vgg": 46, "vgg16": 46, "vgg16_weight": 46, "via": [1, 4, 7, 11, 37, 41, 61], "vice": [38, 55, 58], "video": [1, 7, 8, 9, 10, 11, 19, 23, 24, 25, 26, 27, 28, 44, 46, 48, 49, 50, 55, 58, 61], "vietnames": 33, "view": [6, 7, 11, 29, 30, 40, 43, 46, 47, 48, 49], "viewpoint": 44, "vif": 40, "vikski": 45, "violat": [33, 34, 48, 50, 61], "virginia": 46, "viridi": [36, 57], "visibl": 57, "vision": [10, 50, 52], "visit": [8, 61], "visual": [10, 30, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 46, 47, 48, 51, 53, 56, 57, 61], "viz": 49, "voc": [37, 39, 40, 58], "vocab": 45, "vocabulari": [34, 35, 45], "vocabulary_": 34, "voic": 29, "volcano": 29, "volum": 50, "vote": [32, 33, 39, 52, 59], "voting_ndt": 39, "votingclassifi": [39, 59], "votingclassifierinot": 39, "votingregressor": 39, "w": [11, 34, 35, 38, 42, 45, 47, 49, 50, 60, 61], "w_0": 35, "w_1": 35, "w_1x_1": 35, "w_2x_2": 35, "w_3x_3": 35, "w_4x_4": 35, "w_d": 35, "w_dx_d": 35, "w_j": 35, "wa": [4, 5, 11, 25, 30, 31, 33, 35, 37, 39, 40, 44, 45, 46, 48, 49, 51, 52, 54, 55, 57, 60, 61], "wa_fn": 48, "wai": [0, 2, 6, 8, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 55, 57, 58, 60, 61], "wait": [4, 29, 30, 32, 34, 48, 50, 61], "waitlist": 61, "waiv": 61, "walk": [32, 37, 50, 55], "walker": [29, 46], "wallabi": 46, "want": [4, 6, 7, 8, 11, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 60, 61], "war": 44, "ward": 43, "warm": 33, "warm_start": [37, 49], "warn": [6, 31, 32, 34, 38, 39, 40, 48, 52, 59], "warranti": 0, "washington": 51, "washroom": 61, "wast": [4, 34, 49], "watch": [10, 11, 32, 35, 44, 45, 53], "water": 49, "waterfal": 40, "waterfront": [29, 30], "wavelet": 41, "wb": 50, "wd": [38, 40, 49], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 43, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "weak": 53, "weather": [30, 47, 50], "weatherau": [47, 60], "web": [5, 45, 53], "web_api": 50, "web_appl": 50, "weblog": 45, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "wed": [10, 47], "wednesdai": [10, 47, 61], "week": [6, 13, 14, 31, 32, 33, 34, 37, 38, 39, 40, 44, 45, 47, 49, 58, 61], "weekdai": 47, "weekend": [8, 47, 49], "weekli": 51, "weight": [32, 39, 41, 44, 45, 46, 58, 61], "weighted_averag": 37, "weinberg": 40, "weird": 38, "welcom": [54, 61], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 53, 57, 60, 61], "welsh": [29, 46], "went": [38, 51, 57, 59], "were": [0, 6, 34, 35, 37, 38, 46, 47, 48, 49, 57, 59, 61], "what": [7, 8, 9, 30, 32, 36, 43, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "whatev": 41, "when": [4, 6, 7, 11, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 56, 58, 59, 60, 61], "wher": 51, "where": [0, 7, 10, 11, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 53, 55, 58, 60], "wherea": [2, 30, 35, 36, 38, 40, 43, 49], "whether": [0, 4, 7, 8, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 45, 47, 48, 50, 51, 54, 59, 60, 61], "which": [4, 6, 8, 11, 31, 32, 33, 34, 35, 36, 38, 40, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], "whichev": 39, "while": [30, 31, 35, 36, 37, 39, 40, 42, 44, 45, 48, 51, 57], "white": [37, 39, 40, 43, 45], "whitespac": [45, 48], "who": [4, 5, 6, 29, 37, 40, 42, 43, 47, 48, 49, 50, 51, 53, 61], "whole": [31, 36, 38, 40, 44, 50, 57], "whom": [0, 51], "whose": 4, "why": [8, 31, 32, 37, 38, 39, 42, 43, 45, 47, 48, 53, 54, 55, 56, 57], "wid": [37, 50], "wide": [11, 35, 36, 39, 41, 44, 46, 49], "wider": [32, 55], "widespread": 45, "widget": [32, 37, 42, 43, 55], "width": [30, 31, 32, 37, 45, 54, 55], "wife": [29, 37, 39, 40], "wiki": [45, 49], "wiki_df": 45, "wiki_dict": 45, "wikipedia": [45, 46, 49], "wikipedia2vec": 45, "wild": [29, 31, 46], "willing": 37, "win": [32, 34, 39, 40, 41, 44, 52], "wind": 30, "winddir3pm": [47, 60], "winddir3pm_miss": [47, 60], "winddir3pm_ss": [47, 60], "winddir3pm_ssw": [47, 60], "winddir3pm_sw": [47, 60], "winddir3pm_w": [47, 60], "winddir3pm_wnw": [47, 60], "winddir3pm_wsw": [47, 60], "winddir9am": [47, 60], "windgustdir": [47, 60], "windgustspe": [47, 60], "window": [10, 48], "windsor": 51, "windspeed3pm": [47, 60], "windspeed9am": [47, 60], "wine_1": 8, "winter": 47, "winter_month": 47, "wire": 44, "wisdom": 39, "wish": [29, 30, 42, 49, 61], "within": [30, 33, 35, 39, 41, 42, 43, 48, 50, 53, 57], "without": [0, 7, 29, 30, 37, 39, 40, 41, 44, 46, 47, 48, 49, 50, 57, 61], "wnw": [47, 60], "wolv": 43, "woman": 45, "wombat": 46, "won": [5, 11, 30, 31, 32, 34, 35, 41, 44, 45, 46, 47, 48, 50, 51], "wonder": [29, 31], "wooddecksf": [38, 40, 49], "word": [29, 35, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 53, 57, 61], "word1": 45, "word2": 45, "word2vec": [45, 46, 61], "word3": 45, "word_pair": 45, "word_token": [45, 51], "wordnet": 45, "wordnetlemmat": 45, "work": [0, 4, 5, 7, 8, 11, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 53, 57, 59, 60, 61], "work_of_art": 51, "workclass": [37, 39, 40, 58], "workclass_feder": [39, 40], "workclass_loc": [39, 40], "workclass_miss": 40, "workclass_nev": [39, 40], "workclass_priv": [39, 40], "workclass_self": 40, "workclass_st": 40, "workclass_without": 40, "workflow": [30, 50, 61], "world": [32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 53], "worm": 46, "worri": [29, 42, 43, 44, 59], "wors": [30, 36, 38, 39, 48, 54, 57, 58], "worst": [37, 41, 42], "worth": [30, 32, 37, 38, 58], "worthi": 35, "would": [4, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61], "wouldn": [34, 36, 48], "wow": 40, "wrap": 34, "wrapper": 41, "write": [4, 7, 29, 36, 40, 41, 42, 45, 49, 50, 51, 55, 59, 61], "written": [7, 34, 40, 47, 49, 60], "wrong": [11, 31, 35, 38, 41, 42, 48, 49, 57], "wrote": [45, 47, 60], "wsw": [47, 60], "wtf": 50, "www": [9, 35], "x": [4, 8, 11, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58], "x0": 41, "x0_male": 37, "x1": [41, 44], "x139": 61, "x1x2": 41, "x2": [41, 43, 44], "x27": [33, 34, 36, 37, 38, 39, 41, 46, 49, 51], "x_": 35, "x_1": [35, 41, 42], "x_1x_2": 41, "x_2": [35, 41, 42], "x_binari": 30, "x_citi": 32, "x_count": 34, "x_d": 35, "x_femal": [37, 58], "x_hour": 47, "x_hour_week": 47, "x_hour_week_onehot": 47, "x_hour_week_onehot_poli": 47, "x_hour_week_onehot_poly_lag": 47, "x_i": [35, 44], "x_imp_ohe_train": 33, "x_init": 42, "x_int": 34, "x_label": [30, 31, 32, 54], "x_lag_featur": 47, "x_lag_features_imp": 47, "x_male": [37, 58], "x_mask": 34, "x_multi": 52, "x_n": 41, "x_orig": 43, "x_re": 37, "x_small_citi": 32, "x_spotifi": [32, 36, 57], "x_subset": [30, 31], "x_test": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59], "x_test_big": 36, "x_test_enc": [40, 47, 48, 49, 60], "x_test_happi": [37, 50], "x_test_imp": 33, "x_test_multi": 52, "x_test_pr": 47, "x_test_predict": 33, "x_test_scal": 33, "x_test_transform": 33, "x_toi": [32, 33, 34, 47], "x_toy_oh": 33, "x_toy_ord": [33, 34], "x_tr": 55, "x_train": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59], "x_train_big": [37, 58], "x_train_enc": [37, 38, 40, 47, 48, 49, 58, 60], "x_train_happi": [37, 50], "x_train_hous": 41, "x_train_imp": 33, "x_train_imp_sc": 33, "x_train_multi": 52, "x_train_oversampl": 37, "x_train_perm": 40, "x_train_pp": 34, "x_train_predict": 33, "x_train_scal": [33, 41], "x_train_subsampl": 37, "x_train_tini": 36, "x_train_transform": 33, "x_train_usr": 44, "x_transform": 34, "x_valid": [37, 44, 55, 58], "x_vari": 43, "x_xor": 41, "xanni": 36, "xavier": [41, 44], "xcode": 5, "xgbclassifi": [39, 40], "xgbclassifierxgbclassifi": 39, "xgboost": 40, "xgbregressor": [29, 39], "xia": 61, "xlabel": [8, 30, 31, 32, 35, 36, 37, 38, 40, 43, 46, 47, 48, 49, 52, 54, 57, 60], "xlim": 48, "xor": [35, 41], "xt": 34, "xtick": [31, 37, 47, 60], "xticklabel": [36, 57], "xticks_rot": 37, "xwm\u0259\u03b8kw\u0259y": 61, "xx": [41, 42], "y": [8, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 54, 55, 58, 60], "y_": 44, "y_citi": 32, "y_femal": [37, 58], "y_hat": [35, 39], "y_i": [38, 39, 41, 44], "y_init": 42, "y_label": [30, 31, 32, 54], "y_male": [37, 58], "y_mat": 44, "y_multi": 52, "y_pred": [37, 47], "y_pred_lower_threshold": 37, "y_pred_toi": 37, "y_pred_train": 47, "y_re": 37, "y_small_citi": 32, "y_spotifi": [36, 57], "y_test": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59, 60], "y_test_big": 36, "y_test_happi": [37, 50], "y_test_multi": 52, "y_test_num": [39, 40], "y_toi": [32, 47], "y_tr": 55, "y_train": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59, 60], "y_train_big": [37, 58], "y_train_happi": [37, 50], "y_train_hous": 41, "y_train_multi": 52, "y_train_num": [39, 40], "y_train_ord": [47, 60], "y_train_oversampl": 37, "y_train_subsampl": 37, "y_train_tini": 36, "y_train_usr": 44, "y_true": 49, "y_true_toi": 37, "y_valid": [37, 44, 46, 55, 58], "y_vari": 43, "y_xor": 41, "yale": 45, "yann": 40, "ycxmx": 48, "ye": [4, 29, 30, 33, 34, 40, 42, 43, 44, 46, 47, 49, 50, 51, 53, 60], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 44, 45, 46, 47, 48], "yearbuilt": [38, 40, 49], "yearremodadd": [38, 40, 49], "yellow": 36, "yellowbrick": [42, 43], "yesterdai": [47, 60], "yet": [10, 11, 35, 40, 44, 47, 48, 55, 61], "yield": 57, "yifei": 61, "yjh": [29, 30, 34, 35, 38, 39], "ylabel": [8, 30, 31, 32, 35, 36, 37, 38, 43, 46, 47, 48, 49, 52, 54, 55, 57, 60], "ylim": [48, 49], "yml": 11, "yolo": 46, "yolo8": 46, "yolo_input": 46, "yolo_result": 46, "yolo_test": 46, "yolov8n": 46, "york": [47, 51], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 40, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "your": [0, 2, 4, 6, 7, 8, 10, 11, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "your_miniconda_path": 51, "your_nam": 11, "yourself": [4, 34, 37, 44, 49, 61], "youtub": [1, 10, 44, 45, 49, 61], "yr_built": [29, 30], "yr_renov": [29, 30], "yrpxn": 48, "yrsold": [38, 40, 49], "ytick": [31, 37], "yticklabel": [36, 57], "yy": [41, 47, 60], "yyyi": [47, 60], "z": [8, 35, 41, 42, 43, 44, 46, 48], "z_i": 46, "z_j": 46, "z_km": 42, "z_train": 46, "z_valid": 46, "zachari": 48, "zarei": 61, "zero": [8, 31, 34, 36, 44, 45, 49], "zero_divis": 37, "zhu": 61, "zip": [32, 35, 44, 55], "zipcod": [29, 30, 55], "zmqshell": 51, "zone": [47, 60], "zoom": [7, 57, 61], "\u0259m": 61, "\u03bc": 52}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Class Meeting 4B", "Class Meeting 4C", "Class Meeting 5A", "Class Meeting 5B", "Class Meeting 5C", "Class Meeting 6A", "Class Meeting 6B", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Lecture 21: Communication", "Lecture 23: Deployment and conclusion", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [29, 31, 32, 33, 34, 37, 38, 40, 47, 49], "0": 39, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60], "10": [18, 38, 59], "11": [20, 39], "12": [21, 39, 40], "13": [22, 41], "14": [23, 41, 42], "15": [23, 42, 43, 49, 50], "16": [24, 43, 44], "17": [24, 44, 45], "18": [26, 46], "19": [26, 46, 47], "1a": 13, "1b": 14, "1c": 15, "2": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60], "20": [27, 48, 49, 50], "2025s1": 1, "21": [27, 48, 49], "22": 28, "23": [28, 50], "2a": 16, "2b": 17, "3": [15, 29, 30, 31, 33, 41, 42, 43, 48, 54, 55, 56, 57, 58, 59, 60], "330": [1, 2, 3, 6, 8, 50], "340": [2, 50], "3a": 18, "3b": 19, "3c": 20, "4": [15, 30, 31, 32, 49, 54, 55, 56, 57, 58, 59, 60], "4a": 21, "4b": 22, "4c": 23, "5": [8, 16, 30, 31, 32, 33, 34, 37, 40, 41, 42, 45, 46, 48, 49, 55, 56, 57, 58, 59, 60], "5a": 24, "5b": 25, "5c": 26, "6": [16, 34, 55, 57, 58, 59, 60], "6a": 27, "6b": 28, "7": [17, 35, 57, 59, 60], "8": [17, 36, 57, 59], "9": [18, 37, 59], "A": [4, 37, 43, 47, 51], "No": 8, "Not": 53, "One": [33, 47, 52], "The": [31, 35, 36, 39, 41, 42, 59], "__": 36, "about": [8, 41, 44, 49], "academ": 61, "access": [7, 35, 61], "accommod": 61, "acknowledg": 61, "activ": [37, 40, 41, 42, 45, 49, 58], "actual": 34, "ad": 8, "addit": [7, 40], "address": 37, "advantag": 36, "advic": 41, "ai": 61, "aka": 49, "algorithm": [30, 32, 41, 42], "all": [29, 30, 33, 35, 37, 42, 43, 44, 49], "alpha": [35, 38], "alreadi": 50, "altern": [30, 33], "an": [39, 49, 51], "analogi": 32, "analysi": [47, 48, 50, 53, 55, 60], "angl": 49, "announc": [30, 32, 34, 35, 39], "answer": 48, "ap": 37, "api": [33, 50], "app": 50, "appendix": [51, 52], "appli": [1, 8, 33, 34, 38, 49], "applic": 42, "applymap": 8, "approach": [44, 47, 48, 49, 50, 52], "approxim": 31, "ar": [5, 29, 30, 33, 35, 37, 42, 43, 44], "area": 37, "argument": [31, 32], "around": 49, "arrai": 8, "articl": 9, "asap": 49, "ask": 4, "assign": [7, 61], "associ": 35, "assum": 48, "attent": [30, 32], "attribut": [40, 49], "auc": 37, "autom": 36, "averag": [37, 39, 44, 59], "avoid": 31, "b": [42, 52], "backward": 41, "bad": 36, "bag": [34, 51], "balanc": 37, "base": [32, 39, 41, 44, 47, 60], "baselin": [30, 33, 37, 39, 40, 44, 55], "basic": 45, "befor": 33, "best": 41, "better": [31, 36, 37, 41, 49], "between": [30, 32, 50, 54], "beyond": [40, 44], "bia": [31, 36], "big": [30, 31, 33], "binari": 37, "book": 10, "boost": [39, 49], "bootstrap": 39, "bottom": 49, "boundari": [30, 32, 35, 54], "bow": 34, "box": 46, "break": [8, 30, 31, 32, 33, 34, 41, 45, 46, 48, 49, 50], "broadcast": 8, "build": [29, 30, 38, 44, 50], "c": [32, 36], "calcul": 35, "california": [34, 35, 56], "can": [8, 31, 33, 39, 40, 41, 42], "canada": [30, 54], "care": [44, 49], "carri": [33, 41], "case": [34, 35, 43], "catboost": 39, "categor": [33, 34, 40, 47], "categori": 34, "censor": 48, "centr": 61, "certain": 34, "cfa": 61, "chang": 37, "charact": 29, "characterist": 37, "cheatsheet": 8, "choos": [32, 42], "chunk": 49, "churn": 48, "cite": 7, "citi": 35, "claim": 49, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 36, 37, 38, 39, 40, 44, 46, 52, 61], "class_attend": 34, "class_weight": 37, "classif": [30, 37, 46, 50, 53], "classifi": [30, 35, 39, 51], "clearli": 41, "cluster": [42, 43, 53], "co": 61, "code": [11, 61], "coeffici": [35, 40], "color": [54, 55, 56, 57, 58, 59, 60], "column": [8, 33, 34, 47], "columntransform": [34, 56], "combin": 39, "come": [31, 32], "command": 5, "comment": [30, 36, 37, 38, 42, 43, 44], "common": [33, 42], "commonli": 45, "commun": [49, 53], "compact": 33, "companion": 9, "complet": 44, "complex": 31, "complic": [47, 60], "compon": 35, "comprehens": 56, "comput": [46, 53], "con": [32, 43, 53], "concept": 49, "concern": 6, "concess": 61, "conclus": 50, "conda": 11, "conduct": 61, "confid": [35, 49], "confus": [37, 49], "consid": 48, "construct": 39, "content": 44, "context": 45, "continu": 30, "conveni": 34, "corpu": 50, "correct": 42, "correl": 40, "countri": [30, 54], "countvector": 34, "cours": [9, 10, 29, 50, 61], "cover": [44, 48, 50], "cox": 48, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 30, 31, 34, 44, 50], "credit": [11, 61], "cross": [31, 33, 37, 41, 47, 55], "cross_val_scor": 31, "cross_valid": [31, 38], "csv": 8, "curs": 32, "curv": [37, 48], "custom": [42, 48], "cv": 36, "dai": 47, "data": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 55, 60], "datafram": [8, 34], "dataset": [7, 30, 33, 34, 35, 36, 37, 38, 46, 47, 49, 56, 59, 60], "date": [10, 47], "datetim": [47, 60], "dbscan": 43, "deal": [34, 37], "debug": 11, "decis": [30, 32, 35, 40, 49, 55], "decisiontreeclassifi": [30, 39], "decreas": 37, "deep": [46, 47], "defin": 41, "definit": 29, "deliver": 10, "demo": [41, 47, 50, 51], "demonstr": 37, "dendrogram": 43, "depend": 41, "deploi": 50, "deploy": [28, 31, 50, 53], "descript": 61, "desktop": 5, "detail": [37, 38, 43], "detect": 46, "df": 8, "did": [31, 33, 34, 37, 38, 44, 48, 49, 50], "differ": [33, 36, 37, 38, 40, 50, 53], "dimens": 32, "dimension": 32, "directori": 50, "discuss": [36, 37, 44, 45, 49, 50, 58], "diseas": 29, "distanc": [32, 42], "distribut": 36, "do": [33, 34, 36, 37, 39, 40, 41, 49], "document": [3, 8, 42], "doe": [30, 35, 43, 49], "domain": 41, "drop": 8, "due": 10, "dummi": 51, "dummyclassifi": [30, 39, 47, 48], "dummyregressor": [30, 33, 38], "eda": [33, 37, 38, 50, 55], "effect": [39, 49], "elbow": 42, "element": 8, "elimin": 41, "embed": 45, "encod": [33, 34, 41, 47], "engin": [41, 47, 51, 53], "ensembl": [39, 53], "environ": [11, 50], "equal": 49, "error": [31, 36, 37, 38, 44], "estim": [33, 39], "ethic": [28, 53], "euclidean": 32, "eva": [29, 31], "evalu": [37, 43, 44, 48, 53, 58], "evalut": 37, "event": 48, "everyon": 48, "exactli": 35, "exam": [53, 61], "examin": [34, 38, 49, 53], "exampl": [29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 48, 49, 51], "exercis": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 46, 48, 54], "exhaust": 36, "experi": 49, "explain": [40, 49], "explan": [40, 49], "explor": [32, 42], "exploratori": [47, 55, 60], "extract": [34, 47], "extractor": 46, "f1": 37, "failur": 43, "fair": [37, 58], "fancier": 36, "farewel": 50, "faster": 8, "fastest": 8, "featur": [29, 30, 32, 33, 34, 35, 38, 40, 41, 44, 46, 47, 49, 51, 53, 60], "feature_importances_": 40, "few": [37, 43, 49], "fictiti": 29, "figur": 7, "filter": [8, 44], "final": [30, 36, 42, 43, 44, 47, 53, 55, 61], "find": [32, 41], "first": 33, "fit": [30, 33, 39], "flatten": 46, "follow": [29, 30, 31, 42, 43, 44], "font": [54, 55, 56, 57, 58, 59, 60], "forecast": 47, "forest": [39, 40, 49], "format": [7, 8], "formul": 44, "forum": 4, "forward": 41, "from": [8, 49, 51], "full": 50, "function": [8, 35, 38], "fundament": [31, 32, 39, 53], "further": [47, 51], "futur": 47, "gamma": 32, "garbag": 41, "gb": 49, "gener": [4, 6, 31, 32, 35, 39, 41], "geometr": 32, "get": 40, "git": [5, 11], "github": 5, "given": [29, 30], "global": 44, "goal": 31, "golden": [31, 33, 34], "good": [37, 49], "grade": [4, 6, 30, 61], "gradescop": 7, "gradient": [39, 49], "grid": [36, 49], "gridsearchcv": [36, 38, 49], "group": [37, 42, 58], "guid": 53, "guidelin": [4, 6, 7], "ha": 29, "halv": 36, "handl": 37, "have": [39, 40, 49], "hazard": 48, "heatmap": 36, "help": [4, 41], "here": 31, "hierarch": 43, "home": 43, "homework": 7, "hot": [33, 41, 47], "hous": [29, 30, 33, 34, 35, 56], "how": [4, 7, 30, 31, 32, 33, 35, 39, 40, 41, 43, 49], "hyper": 36, "hyperparamet": [30, 32, 34, 35, 36, 38, 39, 42, 53, 55], "i": [29, 31, 33, 34, 36, 37, 39, 40, 41, 42, 44, 45, 49, 50, 51], "iclick": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 48, 49, 61], "idea": [32, 37, 39, 41, 49], "identifi": [34, 40], "imag": [29, 46], "imagenet": 46, "imbal": [37, 38, 39, 40], "import": [1, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 60], "improv": 51, "imput": [33, 44], "incorpor": 34, "increas": 37, "index": 8, "inertia": 42, "info": 7, "inform": [40, 47], "initi": [42, 50], "inject": 39, "input": [29, 42], "instal": [5, 11], "instruct": [0, 7], "interact": 41, "intercept": 35, "interest": 49, "interim": [37, 40, 41, 47], "interpret": [35, 40, 50], "intra": 42, "intro": 44, "introduct": [8, 29, 40, 41, 42, 43, 45, 46, 49, 53], "intuit": 35, "involv": [47, 49], "issu": 49, "jupyterlab": 11, "k": [32, 33, 42, 43, 44], "kaplan": 48, "kei": [40, 49, 50], "kernel": 32, "kind": 39, "kneighborsclassifi": 32, "label": [29, 42, 49], "lag": [47, 60], "land": 61, "languag": 45, "larg": 36, "late": 7, "latitud": [30, 54], "lda": 45, "learn": [1, 5, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 61], "least": 35, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 61], "lecture03": 15, "let": [32, 33, 34, 37, 38, 40, 49], "licens": [0, 1], "lightgbm": 39, "limit": [6, 35, 43], "line": 5, "linear": [35, 38, 40], "link": 1, "list": 9, "liver": 29, "ll": 31, "lo": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 47, 50], "load": 50, "local": 50, "localhost": 50, "logist": [35, 37, 46], "logisticregress": [37, 47, 48, 49], "longitud": [30, 54], "look": [37, 42], "loop": 8, "loss": 49, "lower": 36, "mac": 5, "machin": [1, 29, 30, 31, 32, 37, 42, 50], "maco": 11, "macro": 37, "magnitud": 35, "mai": 41, "main": [35, 44, 49], "make": [8, 35, 49], "make_column_transform": 34, "make_pipelin": 33, "mani": [34, 36], "manual": 36, "mape": 38, "materi": [0, 9, 10], "matplotlib": 8, "matric": 34, "matrix": [37, 44], "max_depth": 30, "mean": [38, 42, 43, 45, 49], "measur": 41, "media": 45, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 61], "meier": 48, "messag": [29, 43], "meta": 52, "method": [8, 36, 41, 42], "metric": [37, 38, 53], "midterm": [42, 61], "might": 48, "min": [8, 30, 31, 32, 33, 34, 37, 40, 41, 42, 45, 46, 48, 49, 50], "minor": 37, "misc": [9, 10], "miscellan": 44, "mislead": 49, "ml": [29, 31, 32, 37, 40, 49, 53, 58], "model": [29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 45, 46, 48, 50, 51, 53, 55, 58], "model_select": 36, "moment": 50, "month": 47, "more": [30, 32, 33, 34, 35, 37, 38, 41, 43, 47, 60], "most": 35, "motiv": [31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49], "movi": 44, "mse": 38, "much": 36, "multi": [37, 46, 52], "multiclass": 53, "multipl": [32, 34, 38], "multipli": 8, "n_estim": 39, "n_iter": 36, "n_job": 36, "n_neighbor": 32, "name": [31, 38, 44], "natur": 45, "nearest": [32, 33, 42, 44], "need": [33, 36], "neg": 37, "neighbour": [32, 33, 44], "nest": 8, "netflix": 39, "network": 46, "neural": 46, "new": [49, 50], "next": 50, "nlp": [45, 53], "nn": 32, "non": [32, 34, 40], "notat": 8, "note": [8, 31, 47, 55], "now": 48, "number": [39, 42, 47], "numer": [40, 41], "numpi": 8, "object": [30, 39, 45, 46, 47, 48, 49, 50, 61], "observ": 37, "occasion": 33, "off": [31, 32, 39], "oh": [33, 34], "ok": [33, 34], "onc": 37, "one": [34, 41], "onehotencod": 34, "onli": [34, 48], "onlin": [9, 10], "oper": 37, "optim": [36, 53], "option": [11, 32, 33, 36, 37, 39, 41, 48, 50], "ordin": [33, 34, 40, 61], "other": [8, 32, 38, 41, 42, 45, 47, 48, 49], "our": [7, 31, 33, 49, 50, 51], "out": [33, 41, 46, 49, 50], "outcom": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44], "outlin": [54, 55, 56, 57, 58, 59, 60], "output": 42, "over": [8, 32, 35, 37], "overfit": [31, 36], "oversampl": 37, "overview": [32, 37], "ovo": 52, "ovr": 52, "packag": [11, 47], "panda": 8, "pandas_profil": 38, "paper": [37, 39], "paradigm": 33, "paramet": [30, 35, 36, 37, 53], "parametr": 32, "pars": [47, 60], "part": 53, "pass": [36, 61], "patient": 29, "perfect": 42, "perhap": 49, "permutation_import": 40, "persona": 29, "pick": [31, 36], "pictur": [30, 31, 33], "piec": 49, "pipelin": [33, 45], "plan": 43, "playground": [32, 55], "plot": [8, 40, 42, 48], "point": [32, 37, 40, 42, 47], "polici": 6, "poll": 42, "popular": 29, "posit": 37, "posix": 47, "possibl": [34, 38, 42, 51], "post": 9, "pr": 37, "practic": [30, 32], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 22, 46], "precis": 37, "predict": [29, 30, 34, 35, 39, 40, 44, 46, 48, 52, 54], "predict_proba": [35, 49], "predictor": 50, "prefer": 49, "prepar": [7, 53], "preprocess": [33, 34, 38, 45, 47, 49, 50, 53, 58, 60], "preval": 29, "price": [29, 30], "principl": 49, "prize": 39, "pro": [32, 43, 53], "probabl": [35, 36], "problem": [30, 31, 32, 33, 36, 41, 44, 47, 50, 51], "procedur": 37, "process": 45, "product": 29, "profil": 44, "program": 30, "project": 51, "proport": 48, "python": [8, 9, 11], "q": 4, "qualiti": 41, "queri": [8, 32], "question": [4, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60], "quick": 32, "quiz": 30, "quiz2": 30, "quot": 41, "r": 38, "random": [36, 39, 40, 49], "random_st": 31, "randomforestclassifi": [39, 48], "randomizedsearchcv": [36, 38], "rang": 36, "rate": 44, "raw": 35, "rbf": 32, "re": 49, "read": [8, 30, 36, 46], "reader": 49, "real": [30, 50, 54], "realist": 34, "reason": 6, "recal": 37, "recap": [30, 32, 43, 48, 49, 54, 56], "receiv": 37, "recip": 50, "recommend": [33, 44, 53], "record": 61, "recurs": 41, "red": [54, 55, 56, 57, 58, 59, 60], "refer": [9, 10, 48], "reflect": [30, 31, 42, 43], "registr": 61, "regress": [30, 32, 35, 37, 38, 39, 46], "regressor": 32, "relat": [4, 30, 32, 49], "relev": [9, 37, 39, 41], "remark": 47, "rememb": 42, "remind": [30, 44], "remov": 8, "renam": 8, "render": 50, "report": [7, 37], "repositori": 7, "represent": [34, 46], "request": 50, "requir": [50, 61], "rescu": 31, "resourc": [9, 36, 37, 41, 42, 43, 44], "rest": 52, "result": [36, 49], "retail": 47, "reus": 49, "review": [19, 50], "rf": 49, "rfe": 41, "ridg": [35, 38], "ridgecv": 38, "right": 48, "rmse": 38, "roc": 37, "root": 38, "row": 8, "rule": [31, 33, 34], "run": [33, 49], "same": 8, "sampl": [37, 39, 42], "sauc": 42, "save": [29, 50], "scale": [29, 33, 35, 40], "schedul": [10, 61], "scheme": 61, "scikit": [31, 33, 34, 38], "score": [30, 31, 35, 36, 37, 38, 41, 42, 51], "search": [32, 36, 41, 49], "season": 47, "segment": 42, "select": [29, 30, 41, 42, 43, 44, 53], "send": 50, "separ": [38, 40, 49], "seri": [8, 47, 53, 60], "server": 50, "servic": 50, "set": [5, 11, 31, 36, 37, 50], "set_config": 34, "shap": 40, "shape": [8, 43], "shaplei": 40, "short": 9, "should": [39, 44, 49], "show": [40, 49], "sigmoid": [35, 46], "sign": 35, "silhouett": 42, "similar": 32, "simpl": [31, 51], "simplefeatur": 40, "simul": 59, "singl": 31, "size": 8, "sklearn": [30, 33, 34, 36, 37, 39, 40], "slide": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28], "slowest": 8, "small": 49, "smote": 37, "social": 45, "softmax": 46, "softwar": [0, 46, 47], "solv": 36, "some": [30, 36, 37, 39, 41, 50], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 47, "spaci": [45, 51], "spaghetti": 42, "spam": [29, 34], "spars": 34, "specif": [4, 41], "split": [31, 33, 37, 47, 55], "spotifi": [33, 36], "squar": 38, "stack": [39, 59], "standardscal": 33, "statement": [29, 30, 42, 43, 44], "statist": 50, "step": [30, 45, 56], "strategi": [39, 52], "stratifi": 37, "strength": [35, 39], "structur": 50, "studi": 53, "submiss": 7, "submit": 7, "success": 36, "summari": [8, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "summer": 10, "supervis": [29, 30, 31, 32, 42, 44, 50], "support": 32, "surviv": [48, 53], "svc": 37, "svm": [32, 35], "syllabu": [1, 61], "syntax": [33, 34, 36], "synthet": 37, "system": [44, 53], "ta": 61, "tabular": [30, 32, 50], "tackl": 38, "take": 43, "takeawai": 50, "target": [29, 30, 34, 38, 42], "task": 45, "teach": [10, 61], "team": 61, "techniqu": [33, 37], "templat": 7, "tempor": 47, "ten": 10, "tent": 10, "terminologi": [30, 46], "test": [5, 31, 36, 47], "test_df": 31, "test_siz": 31, "text": [34, 45, 51], "than": [34, 36, 41, 49], "thei": 39, "them": 8, "thi": [8, 29, 33, 34, 40, 49, 50], "thing": [33, 49], "threshold": 37, "time": [6, 29, 47, 48, 53, 60], "tip": 53, "todai": [31, 33, 34, 37, 38, 49], "toi": [30, 34, 37, 45], "token": 45, "tool": 45, "topic": 45, "trade": [31, 32, 39], "tradeoff": [31, 37, 39], "tradit": [30, 47], "train": [29, 30, 31, 34, 35, 37, 46, 47, 49, 50, 58], "train_df": 31, "train_siz": 31, "transfer": 46, "transform": [33, 34, 38, 41, 49], "transpar": [40, 50], "tree": [30, 39, 40, 49, 55], "trend": 47, "true": [29, 42, 43, 44], "try": [33, 38, 49, 50], "tune": [38, 42, 55], "tutori": [54, 55, 56, 57, 58, 59, 60], "two": 34, "type": [29, 31, 37, 38, 40, 42, 47, 48, 49], "typic": [31, 45], "u": 49, "ubc": 1, "ubuntu": 5, "under": 37, "underfit": 31, "undersampl": 37, "understand": 50, "unequ": 47, "unknown": 34, "unlabel": 42, "unseen": [29, 31], "unsupervis": [30, 42], "up": [5, 11, 31, 32, 49, 50], "updat": 7, "url": 8, "us": [7, 8, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 45, 46, 49, 52, 54, 61], "usa": [30, 54], "user": [5, 44], "usual": 41, "util": 44, "v": [2, 30, 31, 32, 37, 40, 42, 46, 50, 52], "valid": [31, 33, 36, 37, 47, 55], "varianc": 31, "vector": [8, 32, 45], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 29, 30, 31, 32, 33, 35, 37, 38, 39, 42, 43, 45], "view": [32, 34], "violat": 31, "virtual": 11, "vision": [46, 53], "visual": [9, 36, 49], "wai": [36, 41, 49], "want": [34, 40, 48], "warn": [30, 41], "watch": 49, "we": [8, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50], "weak": 39, "web": 50, "weight": [35, 37], "what": [5, 11, 29, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 48, 49, 50], "when": [8, 33, 36, 49], "where": [34, 48], "whether": 29, "which": [29, 30, 37, 39, 42, 43, 44], "why": [11, 29, 34, 36, 40, 41, 44, 46, 49], "window": [5, 11], "wise": 8, "without": 42, "word": [34, 45, 51], "work": [30, 39, 43, 49], "workflow": [29, 31, 37], "would": 31, "wrapper": 52, "write": 30, "x": [29, 30, 38, 40, 49], "xgboost": 39, "y": [29, 30, 38, 40, 49], "ye": 48, "yield": 36, "you": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50], "your": [5, 30, 49]}})