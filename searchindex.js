Search.setIndex({"alltitles": {"(Optional) Changing the data": [[30, "optional-changing-the-data"]], "(Optional) Evaluation": [[41, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[30, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[29, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[29, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[29, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[32, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[34, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[30, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[25, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[29, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[32, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[34, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[34, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[29, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Some more details": [[30, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[22, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[34, "id1"]], "(iClicker) Exercise 21.1": [[41, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[41, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[25, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[25, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[26, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[26, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[26, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[27, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[27, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[28, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[28, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[29, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[35, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[35, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[35, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[35, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[36, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[36, "id2"]], "16.3 Select all of the following statements which are True": [[36, "select-all-of-the-following-statements-which-are-true"]], "<font color='red'>Question 10</font>": [[50, "question-10"]], "<font color='red'>Question 1</font>": [[45, "question-1"], [46, "question-1"], [48, "question-1"], [49, "question-1"], [50, "question-1"], [51, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[46, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[45, "question-2"], [48, "question-2"], [49, "question-2"], [50, "question-2"], [51, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[46, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[45, "question-3"], [48, "question-3"], [49, "question-3"], [50, "question-3"], [51, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[46, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[45, "question-4"], [48, "question-4"], [49, "question-4"], [50, "question-4"], [51, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[46, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[48, "question-5"], [49, "question-5"], [50, "question-5"], [51, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[46, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[48, "question-6"], [49, "question-6"], [50, "question-6"], [51, "question-6"]], "<font color='red'>Question 7</font>": [[48, "question-7"], [50, "question-7"]], "<font color='red'>Question 8</font>": [[48, "question-8"], [50, "question-8"]], "<font color='red'>Question 9</font>": [[50, "question-9"]], "<font color='red'>Recap Questions</font>": [[45, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[47, "recap-comprehension-questions"]], "A few comments on PR curve": [[30, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[36, "a-few-comments-on-clustering-evaluation"]], "AP score": [[30, "ap-score"]], "AP vs. F1-score": [[30, "ap-vs-f1-score"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[52, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[28, "accessing-learned-parameters"]], "Activity (~5 mins)": [[33, "activity-5-mins"], [33, "id3"]], "Activity: Context and word meaning": [[38, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[34, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[30, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[29, "advantages-of-randomizedsearchcv"], [29, "id1"]], "Alternative and more compact syntax: make_pipeline": [[26, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[23, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[32, "an-effective-strategy"]], "An example from a project": [[42, "an-example-from-a-project"]], "An example of a bootstrap samples": [[32, "an-example-of-a-bootstrap-samples"]], "Analogy-based algorithms in practice": [[25, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[25, "analogy-based-models"]], "Announcements": [[28, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[42, null]], "Appendix B: Multi-class, meta-strategies": [[43, null]], "Applying feature transformations": [[31, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[41, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[41, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[41, "approach-3-survival-analysis"]], "Are we doing better with class_weight=\"balanced\"?": [[30, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[30, "area-under-the-curve-auc"]], "Assignments": [[52, "assignments"]], "Attention": [[23, null], [23, null], [23, null], [25, null]], "Automated hyperparameter optimization": [[29, "automated-hyperparameter-optimization"], [29, "id3"]], "Averaging": [[32, "averaging"]], "Averaging simulation": [[50, "averaging-simulation"]], "Bad range for hyperparameters": [[29, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[27, "bag-of-words-bow-representation"]], "Bag-of-words model": [[42, "bag-of-words-model"]], "Baseline": [[30, "baseline"], [33, "baseline"]], "Baseline Approaches": [[37, "baseline-approaches"]], "Baselines": [[23, "baselines"], [32, "baselines"]], "Baselines [video]": [[23, "baselines-video"]], "Basic text preprocessing [video]": [[38, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[34, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[37, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[24, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[23, "big-picture-and-datasets"]], "Big picture and motivation": [[24, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Break (5 min)": [[8, "break-5-min"], [23, "break-5-min"], [24, "break-5-min"], [25, "break-5-min"], [26, "break-5-min"], [27, "break-5-min"], [34, "break-5-min"], [38, "break-5-min"], [39, "break-5-min"], [41, "break-5-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a supervise machine learning model": [[22, "building-a-supervise-machine-learning-model"]], "Building decision trees with sklearn": [[23, "building-decision-trees-with-sklearn"]], "Building user profiles": [[37, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[35, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[26, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[27, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[32, "catboost"]], "Categorical features": [[33, "categorical-features"]], "Categorical features [video]": [[26, "categorical-features-video"]], "Categorical features with only two possible categories": [[27, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[41, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[52, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[30, "changing-the-training-procedure"]], "Characters in this course?": [[22, "characters-in-this-course"]], "Choosing K [video]": [[35, "choosing-k-video"]], "Choosing n_neighbors": [[25, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"]], "Class imbalance in training sets": [[30, "class-imbalance-in-training-sets"]], "Class meetings": [[52, "class-meetings"]], "Classification report": [[30, "classification-report"]], "Classification vs. Regression": [[23, "classification-vs-regression"]], "Clustering": [[44, "clustering"]], "Clustering Activity (~5 mins)": [[35, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[35, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[35, "clustering-input-and-possible-output"]], "Code of conduct": [[52, "code-of-conduct"]], "Coefficients and intercept": [[28, "coefficients-and-intercept"]], "ColumnTransformer example": [[27, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[27, "columntransformer-on-the-california-housing-dataset"], [47, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[27, "columntransformer-transformed-data"]], "Coming up \u2026": [[24, "coming-up"]], "Coming up:": [[25, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[35, "common-applications"]], "Common preprocessing techniques": [[26, "common-preprocessing-techniques"]], "Communication": [[44, "communication"]], "Completing the utility matrix with content-based filtering": [[37, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[28, "components-of-a-linear-classifier"]], "Confusion matrix (video)": [[30, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[30, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[25, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[37, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[27, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[52, "course-learning-objectives"]], "Course co-ordinator": [[52, "course-co-ordinator"]], "Course description": [[52, "course-description"]], "Cox proportional hazards model": [[41, "cox-proportional-hazards-model"]], "Create X and y": [[23, "create-x-and-y"]], "Create a classifier object": [[23, "create-a-classifier-object"]], "Create a column transformer": [[27, "create-a-column-transformer"]], "Creating train_df and test_df": [[24, "creating-train-df-and-test-df"]], "Creating utility matrix": [[37, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[30, "cross-validation-with-different-metrics"]], "Cross-validation": [[40, "cross-validation"], [40, "id4"]], "Cross-validation [video]": [[24, "cross-validation-video"]], "Cross-validation to the rescue!!": [[24, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[24, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[25, "curse-of-dimensionality"]], "Customer churn": [[41, "customer-churn"]], "Customer segmentation": [[35, "customer-segmentation"]], "DBSCAN [video]": [[36, "dbscan-video"]], "DBSCAN introduction": [[36, "dbscan-introduction"]], "DBSCAN: failure cases": [[36, "dbscan-failure-cases"], [36, "id1"]], "Data": [[27, "data"], [28, "data"], [32, "data"], [33, "data"], [33, "id1"]], "Data Splitting [video]": [[24, "data-splitting-video"]], "Data and main approaches": [[37, "data-and-main-approaches"]], "Data exploration": [[35, "data-exploration"]], "Data splitting": [[46, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[39, "dataset"]], "Dataset [video]": [[31, "dataset-video"]], "Dataset for demonstration": [[30, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[26, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[30, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[27, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[23, "decision-boundary"]], "Decision boundary for max_depth=1": [[23, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[23, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[23, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[25, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[28, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[23, "decision-tree-algorithm"]], "Decision tree feature importances": [[33, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[23, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[23, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[23, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[23, "decision-trees-video"]], "Decision trees with continuous features": [[23, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[32, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[23, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decreasing the threshold": [[30, "decreasing-the-threshold"]], "Deep learning": [[40, "deep-learning"]], "Deep learning software": [[39, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of feature engineering with numeric features": [[34, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[40, "demo-a-more-complicated-dataset"]], "Dendrogram": [[36, "dendrogram"]], "Deployment (Not examinable)": [[44, "deployment-not-examinable"]], "Different models": [[33, "different-models"]], "Different range for hyperparameters yields better results!": [[29, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[31, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[25, "dimensions-in-ml-problems"]], "Discussion question": [[38, "discussion-question"]], "Distance between feature vectors": [[25, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[27, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[32, "do-we-have-class-imbalance"], [33, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[33, "do-we-have-correlated-features"]], "Document clustering": [[35, "document-clustering"]], "Domain-specific transformations": [[34, "domain-specific-transformations"]], "Dummy classifier": [[42, "dummy-classifier"]], "DummyClassifier": [[23, "dummyclassifier"], [40, "dummyclassifier"], [41, "dummyclassifier"]], "DummyClassifier baseline": [[32, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[23, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[23, "dummyregressor"], [31, "dummyregressor"]], "EDA": [[26, "eda"], [30, "eda"], [31, "eda"]], "EDA: Exploratory Data Analysis": [[46, "eda-exploratory-data-analysis"]], "Encoding text data": [[27, "encoding-text-data"]], "Encoding time as a number": [[40, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[40, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[44, "ensembles"]], "Ethics": [[44, "ethics"]], "Euclidean distance": [[25, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[36, "evaluating-dbscan-clusters"]], "Evaluation": [[37, "evaluation"], [37, "id3"]], "Evaluation metrics": [[44, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[30, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[30, "evalution-metrics-overview"]], "Examining the preprocessed data": [[31, "examining-the-preprocessed-data"]], "Example": [[28, "example"], [32, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[22, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[35, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[23, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[23, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[22, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[22, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[33, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[34, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[22, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[35, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[23, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[23, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[30, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[26, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[22, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[37, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[37, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[23, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[23, "exercise-2-4"]], "Exercise 8.2": [[29, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[45, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[29, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[33, "explaining-a-prediction"]], "Exploratory data analysis": [[40, "exploratory-data-analysis"], [51, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[27, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[40, "extracting-date-and-time-information"]], "F1-score": [[30, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[34, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[40, "feature-engineering"]], "Feature engineering and selection": [[44, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[40, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[40, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[34, "feature-engineering-motivation"]], "Feature importances": [[33, "feature-importances"], [44, "feature-importances"]], "Feature importances in linear models": [[33, "feature-importances-in-linear-models"], [33, "id2"]], "Feature interactions and feature crosses": [[34, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[31, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[34, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[26, "feature-transformations-and-the-golden-rule"]], "Feature types": [[31, "feature-types"], [31, "id1"]], "Feature vectors": [[25, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[29, "final-comments-and-summary"], [37, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[23, "final-comments-summary-and-reflection"], [35, "final-comments-summary-and-reflection"], [36, "final-comments-summary-and-reflection"]], "Final exam": [[52, "final-exam"]], "Final exam preparation: guiding questions": [[44, null]], "Final note": [[46, "final-note"]], "Final remarks": [[40, "final-remarks"]], "Finding the distances to a query point": [[25, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[25, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[40, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[40, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[37, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "Garbage in, garbage out.": [[34, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[34, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[32, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[25, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[34, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[24, "generalization-video"]], "Generalization: Fundamental goal of ML": [[24, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[28, "generalizing-to-more-features"]], "Generalizing to unseen data": [[24, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[25, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[37, "global-average-baseline"]], "Golden rule violation: Example 1": [[24, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[24, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[32, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[32, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[52, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[30, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[24, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[36, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[28, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[24, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[33, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[32, "how-do-they-work"]], "How do we carry out feature selection?": [[34, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[23, "how-does-fit-work"], [23, "id2"]], "How does it work?": [[36, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[28, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[23, "how-does-predict-work"]], "How to approximate generalization error?": [[24, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[26, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[25, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[24, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[28, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[44, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[29, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[35, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[25, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[29, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[27, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[39, "imagenet"]], "Import": [[42, "import"]], "Importance of scaling": [[28, "importance-of-scaling"]], "Important hyperparameters": [[32, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[27, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[35, "important-points-to-remember"]], "Imports": [[22, "imports"], [23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [51, "imports"]], "Imports and LO": [[29, "imports-and-lo"], [31, "imports-and-lo"], [39, "imports-and-lo"], [40, "imports-and-lo"]], "Imports and LOs": [[30, "imports-and-los"]], "Imports and learning outcomes": [[35, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[23, "imports-announcements-los"]], "Imports, Announcements, and LO": [[27, "imports-announcements-and-lo"], [28, "imports-announcements-and-lo"]], "Imports, LOs": [[24, "imports-los"], [26, "imports-los"], [33, "imports-los"]], "Imports, announcements, LOs": [[32, "imports-announcements-los"]], "Imports, announcements, and LOs": [[25, "imports-announcements-and-los"]], "Imputation": [[26, "imputation"]], "Imputation and scaling [video]": [[26, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[27, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[30, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[35, "inertia"]], "Initialization of K-Means": [[35, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[32, "inject-randomness-in-the-classifier-construction"]], "Input data": [[22, "input-data"]], "Input features X and target y": [[22, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interim summary": [[30, "interim-summary"], [33, "interim-summary"], [34, "interim-summary"], [40, "interim-summary"]], "Interpretation of coefficients": [[28, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[28, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[33, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[36, "introduction"], [44, "introduction"]], "Introduction to NLP": [[44, "introduction-to-nlp"]], "Introduction to computer vision": [[39, "introduction-to-computer-vision"]], "Introduction to neural networks": [[39, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[35, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[42, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[30, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[27, "is-this-a-realistic-representation-of-text-data"]], "Is \u201cRelevance\u201d clearly defined?": [[34, "is-relevance-clearly-defined"], [34, "id2"], [34, "id3"], [34, "id4"], [34, "id5"], [34, "id6"], [34, "id7"]], "K-Means algorithm": [[35, "k-means-algorithm"]], "K-Means clustering [video]": [[35, "k-means-clustering-video"]], "K-Means example": [[35, "k-means-example"]], "K-Means limitations": [[36, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[36, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[36, "k-means-recap"]], "K-Means: failure case 1": [[36, "k-means-failure-case-1"]], "K-Means: failure case 2": [[36, "k-means-failure-case-2"]], "K-Means: failure case 3": [[36, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[41, "kaplan-meier-survival-curve"]], "Key point": [[33, "key-point"]], "LDA topics in social media": [[38, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[35, "labeled-vs-unlabeled-data"]], "Lag-based features": [[40, "lag-based-features"], [40, "id5"], [51, "lag-based-features"]], "Land acknowledgement": [[52, "land-acknowledgement"]], "Large datasets solve many of these problems": [[29, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[28, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[38, "learning-objectives"], [39, "learning-objectives"], [40, "learning-objectives"], [41, "learning-objectives"]], "Learning outcomes": [[22, "learning-outcomes"], [23, "learning-outcomes"], [24, "learning-outcomes"], [25, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[37, "learning-outcomes"]], "Least confident cases": [[28, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[31, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[32, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[33, null]], "Lecture 13: Feature engineering and feature selection": [[34, null]], "Lecture 14: K-Means Clustering": [[35, null]], "Lecture 15: More Clustering": [[36, null]], "Lecture 16: Recommender Systems": [[37, null]], "Lecture 17: Introduction to natural language processing": [[38, null]], "Lecture 18: Multi-class classification and introduction to computer vision": [[39, null]], "Lecture 19: Time series": [[40, null]], "Lecture 1: Course Introduction": [[22, null]], "Lecture 20: Survival analysis": [[41, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[23, null]], "Lecture 3: Machine Learning Fundamentals": [[24, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[25, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[26, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[27, null]], "Lecture 7: Linear Models": [[28, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[29, null]], "Lecture 9: Classification metrics": [[30, null]], "Lecture learning objectives": [[32, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[36, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[52, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[26, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[27, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[25, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[26, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[33, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[30, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[31, "let-s-separate-x-and-y"], [33, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[31, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[26, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[32, "lightgbm"]], "Limitations of linear models": [[28, "limitations-of-linear-models"]], "Linear SVM": [[28, "linear-svm"]], "Linear models [video]": [[28, "linear-models-video"]], "Linear regression": [[28, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Logistic regression [video]": [[28, "logistic-regression-video"]], "Logistic regression intuition": [[28, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[28, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[39, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[40, "logisticregression"], [41, "logisticregression"]], "MAPE": [[31, "mape"]], "ML fairness activity": [[49, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[30, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[44, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[22, "machine-learning-workflow"], [30, "machine-learning-workflow"]], "Magnitude of the coefficients": [[28, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[28, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[28, "main-hyperparameters"]], "Manual hyperparameter optimization": [[29, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[35, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[35, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[31, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[22, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[35, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[35, "method-2-the-silhouette-method"]], "Midterms": [[52, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[37, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[31, "model-building"]], "Model complexity and training error": [[24, "model-complexity-and-training-error"]], "Model interpretability beyond linear models": [[33, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[22, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[49, "model-training-and-evaluation"]], "Model-based selection": [[34, "model-based-selection"]], "More comments on tackling class imbalance": [[31, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[36, "more-details-on-dbscan"]], "More on feature transformations": [[27, "more-on-feature-transformations"]], "More on k-NNs [video]": [[25, "more-on-k-nns-video"]], "More terminology [video]": [[23, "more-terminology-video"]], "More than one ordinal columns?": [[27, "more-than-one-ordinal-columns"]], "Most confident cases": [[28, "most-confident-cases"]], "Motivating example": [[28, "motivating-example"]], "Motivation": [[29, "motivation"], [40, "motivation"]], "Motivation [video]": [[32, "motivation-video"]], "Motivation and big picture [video]": [[26, "motivation-and-big-picture-video"]], "Motivation and context": [[38, "motivation-and-context"]], "Motivation and distances [video]": [[25, "motivation-and-distances-video"]], "Movie features": [[37, "movie-features"]], "Multi-class classification": [[39, "multi-class-classification"]], "Multiclass classification and computer vision": [[44, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[27, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[24, null], [24, null], [40, null]], "Number of trees and fundamental trade-off": [[32, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[27, "ohe-with-many-categories"]], "Object detection": [[39, "object-detection"]], "Observations": [[30, "observations"]], "One Vs. One approach": [[43, "one-vs-one-approach"]], "One Vs. One prediction": [[43, "one-vs-one-prediction"]], "One vs. Rest": [[43, "one-vs-rest"]], "One-hot encoding (OHE)": [[26, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[40, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[40, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[27, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[30, "operating-point"]], "Optimization bias of hyper-parameter learning": [[29, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[29, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[29, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[29, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[29, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[26, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[33, "ordinal-features"]], "Other applications": [[35, "other-applications"]], "Other approaches / what did we not cover?": [[41, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[38, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[31, "other-possible-preprocessing"]], "Other software package": [[40, "other-software-package"]], "Other tools for preprocessing": [[38, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[38, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[25, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[34, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[24, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[45, "outline"], [46, "outline"], [47, "outline"], [48, "outline"], [49, "outline"], [50, "outline"], [51, "outline"]], "Over confident cases": [[28, "over-confident-cases"]], "Overfitting": [[24, "overfitting"]], "Overfitting of the validation data": [[29, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[29, "overfitting-of-the-validation-error"]], "Oversampling": [[30, "oversampling"]], "Overview": [[25, "overview"]], "POSIX time feature": [[40, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[30, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[23, "parameters"]], "Parameters and hyperparameters: Summary": [[23, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[40, "parsing-datetimes"], [51, "parsing-datetimes"]], "Part 1": [[44, "part-1"]], "Part 2": [[44, "part-2"]], "Passing Requirements": [[52, "passing-requirements"]], "Pipelines": [[26, "pipelines"]], "Playground": [[25, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[23, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[30, "precision"]], "Precision and recall: toy example": [[30, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[30, "precision-recall-f1-score-video"]], "Precision-recall curve": [[30, "precision-recall-curve"], [30, "id1"]], "Precision/Recall tradeoff": [[30, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[22, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[28, "predicting-probability-scores-video"]], "Predicting with learned weights": [[28, "predicting-with-learned-weights"]], "Prediction": [[41, "prediction"]], "Prediction of linear regression": [[28, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[28, "prediction-with-learned-parameters"]], "Predictions": [[39, "predictions"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[27, "preprocessing"], [40, "preprocessing"], [44, "preprocessing"], [49, "preprocessing"], [51, "preprocessing"]], "Preprocessing the targets?": [[27, "preprocessing-the-targets"]], "Prevalence of ML": [[22, "prevalence-of-ml"]], "Problem formulation": [[37, "problem-formulation"]], "Problem: Different transformations on different columns": [[26, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[29, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[24, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[25, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[44, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[25, "question"]], "Question for you": [[36, "question-for-you"]], "Questions for class discussion": [[37, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[29, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[25, "quick-recap"]], "RFE algorithm": [[34, "rfe-algorithm"]], "R^2 (not in detail)": [[31, "r-2-not-in-detail"]], "Random forest feature importances": [[33, "random-forest-feature-importances"]], "Random forests": [[32, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[32, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[32, "randomforestclassifier"], [41, "randomforestclassifier"]], "Randomized hyperparameter search": [[29, "randomized-hyperparameter-search"]], "Range of C": [[29, "range-of-c"]], "Raw scores": [[28, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[23, "reading-the-data"], [39, "reading-the-data"]], "Real boundary between Canada and USA": [[23, "real-boundary-between-canada-and-usa"], [45, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[30, "recall"]], "Recap": [[41, "recap"]], "Recap and motivation [video]": [[36, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[23, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[30, "receiver-operating-characteristic-roc-curve"]], "Recommender systems": [[44, "recommender-systems"]], "Recommender systems intro and motivation": [[37, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[37, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[34, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[41, "references"]], "Registration": [[52, "registration"]], "Regression scoring functions": [[31, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[25, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[25, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[25, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[32, "relevant-papers"]], "Relevant papers and resources": [[30, "relevant-papers-and-resources"]], "Relevant resources": [[34, "relevant-resources"]], "Reminder": [[37, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Report format": [[7, "report-format"]], "Resources": [[35, "resources"], [36, "resources"], [37, "resources"]], "Ridge": [[28, "ridge"]], "Ridge on the California housing dataset": [[28, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[31, "ridgecv"]], "Root mean squared error or RMSE": [[31, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[33, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[33, "shap-plots"]], "SMOTE idea": [[30, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[30, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[25, "svm-regressor"]], "Saving time and scaling products": [[22, "saving-time-and-scaling-products"]], "Scaling": [[26, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[26, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[52, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[25, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[40, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[22, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[39, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[28, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[35, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[25, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[42, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[24, "simple-train-test-split"]], "SimpleFeature correlations": [[33, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[32, "some-important-hyperparameters"]], "Some quotes on feature engineering": [[34, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[23, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[29, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[27, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[32, "stacking"], [50, "stacking"]], "Step 1": [[47, "step-1"]], "Step 2": [[47, "step-2"]], "Step 3": [[47, "step-3"]], "Step 4": [[47, "step-4"]], "Step 5": [[47, "step-5"]], "Steps to train a classifier using sklearn": [[23, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[30, "stratified-splits"]], "Strengths and weaknesses": [[32, "strengths-and-weaknesses"]], "Strengths of linear models": [[28, "strengths-of-linear-models"]], "Study tips": [[44, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[22, "summary"], [25, "summary"], [32, "summary"], [38, "summary"], [39, "summary"], [41, "summary"]], "Summary and reflection": [[24, "summary-and-reflection"]], "Summary of linear models": [[28, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[24, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[36, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[37, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[35, "supervised-learning"]], "Supervised learning (Reminder)": [[23, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[23, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[22, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[25, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[25, "support-vectors"]], "Survival analysis": [[44, "survival-analysis"]], "Survival plots": [[41, "survival-plots"]], "Syllabus": [[1, "syllabus"], [52, null]], "TAs": [[52, "tas"]], "Tabular data": [[23, "tabular-data"]], "Take-home message": [[36, "take-home-message"]], "Teaching Team": [[52, "teaching-team"]], "Terminology": [[39, "terminology"]], "Terminology [video]": [[23, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[32, "the-netflix-prize"]], "The __ syntax": [[29, "the-syntax"]], "The best features may be dependent on the model you use.": [[34, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[50, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[24, "the-golden-rule"]], "The random forests classifier": [[32, "the-random-forests-classifier"]], "The sigmoid function": [[28, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[24, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[35, "the-perfect-spaghetti-sauce"]], "Time series": [[44, "time-series"]], "Time series analysis on a more complicated dataset": [[51, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[41, "time-to-event-and-censoring"]], "Tokenization": [[38, "tokenization"]], "Topic modeling": [[38, "topic-modeling"]], "Topic modeling motivation": [[38, "topic-modeling-motivation"]], "Topic modeling pipeline": [[38, "topic-modeling-pipeline"]], "Topic modeling toy example": [[38, "topic-modeling-toy-example"]], "Toy datasets": [[23, "toy-datasets"]], "Traditional time series approaches": [[40, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[40, "train-test-split-for-temporal-data"]], "Train/test splits": [[40, "train-test-splits"]], "Train/validation/test split": [[24, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[22, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[28, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[24, "training-error-vs-generalization-error"]], "Training models with transformed data": [[27, "training-models-with-transformed-data"]], "Transfer learning": [[39, "transfer-learning"]], "Transformations on the toy data": [[27, "transformations-on-the-toy-data"]], "Transforming the targets": [[31, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[33, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[32, "tree-based-ensemble-models"]], "Tree-based models": [[32, "tree-based-models"]], "Tuning alpha hyperparameter of Ridge": [[31, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[45, null]], "Tutorial 2": [[46, null]], "Tutorial 3": [[47, null]], "Tutorial 4": [[48, null]], "Tutorial 5": [[49, null]], "Tutorial 6": [[50, null]], "Tutorial 7": [[51, null]], "Types of censoring": [[41, "types-of-censoring"]], "Types of errors": [[24, "types-of-errors"]], "Types of machine learning": [[22, "types-of-machine-learning"], [35, "types-of-machine-learning"]], "Types of problems involving time series": [[40, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[41, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[24, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[24, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[30, "undersampling"]], "Unequally spaced time points": [[40, "unequally-spaced-time-points"]], "Unsupervised learning": [[35, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[52, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[43, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[30, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[35, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[31, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[39, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[39, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[31, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[27, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[29, "visualizing-the-parameter-grid-as-a-heatmap"]], "Warning": [[23, null]], "Warnings about feature selection": [[34, "warnings-about-feature-selection"], [34, "id8"]], "Weaknesses": [[32, "weaknesses"]], "What all transformations we need to apply on the dataset?": [[26, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[26, "what-are-the-options"]], "What are we exactly learning?": [[28, "what-are-we-exactly-learning"]], "What did we cover?": [[37, "what-did-we-cover"]], "What did we learn today?": [[24, "what-did-we-learn-today"], [26, "what-did-we-learn-today"], [27, "what-did-we-learn-today"], [30, "what-did-we-learn-today"], [31, "what-did-we-learn-today"]], "What if we apply OHE?": [[27, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[38, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[37, "what-is-a-recommender-system"]], "What is clustering?": [[35, "what-is-clustering"]], "What is feature engineering?": [[34, "what-is-feature-engineering"]], "What is feature selection?": [[34, "what-is-feature-selection"]], "What is model interpretability?": [[33, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[22, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[30, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[32, "what-kind-of-estimators-can-we-combine"]], "What to look for in these plots?": [[35, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[26, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When is it OK to do things before splitting?": [[26, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[29, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[32, "which-model-should-i-use"]], "Which type of error is more important?": [[30, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[29, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[33, "why-do-we-want-this-information"]], "Why feature selection?": [[34, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[22, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[33, "why-model-transparency-interpretability"]], "Why neural networks?": [[39, "why-neural-networks"], [39, "id1"]], "Why not neural networks?": [[39, "why-not-neural-networks"], [39, "id2"]], "Why should we care about recommendation systems?": [[37, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[27, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[38, "word-embeddings"]], "Word vectors with spaCy": [[38, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[23, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[32, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[30, "class-weight-balanced"]], "cross_val_score": [[24, "cross-val-score"]], "cross_validate": [[24, "cross-validate"]], "fit and transform paradigm for transformers": [[26, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[23, "fit-the-classifier"]], "fit, predict , and score summary": [[23, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[52, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[31, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[31, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[32, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[32, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[34, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[39, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[23, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[23, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[23, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[24, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[24, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[30, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[30, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[25, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[37, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[29, "n-iter"]], "n_jobs=-1": [[29, "n-jobs-1"]], "pandas_profiler": [[31, "pandas-profiler"]], "predict the target of given examples": [[23, "predict-the-target-of-given-examples"]], "predict_proba": [[28, "predict-proba"]], "random_state argument": [[24, "random-state-argument"]], "score your model": [[23, "score-your-model"]], "sklearn API summary: estimators": [[26, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[26, "sklearn-api-summary-transformers"]], "sklearn set_config": [[27, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[27, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[33, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[33, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[42, "spacy"]], "test score vs. cross-validation score": [[24, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[24, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[24, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[30, "questions-for-group-discussion"], [49, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[22, "questions-for-you"], [23, "questions-for-you"], [23, "id1"], [23, "id3"], [24, "questions-for-you"], [24, "id1"], [25, "questions-for-you"], [25, "id1"], [26, "questions-for-you"], [26, "id1"], [26, "id2"], [27, "questions-for-you"], [27, "id1"], [28, "questions-for-you"], [28, "id1"], [28, "id2"], [29, "questions-for-you"], [29, "id2"], [30, "questions-for-you"], [30, "id2"], [31, "questions-for-you"], [31, "id2"], [32, "questions-for-you"], [32, "id1"], [32, "id2"], [34, "questions-for-you"], [35, "questions-for-you"], [35, "id2"], [36, "questions-for-you"], [36, "id3"], [37, "questions-for-you"], [37, "id1"], [37, "id2"], [39, "questions-for-you"], [40, "questions-for-you"], [40, "id1"], [40, "id2"], [40, "id3"], [41, "questions-for-you"], [41, "id1"], [41, "id2"], [41, "id3"], [41, "id4"]], "\ud83e\udd14 Eva\u2019s questions": [[22, "eva-s-questions"], [24, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 28, 29, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "0": [0, 1, 7, 8, 10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "00": [10, 22, 23, 25, 27, 28, 29, 30, 33, 36, 37, 40, 41, 51, 52], "000": [22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 38, 39, 41, 42], "0000": [26, 28, 30, 38, 42], "00000": [29, 40, 51], "000000": [23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 51], "00000000e": 33, "000000e": 29, "000001": 31, "00000e": 25, "000010": 31, "000011": 30, "000021": 26, "000036": 30, "000057": 26, "000065": 29, "000067": 29, "000077": 29, "000087": 28, "000089": 28, "0001": [28, 30, 31, 41], "000100": [26, 31], "000108": 28, "000113": 30, "000114": 29, "000117": 31, "000130": 28, "000136": 39, "000137": 29, "000145": 29, "000146": 28, "000147": 29, "000149": 26, "000150": 28, "000151": 29, "000155": [26, 30], "000159": 29, "000163": 29, "000166": [28, 29], "000177": [26, 40], "000180": 26, "000181": 29, "000182": 28, "000183": 28, "000187": 28, "000188": 26, "000190": 40, "000192": 40, "000194": 28, "000195": 26, "000198": 30, "000201": 29, "000206": 29, "000208": 26, "000210": 29, "000212": 34, "000213": 28, "000218": 28, "000221": 31, "000226": 31, "000227": 30, "000231": 26, "000232": 39, "000234": [25, 29], "000235": [26, 30], "000240": 26, "000245": 29, "000247": 39, "000255": 28, "000256": 40, "000259": 26, "000260": 26, "000271": 40, "000273": 39, "000274": 39, "000281": 28, "000283": 28, "000285": 28, "000286": 29, "000289": 26, "000294": 29, "000312": 30, "000332": 31, "000336": 39, "000339": 29, "000348": 29, "000353": 29, "000354": 29, "000363": 39, "000366": 30, "000370": 29, "000371": 28, "000373": 31, "000378": 28, "00038": 29, "000397": 31, "000399": 39, "000433": 31, "000435": 39, "000437": 39, "000452": 26, "000459": 28, "000471": 40, "000472": 39, "000489": 29, "000492": 30, "000498": 40, "000503": 29, "000508": 29, "000520": 31, "000575": 40, "00058": 29, "000580": 25, "000630": 30, "000633": 25, "000637": 39, "000647": 25, "000650": 25, "000651": 25, "000652": 31, "000655": 25, "000661": 25, "000671": 25, "000678": 29, "000713": 31, "000726": 30, "000737": 40, "000747": 29, "000748": 26, "000752": 25, "000758": 39, "000765": 26, "000774": 26, "000786": 30, "000787": 25, "00079": 29, "000794": 25, "000795": 25, "000797": 25, "000803": 31, "000829": 25, "000831": 25, "000832": 31, "000867": 26, "000869": 40, "000873": 25, "000889": 25, "000891": 30, "000917": 29, "000927": 30, "000936": 25, "000945": 34, "000960": 39, "000964": 34, "000976": 29, "000977": 25, "000982": 29, "001": [22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 39, 41, 42], "0010": 28, "00100": 29, "001000": [29, 31], "001002": 24, "001006": 24, "001010": 24, "001011": [25, 31], "001014": 24, "001016": 24, "001017": 24, "001026": 24, "001027": 24, "001029": 24, "001038": 24, "001040": 30, "001043": 26, "001057": [24, 29], "001060": 26, "001063": 24, "001064": 39, "001068": 33, "001071": 24, "001078": 24, "001086": 24, "001087": 34, "001103": 24, "001111": 24, "001139": 25, "001149": 24, "001155": 34, "001162": [29, 34], "001174": 24, "001205": 30, "001220": 28, "001224": 25, "001226": 39, "001236": 29, "001239": 30, "001266": 31, "001279": 34, "001286": 30, "001294": 24, "001299": 24, "001305": 24, "001307": 24, "001315": 24, "001317": 24, "001322": 24, "001323": 24, "001325": 25, "001329": 24, "001337": 24, "001338": 28, "001347": 29, "001352": 24, "001361": 28, "001362": 28, "001365": 25, "001371": 27, "001390": 24, "001391": 24, "001392": 25, "001400": 27, "001406": 31, "001407": 24, "001412": 29, "001414": 25, "001422": 31, "001423": 29, "001429": 24, "001433": 31, "001441": 24, "001448": 27, "001453": 24, "00146": 29, "001466": 27, "001467": 29, "001492": 29, "001495": 25, "001563": 27, "001566": 31, "001585": 29, "001586": 25, "001591": 27, "001594": 29, "001595": 25, "001600": 25, "001604": 27, "001606": 27, "001608": 29, "001616": 29, "001620": 29, "001629": 29, "001641": 39, "001645": 28, "001647": 27, "001679": 29, "001682": 29, "001693": 34, "001699": 24, "0017": 30, "001700": 30, "001710": 28, "001715": 27, "001740": 31, "001769": 29, "001773": 25, "001776": 24, "001790": 31, "001792": 29, "001847": 34, "001850": 28, "001877": 25, "001894": 31, "001900": 25, "001920": 27, "001922": 27, "001933": 31, "001949": 34, "001952": 25, "0019627889": 38, "001968": 24, "001994": 34, "002": [24, 28, 32, 33, 38, 41], "002003": 29, "002022": 27, "002030": 25, "002045": 29, "002057": [26, 27], "002083": 25, "002096": 39, "002105": 29, "002116": 27, "002118": 25, "002123": 29, "002143": 24, "002146": 29, "002158": 34, "002159": 29, "002197": 29, "002221": 31, "002321": 28, "00234": 29, "002355": 34, "002385": 31, "002441": 34, "002460": 39, "002525": 39, "002561": 29, "002646": 34, "002664": 34, "002675": 29, "002682": 39, "002690": 26, "002692": 29, "002704": 29, "002711": 39, "002746": 31, "002783": 29, "002788": 27, "002789": 27, "002807": 27, "002835": 29, "002858": 27, "002867": 34, "002889": 30, "0029": 41, "002910": 27, "002934": 28, "002940": 39, "002948": 25, "002962": 39, "002986": 39, "002999": 29, "003": [29, 32], "003013": 27, "003014": 29, "003015": 29, "003027": 29, "003038": 29, "003083": 29, "003086": 27, "003115": 27, "003124": 31, "003133": 31, "003146": 27, "003148": 28, "003166": [26, 34], "003181": 26, "003183": 34, "003185": 41, "003186": 27, "003188": [26, 27], "003194": 28, "003212": 26, "003242": 39, "003257": 39, "003273": 24, "003283": 39, "003288": 31, "003300": 26, "00332": 29, "003324": 26, "003365": 27, "003401": 34, "003421": 29, "003423": 34, "003427": 34, "003472": 29, "003477": 39, "003479": 29, "003483": 29, "003493": 34, "003528": 29, "003529": 29, "003547": 31, "003563": 29, "003633": 29, "003647": 39, "00369": 29, "003748": 29, "003757": 29, "003785": 31, "003885": 29, "003919": 29, "003919287722401839": 29, "00392157": 39, "003923": 27, "003924": 34, "003933": 29, "003998": 29, "004": [25, 29, 32, 33, 39], "004057": 29, "004065": 40, "004082": 40, "004121": 31, "004143": 31, "004264": 24, "004293": 29, "004305": 29, "004337": 29, "00435173": 35, "004352": 35, "004398": 33, "004402": 29, "004466": 29, "004496": 29, "004521": 31, "004529": 33, "004556": 29, "004574": 31, "004602": 31, "00461": 29, "004714": 29, "004723": 33, "004761": 33, "004770": 26, "004801": [26, 27], "004807": 27, "004826": 31, "004829": 31, "004854": 31, "004884": 39, "004919": 29, "004934": 30, "004952": 29, "004959": 29, "00496": 29, "005": [22, 32, 33, 41], "005067": 26, "005074": 39, "005093": 26, "005098": 31, "005114": 31, "005126": 29, "005151": 29, "005157": 26, "005167": 31, "005196": 29, "005241": 31, "00525962": 26, "005269": 31, "005288": 27, "005335": 29, "005336": 31, "005387": 30, "005423": 29, "005426": 29, "00543825": 26, "005440": 39, "005478": 33, "00548": 29, "005538": 31, "005579": 31, "005641": 31, "005674": 31, "005699": 24, "005708": 29, "00573": 29, "005734": 29, "005735": 29, "005767": 29, "005809": 40, "005834": 29, "005836": 26, "005888": 26, "006": [32, 33, 41], "006012": 29, "006046": 31, "006055": 29, "006067": 31, "006106": 29, "006110": [25, 29, 31], "006236": 31, "006244": 29, "006435": 29, "006452": 28, "006476": 31, "006505": 39, "006531": 24, "006545": 29, "006546893270012566": 28, "006557": 28, "006578": [26, 27], "006652": 29, "006667": 29, "00667": 29, "006744": 31, "006805": 24, "006861": 29, "006904": 29, "00691": 29, "006973": 26, "007": [26, 32, 33, 41, 42], "007068": 34, "00715": 29, "00720988e": 33, "007228": 31, "007291": 27, "007316": 24, "007361": 30, "007362": 29, "007434": 33, "007458": [26, 27], "007517": 31, "007544": 29, "007563": 29, "007588": 35, "00758803": 35, "00759438": 33, "007655": 29, "007666": 30, "00767": 29, "007737": 31, "007776": 31, "007818": 29, "007938": 24, "007986": 31, "008": [32, 33, 42], "008040": 40, "008120": 31, "008153": 29, "008167": [26, 27], "00830586": 27, "008306": 27, "008322e": 41, "008333": 27, "008346": 31, "008377": 29, "008472": 31, "008577": 39, "008581": 31, "008606": 31, "008617": 31, "008667": 29, "00871": 29, "008735": 25, "008785": 31, "009": [27, 32, 41], "009059": 24, "009063": 29, "009082": 29, "009090": 31, "009132": 29, "009140": 31, "009297": 29, "009305": 29, "009339": 31, "009422": 24, "009512": 29, "009514e": 31, "009664": 31, "009692": 39, "009724": 34, "01": [25, 26, 28, 29, 30, 31, 33, 39, 40, 41, 43, 51], "010": [22, 28, 29, 41, 42], "0100": 28, "01000": 29, "010000": [26, 29, 31], "010027": 28, "010183": [26, 27], "0102": [25, 29], "010208": 34, "010294": 24, "010650": 24, "010679": 24, "010688": 34, "010715": 29, "010750": 34, "011": [22, 27, 39, 41], "011210": 34, "011234": 30, "011248": 31, "011252": 34, "011269e": 31, "011287": 34, "011332": 41, "011336": 25, "011440": 31, "011617": 29, "011678": 30, "011767": 31, "011773": 32, "012": [26, 27, 32, 33, 39, 41, 42], "012019": 24, "012030": 34, "012232": 31, "012240": 34, "012252": 29, "012616": 29, "012624": 31, "012707": 30, "012758": 31, "013031": 31, "01311996071": 31, "013120": 33, "013157": 29, "013161": 29, "013433": 25, "013629": 29, "013706928443177698": 29, "013707": 29, "013863": 29, "013888": 29, "014": [24, 26, 32, 33, 41], "014030": 31, "014081e": 31, "01409912": 38, "014305": 31, "01432486e": 33, "014481": 29, "014503": 29, "014650": 41, "014730": 27, "01473536": 25, "014758": 41, "015": [22, 26, 27, 32, 41, 42], "015003": 29, "015039": 30, "015056": 29, "015165": 31, "015372": 29, "015724": 34, "015755": 29, "015819": 29, "016263": 29, "016372": 29, "01647": 29, "016525": [31, 33], "016555": 28, "016587": 30, "016598": 29, "016602": 29, "016607": 29, "016676": 35, "016688": [26, 34], "016693": 31, "016807": 28, "016815": 29, "016918": 30, "016944": 25, "017": [27, 39], "017185": 29, "017226": 31, "017308": 29, "017427": 29, "017610": 33, "017696": 33, "017737": 33, "017741": 33, "017829": [40, 51], "017837": 29, "01784": 29, "017927": 29, "017959e": 31, "017972": 26, "018": 32, "018014": 33, "018046": 30, "018077": 29, "018178": 25, "018243": 29, "018310": 25, "018434": [40, 51], "018459e": 31, "018487": 28, "0185": 28, "018505": 29, "018507e": 31, "018558": 29, "018581": 31, "018653": 29, "018745": 22, "018789": 29, "018846": 29, "018854": 30, "019": 32, "019012": 29, "019163": 29, "019381838999846482": 29, "019382": 29, "019396": 29, "019444": 27, "019446": 29, "019531": 30, "019556": 41, "0195598": 28, "019574": 29, "019839": 29, "02": [25, 26, 27, 28, 29, 31, 33, 34, 40, 41, 47, 51], "02000e": 25, "020123": 31, "020403": 29, "020414": 29, "020641": 33, "020648": 31, "020653": 24, "020833": 37, "020862": 31, "020873": 26, "021": [32, 42], "021043": 30, "021100": 26, "021281": 29, "021305": 25, "021345": 29, "021523": 30, "021603": 39, "021721": 29, "021746": 29, "021813": 30, "021862": 29, "021900": [25, 29], "022039": 30, "022331": 33, "022433": 29, "022629": 29, "022686": 29, "022848": 24, "022866": 30, "023": [32, 39], "023086": 41, "023105": [40, 51], "023305": 31, "023366": 34, "023367": 30, "023511": 29, "023554": 31, "023636": 30, "023666": 29, "023810": 42, "024": 32, "024028": 29, "024122": 29, "024291": 40, "024351e": 31, "024390": 34, "02446630e": 33, "024540": 26, "025": [26, 30], "025381": 33, "025391": [26, 27], "025396": 29, "025489": 33, "025689": 29, "025910": 25, "025998": [26, 27], "026": 41, "0261": [25, 29], "026620": 29, "026777": 29, "02677733855112973": 29, "026793": [31, 33], "026972": 31, "027070": 31, "027112": [40, 51], "027321": 34, "027484": 31, "027578": 31, "028023": 30, "02807617": 38, "028337": 29, "028351": 29, "028420": 31, "028672": 34, "028772": 31, "029": 38, "029137": 30, "029146": 30, "029164": [40, 51], "029198": 29, "029264": 31, "029409": 31, "029475": 31, "029909": 24, "029950e": 31, "02d": 40, "03": [28, 29, 31, 33, 39, 40, 41, 42, 51], "030": 33, "03017665e": 33, "030200": 26, "030343": 31, "030349": 31, "030408": 25, "03049217": 25, "0305": 25, "030739733331869412": 28, "030786": 31, "030805": 31, "031": 27, "031070": 31, "031385": 25, "031483": 31, "031564": 26, "031794": 31, "031863": 31, "0319": 38, "031994": 31, "032140": 31, "032280": 30, "032324": 29, "032404": 29, "032566": 27, "03256625": 27, "032656": 25, "032874": 25, "033165": 31, "033222": 41, "033267": 40, "033279": 33, "033305": 39, "033322": 31, "033459": 25, "0335": 29, "033723": 31, "033739": 31, "033780": 41, "033833": 30, "0339": 26, "034071": 30, "03411038e": 33, "034132": 31, "0344": [25, 29], "034894": 33, "034977": 31, "034979e": 31, "035": 39, "0351": 26, "03516073": 33, "035161": 33, "035223": 31, "035230": [40, 51], "035722": 31, "036": [26, 32, 39], "036136": 34, "0362": 26, "036646": 31, "036749": 30, "036764": 30, "036886": 32, "0370": 26, "0373": 26, "037414": [40, 51], "037785": 30, "0378": [26, 41], "038102": 28, "038609": 31, "038707": 33, "038948": 31, "039": 39, "039498": 28, "039741": 25, "0399": 26, "04": [26, 27, 29, 31, 33, 40, 41, 47, 51], "040": 32, "040129": 41, "040497": 30, "040698e": 31, "040954": 41, "040984": 40, "041": [32, 39], "041031": 30, "04108378": 28, "041084": 28, "041129": 25, "041201": 30, "041488": 31, "041704": 33, "041769": 31, "042081": 33, "042382": 34, "042743": 31, "042957": [26, 27], "043": 29, "043257": 27, "043319": 33, "043509": 29, "0437": [23, 24, 25, 45], "043890": 25, "044": [25, 29], "044029": [26, 27], "044166": 28, "044253": 33, "044313": 26, "044409": 31, "044614": 29, "044873": 24, "045": [23, 39], "045267": 40, "045280": 30, "045304": 25, "045415": 26, "045481": [40, 51], "046": 39, "04600e": 25, "046020": 25, "046116": 29, "046193e": 31, "046216": 29, "046638": 27, "0468": 41, "0469": 26, "046945": 29, "04709519e": 33, "0474": 28, "047567": 31, "04774884": 35, "047749": 35, "048": [24, 27], "048378": 24, "04861878": 35, "048630": 40, "048860": 26, "048889": 31, "049": [27, 39], "05": [25, 26, 29, 30, 31, 36, 40, 41, 51], "050": [22, 39], "050110e": 31, "050132": [26, 27], "051": 39, "051269": [26, 27], "05137470e": 33, "051392": 39, "051472": 25, "051620": 26, "051824": 31, "051925": 29, "052": 26, "052349": 26, "052607": 30, "052790": 30, "052819": 30, "05290827e": 33, "053156": 35, "05350962": 43, "0537": 29, "053763": 24, "053918": 29, "054054": 30, "054461": 30, "054653": 27, "05465323": 27, "054669": [31, 33], "054784": 27, "05478443": 27, "055": [24, 26, 27], "055100": 29, "055915e": 31, "05598498": 27, "055985": 27, "056": 39, "056478": [26, 27], "05656664": 38, "056703": 30, "057": [26, 39], "057003": 25, "057082": 31, "057254": 41, "057296": 30, "057331": 31, "057646": 25, "057729": 30, "057732e": 41, "057793": [26, 27], "057910": [26, 27], "058": 32, "0580": [24, 28], "058298": 31, "058311": 30, "059": [22, 26], "059077": 30, "0591": 26, "059242": [26, 27], "059360": 39, "059588": 29, "059863": 25, "06": [26, 29, 31, 36, 38, 39, 40, 41, 43, 51], "060": 39, "060477": 31, "060543": 34, "061100": 26, "061206": 30, "061241": 25, "061312": 31, "061313": 39, "061937": 25, "062": [22, 25, 29], "062043": 29, "062449": 41, "062658e": 31, "062723": 24, "062792": 25, "062793": 38, "063004": 34, "063110": [26, 27], "063173": 33, "064": [29, 33], "06405": 29, "064050": 29, "064200": 25, "064307": 34, "064452": 25, "065": 39, "065169": 29, "065199": 30, "065449": 31, "065463": 30, "066166": 41, "066251": 24, "066605": 29, "066667": 26, "0667579112160865": 28, "066810": 41, "066944": 29, "067119": 26, "067120": 24, "06797961": 31, "067991": 26, "068": 22, "068214": [28, 29], "068291": 39, "068498": 29, "068775": 29, "068891": 29, "069150": 33, "06915047": 33, "069188": 41, "0694": [25, 29], "069530": 25, "07": [29, 31, 34, 40, 41, 51], "070081": 29, "070195": 29, "070850": 30, "070898": 29, "070907": 24, "070929": 30, "071": 39, "071330": [40, 51], "071541": [26, 27], "071654": 34, "07174469222": 31, "071745": 33, "071975": 34, "072": 32, "072043": 29, "072243": 33, "0723": 26, "072396": 29, "07245741": 31, "072595": 29, "072707": 24, "073058": 26, "073233": 28, "073366": 26, "074": [26, 32], "0741": 25, "074141": 25, "07418": 29, "074327": 32, "074418": 39, "074475": 26, "074719": 27, "07471942": 27, "075000": 37, "075170": 40, "075453": 41, "075467": 41, "075747": 29, "076104": 31, "0762": 26, "076284": 35, "07639": 29, "076533": 31, "076798": 25, "077": [32, 39], "077204": 33, "077749": 38, "077761": 41, "077803": 29, "078": [28, 32], "0780": [23, 24, 45], "078052": 30, "07808506982896266": 31, "078243": 29, "078387": 41, "078552": 29, "078740": 29, "07877994e": 43, "078880": 27, "079": 29, "079282": 29, "079377": 41, "0794": [25, 29], "079471e": 31, "079852e": 31, "08": [26, 29, 31, 34, 36, 39, 40, 41, 51], "080": 39, "08002986030": 27, "080084": 29, "080165": 29, "080319": 27, "08031924": 27, "080694": 33, "080734": 24, "0808": 29, "081": 22, "08116": 29, "081167": 41, "081292": 40, "08151507e": 33, "081837": 41, "082": 26, "082100": 29, "082251": 28, "082265e": 41, "082749": 25, "082835": 33, "082949": 25, "083": [25, 29, 32], "083123": [26, 27], "083338": 24, "08338644": 38, "083545": 30, "083615": 29, "083813": [26, 27], "084288": 29, "084746": [26, 27], "085150": 40, "085415": 33, "085477": 30, "085508": 31, "085546": 31, "085550": 31, "085551": 31, "085693": 29, "085698": 31, "08613": 29, "08642578": 38, "086461": 34, "086932": 24, "087": 27, "087128": 29, "08740234": 38, "087668": 29, "08791477": 38, "087996e": 29, "088": 39, "0880": 26, "088543": 29, "088948": 25, "089294": 29, "089313": 29, "089485": 24, "09": [24, 27, 29, 31, 40, 41, 51], "090000": 30, "09009799": 31, "090231": 33, "090376e": 31, "090453": 30, "090473": 29, "09058097218": 22, "090785": 31, "091": 39, "091243": 29, "091625": 34, "091819": 24, "092": 32, "092072": 29, "092123": 29, "0922": [25, 29], "092204": 24, "09245358900622544": 29, "092454": 29, "092604": 24, "092660": 41, "092670": 29, "092729": 29, "092930": 27, "093051": 29, "0931": 29, "093228": 34, "093390": 25, "09345386": 27, "093454": 27, "093624": 24, "093787": 29, "093893": 29, "094": [22, 38], "094290": 41, "09430199": 27, "094302": 27, "094581": 27, "094586": 30, "094725": 29, "094863": 29, "095018": 29, "09503409246217484": 31, "095177": 29, "095345": 29, "09573445": 29, "09619141": 38, "096462": 31, "096692": 26, "096722": 29, "096858": 29, "096927": 30, "096960": 31, "096990": 24, "096997": 39, "097": 39, "09706504": 39, "097088": 41, "097184": 29, "097293": [26, 27], "097516": 26, "097707": 29, "097763": 29, "098": [28, 39], "098152": 29, "098307": 31, "098326": [25, 39], "098559": 29, "098629e": 29, "098663": 29, "0989147678053208": 28, "098915": 28, "098950": 29, "098966": 26, "099": 32, "099230": 33, "099240": [26, 27], "099454": 29, "099558": [26, 27], "099685": 31, "099723": 26, "099729": 29, "099749": [40, 51], "099802": 29, "099869": 29, "0x1227a36e0": 8, "0x1577111f0": 29, "0x16888d4c0": 29, "0x168921100": 29, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 33, 38, 40, 42, 43, 52], "10": [4, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52], "100": [23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 48, 51], "1000": [24, 25, 27, 28, 29, 30, 31, 33, 34, 39, 40, 41, 42, 43, 48, 49], "10000": [23, 27, 28, 29, 31, 40, 51], "100000": [25, 27, 28, 29, 31, 40, 51], "1000000": 29, "100103": 40, "100105": 29, "100139": 27, "100146": 40, "100248": 25, "100275": 34, "1004": 25, "1005": [40, 51], "1006": [40, 51], "1007": [40, 51], "1008": [40, 51], "100882": 30, "1009": [40, 51], "10092665203438746": 31, "101": [9, 10, 35, 39, 41], "1010": [40, 51], "1012": [40, 51], "101259": 31, "1014": [29, 39], "1015": [39, 40, 51], "1016": [39, 40], "101688": 29, "1017": [39, 40, 51], "101796": 31, "1018": [39, 40, 51], "101810": 24, "101832": 29, "101894": 30, "1019": [39, 40, 51], "102": [30, 31, 50], "1020": [29, 34, 39, 40, 51], "102044": 34, "1021": [39, 40, 51], "102135": 30, "1022": [39, 40, 51], "1023": [39, 40, 51], "1024": [27, 39, 40], "102435": [25, 31], "102474": 27, "10247431": 27, "1025": [40, 51], "10254": 40, "1026": [28, 40], "1027": [40, 51], "10273": 31, "10274": 30, "1028": [40, 51], "1029": [40, 51], "103": 41, "103023": 29, "1031": 40, "103219": 34, "103222": 39, "1034": 34, "103439": 27, "1039": [40, 51], "104": [25, 26, 32, 35, 39], "1040": 26, "104070": 31, "1041": [31, 33, 40, 42, 51], "10416666666666667": 37, "1042": 29, "1044": 22, "104596": 29, "104643": 31, "105": 32, "1050": 23, "105080": 34, "105089": 27, "10513": 40, "1053": 42, "105314": 40, "10556679": 35, "105656": 33, "10584063": 39, "106000": 26, "106023": 31, "106112": 40, "106180": 40, "106319": 40, "106322": 40, "106424": 40, "10644531": 38, "106452": 25, "10645223": 25, "10653": [40, 51], "106705": 40, "106764": 29, "1068": 42, "106816": 40, "1069": 42, "10693359": 38, "106996": 29, "107": 32, "1070": 34, "107050": 40, "107292": 40, "1075": 42, "107502": [40, 51], "1076": 27, "107718": 29, "10781": [32, 33], "107917": [40, 51], "10793260e": 39, "107947": 31, "107985": 31, "107991": 30, "108": 22, "1080": 22, "10800": 22, "1085": 28, "10868": 40, "108681": 25, "1089": 31, "10910": 40, "10931": 27, "109526": 30, "1099": 31, "10_000": 41, "10th": [29, 30, 32, 33, 49], "10x": 30, "11": [1, 10, 11, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 51, 52], "110": [28, 39], "110316": [40, 51], "110319": [40, 51], "1104": 25, "11057": 40, "1106": 34, "110645": 31, "110915e": 31, "111": [26, 29, 30, 31, 41, 49], "11121453": 35, "111215": 35, "111220": 40, "111438": 34, "111543": 31, "112": 25, "1122": [31, 33, 42], "1123": [29, 42], "112441": 29, "112490": 29, "112527": 33, "112848": 31, "11331": 42, "11336331e": 33, "113600": [26, 27, 47], "1138": 34, "113837": 31, "1139": [31, 33], "113949e": 41, "114": 26, "1140": [22, 31, 33], "114000": [26, 34], "114079": 29, "114214": 29, "114507": 39, "11457": [31, 33], "114766": 33, "114836": 34, "114966": 33, "115": 27, "1150": 22, "115083": 26, "115089": 40, "11509": 31, "115090": 40, "115091": 40, "115092": 40, "115183": 29, "115276": 41, "115401": 31, "115406": 25, "115428": [40, 51], "115956": 28, "116": 26, "116145": 34, "116167": 28, "116443": 34, "116497": 31, "11664": 42, "11693": 31, "117": [26, 27, 28, 34, 47], "117058": 28, "117379": 29, "117380": 26, "117412": 31, "117528": 34, "11758": [40, 51], "117612": 39, "117712": 40, "117816": 26, "117899e": 31, "1179": 26, "118": [26, 27, 28, 31, 33, 34], "1180": 23, "118182": [26, 27], "118347": 31, "118450": 30, "118563": 34, "11886432": 29, "118874": 31, "118934": 30, "11898": 30, "119": [26, 27, 28, 34, 40, 47, 51], "1190": 26, "119049": [40, 51], "11909976": 35, "119100": 35, "11914062": 38, "119400": 26, "119570": 34, "119911": [40, 51], "11th": [30, 32, 33, 49], "12": [10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52], "120": [25, 26, 28, 31, 32, 39, 40, 43], "1204": 25, "120769e": 31, "121": [22, 26, 27, 28, 29, 32, 34, 40], "1210": 29, "121056e": 31, "121084e": 31, "121351": 33, "12138": 26, "1214": 31, "121438": 41, "12150684": 28, "121531": 30, "121599": 33, "121628": 25, "1217": 41, "12178": 34, "121846": 33, "121985": 31, "122": [22, 23, 24, 26, 27, 34, 39, 45, 50], "1220": [22, 26, 29], "1222": 29, "122307": [26, 27], "122331": 31, "122668": 29, "123": [4, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49], "123367": 31, "1235387316046016": 29, "123539": 29, "124": [26, 38], "1240": 22, "1241": [31, 34], "1243": 26, "12436984": 27, "124370": 27, "1247": 29, "12498": 33, "124982": 34, "125": [8, 31], "1250": [26, 27, 47], "12508": [31, 33], "125440e": 31, "125476": 25, "125523": [40, 51], "1256": 43, "125617": [40, 51], "125644": 31, "1258": 41, "126": 34, "126238": 34, "126398": [26, 27], "126488": 35, "12649": 26, "126500": 26, "126563": 29, "126808": [26, 27], "127": [24, 26, 28, 29], "127086": 26, "127087": 41, "1271": 32, "127107": 33, "127226": 27, "127242": 31, "1273": 33, "127326": 31, "1274": 34, "127418": 31, "127439": 31, "127441": 31, "127614": 31, "12761659": 31, "127878": 25, "1279": 31, "128": 42, "1280": [26, 29, 31], "1281": 31, "128188": [26, 27], "128384": 31, "128528": 31, "128820": 40, "128828": 40, "128829": 40, "128830": 40, "12890625": 38, "128984": 31, "129": [25, 28, 34, 41, 50], "1290": [26, 27], "12906": 22, "129257": 31, "12927": 22, "129300": [26, 27, 47], "129459": 34, "129600": 31, "129900": 30, "129904": 31, "129985": 26, "12th": [30, 32, 33, 49], "13": [8, 10, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 36, 37, 38, 40, 41, 42, 44, 47, 51], "130": [22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 45, 47], "1300": [31, 33], "1302": 30, "130395": [40, 51], "1304": [25, 41], "130432": [40, 51], "130690e": 31, "1307": 31, "131": [26, 32, 40, 41], "131000": 31, "13107": 40, "131275": 30, "1313": 31, "1314": [31, 33], "131607": [31, 33], "131773": 41, "1319796954314723": 32, "132": 41, "1320": 34, "1321": 22, "132158": 31, "132292": 34, "13229595e": 33, "13255": 40, "132875": [26, 27], "132886": 40, "133": [29, 41], "133000": 31, "133210": 29, "133270": 31, "133337": 31, "133562": 41, "13392236": 39, "134": [23, 24, 27, 28, 45], "1340": 23, "134061": 34, "13407": 33, "134287": 30, "1346": [26, 31, 33, 34, 41, 42], "134615": 28, "134658": 26, "1347": 42, "13476562": 38, "134894": [40, 51], "135": [40, 41, 51], "135134": [40, 51], "135197": [40, 51], "13521135": 33, "135299": 34, "135305": [26, 27], "135384": 31, "135422": 31, "1357": 22, "136": [26, 27], "1360": 23, "13665": [26, 27, 47], "136714": 30, "1370": [22, 25, 29, 41], "13704": [31, 33], "137410": 35, "137500": [26, 27, 47], "1378": 31, "138": 42, "1380": 22, "138103": 39, "1383": 29, "138503": 34, "138528": 28, "138876": 41, "1389": [26, 31, 33], "139": [26, 42], "1390": 22, "139297": 30, "139317": 30, "139322": 30, "139349": 30, "13941": 30, "139554": 30, "1396": 29, "1397": 29, "14": [10, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 44, 51], "140": 26, "140185": 34, "1404": [25, 41], "1405": 34, "1406": [26, 31, 33], "140641": [40, 51], "140953": [40, 51], "141": [26, 28], "141232": [40, 51], "14159265358979323": 8, "14160": 30, "141851": [40, 51], "142": 32, "142193": [40, 51], "142199": [40, 51], "1423": 30, "142398": [40, 51], "142467": 24, "142806": [40, 51], "142857": 27, "14289": [26, 27, 47], "143": [29, 30], "143693": [40, 51], "143803": 34, "1438387200": 40, "1438398000": 40, "1438408800": 40, "1438419600": 40, "1438430400": 40, "1438441200": 40, "1438452000": 40, "1438462800": 40, "1438473600": 40, "1438484400": 40, "143975": [40, 51], "144": [22, 29], "144000": [31, 33], "1441": 42, "144199": [40, 51], "144686": 33, "14471": [26, 27, 47], "144729": 40, "144730": 40, "144731": 40, "144732": 40, "144733": [40, 51], "144750": 25, "14485": 31, "145": [40, 51], "1452": 34, "145425": 31, "145454": [40, 51], "145455": [40, 51], "145456": [40, 51], "145457": [40, 51], "145458": [40, 51], "145459": [40, 51], "145460": [40, 51], "1457": [26, 27, 41, 47], "14579": 34, "1458": [26, 27, 47], "145833": 37, "146": [22, 32], "1460": [31, 41], "14648438": 38, "1465": [26, 27, 47], "146656": [40, 51], "1467": 34, "146767": [30, 33], "146809": 30, "146830": 30, "14690": 27, "147": 33, "147166": [32, 33], "14716638": 33, "147641": 31, "1477": 42, "147737": 39, "147893": 26, "147898": 30, "148": [25, 29, 33, 43], "14813": 40, "148141": 32, "148343": 31, "148349": 41, "14841": 30, "149": 41, "14970": 26, "149788": 33, "149822": [26, 27], "14999": 26, "15": [8, 10, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 44, 45, 49, 51], "150": [25, 29, 31, 39], "150000": [30, 37], "150115": 29, "15026771": 31, "150395": 25, "1504": 25, "1505": 26, "150mb": 30, "150p": 22, "151357": 34, "152": 40, "1520": 29, "152401": 30, "152859": 30, "1530": 22, "1534": 26, "15377": [26, 34], "1540": 22, "154076": [30, 33], "154105": 34, "15429": 40, "154386": [26, 27], "1545": 34, "154795": [31, 33], "154842": 41, "155": [22, 29], "15500": 31, "155178e": 31, "15559528e": 33, "155624": 31, "156": [26, 29, 30], "1562": 29, "156311e": 31, "1564": 29, "15661": 40, "157": [22, 29, 39], "157008": 31, "157157": 42, "157234": 34, "15725": [26, 34], "15775": 40, "1578": 33, "15795": [30, 33], "158": 29, "1580": 22, "1582": 33, "158867": [40, 51], "158982": 31, "159": 29, "1590": [25, 29], "15915": 40, "15992": 33, "16": [10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 38, 40, 41, 42, 44, 45, 51], "160": [24, 25, 28, 29, 31, 33], "160000": [31, 33], "160258": 24, "160282": 34, "1604": 25, "160506": 30, "160634": 39, "16063983": 27, "160640": 27, "160727": 33, "160729": [40, 51], "161": 26, "1610243052583638": 28, "16111330565237164": 28, "1613": 26, "16153": 40, "16157": 40, "16160": 40, "161606": [26, 27], "161782": 30, "1619": 29, "161931": [31, 33], "162": 22, "162000": 31, "162007": 42, "162330": 30, "162667": [30, 33], "1627": 34, "162904": 41, "1631": 29, "163195": [26, 27], "163397": [26, 27], "1634": [26, 27, 29, 47], "16358": 40, "164": [34, 39], "1645": 28, "16460": 34, "164679": 30, "165": [28, 31], "1650": [25, 29], "16507": [28, 34], "16508": [28, 34], "16509": [28, 34], "16510": [28, 34], "16511": [28, 34], "16512": [28, 34], "165198e": 31, "1652": [24, 28], "16533": 40, "165485": 33, "165617": 40, "165811": 29, "16630": 34, "166631": [26, 27], "167": 24, "167214": 25, "167241": 42, "167600": 34, "167620": 39, "168": 31, "1680": 23, "168151": 39, "168196": [26, 27], "168244": 33, "1687": 29, "169": [24, 28, 34], "1690": [22, 23], "169269e": 41, "169421": 29, "169693": 25, "169748": 28, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 23, 25, 26, 27, 28, 29, 30, 31, 34, 40, 41, 44, 47, 51], "170": [26, 36], "170100": [26, 27, 47], "170277": [32, 33], "1704": 25, "17054987": 39, "170670": 31, "170931": 39, "171": [22, 39], "17144": 40, "171468": [31, 33], "1715": 29, "171657": 24, "171899": 41, "1720": 26, "17205": 40, "1724668": 38, "172792": 30, "173": [25, 29], "173025": 29, "17393037": 8, "1739787032867638": 29, "173979": 29, "174": [22, 25, 29], "174590": 30, "174766": 34, "1750": 26, "175000": [31, 33], "17518": 40, "176": 26, "1766": 31, "176924": 41, "177": 34, "17730": [26, 34], "177709": 41, "178": [22, 31], "178494": 31, "17896": 40, "179": [32, 41], "179080": 30, "179123": 25, "179300": 26, "179730": 29, "17973005068132514": 29, "179802": 31, "18": [10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 40, 41, 42, 44, 47, 51], "180": [29, 31, 39], "1800": [22, 23, 25, 29], "18000": 40, "180000": 23, "180279e": 31, "180388": 25, "1804": 25, "18066406": 38, "180900": 34, "18096": 40, "181": 41, "18113": 40, "18116": 40, "1813": 29, "182": [40, 41], "18201414": 33, "18245": 40, "182639": 31, "182648": 31, "18311": 40, "18313": 40, "18317085": 8, "183179": 41, "183423": 25, "183471e": 31, "18365": 27, "18391": [26, 27], "184": [40, 41], "1840": 22, "184405": 33, "1847": 27, "185": 41, "185155": 33, "185175": 41, "18533": 40, "1854": 29, "185707": [25, 29], "18571": [26, 27], "18572": [26, 27], "18573": [26, 27], "18574": [26, 27], "18575": [26, 27], "18576": [26, 27], "1858": 34, "185868": 34, "185975": 33, "18597545": 33, "186024": 22, "186814": 30, "186899": 30, "187": [24, 28, 32], "1870": 29, "187000": 26, "1872": 31, "1875": [28, 38], "187503": 40, "187663": 25, "187700": 26, "188": [22, 24, 28], "1880": 29, "1886": 28, "1887": [30, 33], "18955": 40, "189981": 31, "19": [8, 10, 22, 23, 24, 25, 27, 29, 30, 31, 34, 37, 38, 41, 42, 44, 51], "190": [24, 31, 34], "19000e": 25, "1901": 22, "190319": 34, "19032": 40, "1904": 25, "190617": [26, 27], "191": [24, 26], "1911": 34, "191169": [31, 33], "191204": 34, "191250": 24, "191396": 25, "191700": 34, "1918": 27, "191k": 33, "1920": 22, "19213263": 27, "192133": 27, "19266": 40, "1927": 42, "1928": 42, "193": 39, "1930": 22, "193021": 30, "193122": 30, "193247": 34, "1933": 23, "193346": 33, "193427": 29, "19365": 40, "193704": [40, 51], "19380": 40, "1940": 27, "194002": 25, "194034": [40, 51], "194040": 26, "19422": 33, "19433594": 38, "1945": 31, "1946": [22, 31], "194710": 31, "19485": 26, "194985": 31, "195": 26, "1950": 31, "1951": 23, "195228": 27, "1953": [29, 31], "19536": 30, "1954": 38, "1955": 23, "195564": 34, "1957": 38, "1959": 22, "19591": 34, "1960": 23, "1962": 38, "1963": 29, "196385": 33, "1965": 23, "196599": 31, "1966": 31, "196717": 39, "196739": 40, "1968": 22, "1970": [28, 31, 40], "1972": 31, "197649": 34, "1977": [22, 41], "19777": [32, 33], "19781": 40, "198": [39, 42], "198127": 31, "1984": 31, "1985": 31, "198629": 39, "198645": 41, "1987": [22, 23], "1989": 22, "198924": [26, 27], "199": [22, 25, 30], "1990": [25, 28, 29], "1991": [23, 32], "1992": [40, 42], "1993": 31, "199364": 30, "1994": 22, "199412": 41, "199413": [25, 29], "19966": [26, 27, 34], "1997": [28, 29], "199771": 33, "1_000_000_000": 29, "1d": 39, "1e": [29, 31, 48], "1e3": [29, 48], "1e4": 29, "1h": [26, 27, 34], "1st": [8, 30, 32, 33, 40, 49], "1stflrsf": [31, 33], "1v": 43, "1v2": 43, "1v3": 43, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 32, 33, 34, 38, 39, 40, 42, 43, 52], "20": [4, 8, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 42, 43, 44, 46, 47, 51, 52], "200": [22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 38, 39, 45, 46, 47, 48, 49], "2000": [25, 29, 30, 31, 32, 33, 34, 39, 43, 48], "200000": [29, 40, 51], "200326e": 31, "2004": 31, "200475": 30, "2006": [31, 33], "2007": [31, 33, 40, 51], "2008": [31, 33, 40, 51], "200876": 27, "20087625": 27, "2009": [31, 33, 40], "200978": 25, "200k": 49, "201": [25, 52], "2010": [31, 33, 40], "20113": [26, 27, 47], "2012": [8, 26, 29], "2013": [38, 40, 51], "201332": 36, "2014": [22, 32, 40], "2015": [39, 40, 51], "20150630": [40, 51], "2016": [8, 39, 40], "20160101": 40, "2017": [33, 40, 51], "201810": 30, "201862": 34, "202": [25, 27], "2020": 42, "2022": 40, "2023": [10, 40], "2024": [0, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51], "20248": 26, "2024w1": 39, "2025": 1, "2025s1": [0, 11], "20274": 40, "202839": 30, "203": 25, "20310": 40, "20311": 34, "20319": 40, "203265": 33, "20334": 40, "203421": 31, "203500": 26, "20357847293371892": 28, "204": [23, 24, 25, 29, 38, 45], "204167": 24, "2043": 41, "204302": [40, 51], "20433": 34, "204583": 24, "2046": 27, "204600": [25, 29], "204692": 31, "204734": 30, "20485": 40, "205": [23, 24, 25, 42, 45], "205000": [26, 27, 31, 33, 47], "205059": 34, "20509": 40, "20514": 40, "205144": 34, "205323": [40, 51], "205479": 28, "205597": 31, "20564": 40, "206": [23, 24, 25, 29, 30, 45], "206041": 33, "206073": 30, "206099": 29, "20620": 40, "206292": 26, "20639": 34, "2064": 26, "20640": [28, 34], "206724": 41, "20683258": 28, "20694": 40, "207": [23, 24, 25, 26, 29, 38, 39, 45], "207039e": 31, "2071": 34, "207814e": 31, "20794": 40, "208": [23, 24, 25, 28, 29, 45], "209": [22, 23, 24, 25, 29, 45], "209583": 24, "209746": 30, "209903": 34, "20analysi": 41, "20assumpt": 41, "20hazard": 41, "20intro": 41, "20learn": 39, "20lifelin": 41, "20with": 41, "21": [10, 22, 23, 25, 26, 27, 30, 31, 34, 35, 37, 38, 40, 42, 51], "210": 29, "210001": 30, "210240": 29, "210272": 34, "210591": [26, 27], "210779": 40, "21086181023099526": 28, "211": 29, "2110": 26, "211250": 24, "211343": 34, "211544": 30, "211892": [26, 27], "212": [24, 29], "212385": 33, "212581": 34, "21274": 40, "212870": 31, "212975": 31, "213": [29, 39, 40], "2130": 22, "21353": 40, "21382972": 32, "21389": 40, "2139": [26, 27, 47], "214": [22, 27, 29], "21405": 40, "2144": 29, "214740": 26, "214769": 39, "214821": 40, "214852": 30, "215": 29, "215245": 31, "21530": 40, "215412": 31, "21549": 40, "21571": 40, "21581": 40, "21582031": 38, "215865": 33, "21596": 40, "216": 29, "21603": 40, "21605": 40, "216123": 41, "21613": 23, "21616484": 43, "21617": 40, "216346": 33, "21634631": 33, "216585": 26, "216596": [40, 51], "21668": 40, "21670": 40, "216718": 30, "216728": 26, "21694": 40, "21697": 40, "2170": 23, "217334": 27, "21733442": 27, "2173627": 38, "21767954": 33, "21768": [33, 40], "217680": [32, 33], "21774": 40, "218207": [26, 27], "21847": 40, "21872": [31, 33], "218760": 33, "218830": 26, "219": 34, "2190": 26, "2192": 29, "219512": 34, "219700": 34, "21972656": 38, "219845e": 31, "22": [10, 25, 26, 27, 29, 30, 31, 32, 33, 34, 38, 40, 41, 42, 43, 47, 51, 52], "220": 24, "22001": 33, "220392": 41, "22057": 40, "2206": 41, "22078": 40, "2210": 22, "22114": 40, "221329": 31, "221348": [40, 51], "2214": 42, "22154": 40, "221622": [26, 27], "22168237": 43, "221900": 23, "22219": 40, "22221894": 31, "222222": 26, "22225": 40, "222307": 26, "222500": 24, "22260": 40, "222647": [31, 33], "2229": 28, "222963e": 31, "22305705": 32, "22320": 40, "223333": 24, "223460": 41, "223750": 24, "223804": 33, "224": [29, 39], "22452": 40, "2246468746": 24, "224662": 31, "22471154513694713": 28, "224865": [31, 33], "225": 39, "225301e": 31, "2254": 26, "22550": 40, "226": 29, "226415": 26, "226789": 41, "2268": 32, "22697768": 27, "226978": 27, "2270": 29, "227143": 26, "2272": 30, "227304": 40, "22741": 34, "227559": [31, 33], "227836": 30, "22788": 40, "22811601": 28, "22826": 40, "228329": 30, "2285": 40, "22851562": 38, "228603": 31, "228750": 24, "229": 39, "229000": 26, "22910": 40, "229102": 33, "2293467570951035": 32, "2295": 40, "229583": 24, "229718": 33, "23": [10, 25, 26, 27, 28, 29, 30, 31, 34, 38, 40, 41, 47, 51], "230": [25, 29], "2300": 22, "23011": 33, "2305": 33, "2307": [24, 28], "2309": 40, "23091772": 32, "2310": 40, "2311": 40, "2312": 40, "2313": 40, "23175": 40, "231815": 33, "232143": 27, "232751": 41, "23290": 40, "233": 23, "234": 41, "234040": 30, "234436": 41, "235": 34, "235096": [26, 27], "235152": 25, "235417": 24, "235706": 34, "236": [25, 29, 41], "236096": 39, "236174": 34, "236210": 35, "23621041": 35, "23640124": 28, "236456": 26, "23654": [30, 33], "236960": 29, "237": [30, 41], "237895": 30, "237935": 33, "238": [30, 41], "238192": [30, 33], "2389": 27, "239": 41, "23902": 40, "23941": 40, "239944e": 31, "24": [1, 11, 22, 25, 26, 30, 31, 32, 33, 34, 38, 39, 40, 41, 51], "240": 41, "2401": 34, "240893": 34, "241": 41, "241489": 41, "241620": 30, "24182": 40, "242015": [32, 33], "242083": 24, "242169": 30, "242381": 40, "24295676": 27, "242957": 27, "242996": [26, 27], "243": 40, "243243": 31, "2435": 34, "2436": 34, "24395": [32, 33], "24397122221206388": 40, "244": 40, "244592": 25, "2447": 32, "244814": 41, "245": 40, "2451": 29, "245329": 31, "245521": 30, "245686": 30, "246": 40, "246332": 31, "246646": 29, "246646103936": 29, "246653": 29, "247": 40, "247119": 40, "247439": 35, "24743939": 35, "247690828913": 29, "247691": 29, "248": 40, "248328": 32, "248333": 24, "2484": 22, "248457": [31, 33], "248609": 31, "248664": 34, "2488": 25, "248999": 41, "249": 42, "2496": [24, 28], "249601e": 31, "249618e": 31, "249720": 25, "24h": 30, "25": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52], "2500": [8, 42], "250000": [26, 30, 31], "25031": 40, "25037": 40, "2506": [23, 24, 45], "250900": 31, "251093": 29, "251158e": 31, "2516": 32, "25176": 40, "251769": 39, "252042": 34, "25214": 40, "252160": 25, "252859": 33, "2530": 22, "2533": [24, 28], "253312": [26, 27], "253432": 33, "253724": 25, "253914": 31, "254380": 41, "254443": 30, "255": 26, "2551": 42, "255134": 39, "2556": 32, "255751": 34, "255889": [40, 51], "256": [22, 39], "25622": 40, "256263": [32, 33], "256333": 26, "256437": 34, "25658": 34, "256813": 25, "257": 23, "2570": [22, 23], "257024": 29, "257103": 30, "2574": 34, "2580": 22, "258225": 40, "25823": 30, "258387": 33, "2584": 38, "258427": 25, "258886": 30, "259": [31, 34], "25904": 40, "2590575478171884": 28, "259286": 25, "259500": 26, "26": [8, 10, 22, 25, 26, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 51], "2600": [26, 27, 47], "260258": 34, "26048": 33, "260572": 31, "26063": 40, "260890": [31, 33], "261035": 31, "261953": [40, 51], "262": [31, 33, 41], "262079e": 31, "262156e": 31, "262269e": 31, "2623": 31, "262361": 34, "262500": 31, "263": 31, "2630": 26, "263541": 41, "263600": 26, "26370005": 28, "263736": 41, "263742e": 31, "26376": 40, "264195": 41, "264283e": 31, "26447953": 27, "264480": 27, "265": 32, "265273": 28, "266120": [40, 51], "266135": [26, 27], "2670": 29, "267612e": 31, "268": 29, "2683": 30, "26831": 40, "2691": [23, 24, 45], "26919": 34, "269689": 30, "269880": 25, "269972": [31, 33], "27": [8, 25, 27, 29, 30, 31, 38, 40, 41, 51], "270093": 29, "270093376167": 29, "27021": 40, "270270": 37, "27048": 30, "2705": 29, "271037": 34, "271287": 40, "271500": 34, "271738e": 31, "2720": 23, "27206": 40, "27263": 33, "272667": [26, 27], "2730": 26, "273382": [26, 27], "273606": [26, 27], "273890": 39, "273962": 34, "274": [26, 27, 40, 47], "274404": 26, "275008": [40, 51], "27502379069": 31, "275290": 30, "275352": 25, "275410": 28, "2759": 33, "276": 26, "27610135": 38, "27638": 40, "27652": 30, "276687": 31, "27676": 30, "27678": 30, "276943e": 31, "27697": 30, "2770": 29, "27705": 30, "27715": 30, "277381": 25, "2777": 41, "278441": [40, 51], "278634": 30, "27874871715903093": 28, "278755": 27, "27875502": 27, "2788": [24, 28], "2794": 28, "28": [10, 25, 26, 27, 28, 29, 30, 31, 34, 35, 38, 40, 41, 51], "280": [26, 34, 42], "2800": 8, "280028": 34, "280310": [26, 27], "2806": 29, "280618": 30, "2807": 41, "280801": 41, "281": 26, "28122025543": 31, "281583": 31, "2817": 33, "2820": 29, "282021e": 31, "2822": 33, "282600": 41, "283119e": 31, "28327": 40, "283421": 31, "2836": 33, "28362": 40, "283857": 25, "283921": 26, "284": [34, 40], "2845": 41, "2846": 42, "2847": 42, "285": [26, 27, 40, 47], "285263": 33, "28526302": 33, "285467": [31, 33], "28571429": 23, "286": [24, 25, 29, 40], "286000": 29, "286200": 34, "286416": 27, "2865025": 43, "286821": 25, "287": 40, "287031": [40, 51], "287079e": 31, "287344": [26, 27], "287500": 34, "28753559": 38, "288": 40, "288002": [40, 51], "288462": 28, "28854": 40, "28868": 30, "289": 40, "2890": [25, 29], "28953": 40, "289541": [31, 33], "289799": 25, "29": [8, 25, 26, 30, 31, 38, 40, 41, 42, 51], "290": 40, "290002": 30, "290424": 31, "29045704": 31, "290961e": 31, "291": [28, 40], "291667": 37, "292": 40, "292587": 41, "293": 40, "29324459": 39, "293663": 30, "294": [26, 38], "294251": 27, "2948": [26, 27, 47], "294855": 33, "2953863599856862": 28, "295397": 30, "29545": 31, "29572402": 38, "296": [26, 42], "296601": 34, "29691": 40, "297": 28, "29802": [30, 33], "298561": 41, "298612": [40, 51], "29881": 40, "298813": 30, "299": 39, "299164": 34, "2d": 39, "2d454e5fd9a5": 41, "2e": 10, "2f": [24, 29, 37, 40], "2nd": 28, "2ndflrsf": [31, 33], "2v": 43, "2v3": 43, "3": [7, 8, 10, 11, 14, 16, 17, 18, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 52], "30": [4, 10, 22, 24, 25, 28, 30, 31, 32, 33, 34, 38, 40, 41, 42, 51, 52], "300": [25, 36, 38, 43], "3000": 39, "300000": [26, 27, 40, 51], "3000000": 38, "300464": 34, "300837": 30, "301": 41, "3010": 34, "301200": 29, "3014": 34, "30146": 40, "301563": 31, "30167": 40, "301784": 41, "3019": [23, 24, 28, 45], "301952": 34, "302": [31, 33], "302131": 31, "30279": 40, "302801": 41, "302844": 41, "303": [31, 33], "303000": 26, "303004": 34, "303030": 28, "303109": 27, "303790": 29, "3038": 42, "3038344082": 33, "303916": 25, "304": 25, "3040": 40, "3041": 40, "3042": 40, "3043": 40, "3044": 40, "304784": 31, "305": 22, "30504657": 35, "305047": 35, "30530902": 25, "305346": 25, "305674": 34, "3057": [24, 28], "30573": 34, "306": 42, "306500": 25, "306564": 39, "307": 26, "3075": 42, "307516": 39, "307521": 28, "30792853": 38, "30798381": 38, "308120": 26, "30815": 31, "308216": 39, "308220": 30, "308448": 25, "3089": 29, "309": 34, "3092": [23, 24, 45], "309249": 39, "309859": 28, "31": [10, 22, 25, 26, 27, 28, 30, 31, 32, 33, 35, 38, 40, 41, 42, 47, 51], "310": 52, "310000": 26, "31000e": 25, "310284": 33, "31038074": 38, "310405": 30, "311": 26, "3110": 26, "311151": 41, "31127015": 33, "311310": 22, "311769": 34, "31196406381465247": 28, "3120": 26, "3125": 26, "312500": 37, "312501": [31, 33], "312696": 42, "3129": 42, "31297381": 27, "312974": 27, "31298589e": 39, "313": [27, 31], "3130": 42, "31384": 30, "314": 26, "3140": 26, "314000": 29, "31449687e": 33, "31454": 34, "314582": 33, "314840": 34, "314929": [40, 51], "315134": [40, 51], "315630": 30, "316164": 34, "316230": 34, "31634363": 38, "316363": 25, "316395e": 31, "316426": 34, "316552": 27, "31655231": 27, "316798": 34, "317": [26, 33], "317277": 34, "317761": 30, "318": 26, "3180": 29, "3180174485124284": 26, "318937": [26, 27], "319": [23, 26], "31908384": 39, "319630": 41, "31984311": 31, "31st": 40, "32": [8, 25, 26, 27, 28, 29, 31, 35, 38, 40, 41, 47, 51], "320": 26, "320155": 30, "320430": 31, "32064171": 32, "321": 33, "32127053": 31, "322": 34, "32240": [32, 33], "32247597e": 33, "322755": 25, "323045": [26, 27], "32323": 22, "32397724e": 33, "3245": 22, "3252": 34, "325319": 34, "32561": 30, "326": [26, 34], "326730": 30, "326741e": 41, "326933": [25, 29], "327188": 30, "3272": 41, "327283": 31, "32734": 34, "3274": 41, "327408": 30, "32791718": 38, "328": 34, "328077e": 31, "328799": 30, "328953": 25, "3298721": 39, "3299": [38, 42], "33": [8, 22, 25, 26, 27, 28, 29, 30, 31, 34, 38, 40, 41, 51], "330": [9, 10, 11, 22, 23, 39, 40, 42, 52], "33000e": 25, "330346": 41, "3310": 26, "33191802": 38, "332125": 30, "332130": 31, "33223002": 38, "3322447": 38, "33224516": 38, "33224759": 38, "332671": 33, "3327": 40, "332710": 31, "332746": 41, "332791": 41, "332824": 31, "3330": 26, "33308783": 27, "333088": 27, "333139": 30, "333333": [23, 26, 29, 37], "3333333333333333": [37, 39], "333340": 25, "3334": 42, "33380649": 38, "33380754": 38, "33380761": 38, "33381373": 38, "33394593": 38, "3339473": 38, "33394769": 38, "33395626": 38, "33397112": 38, "334": 34, "33400489": 38, "33411086": 38, "33425967": 38, "33435326": 38, "33439238": 38, "33440682": 38, "334411": 25, "334576": 31, "33462759": 38, "33476534": 38, "335": 32, "335309": 31, "3355": [26, 27, 47], "3356700488_183566145b": 39, "33590": 40, "336389": 33, "33641142": 33, "3364114233677307": 33, "336411423367732": 33, "336735": 29, "336826": 27, "33682642": 27, "33683087": 28, "336831": 28, "337034": 34, "33726089": 31, "33732465": 38, "33782315": 38, "33797555": 38, "338": [25, 29], "33888659": 8, "339": 30, "339368": 41, "339889": 41, "34": [22, 25, 26, 27, 28, 30, 31, 34, 38, 40, 41, 47], "340": [3, 10, 23, 32, 34, 39, 40, 41], "34000e": 25, "340988": 30, "341109": 31, "341300": 34, "341571": 41, "34161762": [31, 33], "341712": [40, 51], "34182": 33, "3420": 26, "342200": 34, "342605e": 31, "3436": [40, 51], "3437": 42, "3438": 42, "344": 26, "3442": 41, "34426571": 31, "34441": 31, "345": 33, "345136": 25, "345386e": 31, "3454": [41, 42], "3455": 42, "345831": 22, "346": [26, 27, 47], "346850": 30, "34691": 40, "347523": 29, "348": [26, 34], "34806": 31, "34900": 31, "34924955": 38, "35": [25, 26, 28, 30, 31, 32, 33, 38, 40, 41, 42, 46, 50, 51], "350": 22, "3500": 46, "350000": 26, "351351": 37, "351366": 30, "3515": 41, "3517": 42, "351821": 41, "3520": 41, "3521": 22, "352100": 34, "352930": [26, 27], "353": 39, "35375221": 43, "353961": 29, "354114": [31, 33], "354604": 30, "3547": 34, "354759e": 31, "35561437": 38, "356689": [32, 33], "35671794": 33, "357": 26, "3573886": 38, "357500": [26, 27], "3576": 22, "3577": 42, "35771821": 38, "357823": 22, "358": [22, 29], "358032": 33, "3582": [41, 42], "358264": [31, 33], "3583": 42, "358333": 25, "358500": 34, "358913": 27, "3589134": 27, "359": [25, 29], "3590": 29, "359784": 29, "359887": 35, "359992": 25, "35p": 22, "36": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 41, 51], "360": 27, "360172": 30, "360918": [40, 51], "361": 41, "361718": 30, "362": [41, 42], "362009": 40, "362185e": 31, "362553": 34, "36269995": 27, "362700": 27, "363": 41, "363192": 25, "363913": 30, "364": [40, 41], "364352": 28, "365": 40, "36525": 33, "365420": 42, "365603": 28, "365623": 25, "366": [27, 40, 41], "366005": 30, "3663": 41, "366626": 25, "36695134": 38, "367": 40, "367329e": 41, "367423": 29, "368": [40, 42], "3681": 33, "368304": 28, "3684": 41, "368922": 36, "369": 31, "369875": 25, "369896": 39, "37": [26, 27, 28, 31, 34, 38, 40, 41, 42, 47, 51], "37050406": 8, "370643": 30, "371": [34, 40, 51], "3717": 33, "371722": 33, "372": 26, "372706": [40, 51], "372763": [31, 33], "373031": 25, "373275": [40, 51], "373656": 40, "374": 26, "374584": 39, "37546": 33, "376": [26, 31], "376089": 31, "37647072": 32, "3768": 42, "3769": 42, "377032": 31, "377619": 29, "377619120792": 29, "37797291": 27, "377973": 27, "37807203": 38, "378159": 31, "378764": 25, "378971e": 31, "37906": 30, "379416e": 31, "379875e": 31, "38": [8, 25, 26, 28, 30, 31, 34, 38, 40, 41, 51], "3803": 41, "380436": 27, "38043616": 27, "380495": 25, "380504": [26, 27], "380643": 25, "381190": 34, "3814": 27, "381416e": 41, "381428": [31, 33], "381676": 25, "38192364": 35, "381924": 35, "382558": 30, "3828125": 38, "383": [26, 34], "384111": 42, "384127": 25, "384613e": 29, "3851": 30, "3856": 25, "385639": 35, "386": 29, "386071e": 31, "386530": 33, "387": 29, "388023": 30, "388169": 34, "38853": 31, "3889": 27, "389": [29, 34], "389065": 33, "389349": 34, "389736": [26, 27], "39": [25, 29, 30, 31, 35, 38, 40, 50, 51], "390428669205": 29, "390429": 29, "390725": 31, "39095422e": 33, "391": 26, "3912": 41, "39163": 30, "391996": 39, "392": [22, 41], "392082": 33, "392221": 28, "392385": 41, "392612": 31, "392893": [25, 29], "393": [23, 27], "3932": 41, "39375": 40, "394113e": 31, "394920": 26, "395282e": 31, "395686e": 31, "395688": 41, "395697e": 31, "396": [26, 41], "396266": 39, "396752e": 31, "396991": [26, 27], "397": 41, "398": 34, "398495": [40, 51], "39896994": 27, "398970": 27, "399": 26, "3990": [23, 24, 45], "3991": 31, "39931": 33, "399827": 30, "39x15": 38, "3blue1brown": 39, "3d": [34, 39], "3f": [23, 24, 25, 26, 30, 31, 37, 38, 42], "3h": 40, "3m": 39, "3rd": 38, "3ssnporch": [31, 33], "3v": 43, "4": [0, 1, 8, 9, 10, 14, 16, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52], "40": [8, 22, 25, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 46, 51, 52], "400": [23, 26, 29, 48], "40000": [39, 40, 51], "400000": [29, 40, 51], "400047": 41, "400157": 34, "400164": 39, "400649628005": 29, "400650": 29, "401": [25, 29], "4011": 38, "401102": 40, "401541": 30, "401623": 31, "401830": 33, "401895": 29, "402": 22, "402808": 33, "404": [25, 34], "405": 32, "405227e": 31, "405415": 25, "405650": 31, "406": 39, "406202": 29, "40689": 34, "407": 30, "407234": 39, "40725012": 39, "407510": 30, "40756124": 32, "407862": 41, "4084": 41, "40_000": 39, "40b5a809b05a": 41, "41": [25, 26, 30, 31, 33, 34, 35, 37, 40, 41, 51], "410": 26, "410240": [30, 33], "410599": 34, "411412": 31, "41150573": 31, "412": [22, 25, 29], "41210938": 38, "412500": 34, "413050": 39, "413718": 41, "413796": 31, "413958": 30, "414": 42, "4143": 41, "4151": 32, "4153": 34, "4158382658": 26, "416": 33, "4165": 32, "4169": 41, "418": 38, "418031": 25, "418069": 29, "41901484361": 29, "419015": 29, "419355": 28, "4195": 33, "4197": [23, 24, 28, 45], "419973": 30, "42": [22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 45, 46, 49, 50], "420": 29, "420000": 22, "42060": 34, "421": 39, "42104086": 33, "421215": 35, "42121526": 35, "421875": 28, "422": 31, "4234": 33, "4236": 33, "4238": 30, "423852": 30, "424222": 31, "424337e": 31, "425": 32, "425365": 41, "42541681": 43, "425419": 31, "426067": 26, "426410": 25, "427": 41, "428": 41, "429": [31, 33], "429217": 30, "429634": 41, "4296875": 38, "43": [25, 28, 29, 30, 31, 40, 41], "430": [29, 31, 33, 41], "430323": 26, "430571": 30, "430704": 35, "4307043": 35, "430868": 28, "431": [24, 41], "4310": [25, 26, 29], "431137": 28, "4314": 30, "432": 41, "433": 41, "433514": [40, 51], "433814": 41, "434": [25, 28, 29, 41], "43445": 34, "435": 41, "435186": 25, "435489": 30, "435792": 29, "436": 41, "436492": 31, "43697758253484614": 28, "437": 42, "4372": 35, "437367": [26, 27], "4375": [34, 37], "437500": 37, "437684": 40, "438": 37, "438231": 39, "438275": 27, "43827545": 27, "43833466": 31, "438592": 33, "438906": 33, "439": 26, "4390": [25, 29], "439209": 30, "439360": 26, "439779": 30, "44": [24, 25, 26, 28, 30, 31, 34, 38, 40, 41, 42, 51], "440": [29, 40], "441": 31, "441404": 39, "441445": 34, "442377e": 31, "442806": 25, "4430": 41, "44311": 34, "4432": 34, "443317": 25, "443419": [31, 33], "444297": 34, "444444": 26, "4448": 34, "445": 29, "445111e": 31, "445124e": 31, "44586935": 32, "44586935141902073": 32, "446216": 34, "446284e": 31, "446869": 34, "447": [26, 33], "447461": [40, 51], "447517": 33, "44787197": 38, "4482": 22, "4484": 25, "448757": 41, "449": 42, "449666": 25, "44966612": 25, "45": [8, 23, 24, 25, 28, 30, 31, 38, 40, 41, 45, 51, 52], "450000": 37, "450132": [40, 51], "450739": 31, "450822": 34, "451888": 30, "452600": 34, "453367": 34, "4537": 41, "454427": [26, 27], "454677": 35, "45467725": 35, "454788": 33, "454966": 30, "455": 27, "4552": 33, "45555535": 33, "45587": [40, 51], "45588": [40, 51], "45589": [40, 51], "45590": [40, 51], "45591": [40, 51], "456": 39, "456419": 34, "45653693": 27, "456537": 27, "456904786": 42, "457435": [40, 51], "45756": 42, "458": 26, "458333": 37, "458524": 41, "459": 31, "4591": 26, "459214e": 31, "459873": 41, "459937": 38, "45a": [40, 51], "45am": [40, 51], "46": [8, 23, 24, 25, 26, 27, 28, 30, 31, 40, 41, 42, 45, 47, 51], "460047": 41, "46019608e": 33, "46021": 42, "46075": 42, "4608": [23, 24, 45], "460950": 35, "461": [26, 29], "462060": 41, "462545": 33, "462963": 28, "46299": 42, "463": 30, "463582": 32, "464104e": 31, "465279e": 31, "46530779": 27, "465308": 27, "466246": 39, "4664": 22, "46729488": 31, "467379": 33, "467628": 34, "468": [25, 29, 33], "468232": [40, 51], "4687": 34, "46880": 42, "469": [26, 30], "469383": 30, "4695": 30, "469571": 34, "47": [10, 22, 23, 24, 25, 26, 28, 29, 31, 34], "470": [26, 42], "4700": 29, "470060": 31, "470666": 31, "471032": 33, "472": 42, "47242662": 43, "4726": 41, "472603": 31, "472790": 30, "473": 38, "473691": 25, "474": 30, "474552": 25, "47491": 30, "475099": 33, "475540": 38, "476": 23, "4760": 29, "47606": 34, "476092": [31, 33], "476406": 33, "476412": 35, "47641249": 35, "477": 29, "477291": 34, "47799": 42, "478060": [40, 51], "479109": 25, "479132": 34, "479773": 38, "48": [23, 24, 25, 28, 30, 31, 37, 40, 41, 45, 51], "480": 31, "4800": 22, "480249": 25, "4806334": 38, "48073598": 35, "4809": 29, "481": 26, "4813": [24, 28], "481514": 31, "481793": 26, "481893": 30, "481960": 30, "4822": 41, "483751": 25, "48390": 42, "48407": 42, "484937": 28, "485": 39, "48535": 42, "4854": 33, "485722": 38, "486": 33, "4861": [26, 27, 47], "486266": 26, "486664": 38, "487": 26, "48721": 42, "487740": 38, "4879": 42, "488": 26, "488163": 38, "488753": [40, 51], "489130": 28, "489593": 38, "49": [25, 28, 30, 31, 34, 40, 41, 50, 51], "490": [34, 43], "490000": 26, "490033": 31, "490568": 29, "490797": 38, "490930": 38, "491217": 30, "491366": 33, "491379": [26, 34], "491968": 38, "492": [26, 30], "492270": 27, "492307": 38, "492551": 38, "493": [23, 24, 26], "493489": 38, "493544": 26, "493921": 27, "494": [25, 26, 29], "4943": 29, "49575": 30, "496": 34, "496213": 31, "496757": 33, "497143": 38, "497386": 25, "497787": 31, "497949": 38, "498": 30, "498133e": 31, "498562": 25, "499900": 26, "4f": [25, 27, 30, 38], "4m": 39, "4th": [30, 32, 33, 49], "4x": 52, "5": [4, 10, 22, 28, 29, 31, 32, 36, 37, 40, 42, 43, 44, 45, 52], "50": [10, 22, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 48, 49, 51, 52], "500": [22, 26, 30, 32, 33, 34, 49], "5000": [22, 23], "50000": [40, 51], "500000": [26, 27, 30, 31, 36, 40, 42, 51], "500000e": 29, "500001": 26, "5002": 31, "500625": 25, "50062e": 25, "500924": [26, 27], "501": [26, 42], "501071": 39, "501191": 38, "501250": 25, "501304e": 31, "501875": 25, "5024752475247525": 29, "502500": 25, "502985": 30, "503000": 26, "503090": 30, "503125": 25, "503750": 25, "503807": 38, "504": [25, 34], "504231": 41, "504375": 25, "504429": 27, "504644": 29, "50475372e": 33, "504fde4fcf8": 41, "505180": 38, "505335": 30, "505592e": 31, "505625": 25, "5057": 31, "50596432e": 43, "506023": 32, "506035e": 31, "506079e": 31, "506084e": 31, "506211": [26, 29], "506410": 28, "506875": 25, "507130": 29, "507359": [26, 29], "507500": 25, "50774": 29, "507740": 26, "50775": 29, "507750": 29, "507752": [26, 29], "507995": 28, "508": [26, 31], "508125": 25, "508133": [26, 29], "508371": 29, "508534": 38, "508741": 38, "50884": 34, "50899": 29, "509000": 22, "509001": 31, "509317": [26, 29], "5098": 38, "509859": 38, "509930": [40, 51], "50k": [30, 32, 33, 49], "51": [25, 26, 27, 29, 30, 31, 33, 35, 40, 41, 47, 51], "510000": [23, 25, 29], "510421": 38, "510505": 38, "5106": 42, "510836": 29, "5109": 33, "511": 9, "5112": 23, "51137414e": 33, "51143": 34, "51150": 30, "511620e": 31, "5118": 33, "512": 39, "5120": 22, "512000": [25, 29], "51226051": 35, "5123": 38, "512319": 26, "512408": [31, 33], "512897": 25, "512x640": 39, "513": 26, "5131": 38, "513678": 41, "514150": 38, "514155": [26, 27, 31], "514347": 38, "514598e": 31, "5146": 28, "515000": 25, "51503393": 27, "515034": 27, "515351e": 31, "5156": [26, 34], "515848": 34, "516199": 38, "516394": 34, "516858": 38, "517273": 38, "517346": 30, "518113": 38, "519029": 30, "52": [25, 26, 28, 30, 31, 34, 40, 41, 42, 51], "520495": 38, "52061": 40, "520700": 38, "520782": 38, "5208": 23, "520857": 30, "5209": 31, "5212": 31, "521284e": 31, "521567e": 31, "521578e": 31, "521743e": 31, "521772": 38, "522": 31, "522563e": 31, "5227966": 38, "523595": 38, "523684": 38, "5238095238095238": 23, "52398": 34, "524": [23, 37], "524364": 41, "5253": 33, "525554": 34, "525757": 25, "526046": 38, "526078": [26, 27], "526214": 33, "526596": 34, "526602": 31, "5274": 41, "527500": 26, "528": 31, "5282": 41, "528403": 25, "52881619": 25, "529210": 30, "529388e": 31, "5294": 32, "529412": 26, "53": [28, 31, 40], "530052": 29, "530978": 30, "531116e": 31, "531353": 39, "5315": 29, "532034": 31, "533454": 39, "533498": 25, "534": 42, "534114": 29, "534342": 34, "535": [26, 34], "535014": 26, "53520104": 25, "535604": 26, "535622": 34, "536362": 35, "53636249": 35, "537267": 26, "537732": 38, "538000": 23, "538702": 25, "538816": 30, "5390": [30, 33], "5391": [26, 34], "539116": [40, 51], "539376": 41, "539459": 42, "54": [31, 40, 41, 50, 51], "540": 40, "540000": 26, "540039": 38, "540359": 34, "541117": 31, "541347": 38, "541488": 34, "54152": 30, "541667": 27, "541795": 30, "54240": 30, "542624": 33, "542873": [26, 27], "543297": 29, "543351": 33, "543464": 38, "544": 29, "544462": 33, "545": [31, 42], "546": 26, "5461": 31, "546473": 28, "546610": 25, "54676006e": 33, "547": [29, 31, 33], "547090": 38, "547993": 30, "548831": 33, "549": 42, "549682": 30, "5498": 25, "549946": 38, "55": [23, 24, 25, 28, 30, 31, 32, 33, 40, 41, 45], "55000": 29, "550000": [26, 27, 29], "550004": 32, "550616": 30, "55101": 40, "5513": 29, "5514": [32, 33], "5515": 41, "551579e": 31, "551862e": 31, "551975": 31, "552": [26, 31], "552721": 32, "553965": 33, "553979": 30, "5540": 41, "5541306485809793": 32, "55413065": 32, "554180": [40, 51], "554463": 38, "554621": 34, "5551": 28, "555740": 25, "5566": [26, 27, 47], "557197": 39, "557242": 30, "557739": 31, "558": [31, 33, 34], "558564": 30, "55862988e": 33, "55873324": 39, "5588": 22, "558824": 30, "558889": 31, "559": [29, 31, 33], "56": [25, 27, 30, 31, 40, 41, 50, 51], "560225": 26, "560768": 31, "561": [10, 25, 29, 33, 34], "561467": [26, 27], "561602": 33, "561645e": 31, "562112": 26, "5623062252998352": 38, "562712": 38, "563": 10, "5630224174651539": 28, "5630921721458435": 38, "563314": [31, 33], "563467": 26, "5644": 31, "564483": 34, "565": 34, "5650": 23, "565062": 41, "56521734": 8, "565679": 30, "565746": 41, "565888": 26, "566": 26, "566092": 26, "566222": 39, "5667": 30, "567724": 39, "567856e": 31, "568": 39, "568009": 25, "56804591": 31, "568663": 31, "5690201394302518": 33, "56902014": 33, "569375": 25, "5694": 34, "57": [25, 26, 27, 30, 31, 33, 40, 41, 47, 51], "57000": 41, "570015": 31, "570449": 30, "570473": 34, "5707": 41, "570739": 34, "571": [35, 43], "571431": 38, "571500": 34, "571901e": 31, "571969": 34, "572": 10, "572105": 25, "572549": 26, "572962": 41, "573": 43, "573050": 30, "573129": [31, 33], "5732": 30, "573542": 34, "573818": 30, "57415": [40, 51], "574260": 34, "575000": 37, "57510": 34, "5755444169044495": 38, "575907": 34, "576": 26, "57640869": 27, "576409": 27, "576921": 38, "578523": 28, "578654": 30, "5789": 31, "579091": 34, "579245": 38, "579432": 28, "579559e": 31, "579660": 32, "5798": 32, "57994": 30, "58": [23, 24, 25, 28, 31, 40, 41, 45], "580": 39, "5804311633110046": 38, "580539e": 31, "581": 33, "58137177": 27, "581372": 27, "5814": 22, "581687": 34, "581787": 41, "582": [22, 32], "582090": 30, "5824530720710754": 38, "582469": 31, "58387198": 35, "583872": 35, "584": 26, "584615": [26, 34], "585": 26, "585513": 28, "5857": 41, "586095": [26, 27], "587773": 30, "588": [25, 29], "588125": 25, "588235": 28, "588307": 26, "589286": 42, "59": [1, 25, 31, 40, 41], "590243": 38, "59049": 30, "59050": 30, "590618": 34, "59082668": 27, "590827": 27, "5915": 27, "592": 42, "592401": 22, "59243876": 32, "5925410985946655": 38, "59300": 34, "5931": 31, "593370": 31, "593508": 35, "5938": 26, "594": 26, "594595": 25, "594982": 30, "594995": 30, "5950": 26, "595427": 39, "595569e": 31, "596088e": 31, "596151": 34, "596810": 25, "596864": 31, "5970": 32, "59700": 30, "597015": 28, "59708": 30, "597326": 30, "597555": 22, "597924": [31, 33], "598": 26, "59810": 30, "598100": 28, "598149": [31, 33], "598750": 25, "599": 42, "5993570685386658": 38, "599492": 28, "599860": 25, "599894": [40, 51], "5fin": 31, "5th": [30, 32, 33, 49], "5unf": 31, "6": [8, 10, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 52], "60": [8, 22, 26, 30, 31, 33, 34, 35, 37, 38, 40, 41], "600": [26, 28, 38], "60000": [40, 51], "600000": [24, 25, 29, 40, 51], "600193": 30, "60023631": 31, "600k": 31, "601": 29, "601042": 22, "601504": 28, "601712": 30, "601790": 28, "602": [26, 27, 47], "602000": 26, "602649": 25, "6028": 30, "602941": 30, "602954": 32, "6031432151794434": 38, "60319915": 43, "603684e": 29, "603970": 41, "604": 25, "6040": [25, 29], "604000": 23, "604032": 30, "60429913": 31, "604320": 28, "60455": [40, 51], "604619": 28, "604797": 28, "6048": 40, "604807": 41, "60495488": 25, "605060": 30, "6051": [26, 27, 47], "605100": 28, "605101": 28, "605102": 28, "605263": 25, "605625": 25, "605696": 28, "606": 26, "606061": 28, "6063088774681091": 38, "606557": 28, "606567": 28, "606811": 29, "606875": 25, "606902": 28, "607062": [40, 51], "608050": 28, "608125": 25, "6082": 26, "608468": 28, "608532": 39, "608565": 41, "60860": 26, "6086405515670776": 38, "609": 26, "6092": 22, "6093292236328125": 38, "609375": 25, "60943": 30, "60k": 31, "61": [25, 27, 28, 30, 31, 35, 40, 41], "61029914": 31, "610407": 30, "610931": 36, "611": 27, "611007": 39, "6111123561859131": 38, "611178": [40, 51], "612349": 27, "61234944": 27, "6124": 41, "612546": 30, "612621": 28, "612755": 25, "613507": 28, "613738": 29, "613738418384": 29, "614": 26, "61420598": 27, "614206": 27, "614567": 34, "615": 26, "6154": 34, "615730": 32, "616": 29, "616099": 29, "6168": 23, "617342": 41, "617431": 36, "6176": 30, "617647": 30, "618": 26, "618012": 29, "6186580061912537": 38, "618967": 38, "619": 42, "61912405": 33, "62": [25, 29, 30, 31, 40, 41, 51], "622255": 26, "622454": 29, "622500": 25, "6226": 34, "622612": 30, "622709": 28, "623000": 26, "62320": 40, "62352928": 32, "624049": 31, "6241": 22, "624375": 25, "624450e": 31, "624615": 31, "6250": 26, "625387": 29, "6257": 41, "626206": 31, "62657": 40, "626875": 25, "62688064": 33, "627": 41, "6273": 29, "6275": [23, 24, 45], "627722": 33, "627966": 26, "628032": 34, "628139": 30, "62873917": 33, "629792e": 31, "63": [25, 29, 30, 31, 40, 41, 42, 51], "6303": [26, 27, 47], "6306": [26, 34], "631899": 41, "632": 42, "6320": 28, "6320979595184326": 38, "6322": 34, "632353": 30, "632786": [40, 51], "63316788": 43, "63362": 31, "633933424949646": 38, "634397": 28, "634490": 27, "634686": 30, "635": 26, "635200": 34, "635239": [26, 27], "635648": 28, "636": [22, 26, 27, 41, 47], "636364": 42, "636410": 32, "636849e": 31, "637": 39, "637982": 25, "638169": 33, "6389": [26, 34], "6391518364256": 41, "6392": 34, "639754": 31, "64": [11, 25, 28, 31, 39, 40, 41], "640": [29, 39, 42], "6400": 26, "640000": [30, 42], "640266": [26, 27], "640x480": 25, "641216": 40, "641538": 41, "641873": 31, "642676": 40, "642965": 30, "643": 29, "6431": 34, "643311e": 31, "644106": 30, "64417243": 39, "64454": 30, "644770": 36, "645519": 30, "6458": [23, 24, 45], "645963": 29, "646050": 33, "6464": 41, "647796": 34, "648": [25, 26, 29], "6480": 32, "648195": 30, "648550": 39, "649658": 33, "64994": [40, 51], "65": [23, 27, 31, 41], "650": 30, "65000": 29, "650000": 29, "65000e": 25, "65013704": 35, "65125032": 43, "6513": 33, "651446": 40, "65243": 31, "652487": 34, "6526853": 31, "652828": 29, "652986": 34, "653": 26, "653205": 29, "653205232272": 29, "654": 26, "65424895": 31, "65486": 38, "656297e": 31, "656349": 25, "656827": 30, "657675": 34, "658047": 28, "658645": 28, "659056": 31, "66": [23, 24, 26, 28, 30, 31, 39, 40, 45, 51], "6601256728172302": 38, "660171": 25, "6604": [26, 27, 47], "660714": 27, "661023": 38, "66214339": 25, "66221": 40, "6622507572174072": 38, "662450": 30, "662541e": 31, "662745": 26, "662879": 32, "66368": 33, "663680": [31, 33], "6637": 41, "6638": 41, "663822": 33, "6639": 41, "6639009118080139": 38, "6641": 41, "6642": 41, "664207": 30, "6643": 41, "6644": 41, "6645": 41, "664625": 38, "664707": 28, "66473": [40, 51], "665": 26, "665307": 38, "665351e": 31, "665625": 25, "665882": 32, "666": [26, 27], "666166": [40, 51], "6666666666666666": 39, "666667": [24, 26, 37], "666754": 39, "667450": 40, "668": 38, "668787": 25, "6688": 22, "669614": 30, "669725": 30, "669805e": 31, "67": [23, 24, 27, 28, 30, 31, 40, 41], "670344": 25, "6709133982658386": 38, "67186503136": 31, "6731126308441162": 38, "673277": 29, "6733849048614502": 38, "6734487414360046": 38, "6744": 33, "674490": 29, "674721": 32, "675000": 22, "67501": 40, "67512181": 31, "67562658": 27, "675627": 27, "675676": 37, "675814": 25, "676250": 25, "676373": 30, "67672595": 31, "677": 26, "6771429181098938": 38, "6772": 41, "677268": 41, "677579": 25, "677601": 29, "677629": 25, "6778583526611328": 38, "678": [25, 29], "678689": 28, "679478": 26, "679877": [31, 33], "68": [23, 24, 25, 27, 30, 31, 33, 35, 36, 40, 41, 43, 51], "680000": 22, "6800296306610107": 38, "680657": 26, "681223": 25, "681716": 38, "683015": 32, "683171": 30, "68323": 29, "68339": [40, 51], "684211": 25, "684447": 26, "684960": [26, 27], "685103e": 31, "68523": 40, "685786": 32, "6858": 28, "686": 26, "686348e": 31, "687": 31, "687055": 30, "687307": 29, "687500": 24, "687504": 38, "688": 29, "6880359361853475": 28, "688043475151062": 38, "688135": 29, "689338": [31, 33], "69": [23, 24, 25, 27, 31, 35, 40, 41, 51], "690": 42, "69027185e": 33, "690402": 29, "690778": 33, "691241": 30, "691617": 38, "691640": 25, "691877": 29, "691924": 35, "69192445": 35, "692308": 26, "693": 26, "693498": 29, "693590": 27, "6938": [22, 40], "693890": 40, "693898": 40, "693936": 27, "69393613": 27, "69411": 34, "694155": 25, "694334": 32, "6950": 33, "695532": 26, "695783": 38, "696034e": 31, "6962": 26, "6963": 33, "696373": 26, "696429": 30, "696712": 40, "696859": 29, "696875": 25, "696970": 28, "69698010e": 33, "697": [26, 34], "697248": 30, "6973": 26, "698": 26, "698167": [40, 51], "698206": 31, "698384608345687": 29, "698385": 29, "6984": 34, "698857": 29, "699224": 25, "699706": 39, "699901396097971": 36, "6th": [30, 32, 33, 49], "6x6": 48, "7": [10, 11, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 52], "70": [23, 24, 27, 30, 31, 35, 36, 40, 41, 51], "70000": [40, 51], "700000": [40, 51], "700855": 30, "701128": [40, 51], "701173": 29, "701186e": 31, "70162085e": 33, "7017": 41, "701863": 29, "702703": 25, "703406": 41, "704": [25, 26, 31], "704099": 27, "7041": 38, "7042": 41, "7043": 41, "7046136400143138": 28, "70472": 34, "704969": 29, "705000": 26, "705470": 38, "705511": 29, "70560276": 27, "705603": 27, "70568": 31, "705696": 25, "705882": [24, 29], "70588235": 24, "705898": 34, "706": 27, "706128": 25, "706444": 30, "706783": 27, "70678332": 27, "706966": 40, "707681": 25, "707712": 41, "707899": 35, "70789903": 35, "70799": 29, "708": [26, 27, 29, 32, 47], "708075": 29, "708527": 26, "708978": 29, "709185": 25, "70978": 34, "709874": 29, "709880": 29, "709893": 40, "7099": 34, "71": [22, 23, 24, 27, 28, 30, 31, 35, 40, 41, 51], "710000": 26, "710031": 33, "710526": 25, "710896": 30, "71096": 34, "711": [27, 29], "711077": 26, "711086": 29, "711717": 29, "711754": [26, 27], "711819": 38, "711852": 34, "71199006": 31, "712": 26, "712074": 29, "71219761": 27, "712198": 27, "712324": 29, "712402": 32, "7129": 29, "713": 27, "71327467": 31, "714": 39, "714077": [26, 27], "714286": 29, "714402": 30, "715072": 39, "71517": 29, "7153": 41, "715424": 29, "715728": 30, "715992": 39, "716157": 30, "716655": 29, "716657": 29, "716792": 30, "716985": 25, "717289": 29, "717391": 29, "717829": 26, "718242": 29, "718266": 29, "718524": 40, "71866979": 31, "718750": 25, "7188": 27, "719": [22, 26, 34], "719056": 32, "719427e": 31, "719500": 25, "719747": 30, "72": [23, 24, 25, 30, 31, 40, 41, 45, 48], "720357": [40, 51], "72036": 40, "720497": 29, "720859": 26, "720893": 41, "720904": 40, "7210": 23, "721006": 29, "721008": 29, "7212512828409691": 28, "721616": 29, "721705": 26, "7218": [23, 24, 45], "721818": 34, "721921": 26, "722": 26, "722241": 29, "722249": 29, "723": 26, "72345029": 31, "723602": 29, "723613": 25, "7242": 23, "724458": 29, "724539": [40, 51], "724891": 30, "725": [28, 29], "7250894": 43, "726": [26, 30, 34], "726412": [26, 27], "726474": 39, "726573": 29, "726583": 29, "726634": 30, "7266666666666667": 43, "726788": 31, "727014": 40, "727198": 29, "727273": 25, "727554": 29, "7277854625841886": 41, "727821": 29, "7278214718381631": 29, "727829": 29, "728": [26, 30], "728235": [26, 27], "7283": 30, "728324": 30, "728777": 25, "729": 29, "729109": 42, "729143": 30, "7292": 34, "729814": 29, "73": [23, 24, 27, 28, 29, 30, 31, 36, 40, 41], "730383": 30, "731498": 41, "7315": 28, "7315558717766282": 29, "731572": 28, "731583": 25, "73183": 38, "7328": 26, "732919": 29, "733102": [26, 27], "733333": [24, 26, 27], "733746": 29, "734": [29, 31, 41], "734011": 29, "734385": 30, "734816": 40, "735": 31, "735043": 30, "735261": 29, "7352614272253524": 29, "7356575131416321": 38, "735879": 29, "736285": 30, "7363681793212891": 38, "736498": 29, "736900": 26, "7379": 23, "738": [26, 31], "738564": 40, "738701": [26, 27], "738715": 41, "738839": 28, "738977": 29, "739": 42, "739264": [26, 34], "7395977155164125": 29, "739598": 29, "739938": 29, "74": [23, 24, 26, 27, 28, 29, 30, 31, 36, 47], "740542": 22, "740844": 29, "741": 41, "741037": [40, 51], "741250": 25, "741463": 29, "7418": 33, "741935": 42, "742084": 29, "742088": 29, "742703": 29, "742981": 30, "743": [25, 26, 29, 41, 42], "743133": 25, "743135": 30, "743321": 29, "743323": 29, "743324": 29, "743391": 25, "743555": 33, "7436": [23, 24, 45], "743917": [26, 27], "7440": 22, "744201": 30, "744565": 29, "745": 32, "745178": 29, "746114": 32, "746328": 25, "747": 22, "74720920774": 31, "74798624e": 33, "748510": 30, "748725": 41, "748749e": 29, "748797": 28, "749118": 33, "75": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 40, 41, 47, 51], "750": 22, "7500": 31, "750000": 31, "7503": 23, "7504": 42, "750401": 38, "751": 42, "7524": 40, "753286": [26, 27], "754": 26, "754165": 42, "754386": 30, "754874": 34, "755": 41, "755000": 31, "7551": 29, "755364": 25, "755418": 29, "755477": 25, "756": 41, "7562": 22, "75625": [40, 51], "757": 30, "7574257425742574": 29, "75745416": 35, "757545": 31, "757591": 40, "757932": 41, "757985": [32, 33], "758": [32, 33, 41], "758062e": 31, "75826": [32, 33], "758514": 29, "7588186": 39, "7588527798652649": 38, "759561": 35, "75956122": 35, "7599": 28, "76": [24, 26, 28, 29, 30, 31, 33, 34, 41], "760": 41, "760262": 29, "760678": 40, "76161": 29, "761945e": 31, "762": [24, 41], "7620": 22, "762093e": 31, "76270194": 33, "763": 26, "7639": 23, "764052": 34, "76470588": 24, "764706": [24, 25, 29], "765": 30, "765591": 30, "765601": 31, "766317e": 31, "766423": 31, "766430": 25, "767": [31, 33], "767742": 28, "767802": 29, "767819": 40, "767852": 25, "768": [26, 27, 31, 33, 47], "768176": 41, "768512": 30, "76908228": 32, "769231": 26, "77": [23, 24, 27, 28, 30, 31, 36, 40, 41, 44, 50], "770": 23, "7706532429048965": 32, "770833": 37, "770898": 29, "771": 26, "771969": 25, "772532": 30, "773017": [31, 33], "7736": 29, "773851": 40, "774261": 40, "774844": 27, "77484447": 27, "7750553478074826": 40, "775270": 31, "7752884548630529": 28, "775311": 33, "77536150e": 33, "7758": 29, "776": 29, "7763": [26, 34], "776427": 41, "77694295": 32, "77709": 29, "777934": 25, "778": 42, "7781845435415525": 40, "779": [26, 34], "779271": 34, "78": [22, 23, 24, 26, 27, 30, 31, 34, 35, 40, 41, 44], "7800": 29, "780000": 32, "780296": 31, "780298": 31, "780316": 31, "780497": 31, "78058051e": 33, "780864": 30, "781": 26, "781004": 25, "781531": 30, "7816": 31, "782183": 31, "782219": 25, "7827": 30, "783282": 29, "783582": 25, "783784": 37, "783789": 25, "784424": 28, "784573": 34, "785": 27, "785105": 31, "785108": 31, "785134": 31, "78521263": 38, "785399": 31, "785483": [40, 51], "785714": 26, "786115": 34, "78617028": 32, "786555": 31, "787": 26, "787574": 31, "787879": [25, 28], "787933": 31, "788": 24, "788374": 39, "788647472858429": 38, "7887": 33, "7891381897690047": 28, "789436": 26, "789657": [40, 51], "79": [23, 24, 26, 27, 28, 30, 31, 40, 41, 45], "790": 30, "790000": 26, "79041": 31, "790731": 28, "791017": 41, "791467": 26, "792": 43, "792023": 33, "79250": 26, "792577": 31, "792603": 25, "792828": 31, "793": 34, "793243": 26, "79378": 30, "7938": 27, "794": 41, "794118": 25, "794236": 26, "794820": 26, "795": [25, 29], "79500e": 25, "7951": 29, "7951559890417761": 31, "795902": [40, 51], "796": 26, "7964215270662811": 28, "797": 26, "797355": [26, 27], "7978563117812038": 26, "798": 26, "7982": 25, "7986546": 31, "799983": 25, "79998417": 43, "7f688092391a": 39, "7pm": 34, "7th": [30, 32, 33, 49], "8": [9, 10, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 51], "80": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 40, 41, 44, 51], "800": [22, 24, 29, 38, 48], "800000": [29, 40, 51], "8001": 28, "800190": 25, "80062924": 25, "801219e": 31, "801666": 30, "801863": 25, "802502": 34, "802902": 31, "802987": 25, "803": [25, 26, 42], "803617": 30, "804": [25, 41, 42], "804818": [26, 27], "80482065": 27, "804821": 27, "805198": 31, "805342": 40, "805970": [25, 28], "806": 27, "8062": 23, "806899": 39, "8076": 31, "807684": 25, "807735": 30, "8078": 22, "808": 41, "8080": 23, "808208": 30, "808958": 25, "809": 26, "8098": 41, "81": [23, 24, 25, 27, 28, 29, 30, 31, 33, 35, 40, 41, 51], "810073": [31, 33], "810098": 34, "810368": 25, "81071706": 29, "810811": 37, "8112": 22, "812272": 31, "812363": 31, "812500": 24, "812593": 39, "812875": 41, "813": 26, "813586": 30, "815669": 30, "816717791411044": 41, "817": 32, "817034": 42, "817558": [26, 27], "8180": 26, "818041": 41, "818868": 26, "819152": 25, "819213": 41, "8195": 28, "819549": 25, "819584": 25, "81970188": 27, "819702": 27, "82": [23, 27, 29, 30, 36, 40, 41, 51], "820": 25, "820033": 31, "820143": 28, "82025568e": 33, "820564": 31, "821040": 33, "821327": 38, "821807": 31, "8219": 26, "8221": 27, "8225": 42, "82273995": 27, "822740": 27, "823511": 30, "823529": [24, 25, 28], "82352941": 24, "823543": 34, "824849": 30, "824884": 31, "825": 26, "825123": 34, "8253": 25, "825306": 29, "825470": 41, "825697": 31, "826142": 31, "826203": 28, "826216": 31, "826513": [40, 51], "826553": 31, "82670": [40, 51], "826739": 31, "826758": 31, "826760": 31, "827039": 28, "827068": 28, "827130": 30, "827261": 31, "827842": 28, "827907": 29, "8280229354283182": 31, "82804": 29, "828332": [31, 33], "828358": 25, "828405": 40, "828682": 29, "82869879": 38, "828891": 29, "828976": 29, "83": [23, 24, 27, 29, 30, 36, 37, 38, 40, 41, 44, 51], "830382": 30, "830712e": 31, "831135": 25, "831611": [31, 33], "831989": 29, "832": 26, "832320": 28, "832370": 30, "832866": 31, "833": [25, 29], "83320": 40, "8334": 33, "8340": 25, "834109": 29, "834356e": 31, "83437": 31, "834455": 25, "8356": 33, "835651": 29, "835749": [31, 33], "83603": [31, 33], "8361313": 31, "836189": 25, "836735": 30, "836878e": 31, "836880e": 31, "837022e": 31, "837838": 25, "837848": 25, "838": [25, 29], "83848729e": 39, "83876": 29, "8388866943476283": 28, "838951": 31, "8389756947416362": 28, "839225": 31, "84": [23, 24, 27, 40, 41, 42, 43, 44], "840": 26, "84002795": 27, "840028": 27, "840074": 24, "840183": 31, "840492": [31, 33], "84062193": 33, "841": 31, "841208": 29, "841886": 29, "841983": 29, "842": 26, "842028": 30, "842064": 41, "842105": 25, "843": 32, "843281": 33, "843284": [25, 28], "843842": [26, 27], "843992": [31, 33], "844409": 27, "84440919": 27, "844921": 35, "845": 29, "846154": [26, 42], "8462": 34, "846260e": 31, "846650": 31, "84679073": 25, "84698489": 39, "847178": 30, "847287": 29, "8475": 40, "84772": 30, "847799": 29, "847808": 30, "8478316682480326": 40, "848": [32, 33], "8481": 42, "84893192": 29, "849": [32, 33], "849102e": 31, "849438e": 31, "849612": 29, "85": [23, 24, 27, 30, 31, 32, 33, 34, 40, 41, 44, 51], "850": [22, 32, 33], "8502": 29, "850283": [40, 51], "850503": 29, "850746": 25, "851460": 31, "851852": 28, "852": [41, 42], "852053": 29, "852104": 31, "852941": 28, "853125": 25, "853399": 30, "854129": 31, "854167": 37, "854500": 41, "8546143543902771": 41, "854744525547446": 41, "854749": 40, "85545875": 25, "85597188": 27, "855972": 27, "856": 29, "856175": 26, "856589": 29, "857": 31, "857874": 29, "858": 28, "8580": [26, 27, 47], "858209": [25, 28], "858915": 29, "859": 32, "859318": 31, "859439": 35, "85943906": 35, "859455": 41, "85969": 29, "859799": 29, "86": [23, 25, 27, 28, 29, 30, 34, 40, 41], "860": [30, 33], "86000e": 25, "8601643854446082": 31, "860677": 30, "861": 26, "86102": [40, 51], "861348": 29, "862432": 31, "862552": 26, "8625888648969532": 41, "86267067": 27, "862671": 27, "862997": 34, "863014": 28, "863889": 40, "863941": 31, "864": 32, "86400": [40, 51], "8641864337292489": 41, "864205": 33, "865562": 41, "8661": 42, "866110": 28, "866667": [24, 30], "866980": 31, "867434": 39, "867558": 34, "868003": 31, "868281": 31, "868305": 31, "868308": 31, "869077": 27, "86907725": 27, "869094": 29, "8691": 27, "869531": 25, "869964": 29, "87": [23, 26, 27, 30, 40, 41], "870": [32, 33], "870503": 39, "871": [29, 32], "871094": 40, "8711": 30, "872": [32, 33], "872093": 29, "872603": 39, "872722908439952": 33, "8727229084399575": 33, "872961060": 31, "8729610607986": 31, "873": 32, "8731": [31, 33], "873103": 25, "873182": 40, "873356": 25, "873643": 29, "873704": 31, "874062": 27, "87406235": 27, "874305": 40, "874516": 29, "874532": 31, "874767e": 31, "875": 30, "8750": [26, 34], "875000": 24, "876065": 29, "876540": 41, "876574": [26, 27], "87681182": 38, "877046": 34, "877390": 33, "877519": 29, "877551": 30, "878183": 25, "87844893": 31, "87849316": 28, "879": 26, "87907": 29, "879938": 29, "88": [23, 24, 26, 27, 28, 30, 34, 41, 42, 47], "880": 34, "8801": 38, "880348": 29, "880831": [40, 51], "881395": 29, "881720": 30, "883138": 29, "884586": 29, "885": [22, 27], "885044": [31, 33], "885968": 41, "886047": 29, "886759": 28, "887": 32, "887017": 30, "887159": [40, 51], "8873": 30, "887324": 30, "887343": 25, "887597": 29, "887701": 30, "8878117": 27, "887812": 27, "888": [29, 32, 33], "888066": 33, "888372": 29, "888513": 30, "888811": 29, "888889": [26, 28], "888961": 33, "889086": 31, "889147": 29, "889429": 40, "889921": 40, "89": [23, 24, 27, 30, 36, 40, 41, 44, 51], "890": 32, "890457": 31, "890933": 41, "891001": 30, "891557": 29, "892476": 30, "892477": 25, "892491": 26, "89270": 34, "892733": 40, "892961": 34, "893000": 26, "893260": 27, "8937442459553657": 33, "894": 26, "895": 32, "895349": 29, "895541": 31, "89572": [40, 51], "895833": 30, "895963": 28, "897010": [26, 27], "89706451e": 33, "897674": 29, "898": 33, "898016": 29, "898703e": 31, "899": [26, 27, 29, 32, 47], "8994": 33, "8997": 31, "899969": [40, 51], "8m": 39, "8th": [30, 32, 33, 49], "9": [4, 10, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 51, 52], "90": [8, 22, 23, 24, 25, 27, 30, 31, 36, 37, 40, 41, 44], "900": [27, 29, 30], "90000": [40, 51], "900000": [24, 40, 51], "900662": 24, "901085": 28, "9010852321946792": 28, "901262": 40, "90159483": 35, "901595": 35, "902401": 29, "903101": 29, "904": [25, 29], "90403853": 27, "904039": 27, "904226": 25, "9047619047619048": 23, "904902": 39, "905": [25, 26], "905327": 40, "906667": 24, "90669": 34, "906865": 24, "907": 41, "907143": 42, "907595": 40, "908": 26, "908140": [26, 27], "908215": 31, "909091": 26, "90982": 34, "91": [23, 24, 26, 27, 29, 30, 34, 35, 40, 44, 51], "910": 23, "9100": 40, "910018": 31, "910174": 31, "9103": 40, "910456e": 31, "91063776": 33, "910714": 42, "910843": 31, "911615": 31, "911846": 31, "912": 26, "912395": 33, "913333": 24, "913767": 31, "913849": 31, "914003": 33, "914451894267": 31, "914585": 33, "91515735": 31, "915714e": 31, "915952": 31, "916254": 25, "916722": 33, "917526": 30, "917837": 30, "918": 32, "918124": 30, "918191": 39, "9182": 40, "919198": 33, "9196": 22, "92": [23, 24, 27, 30, 36, 39, 40, 41, 44], "920000": 24, "9203": 29, "920305": 34, "920462": 33, "92120500e": 43, "921422": 41, "921438": 31, "921850": 31, "92195464": 33, "921955": 33, "922": 27, "923077": 30, "923283": [26, 27], "923432": 33, "924485": 34, "9245": [24, 28], "925272e": 31, "925288e": 31, "925593": 25, "925768": 30, "926657": 31, "926733e": 31, "926829": 30, "928": 29, "92809": 34, "92852376": 25, "929": 29, "9295": 29, "93": [23, 24, 27, 28, 29, 35, 40, 41, 44], "930000": 26, "930123": 25, "930561": 25, "931439e": 31, "931786": 28, "932": 26, "932070": 41, "932124": 25, "932143": 42, "93279": 40, "9336": 26, "934205": 25, "934269": [26, 27], "934783": 30, "9351": 34, "935512": 41, "935802": 25, "93665": [40, 51], "9375": 24, "937500": [24, 27], "938": 30, "9383": [25, 28], "93869659": 27, "938697": 27, "939006": 30, "9391": 31, "939394": [25, 28], "94": [23, 24, 26, 27, 28, 29, 30, 31, 40, 44, 47], "9401": 40, "9406": [23, 24, 45], "941": 41, "941176": [24, 27], "94117647": 24, "943609": 34, "944": 22, "944092": 30, "944354": 27, "946783": 25, "947": [26, 29, 42], "9471": 29, "948482": 41, "94888": 30, "949": 26, "9490": 26, "9492": 31, "94933723": 31, "94959681": 27, "949597": 27, "95": [23, 24, 27, 30, 36, 40, 41], "950000": 26, "950088": 34, "9505": 33, "950564": 34, "9506": 33, "950696": 41, "950733": 25, "951294": 31, "951574": 34, "951644": 34, "951669": 34, "951696": 25, "953": 32, "95511263": 25, "955113": 25, "9558": 40, "956": 26, "956966": 34, "957075": 34, "9573": 40, "9576": 22, "957886": 39, "957919": 25, "957987": 25, "9583333333333334": 39, "958393": [26, 34], "95886206e": 39, "959": 26, "959139": 33, "959402e": 31, "959870": 30, "959873": 41, "96": [23, 27, 28, 29, 30, 34, 40], "960": 28, "961106": 30, "961109802000133": 36, "961404": [26, 27], "961498": [31, 33], "961771": 28, "961898": 28, "962776": 30, "96319": 40, "96320": 40, "96321": 40, "96322": 40, "96323": 40, "96325": 40, "963689": 34, "96554": 34, "9661": 31, "966131": [26, 27], "9664": [23, 24, 45], "966491": 30, "967102": 30, "967907": 30, "968": 26, "968233": 34, "96833": 38, "96834506": 25, "968493": 41, "968514e": 31, "96875": 39, "969048e": 31, "9691": 31, "9692602666681306": 28, "96965253": 33, "969653": 33, "97": [23, 24, 27, 28, 29, 33, 36, 40, 41], "970518": 30, "970683": 34, "971": 27, "97203586": 27, "972036": 27, "97217": 40, "972198": 29, "97223953": 27, "972240": 27, "972440": 30, "97253": 40, "9730": 27, "973225": 30, "973280": 27, "97328024": 27, "973482e": 29, "973750": 25, "974": 26, "974480": 34, "9748": 28, "974801e": 31, "975895": 40, "976": [26, 30, 32], "977": [26, 40, 51], "977278": 34, "9773": [23, 24, 25, 45], "978": 28, "9781449369880": 40, "9781789957211": 39, "97823755": 28, "9785299": 38, "978738": 34, "979": [32, 33], "979562": 41, "98": [23, 26, 27, 28, 31, 33, 35, 38, 40, 41], "980": [40, 51], "98007": 22, "98028": 23, "98045": 22, "98052": 22, "98055": 22, "980634": 41, "98072": 22, "98074": 23, "98075": 22, "9808": 28, "98107": 22, "98112": 22, "98116": 22, "981195": 40, "98125": 23, "98136": 23, "981735": 28, "98178": 23, "982": 27, "982184": 29, "982570": 41, "983": 39, "9837": [24, 28], "984": 29, "984653": 28, "984664": 31, "985283": 29, "9854": [23, 24, 28, 45], "985457": 41, "985816": 24, "986047": 29, "9862": 42, "986207": 29, "987": [29, 39], "987062": 31, "987597": 29, "9876": [32, 33], "987681": 34, "988": 34, "9881": [23, 24, 45], "988381": 29, "988841": 29, "988901": 31, "989": 23, "989147": 29, "989156": 29, "989443": 41, "989922": 29, "989973": 28, "99": [23, 24, 26, 27, 29, 30, 40, 49, 51], "990631": [40, 51], "990754": 40, "9912": [25, 28], "9915": [40, 51], "991966": 41, "992": [24, 29], "992254": 29, "99240562": 33, "992406": 29, "9926": 27, "992857": 24, "992908": 24, "993023": 29, "993029": 29, "993065": 41, "9931": [23, 24, 45], "9934531067299874": 28, "993666": 33, "993969": [31, 33], "994": 22, "994266": 29, "994574": 29, "994764": 40, "995": [34, 39], "9950": 34, "9951": [23, 24, 45], "99515": 40, "995434": 31, "996588e": 31, "996765": 33, "996788": 41, "996820": 41, "996899": 29, "99744241e": 33, "9977957422135844": 33, "998": [30, 41, 42], "9983": 30, "998302": 30, "99845": 29, "998451": 29, "999": [28, 42], "99907": 29, "999122": 30, "999147": 30, "999172": 30, "999183": 30, "999185": 30, "999192": 30, "999210": 30, "999214": 30, "999221": 30, "999223": 30, "999225": 29, "999254": 30, "999298": 30, "999317": 30, "99931882": 31, "999335": 30, "999535": 29, "999577": 40, "999622": 26, "9am": 34, "9th": [30, 32, 33, 49], "A": [0, 8, 9, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 51, 52], "AND": [0, 31], "AS": 0, "And": [22, 23, 29, 31, 38, 40, 41, 45, 46], "As": [4, 24, 27, 29, 31, 32, 33, 37, 40, 41, 43, 46, 48, 50, 52], "At": [4, 22, 24, 28, 30, 32, 34, 35, 39, 40], "BE": [0, 38], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 25, 33, 44, 46], "Being": 39, "But": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 46, 48, 50, 51, 52], "By": [22, 24, 25, 27, 30, 32, 35, 38, 39, 41, 46, 48, 52], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 48, 49, 50, 51, 52], "IN": [0, 24, 28], "IT": 28, "If": [4, 5, 6, 7, 8, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52], "In": [6, 7, 8, 9, 10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52], "Ines": 42, "It": [2, 4, 7, 8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 46, 48, 50, 52], "Its": 41, "NEAR": [26, 27, 34, 47], "NO": 0, "NOT": [0, 8, 27, 28], "No": [0, 22, 23, 31, 32, 33, 34, 36, 40, 41, 44, 51], "Not": [30, 31, 32, 33, 34, 35, 37, 40, 41, 49], "OF": 0, "OR": [0, 8, 31], "Of": [9, 27, 29], "On": [4, 7, 22, 26, 27, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42], "One": [5, 8, 16, 23, 24, 27, 28, 29, 30, 33, 35, 36, 41, 44, 49, 51], "Or": [25, 27, 29, 46], "Such": [6, 37, 40], "THE": [0, 24], "TO": [0, 38], "That": [23, 24, 26, 28, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 49], "The": [0, 1, 2, 5, 7, 8, 10, 22, 23, 25, 26, 27, 30, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52], "Their": 5, "Then": [23, 28, 32, 35, 40, 49], "There": [2, 5, 8, 9, 10, 11, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 52], "These": [4, 11, 23, 24, 25, 28, 30, 31, 32, 33, 34, 35, 37, 40, 50, 52], "To": [8, 11, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 36, 38, 39, 40, 42, 46, 48, 50, 51, 52], "WITH": 0, "Will": [30, 41, 42, 44, 49], "With": [0, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 41, 43, 46, 52], "_": [32, 38, 39, 41, 42], "__call__": 27, "__class__": [28, 40], "__finalize__": 41, "__getitem__": [24, 26], "__init__": 42, "__name__": [28, 40], "__testing_word2vec": 38, "_arg": 42, "_array_api": 42, "_astype_nansaf": 41, "_c": 42, "_california_housing_dataset": 28, "_call_func_on_transform": 27, "_callback": 42, "_column_transform": 27, "_constructor_from_mgr": 41, "_context": 42, "_data": 29, "_distn_infrastructur": 29, "_encod": 27, "_get_default_devic": 42, "_get_sequential_output": 27, "_i": 39, "_logist": 43, "_mgr": 41, "_proba": 32, "_pseudo_sync_runn": 42, "_run": 42, "_run_cel": 42, "_run_cod": 42, "_run_module_as_main": 42, "_run_onc": 42, "_score": 27, "_scorer": 27, "_set_output": 27, "_temp": 42, "_time_fit_was_cal": 41, "_transform": 27, "_transform_on": 27, "_valid": 27, "ab": [28, 30, 31, 33], "abbrevi": 38, "abil": [22, 27, 29, 33, 38, 40, 46], "abl": [8, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 46, 48, 52], "about": [2, 4, 7, 10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52], "abov": [0, 5, 8, 11, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 46, 48, 51, 52], "absenc": [27, 33, 37], "absolut": [28, 30, 31, 33, 35, 42, 52], "abspath": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51], "academ": [7, 34], "accept": [5, 8, 30, 31, 38], "accept_spars": 27, "access": [10, 11, 24, 26, 29, 32, 35, 37, 38, 40, 48], "accessori": 40, "accident": [25, 26], "accommod": 7, "accompani": [7, 22, 23], "accord": [28, 30, 31, 34, 37, 41, 48, 49, 50, 52], "account": [7, 10, 24, 30, 34, 37, 41, 44, 49], "accur": [22, 24, 32, 33, 34, 37, 41, 44, 45], "accuraci": [23, 24, 25, 26, 29, 30, 32, 33, 34, 36, 39, 41, 42, 44, 45, 49, 50, 52], "accuracy_scor": 30, "acdm": [30, 32, 33, 49], "acf": 40, "achiev": [8, 25, 30, 48, 50, 51], "acinonyx": [22, 39], "acoust": [25, 26, 29, 48], "acquir": 52, "acquisit": 37, "across": [22, 23, 24, 26, 30, 33, 39, 52], "act": [28, 52], "action": [0, 22, 32, 33, 35, 37, 38, 41, 52], "activ": [4, 11, 22, 29, 42, 44, 52], "actor": [37, 38], "actual": [7, 22, 28, 30, 32, 33, 35, 37, 38, 40, 41, 48, 50], "ad": [27, 28, 29, 30, 32, 33, 34, 36, 38, 39, 41, 42, 48, 51], "adapt": [0, 26, 27, 30, 32, 38, 40, 42], "add": [7, 8, 11, 26, 27, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 47, 49, 50, 51], "add_pip": 42, "addit": [0, 4, 31, 37, 49, 52], "addition": [45, 46, 52], "address": [18, 36, 49], "adelaid": [40, 51], "adj": [38, 42], "adject": 38, "adjust": [25, 29, 36, 40, 46], "adm": [30, 32, 33], "admin": 52, "administr": 1, "admit": 24, "adopt": [6, 37], "adp": [38, 42], "adult": [30, 32, 33, 49], "adult_df_larg": [32, 33], "adv": 38, "advanc": [27, 29, 35, 36, 37, 38, 39, 45, 52], "advantag": [26, 27, 28, 32, 36, 37, 38, 44, 52], "advic": 41, "advis": 22, "advisor": 52, "af": 33, "affect": [11, 25, 26, 28, 29, 30, 35, 40, 41, 42, 46], "affix": 38, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 44, 50, 51, 52], "ag": [22, 28, 30, 31, 32, 33, 34, 37, 49, 50], "again": [11, 23, 24, 26, 36, 37, 38, 39, 41, 46, 49, 50, 51], "against": [37, 38, 40, 48], "agenc": [38, 42], "agent": 10, "agglomerativeclust": 36, "aggress": 38, "agnost": 33, "ago": [39, 40], "agre": 46, "agreement": [41, 52], "ahead": 49, "ai": [7, 9, 30, 34, 38, 39, 49], "aight": 22, "aim": 44, "ain": 38, "airport": 30, "aka": [28, 41], "al": [32, 38], "alamine_aminotransferas": 22, "alan": 10, "alaska": 28, "alberta": 38, "album": 29, "albumin": 22, "albumin_and_globulin_ratio": 22, "alburi": [40, 51], "alexnet": 39, "algebra": [37, 38], "algorithm": [2, 15, 22, 24, 26, 27, 30, 31, 32, 33, 36, 38, 39, 45, 46, 47, 49, 52], "align": [8, 22, 23, 24], "align_kei": 41, "alkaline_phosphotas": 22, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 24, 25, 27, 29, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52], "all_cap": 42, "all_featur": [40, 51], "allei": [31, 33], "allen": 42, "alley_grvl": 31, "alley_miss": 31, "alley_pav": 31, "alloc": [8, 38, 39], "allow": [5, 7, 11, 24, 26, 29, 30, 34, 38, 40, 41, 45, 46, 48, 51, 52], "allpub": [31, 33], "almost": [28, 29, 31, 34, 36, 37, 38, 49], "along": [7, 23, 27, 30, 39, 40, 45], "alpha": [25, 26, 40, 46, 51], "alpha_": 31, "alphabet": 28, "alphago": [22, 35], "alq": [31, 33], "alreadi": [4, 8, 11, 30, 31, 33, 35, 38, 40, 41, 42, 45, 48, 51, 52], "also": [2, 4, 5, 7, 8, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "altar": 39, "altern": [8, 29, 35, 48, 52], "although": [24, 32, 35, 37, 41], "alwai": [22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 42, 44, 45, 46, 48, 52], "am": [26, 35, 38, 42], "amatriain": 37, "amazon": [22, 35, 37, 42], "ambigu": 38, "amer": 30, "america": [27, 38], "american": 35, "aml": 26, "among": [22, 23, 29, 30, 32, 33, 37, 50], "amongst": 42, "amount": [4, 22, 24, 28, 29, 30, 31, 33, 35, 39, 40, 41, 48, 51], "amp": [32, 33], "amplifi": [30, 38, 49], "amuel": 26, "an": [0, 2, 4, 6, 7, 8, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48, 50, 51, 52], "anaconda": [11, 33, 42], "analogi": [15, 36, 38], "analysi": [2, 9, 10, 23, 30, 31, 35, 36, 38, 49, 52], "analyt": 40, "analyz": [30, 34, 40, 41, 51, 52], "anatinu": 39, "anca": 52, "ancestor": 34, "ancestr": 52, "ancuta": 52, "andrea": [9, 10], "andrew": [9, 10, 29, 34], "anemon": 39, "angel": [41, 42], "ani": [0, 11, 23, 24, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52], "anim": [30, 39], "animal_fac": 39, "anneal": 34, "annot": [33, 35], "announc": 7, "annoyingli": 31, "annual": 42, "anomali": [30, 31, 35], "anonym": 40, "anoth": [8, 11, 23, 25, 28, 29, 30, 32, 33, 35, 36, 37, 39, 40, 41, 44, 45, 47, 50, 51], "answer": [4, 6, 7, 22, 23, 24, 29, 32, 35, 37, 38, 40, 43, 45, 46, 49, 50, 51, 52], "anteat": 39, "anti": 41, "anymor": [31, 35, 37, 46], "anyth": [0, 24, 27, 30, 37, 38, 41, 48], "anytim": 52, "anywher": 27, "ap": [44, 52], "ap_lr": 30, "ap_svc": 30, "apart": [25, 36], "apeendixa": 34, "api": [30, 38, 40, 44], "app": [23, 42, 44], "appeal": 38, "appear": [2, 7, 27, 32, 46, 50, 52], "append": [4, 8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50], "appendix_b": 38, "appendixb": 39, "appl": 38, "appli": [0, 2, 6, 9, 10, 22, 23, 24, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 52], "applic": [0, 5, 22, 27, 29, 30, 31, 33, 34, 38, 41, 42, 44, 49, 52], "appreci": [35, 52], "approach": [10, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 44, 46, 51, 52], "appropri": [0, 4, 11, 23, 24, 27, 30, 31, 35, 36, 40, 41, 44, 52], "approv": [30, 49, 52], "approx": [25, 33], "approxim": [23, 29, 34], "april": 40, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 29, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "arang": [8, 24, 25, 28, 29, 30, 31, 46, 48], "arbitrari": [33, 35, 36, 40], "architectur": 39, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21], "area": [29, 31, 32, 34, 35, 48], "aren": [7, 31, 34, 35, 38, 39, 40, 42, 51], "arena": 34, "arg": [24, 27, 42], "argh": 41, "argmin": [24, 25, 30, 35], "argsort": [33, 38], "argu": [35, 38, 48], "argument": [8, 23, 27, 29, 30, 31, 33, 42, 44, 47], "arima": 40, "arima_model": 40, "aris": [0, 22, 38], "aristotl": 25, "arithmet": 8, "around": [7, 25, 27, 30, 31, 40, 41, 45], "aroundn": 22, "arr": 41, "arr1": 8, "arr2": 8, "arrai": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48], "array_equ": 8, "arriv": 34, "arthur": 22, "articl": [10, 23, 24, 26, 30, 35, 37, 38, 39], "articul": 44, "artifici": [10, 38], "artist": [25, 26, 29, 48], "as_fram": [25, 46], "ascend": [8, 27, 28, 29, 31, 32, 33, 34, 40, 41, 44, 50], "ased": 36, "asi": 42, "asia": 27, "asid": [4, 24, 32, 46], "ask": [3, 7, 11, 22, 23, 24, 25, 27, 30, 34, 35, 37, 38, 41, 42, 45, 52], "asleep": 28, "aspartate_aminotransferas": 22, "aspect": [28, 33, 34, 36, 37, 41, 44], "assault": 52, "assert": [7, 27, 30, 32, 33, 49], "assess": [6, 10, 22, 23, 24, 26, 30, 33, 35, 52], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 40, 41, 42, 44, 45, 47, 49, 51], "assist": 22, "assoc": [30, 32, 33, 49], "associ": [0, 22, 24, 25, 30, 31, 33, 34, 35, 38, 39, 40, 41, 44, 50, 52], "assum": [22, 23, 27, 28, 30, 31, 36, 37, 38, 40, 44, 49], "assumpt": 41, "asterisk": 29, "astyp": [8, 40, 41, 51], "astype_arrai": 41, "astype_array_saf": 41, "async_": 42, "async_help": 42, "asyncio": 42, "asyncio_loop": 42, "atabak": 52, "atratu": 39, "attack": 23, "attempt": [24, 48, 49], "attend": 52, "attent": [6, 38], "attic": 31, "attract": 38, "attribut": [0, 1, 22, 23, 25, 26, 28, 29, 34, 35, 38, 39, 48, 50], "attrit": 41, "auc": [41, 44, 49, 52], "audienc": [49, 52], "audio": [39, 52], "audit": 52, "auditor": 52, "augment": 30, "august": 40, "austin": 38, "australia": [40, 51], "authent": 35, "author": [0, 38, 52], "auto": [22, 29, 30, 34, 35], "autocorrel": 40, "autom": [23, 31, 38], "automat": [26, 27, 31, 34, 38, 40, 41, 51], "autoregress": 28, "autumn": 40, "autumn_month": 40, "aux": [38, 42], "av": [31, 33, 38], "avail": [0, 1, 7, 9, 10, 11, 24, 27, 29, 30, 31, 36, 37, 38, 39, 40, 41, 44, 49, 50, 51, 52], "avebedrm": 28, "aveoccup": 28, "averag": [24, 25, 27, 28, 29, 31, 33, 35, 36, 38, 41, 42, 44, 46, 52], "average_precis": 30, "average_precision_scor": 30, "average_word_length": 42, "averaging_model": [32, 50], "averaging_model_ndt": 32, "averoom": 28, "avg": [30, 37, 40], "avg_sent_emb": 38, "avoid": [7, 8, 23, 26, 30, 31, 36, 40, 41, 43, 44, 46, 49, 52], "awai": [4, 6, 23, 28, 35, 37, 39, 41, 44], "await": 42, "awar": [27, 41, 52], "award": 52, "awesom": 9, "ax": [24, 25, 28, 30, 35, 36, 39, 41, 46, 49], "axi": [7, 8, 22, 23, 24, 26, 27, 28, 33, 35, 36, 38, 39, 40, 51], "axvlin": 35, "az": 42, "b": [8, 10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41], "b3": [26, 33], "babe": 22, "babi": [34, 38], "bachelor": [30, 32, 33, 49], "back": [8, 26, 29, 38, 44], "backdrop": 40, "background": [23, 52], "bad": [8, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 39, 40], "badgeryscreek": 40, "bag": [34, 38, 39, 44, 48], "bai": [26, 27, 34], "baidu": 24, "bal_scor": 30, "balanc": [6, 25, 32, 35, 37, 43, 49, 50], "ballarat": [40, 51], "balust": 39, "balustrad": 39, "bambi": 37, "banist": 39, "bank": [30, 33, 40, 41, 49], "bannist": 39, "bar": [30, 31, 33, 39, 40, 41, 51], "baranski": 42, "barbu": 52, "barri": 28, "base": [5, 8, 11, 15, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36, 38, 41, 42, 44, 45, 48, 49, 50, 52], "base_ev": 42, "base_scor": 32, "base_valu": 33, "baseblockmanag": 41, "baselin": [14, 41, 44, 45, 47, 48, 51], "baseline_hazard_": 41, "bash": 5, "basi": [23, 25], "basic": [2, 8, 23, 29, 34, 37, 39, 41, 42, 50, 51], "batch": [38, 39], "batch_siz": 39, "batch_t": 39, "bath": 22, "bathroom": [22, 23, 28], "bayesian": 29, "bayesopt": 29, "beagl": [22, 39], "bear": 39, "beat": [32, 41], "beauti": [37, 38], "becam": 39, "becaus": [7, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 49, 51, 52], "becom": [4, 24, 25, 28, 29, 30, 33, 34, 35, 38], "bed": 30, "bedroom": [22, 23, 28], "bedroomabvgr": [31, 33], "bedrooms_per_household": [26, 27, 47], "beef": 38, "been": [4, 6, 10, 22, 23, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 52], "befor": [4, 10, 11, 22, 23, 24, 25, 27, 28, 31, 32, 35, 36, 37, 38, 39, 40, 41, 45, 46, 48, 49, 50, 51], "begin": [23, 28, 34, 37, 40, 41, 44], "beginn": 39, "behav": [29, 33], "behavior": [24, 26, 30, 37], "behaviour": [27, 49, 50], "behind": [22, 28, 52], "being": [4, 22, 24, 26, 30, 31, 32, 33, 36, 38, 41, 46, 52], "believ": [29, 33, 40], "bell": 39, "belong": [23, 28, 36, 45], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52], "bench": 39, "benchmark": 39, "bendigo": [40, 51], "benefici": 27, "benefit": [4, 25, 32, 36, 38, 44], "bengio": 29, "ber": 38, "bergstra": 29, "berri": 38, "bertop": 38, "best": [2, 23, 24, 25, 29, 30, 31, 32, 33, 35, 36, 37, 41, 45, 46, 48, 50], "best_alpha": 31, "best_depth": 24, "best_estimator_": [29, 31], "best_n_neighbour": 25, "best_param": 29, "best_paramet": 29, "best_params_": [29, 31, 48], "best_scor": 29, "best_score_": [29, 31, 48], "bestalpha_coeff": 31, "better": [6, 22, 23, 25, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 52], "between": [2, 8, 11, 22, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 52], "bewar": 38, "beyond": [24, 29, 34], "bia": [28, 30, 33, 41, 44, 49], "bias": [30, 33, 38, 41, 49, 52], "bicycl": [23, 40], "big": [7, 25, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 46], "bigalpha_coeff": 31, "bigger": [25, 27, 28, 31, 33, 36, 38, 39, 40], "biggest": [31, 34, 51], "bike": 40, "bill": 39, "billboard": 40, "billie_holidai": 38, "billion": 31, "billionth": 40, "bin": [26, 29, 31, 34, 40, 41, 42, 45], "binar": [23, 27], "binari": [23, 26, 27, 28, 39, 41, 43, 44, 49], "binary_feat": 27, "binary_featur": [30, 32, 33, 49, 50], "binary_transform": [30, 32, 33, 49, 50], "bincount": [30, 32, 49], "bind": [25, 46], "binomi": 29, "biolog": 34, "biologi": 27, "bit": [11, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 39, 40, 41, 48, 49, 51], "black": [25, 33, 35, 39, 40, 51], "blackhawk": 38, "bld": 42, "bldgtype": [31, 33], "bldgtype_1fam": 31, "bldgtype_2fmcon": 31, "bldgtype_duplex": 31, "bldgtype_twnh": 31, "bldgtype_twnhs": 31, "blei": 38, "blend": 38, "blindli": [30, 31], "blob": 43, "block": [28, 41], "blog": [38, 40], "bloomberg": [9, 10], "blq": [31, 33], "blue": [23, 25, 29, 30, 33, 34, 35, 40], "bluesman": 38, "bmatrix": [34, 37], "board": 4, "boathous": 39, "bob_dylan": 38, "bodi": 42, "boggl": 32, "bond": 30, "bonu": 32, "book": [1, 9, 30, 31, 37, 38, 40, 52], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21], "bool": [31, 40], "boom": 42, "boost": [19, 20, 38, 44], "booster": 32, "bootstrap": 11, "border": [23, 28, 36, 38, 43, 45], "bore": 28, "boston": 28, "both": [2, 6, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 47, 48, 49, 52], "bother": 33, "bottom": 36, "bought": 37, "bound": [34, 41], "boundari": [24, 36, 38, 46], "bow_df": 27, "box": [9, 33, 44], "boxplot": 33, "boyc": 23, "br": 38, "bracket": 8, "brain": [34, 39], "branch": [23, 36, 38, 41], "break": [30, 44, 46], "breakwat": 39, "breath": 44, "breathtak": 38, "breed": 44, "breiman": 32, "brief": [4, 28, 32], "briefli": [22, 30, 32, 34], "bring": [6, 33, 36, 42, 44], "british": [1, 38], "british_columbia": 38, "broad": [25, 38, 46], "broadcast": 38, "broader": [2, 32, 38], "broadest": 38, "broadli": [23, 25, 28, 30, 32, 35, 36, 38], "brownle": 34, "browser": 11, "brush": 39, "bsmtcond": [31, 33], "bsmtexposur": [31, 33], "bsmtfinsf1": [31, 33], "bsmtfinsf2": [31, 33], "bsmtfintype1": [31, 33], "bsmtfintype2": [31, 33], "bsmtfullbath": [31, 33], "bsmthalfbath": [31, 33], "bsmtqual": [31, 33], "bsmtunfsf": [31, 33], "btw": 33, "bubbl": [37, 39], "bucket": [34, 42], "budget": [29, 37], "bug": [4, 8], "bui": 37, "build": [0, 2, 11, 24, 26, 27, 32, 34, 35, 38, 40, 43, 46, 51, 52], "built": [8, 22, 23, 24, 28, 29, 33, 40, 51], "bullshit": [10, 41], "bulwark": 39, "bunch": [8, 11, 23, 31, 32, 39, 41, 46], "bundl": [7, 11], "bureau": 28, "busi": [30, 35, 41, 42], "businesswoman": 38, "bustl": 40, "butterfli": 36, "buzz": 22, "bypass": 52, "c": [0, 5, 8, 9, 10, 11, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 46, 48, 52], "c1": 36, "c2": 36, "c_1": 35, "c_2": 35, "c_3": 35, "c_log": [25, 46], "c_widget": [25, 46], "ca": [5, 9, 42, 52], "ca_transform": 27, "cal_hous": 28, "calcul": [7, 24, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 43, 44, 46, 49, 51], "calgary_flam": 38, "california": [26, 34], "california_h": 34, "californian": 26, "call": [8, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 50, 51], "callback": 32, "calm": 44, "came": 40, "camera": 27, "campu": [34, 52], "can": [4, 6, 7, 10, 11, 22, 23, 25, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "canada": [5, 24, 25, 27, 28, 38, 42, 44], "canada_usa_c": [23, 24, 25, 28, 45], "canadian": 38, "canadien": 38, "canberra": [40, 51], "cancel": 52, "cancer": [22, 34], "candid": [29, 32, 38, 46], "cannot": [0, 8, 24, 25, 29, 30, 32, 33, 34, 36, 40, 41, 42, 52], "canuck": 38, "canva": [1, 7, 10], "capabl": 9, "capit": [30, 32, 33, 49], "caption": [7, 39], "captiv": 38, "captur": [24, 26, 28, 32, 34, 36, 37, 38, 40, 41, 44, 52], "car": [22, 38, 39], "card": [22, 23, 30, 41, 49], "care": [5, 7, 24, 26, 29, 30, 31, 33, 34, 35, 40, 41, 44, 48, 50, 51], "carefulli": [1, 30, 31, 49, 52], "carpentri": 5, "carri": [23, 24, 25, 27, 29, 30, 31, 32, 35, 37, 38, 40, 42, 46, 48, 51], "caruana": 33, "case": [6, 11, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 43, 44, 51, 52], "cash": 22, "cast": [29, 37, 42], "castl": 39, "cat": [22, 30, 32, 38, 39, 42, 44], "catamount": [22, 39], "catboost": [33, 44, 52], "catboostclassifi": 32, "catboostregressor": 32, "catch": [30, 52], "categor": [23, 29, 30, 31, 32, 34, 35, 37, 38, 41, 44, 46, 47, 49, 51], "categori": [25, 26, 30, 31, 32, 33, 34, 35, 39, 44, 49], "categorical_feat": [27, 29, 44, 48], "categorical_featur": [27, 30, 31, 32, 33, 40, 41, 49, 50, 51], "categorical_transform": [27, 30, 31, 32, 33, 40, 49, 50, 51], "categories_": [26, 27], "cater": 35, "caus": [30, 33, 34, 37, 41, 48], "causal": [33, 34], "caution": 40, "cbar": 28, "cbtf": [10, 52], "cc": [0, 1], "cc_df": [30, 49], "cconj": 38, "cell": [7, 8, 22, 26, 27, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 45, 46, 48, 50], "cell_nam": 42, "censor": [10, 44, 52], "censu": [28, 30, 32, 33, 49], "census_df": [30, 49], "cent": 31, "center": [25, 35, 36, 39, 43], "centercrop": 39, "centers_idx": 35, "central": 5, "centralair": [31, 33], "centralair_i": 31, "centralair_n": 31, "centric": 52, "centroid": [35, 36], "centroids_idx": 35, "centroids_idx_init": 35, "centuri": 38, "certain": [11, 25, 28, 29, 30, 33, 34, 35, 38, 41, 49], "certainli": 45, "certainti": 30, "cezannec": 39, "chaat": 38, "chage": 48, "chain": 27, "challeng": [6, 24, 34, 35, 37, 39, 40, 44, 50, 52], "chanc": [23, 24, 29, 30, 31, 34, 35, 41, 49], "chang": [0, 5, 7, 8, 11, 23, 24, 25, 26, 29, 31, 32, 33, 35, 36, 37, 39, 40, 41, 45, 46, 48, 49, 50, 51, 52], "channel": [1, 11, 39], "chapter": 10, "charact": [27, 30, 38], "characterist": [23, 24, 28, 48], "charg": [0, 22, 41], "charl": 28, "charm": 38, "chart": [33, 40, 41, 51], "chat": 52, "chatgpt": 38, "che210d": 9, "cheaper": 34, "cheat": 9, "check": [4, 7, 10, 11, 22, 23, 24, 26, 28, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 46, 49, 50, 51], "check_assumpt": 41, "check_invers": 27, "checklist": 44, "checkmark": 37, "checkout": 29, "cheetah": [22, 39], "chest": 24, "chestpaintyp": 50, "chetah": [22, 39], "chi": 41, "chicago": 42, "chicken": 35, "child": [30, 33], "children": 37, "chines": 38, "chn": 8, "choic": [2, 29, 31, 32, 33, 35, 36, 37, 40, 42, 46, 47, 48], "cholesterol": 50, "choos": [22, 29, 30, 32, 36, 44, 46], "chop": [29, 38], "choreograph": 42, "chosen": [24, 29, 30, 41, 44, 50], "chrbv": 41, "christin": 42, "christma": 42, "chunki": 35, "churn": 44, "ciml": 10, "cinematographi": 38, "cinereu": 39, "circl": [25, 30], "circumst": 7, "citat": 7, "cite": 41, "citi": [23, 24, 25, 38, 40, 44, 45], "citibik": 40, "cities_df": [25, 28], "citizen": 41, "cityscap": 40, "civ": [30, 32, 33], "clai": 33, "claim": [0, 29, 30], "clarif": 35, "clarifi": 44, "clariti": 52, "class": [4, 5, 11, 22, 23, 24, 25, 26, 27, 28, 34, 35, 38, 40, 41, 45, 46, 49, 50, 51], "class_attend": [23, 24, 44], "class_attendance_enc": 27, "class_attendance_level": 27, "class_label": 30, "class_labels_fil": 22, "class_nam": [23, 25, 32, 39], "class_sep": 30, "class_weight": [32, 49], "classes_": [28, 30, 32, 33, 39, 43], "classic": [25, 39, 43], "classif": [2, 10, 24, 25, 26, 27, 28, 31, 32, 33, 34, 37, 38, 40, 41, 43, 45, 46, 48, 49, 50, 52], "classifi": [24, 25, 26, 27, 29, 30, 33, 39, 43, 45, 47, 49, 50], "classification_df": [23, 24], "classification_report": [30, 39, 49], "classifiers_ndt": 32, "classify_imag": [22, 39], "classmat": [6, 46, 47, 48, 49, 50, 51, 52], "classroom": 10, "clean": [2, 22, 36, 51, 52], "clean_text": 38, "cleaned_hm": 30, "cleaner": [30, 33], "clear": [7, 30, 35, 46, 52], "clearli": [4, 6, 7, 29, 32, 33, 40], "cleric": [30, 32, 33], "clf": [22, 23, 25, 28, 39], "click": [5, 7, 10, 30, 37], "client": 37, "clinic": 23, "clip": 22, "clone": [5, 7, 11], "close": [2, 24, 25, 28, 29, 30, 35, 36, 38, 40, 42, 43, 46, 52], "close_default_lr": 30, "close_zero_svm": 30, "closer": [25, 26, 28, 37, 45, 48, 52], "closest": [25, 26, 30, 35, 36, 38, 40], "cloth": 40, "cloud": [22, 23, 27, 28, 29, 31, 32, 42], "cloud3pm": [40, 51], "cloud9am": [40, 51], "clust_label": 35, "cluster": [2, 10, 37, 38, 40, 52], "cluster_cent": 35, "cluster_centers_": 35, "cluster_std": [36, 39], "clutter": 23, "cm": [25, 28, 30, 33, 37, 46, 49], "cmap": [26, 29, 30, 33, 39, 48], "cmn": 31, "cmp": 41, "cnn": [39, 40], "co": [27, 38], "coast": 39, "code": [4, 7, 8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51], "code_ast": 42, "code_obj": 42, "codecademi": 9, "coef": [40, 41, 42, 51], "coef_": [28, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 50], "coef_df": [28, 33], "coef_nonzero": 40, "coeff": 28, "coeff_df": 40, "coeffici": [31, 32, 34, 37, 39, 40, 41, 42, 43, 44, 50, 51], "coefs_df": 34, "coher": 35, "col": [23, 27, 28, 37, 40, 44], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 26, "colinear": 33, "collabor": [5, 37, 52], "collaps": 33, "colleagu": [8, 9], "collect": [22, 23, 26, 27, 30, 32, 33, 34, 37, 38, 39, 40, 41, 44, 50, 52], "colleg": [30, 32, 33, 49], "collinear": 34, "color": [19, 28, 33, 34, 35, 36, 40], "color_continuous_scal": 34, "color_threshold": 36, "colorbar": [26, 28], "colour": [27, 28, 29, 33, 35, 36, 39], "colsample_bylevel": 32, "colsample_bynod": 32, "colsample_bytre": 32, "columbia": [1, 9, 38], "column": [7, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "column_nam": 27, "column_stack": 34, "columntranform": 47, "columntransform": [10, 16, 17, 26, 29, 30, 31, 32, 33, 34, 40, 41, 42, 48, 49, 50, 51], "columntransformer__countvectorizer__max_featur": [29, 48], "columntransformercolumntransform": [27, 29, 31, 32, 34, 42], "columntransformerifittedcolumntransform": [27, 31], "columntransformerinot": [27, 32], "com": [0, 5, 8, 9, 11, 22, 23, 27, 28, 30, 31, 32, 39, 40, 41, 42, 49], "comat": 38, "combin": [23, 26, 27, 29, 30, 34, 37, 39, 40, 41, 45, 46, 48, 50], "come": [11, 22, 23, 26, 27, 30, 34, 37, 38, 39, 40, 41, 45], "comedi": 37, "comfort": 5, "command": [4, 11, 30, 38], "comment": [8, 9, 51], "commerci": 0, "commit": [7, 30, 52], "common": [1, 8, 23, 24, 25, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 43, 46, 52], "commonli": [23, 26, 29, 30, 35, 41], "commonwealth": 38, "commun": [2, 10, 11, 27, 29, 31, 52], "commut": 8, "comp_dict": 30, "compact": [29, 34], "compani": [30, 35, 37, 38, 41, 42, 49], "compar": [8, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 48, 49, 50, 51, 52], "comparison": [36, 39, 41, 44], "compassion": 52, "compat": [8, 33, 42], "compatibitl": 8, "compel": 40, "compet": 42, "competit": [32, 39, 43], "compil": 42, "complain": [6, 42], "complaint": [6, 52], "complement": 38, "complet": [1, 6, 7, 22, 26, 29, 32, 33, 34, 36, 38, 41, 45, 46, 49, 50, 52], "complex": [23, 25, 28, 29, 31, 32, 33, 34, 36, 38, 39, 40, 46, 52], "compli": 0, "complic": [4, 23, 24, 29, 31, 34], "compon": [27, 30, 37, 40, 52], "components_": 38, "compos": [25, 27, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 47, 48, 49, 50, 51], "composit": 27, "compound": [38, 39, 41, 42], "comprehend": 38, "comprehens": [35, 44, 52], "compress": [27, 35, 38], "compris": [22, 23, 35], "comput": [7, 9, 10, 11, 22, 27, 29, 30, 32, 33, 34, 35, 36, 38, 40, 43, 49, 50, 52], "computation": 34, "compute_class_weight": 30, "computer_programm": 38, "coms4995": 26, "con": [35, 38, 39], "concat": [22, 25, 26, 27, 28, 33], "concaten": [27, 38], "concav": 34, "concensu": 24, "concentr": [29, 44], "concept": [10, 23, 24, 33, 34, 35, 40, 44, 46, 52], "conceptnet": 38, "conceptu": 32, "concern": [4, 27, 32, 52], "concess": 7, "concis": 23, "concord": 41, "concordance_index": 41, "concordance_index_": 41, "concret": 22, "conda": [22, 30, 31, 32, 33, 35, 38, 41, 42], "condit": [0, 22, 23, 27, 34, 38, 41, 52], "condition1": [31, 33], "condition1_arteri": 31, "condition1_feedr": 31, "condition1_norm": 31, "condition1_posa": 31, "condition1_posn": 31, "condition1_rra": 31, "condition1_rran": 31, "condition1_rrn": 31, "condition1_rrnn": 31, "condition2": [31, 33], "condition2_arteri": 31, "condition2_feedr": 31, "condition2_norm": 31, "condition2_posa": 31, "condition2_posn": [31, 33], "condition2_rra": 31, "condition2_rran": 31, "condition2_rrnn": 31, "conditional_aft": 41, "confer": 38, "confid": [22, 24, 33, 41, 44, 46, 49, 50], "confidenti": 30, "config": [11, 42], "configur": [29, 31, 32], "confirm": 11, "conflict": [11, 36, 52], "confound": 34, "confus": [8, 18, 25, 27, 31, 35, 46, 49], "confusion_matrix": [30, 39, 41], "confusionmatrixdisplai": [30, 49], "congrat": 27, "conjunct": 34, "connect": [0, 23, 36, 37], "connot": 38, "conort": 34, "consciou": 52, "consecut": 40, "consequ": [7, 22, 27, 30, 37, 49], "consid": [4, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 44, 46, 52], "consider": [2, 30, 32, 35, 37, 41, 52], "consist": [6, 7, 23, 24, 26, 35], "const": 38, "constant": [23, 30, 31, 32, 33, 40, 41, 49, 51], "constitu": 32, "constitut": [38, 52], "construct": 37, "constructor": [23, 26], "consult": [25, 46, 52], "consum": [22, 34, 35, 37, 44], "consumpt": 40, "contact": [22, 52], "contain": [8, 11, 19, 22, 23, 26, 27, 28, 31, 37, 38, 39, 42, 43, 52], "content": [1, 4, 11, 35, 38, 39, 44, 52], "contest": 6, "context": [23, 26, 28, 29, 30, 32, 33, 34, 36, 37, 39, 40, 44, 46, 52], "contextu": 52, "contin": 27, "conting": 36, "continu": [15, 27, 29, 31, 32, 34, 38, 40, 51], "contract": [0, 41], "contract_month": 41, "contract_on": 41, "contract_two": 41, "contrast": [44, 52], "contribut": [25, 28, 33, 39, 50, 52], "control": [5, 8, 23, 24, 25, 27, 28, 31, 32, 39, 52], "convei": 52, "conveni": [8, 29, 30, 35, 38, 40, 41], "converg": 35, "convers": [30, 31, 33, 38, 48], "convert": [22, 26, 27, 28, 32, 33, 34, 38, 40, 41, 51], "convinc": 27, "convolut": [34, 39], "convolutional_neural_network": 39, "cooccurrencematrix": 38, "cook": 35, "cool": 39, "coolwarm": 28, "coordin": 52, "copi": [0, 7, 8, 11, 23, 29, 32, 33, 35, 37, 39, 40, 41, 50, 51, 52], "copy_arrai": 42, "copyright": 0, "cor": 33, "coral": 39, "core": [9, 24, 26, 27, 29, 30, 31, 34, 36, 37, 40, 41, 42, 44, 51, 52], "corefer": 38, "corgi": [22, 39], "coro": 42, "corona_nlp_test": 42, "coronapocalyps": 42, "coronaviru": 42, "corpor": [5, 42], "corpora": [27, 38], "corpu": [27, 30, 38], "corr": 33, "corr_df": 33, "correct": [7, 22, 23, 24, 25, 30, 32, 33, 41, 45, 46, 50], "correctli": [10, 11, 23, 24, 30], "correl": [40, 44], "correspond": [10, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 35, 37, 40, 46, 48], "cosin": 38, "cosine_similar": 38, "cost": [8, 22, 39, 52], "cost_rep": 8, "costco": 38, "costli": 30, "cot": 39, "cote": 39, "could": [6, 8, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 46, 48, 49, 51, 52], "couldn": 38, "count": [8, 23, 26, 27, 30, 31, 34, 38, 39, 40, 41, 42, 43, 46, 48, 49, 51, 52], "counter": 30, "counti": 46, "countri": [24, 25, 27, 28, 30, 32, 33, 38, 49, 52], "country_columbia": 33, "country_dominican": 33, "country_guatemala": 33, "country_hondura": 33, "country_hong": 33, "country_hungari": 33, "country_india": 33, "country_iran": 33, "country_miss": [32, 33], "country_puerto": 33, "country_scotland": 33, "country_south": 33, "country_taiwan": 33, "country_thailand": 33, "country_trinadad": [32, 33], "country_unit": [32, 33], "country_vietnam": [32, 33], "country_yugoslavia": [32, 33], "countvector": [22, 28, 29, 30, 38, 42, 44, 48], "countvectorizercountvector": [27, 29, 42], "countvectorizeroriginaltweet": 42, "countvectorizersong_titl": 29, "coupl": [4, 23, 29, 36, 42, 51], "cour": 38, "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48], "coursera": [9, 10], "coursework": 52, "court": 38, "covari": [23, 41], "cover": [8, 30, 32, 35, 39, 40, 52], "coverag": 30, "covid": 42, "covid2019": 42, "cox": 52, "coxph_fitt": 41, "coxphfitt": 41, "cph": [41, 44], "cph_param": 41, "cpp": 42, "cpsc": [9, 10, 11, 22, 23, 32, 34, 38, 39, 40, 42, 52], "cpsc330": [0, 11, 22, 23, 24, 27, 29, 33, 38, 39, 41, 42, 52], "cpsc330env": 11, "cpu": [29, 39, 42], "craft": [25, 30, 32, 33, 35, 46], "crash": [10, 42], "crate": 39, "creat": [8, 9, 11, 22, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "create_lag_df": 40, "create_lag_featur": [40, 51], "create_y_from_r": 37, "creativ": [1, 38], "credit": [0, 23, 30, 32, 38, 40, 41, 49], "creditcard": [30, 49], "crime": 28, "crimin": 33, "criteria": [23, 36], "criterion": 36, "critic": 52, "cross": [15, 23, 25, 27, 29, 31, 32, 33, 35, 37, 41, 42, 44, 47, 48, 49, 50, 51], "cross_val": 32, "cross_val_predict": [30, 32, 41], "cross_val_scor": [26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 44, 47, 48, 49, 50, 51], "cross_valid": [25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51], "cross_validate_std": 24, "crowd": [32, 36], "crown": 52, "crown_princ": 38, "crucial": [22, 24, 28, 33, 35, 36, 37, 38], "crude": 38, "cs189": 9, "cs189_ch7": 9, "csrc": 42, "csv": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "ct": 27, "cuda": 39, "cui": 52, "cultiv": 52, "cultur": [39, 52], "cupi": 42, "curios": 22, "curiou": [22, 46], "current": [32, 38, 39, 40, 41, 42], "curriculum": 52, "curv": [7, 8, 35, 44, 46, 52], "custom": [5, 8, 22, 23, 27, 30, 31, 37, 42, 44], "custom_plot_tre": [23, 24, 32, 33], "customerid": 41, "customiz": 42, "cut": 36, "cv": [24, 27, 30, 31, 32, 33, 34, 40, 41, 44, 46, 48], "cv_feat": 42, "cv_results_": [29, 31, 48], "cv_score": [24, 31], "cv_train_scor": 46, "cv_valid_scor": 46, "cycl": 8, "cyclic": 40, "cycling_data": 8, "cygnu": 39, "d": [4, 8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 49, 50, 51], "d1b": 52, "d1c": 52, "d1e": 52, "d1f": 52, "d3": 35, "da": 22, "dabeaz": 9, "dad": 34, "dai": [4, 8, 10, 34, 39, 41, 44, 51, 52], "daili": [41, 44], "dall": 40, "damag": [0, 30], "dan": 38, "danceabl": [25, 26, 29, 48], "dark": 42, "darker": 29, "dashboard": [25, 46], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 36, 38, 41, 43, 44, 45, 47, 48, 49, 50, 52], "data_dict": 28, "data_dir": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51], "data_to_wrap": 27, "data_transform": 39, "data_transforms_bw": 39, "data_url": [30, 49], "datacamp": 9, "datafram": [22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 51], "dataload": 39, "dataloaders_bw": 39, "datapoint": 28, "dataquest": 9, "dataset": [8, 18, 22, 24, 25, 32, 33, 34, 35, 36, 41, 42, 43, 44, 46, 48, 49, 52], "dataset2": 35, "dataset_s": 39, "date": [7, 11, 22, 23, 37, 38, 41, 42, 44, 46, 51, 52], "date_rang": 40, "dates_rain": [40, 51], "datetim": 41, "datetime64": [40, 51], "datetimeindex": 40, "datum": 38, "daughter": 30, "daum\u00e9": 10, "daunt": 37, "dave": 38, "david": [10, 38], "day_nam": [40, 51], "daylight": [40, 51], "dayofweek": 40, "days_sinc": 40, "dbscan": 52, "dc": [40, 41, 42], "dcc": 28, "dd": [40, 51], "de": [38, 40], "deactiv": 11, "deadlin": 52, "deal": [0, 24, 25, 26, 31, 38, 41, 44, 47], "death": 52, "debat": [8, 33], "debbi": 42, "debug": [4, 33], "decad": 39, "decemb": [40, 51], "decid": [8, 23, 25, 28, 32, 33, 34, 35, 36, 38, 40, 41, 44], "decis": [2, 6, 10, 14, 24, 26, 29, 30, 32, 34, 39, 43, 44, 45, 47, 50, 52], "decision_boundari": 43, "decision_funct": 30, "decisiontreeclassifi": [24, 25, 26, 27, 28, 29, 33, 45, 46, 47, 48, 50], "decisiontreeclassifierdecisiontreeclassifi": 32, "decisiontreeregressor": [23, 31, 45, 46], "deck": 9, "declar": 52, "decomposit": [36, 37, 38], "decor": 42, "decreas": [24, 28, 29, 32, 33, 35, 46], "deduct": 7, "deem": 6, "deep": [2, 9, 29, 33, 34, 38, 41], "deepen": [44, 52], "deeper": [2, 29, 30, 31, 33], "deepexplain": 33, "def": [24, 25, 26, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 42, 46, 48, 51], "defalut": 48, "default": [5, 11, 23, 24, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 43, 48, 49, 52], "default_threshold": 30, "defaultdict": 37, "defin": [23, 25, 26, 27, 30, 32, 33, 35, 36, 37, 40, 51], "definit": [8, 25, 33, 35, 38, 40, 43, 44, 45], "degre": 30, "degrees_freedom": 41, "degrees_of_freedom": 41, "del": 32, "delai": [10, 11, 34], "deleg": 38, "delet": [4, 7, 26], "delgado": 32, "delight": 38, "deliver": 7, "delv": [38, 52], "demo": [10, 32, 52], "demograph": [23, 37], "demonstr": [23, 24, 26, 28, 29, 31, 32, 35, 37, 38, 39], "denomin": [31, 42], "denot": [23, 37], "dens": [36, 38], "densenet": 39, "densenet121": 39, "densenet121_weight": 39, "densiti": [33, 36, 44], "dep": 38, "department": 52, "departur": 34, "depend": [2, 8, 11, 23, 24, 25, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 50], "dependence_plot": 33, "dependents_no": 41, "dependents_y": 41, "deploi": [24, 30, 37, 44], "deploy": [33, 40, 52], "deprec": [24, 26, 30, 31, 41, 43], "deprecationwarn": [32, 41], "depth": [10, 23, 24, 29, 32, 36, 45, 46], "dequ": [32, 33, 50], "deriv": [0, 23, 28, 30, 37, 41, 44, 49], "descend": [8, 36, 39, 44], "descent": 40, "descr": 28, "describ": [8, 22, 23, 24, 25, 26, 28, 30, 31, 37, 38, 40, 46, 49, 51, 52], "descript": [31, 41, 42], "deserv": 6, "design": [23, 33, 36, 39, 48, 52], "desir": [30, 38, 41, 47], "desk": 52, "despit": [34, 38], "det": [38, 42], "detach": 39, "detail": [7, 25, 27, 32, 38, 39, 52], "detect": [22, 23, 30, 31, 35, 36, 40, 49], "determin": [25, 35, 36, 38, 41, 46, 50, 52], "detriment": [30, 37, 49], "dev": [24, 43], "develop": [9, 10, 22, 24, 26, 27, 29, 30, 31, 32, 38, 39, 42, 44, 52], "devianc": 41, "deviat": [6, 24, 26, 32, 33], "devic": [32, 39, 42], "deviceprotect": 41, "deviceprotection_no": 41, "deviceprotection_y": 41, "df": [22, 23, 24, 26, 27, 29, 30, 31, 33, 34, 39, 40, 41, 42, 45, 51], "df_concat": 22, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 40, "df_locat": [40, 51], "di": 41, "diagnos": [24, 33, 44], "diagnosi": 30, "diagnost": 41, "diagon": [25, 30, 33], "diagram": [27, 29, 32, 33], "dialogu": 38, "dict": [30, 37], "dict_kei": 32, "dictionari": [8, 26, 29, 30, 32, 33], "did": [6, 23, 25, 33, 35, 38, 40, 42, 46, 48, 49, 50, 52], "didn": [29, 32, 33, 36, 38, 40, 41], "die": 42, "diet": [23, 38], "diff": [40, 51], "differ": [2, 5, 7, 8, 10, 11, 22, 23, 24, 25, 27, 28, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 50, 51, 52], "differenti": [22, 23, 52], "difficult": [4, 6, 7, 30, 34, 35], "difficulti": [35, 44], "dig": [30, 31], "digit": 40, "dilemma": 37, "dim": 39, "dimens": [8, 28, 34], "dimension": [2, 8, 28, 29, 30, 32, 34, 35, 38], "direct": [28, 33, 34, 36, 38, 42], "direct_bilirubin": 22, "directli": [8, 10, 27, 31, 39, 41, 52], "director": 37, "directori": [11, 23, 24, 26], "dirichlet": [38, 39], "disabl": 38, "disadvantag": [29, 32, 36, 37, 47], "disast": 22, "discard": [34, 38], "disciplin": [30, 34], "disclos": [42, 52], "discourag": 8, "discours": 37, "discov": [34, 35], "discoveri": 22, "discret": [23, 34, 52], "discrete_scatt": [23, 24, 25, 28, 35, 36, 39, 43, 45, 46], "discretization_feat": 34, "discrimin": 32, "discuss": [1, 4, 24, 25, 26, 28, 33, 34, 35, 36, 40, 44, 46, 47, 48, 50, 51, 52], "diseas": [23, 30, 41], "dispatch": 42, "dispatch_queu": 42, "dispatch_shel": 42, "displaci": [38, 42], "displai": [7, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 36, 37, 39, 40, 41, 45, 46, 47, 48, 49, 51], "display_heatmap": [29, 48], "display_label": [30, 49], "displaystyl": 38, "disput": 38, "disrespect": 4, "dist": [25, 35, 36], "distanc": [8, 26, 34, 36, 37, 38], "distinct": [30, 34, 40], "distinguish": [23, 25, 27, 30, 46], "distract": 52, "distribut": [0, 11, 24, 30, 33, 34, 36, 38, 39, 40, 48, 51, 52], "district": [26, 28], "districtdatalab": 35, "disturb": 22, "dive": 33, "divers": [32, 35, 37, 40, 52], "divid": [28, 30, 32, 33, 40, 46], "divis": 33, "divorc": [32, 33], "dktal": 41, "dlwqn": 41, "dmp": 52, "do": [0, 4, 5, 6, 7, 8, 10, 11, 22, 23, 24, 25, 28, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "do_execut": 42, "dobj": 38, "doc": [8, 9, 33, 38, 39, 42, 52], "doc_id": 38, "doctor": [30, 32, 33, 49], "document": [0, 1, 7, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 44, 48, 49, 50, 52], "document_top": 38, "documentari": 37, "doe": [5, 8, 11, 22, 24, 25, 26, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 46, 48, 50, 51, 52], "doesn": [7, 8, 24, 26, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 44], "dog": [30, 39], "dollar": [4, 28, 31], "dolli": 42, "domain": [0, 22, 33, 35, 38], "domin": [26, 31, 39], "domingo": [10, 24, 34], "dominican_republ": 38, "don": [4, 22, 24, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "done": [5, 11, 24, 27, 29, 30, 39, 40, 44, 47, 49], "dont": 42, "door": 39, "dosa": 38, "dot": [25, 28, 30, 32, 33, 34, 36, 38], "dot_product": 38, "doubl": 29, "down": [24, 30, 33, 38, 41, 46, 50, 52], "downfal": 37, "downgrad": 42, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 30, 31, 33, 38, 39, 42, 46, 50], "dpi": 34, "dr": [38, 52], "draft": 10, "drag": 7, "drama": 37, "drastic": 30, "draw": [28, 29, 38], "drawback": [33, 37, 52], "drawn": 32, "dream": 39, "dreampharmaceut": 38, "drinker": 38, "drive": [22, 33], "driven": [11, 29, 30], "droit": 38, "drop": [7, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52], "drop_dupl": [25, 29], "drop_feat": [27, 44], "drop_featur": [30, 31, 32, 33, 40, 41, 42, 49, 51], "dropdown": 19, "dropdrop": [27, 31, 32, 42], "drope": 26, "dropna": [30, 40, 51], "dropoff": 35, "drug": 22, "dsci": [9, 10, 33, 43], "dsl": 41, "dt": 46, "dt88trtd17lf726d55bq16c40000gr": 42, "dt_best": 46, "dt_pipe": 29, "dtype": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51], "dual": 30, "duan": 52, "duck": 39, "duckbil": 39, "due": [7, 28, 32, 34, 37, 52], "dummi": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 45, 47, 48, 49, 50, 51], "dummy_clf": [23, 45], "dummy_scor": 25, "dummy_valid_accuraci": 25, "dummyclassifi": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 39, 42, 45, 46, 47, 48, 49, 50, 51], "dummyregressor": [27, 32, 33, 34, 42, 47, 50], "dun": 22, "dunno": 22, "duplex": 31, "duplic": 8, "durat": [7, 34, 40, 41], "duration_col": 41, "duration_m": [25, 26, 29], "dure": [4, 8, 10, 22, 23, 25, 27, 28, 29, 32, 33, 34, 37, 38, 44, 45, 46, 47, 48, 49, 50, 51, 52], "dwell": 31, "e": [6, 7, 8, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 51, 52], "e737c5242822": 41, "e_": 24, "each": [7, 8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52], "earli": [33, 41], "earlier": [26, 32, 34, 40, 41], "early_stopping_round": 32, "earn": 52, "earnest": 52, "easi": [7, 25, 26, 28, 32, 33, 34, 35, 36, 38, 42], "easier": [5, 7, 30, 33, 34, 37], "easiest": [33, 41, 42], "easili": [32, 34, 40, 45, 51], "echidna": 39, "econom": [27, 40], "ecosystem": 39, "ed": 1, "eda": [24, 38, 41, 44, 51], "edg": [23, 29], "edgecolor": [29, 40, 51], "edit": [29, 38], "edu": 9, "educ": [30, 32, 33, 37, 49], "education_level": [30, 32, 33, 49], "effect": [25, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 44, 46, 49], "effici": 29, "effort": [4, 11, 29, 34, 35, 37, 39, 52], "egg": 35, "eghbal": 52, "either": [4, 23, 24, 25, 27, 30, 33, 35, 36, 38, 39, 40, 46, 48], "elast": 41, "elbow": 36, "elect": 38, "electr": [31, 33], "electrical_engin": 38, "electrical_fusea": 31, "electrical_fusef": 31, "electrical_fusep": 31, "electrical_miss": 31, "electrical_mix": 31, "electrical_sbrkr": 31, "electron": [41, 52], "eleg": [26, 38], "elegantli": 38, "element": [0, 9, 10, 24, 27, 38, 45], "eli5": 33, "elif": [23, 40, 41], "elimin": 52, "els": [23, 27, 30, 39, 40, 41, 42, 49], "email": [22, 24, 30, 52], "emb": [7, 25, 30, 35, 36], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 27, 39, 44, 52], "emoji": 42, "emoticon": [34, 35], "emp": 33, "empathi": 38, "emphas": 52, "emphasi": 52, "emploi": [40, 41, 44], "employ": 37, "employe": 23, "empti": [28, 38, 39, 40, 51], "en": [40, 41, 42, 51], "en_core_web_lr": 38, "en_core_web_md": [38, 42], "enabl": [11, 37, 38, 40], "enable_categor": 32, "enable_halving_search_cv": 29, "enc": [26, 27, 40], "enclosedporch": [31, 33], "encod": [16, 17, 22, 24, 29, 30, 31, 33, 37, 41, 44, 47, 49, 51], "encompass": [41, 44], "encount": [27, 29], "encourag": [11, 52], "end": [4, 8, 22, 24, 25, 28, 29, 30, 34, 35, 36, 37, 38, 40, 41, 46, 52], "endors": 0, "endpoint": 41, "energi": [25, 26, 29, 40, 48], "engag": 52, "engin": [9, 10, 27, 30, 31, 35, 37, 38, 41, 51, 52], "england": 42, "english": [22, 26, 29, 30, 38, 39, 42, 48], "enhanc": 52, "enjoi": [10, 28], "enjoy_class": 27, "enjoy_cours": [27, 44], "enjoy_course_enc": 27, "enjoy_the_mo": 30, "enough": [7, 25, 27, 30, 31, 32, 35, 37, 44, 48, 49, 51], "ensembl": [10, 19, 20, 31, 33, 34, 36, 37, 40, 41, 42, 50, 51, 52], "ensiti": 36, "ensur": [7, 26, 32, 40, 51, 52], "ent": [38, 42], "enter": [27, 41, 48], "enterpris": 5, "entertain": 38, "enthusiast": 22, "entir": [4, 8, 24, 31, 39, 40, 42, 50, 52], "entiti": [34, 37, 38, 42], "entitl": 27, "entlebuch": [22, 39], "entri": [25, 26, 27, 28, 30, 31, 34, 37, 40, 41, 51], "entropi": 23, "enumer": 32, "env": [11, 23, 24, 27, 29, 33, 41, 42, 43], "environ": [3, 5, 8, 22, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 41, 42, 52], "environemnt": 11, "environment": 44, "ep": [23, 24, 25, 28, 36, 45], "epoch": 40, "epsilon": 36, "equal": [8, 25, 27, 30, 31, 32, 33, 36, 37, 40, 44, 51, 52], "equat": [4, 28], "equip": [25, 41, 52], "equival": [8, 30, 32, 49], "erik": 38, "err": 38, "error": [4, 6, 7, 8, 11, 23, 25, 27, 28, 32, 33, 34, 38, 41, 42, 44, 46, 50, 52], "error_": 24, "erupt": 22, "erythrocebu": [22, 39], "es": [40, 51], "eskimo": 30, "esl": 10, "especi": [2, 23, 25, 29, 30, 32, 34, 37, 40], "essenti": [41, 44], "estat": 23, "estim": [24, 25, 27, 28, 29, 34, 35, 41, 44, 50], "estimators_": 32, "et": [32, 38], "etc": [2, 7, 8, 23, 34, 38, 39, 40, 41, 42, 52], "ethic": [10, 52], "euclidean": [35, 36, 38], "euclidean_dist": [25, 26, 35, 36, 38], "ev": 42, "eva": 37, "eva_model": 37, "eval": 39, "eval_metr": [32, 33], "eval_on_featur": 40, "evalu": [8, 10, 23, 24, 29, 31, 33, 35, 40, 46, 50, 52], "evapor": [40, 51], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 28, 29, 30, 34, 35, 36, 37, 40, 41, 42, 44, 46, 47, 49, 52], "event": [0, 30, 31, 42, 52], "event_col": 41, "event_observ": 41, "ever": [23, 43], "everi": [8, 23, 24, 32, 36, 40, 46], "everydai": [8, 38], "everyon": [6, 33, 44], "everyth": [27, 30, 37, 40, 50], "everywher": 40, "evict": 42, "evok": 38, "ex": [31, 33], "ex1_idx": 33, "ex2_idx": 33, "exact": [4, 41], "exactli": [7, 22, 24, 33, 46, 48], "exam": [6, 10], "examin": [24, 25, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 49, 51], "exampl": [0, 4, 5, 6, 7, 8, 11, 31, 36, 37, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52], "example1": 23, "example2": 23, "exceedingli": 46, "excel": [27, 28, 31, 33, 41, 44, 47], "except": [0, 7, 8, 24, 40, 41, 51, 52], "exception": 4, "exchang": [30, 44], "excit": 37, "exec": 42, "execut": [4, 7, 35], "execute_request": 42, "exercis": [7, 9, 10, 38, 42, 46, 47, 48, 49, 50, 51, 52], "exerciseangina": 50, "exhaust": 48, "exist": [8, 30, 34, 41, 49], "exp": [28, 41], "expand": [10, 23, 52], "expect": [1, 4, 7, 8, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 49, 51, 52], "expected_valu": 33, "expenditur": 40, "expens": [22, 30, 31, 34, 35, 37], "experi": [22, 29, 37, 38, 52], "experienc": 52, "experiment": 29, "expert": [22, 23, 24, 29, 33, 34, 49], "explain": [4, 7, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 49, 50, 52], "explan": [4, 24, 25, 44, 49], "explanatori": 23, "explicit": [30, 41], "explicitli": [8, 22], "exploit": 6, "explor": [23, 24, 27, 29, 30, 33, 34, 37, 38, 39, 46, 48], "exploratori": [31, 41, 44], "explos": 42, "expm1": 31, "expon": 29, "exponenti": 29, "export_graphviz": [23, 45], "exposur": 37, "express": [0, 8, 27, 28, 34, 38], "extend": [38, 39, 43, 52], "extend_block": 41, "extens": [25, 30, 33, 35, 36, 38, 40, 46, 52], "extent": [35, 38], "extercond": [31, 33], "exterior": 33, "exterior1st": [31, 33], "exterior1st_asbshng": 31, "exterior1st_asphshn": 31, "exterior1st_brkcomm": 31, "exterior1st_brkfac": 31, "exterior1st_cblock": 31, "exterior1st_cemntbd": 31, "exterior1st_hdboard": 31, "exterior1st_imstucc": [31, 33], "exterior1st_metalsd": 31, "exterior1st_plywood": 31, "exterior1st_ston": 31, "exterior1st_stucco": 31, "exterior1st_vinylsd": 31, "exterior1st_wd": 31, "exterior1st_wdsh": 31, "exterior2nd": [31, 33], "exterior2nd_asbshng": 31, "exterior2nd_asphshn": 31, "exterior2nd_brk": 31, "exterior2nd_brkfac": 31, "exterior2nd_cblock": 31, "exterior2nd_cmentbd": 31, "exterior2nd_hdboard": 31, "exterior2nd_imstucc": 31, "exterior2nd_metalsd": 31, "exterior2nd_oth": 31, "exterior2nd_plywood": 31, "exterior2nd_ston": 31, "exterior2nd_stucco": 31, "exterior2nd_vinylsd": 31, "exterior2nd_wd": 31, "exterqu": [31, 33], "extra": [4, 35, 40, 51, 52], "extract": [34, 35, 37, 38, 39, 42, 51, 52], "extractor": 44, "extrapol": [40, 41], "extratreesclassifi": 32, "extrem": [6, 27, 30, 32, 33, 37, 41, 42], "ey": 42, "f": [8, 11, 22, 23, 24, 25, 26, 27, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 46, 50, 51, 52], "f1": [18, 31, 44, 52], "f1_score": 30, "f403": 42, "fa": [31, 33], "face": [22, 23, 25, 37, 39], "facebook": [37, 38, 52], "facial": 25, "facil": 52, "facilit": [8, 52], "fact": [22, 29, 30, 32, 39, 40, 41, 51], "factor": [23, 29, 33, 34, 36, 37, 41], "fail": [7, 8, 10, 11, 24, 26, 27, 34, 36, 38, 41, 42], "failur": [7, 22, 41, 50, 52], "fair": [6, 24, 26, 31, 33, 35, 44, 52], "fairli": [24, 29, 30, 33, 49], "fake": 25, "fall": [25, 35, 38, 40], "fals": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 44, 49, 50, 51], "famili": [22, 29, 30, 31, 32, 33, 35, 52], "familiar": [8, 11, 23, 26, 46, 51, 52], "famou": [9, 10, 38, 39], "fanci": [4, 22, 29], "fancier": 34, "far": [23, 25, 26, 27, 28, 30, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 48, 50], "farm": 30, "farthest": 23, "fashion": [32, 38], "fast": [24, 25, 28, 32, 33, 38, 41, 52], "faster": [22, 29, 32, 34, 39], "fastest": 32, "fastingb": 50, "fasttext": 38, "favourit": 38, "fc": 28, "fcluster": 36, "feat": [29, 40, 42], "feat1": 35, "feat2": 35, "feat_nam": [40, 42], "feat_vec": 37, "featur": [10, 16, 17, 21, 24, 30, 32, 35, 36, 38, 41, 43, 46, 47, 48, 49, 50, 52], "feature_extract": [22, 27, 28, 29, 30, 38, 42, 48], "feature_importances_": 34, "feature_nam": [23, 24, 28, 32, 33, 34, 38], "feature_names_out": 27, "feature_select": 34, "feature_typ": 32, "features_lag": 40, "features_nonzero": 40, "features_poli": 40, "februari": 40, "feder": [30, 33, 38, 40], "feedback": [23, 44], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 35, 44], "feli": [22, 39], "fell": 28, "femal": [30, 32, 33, 41, 49], "female_cm": [30, 49], "female_pr": [30, 49], "fenc": [31, 33, 39], "fernandez": 32, "fetch_california_h": 28, "few": [8, 10, 22, 28, 31, 32, 34, 37, 38, 39, 40, 41, 45, 50], "fewer": [11, 32, 34, 36], "fewest": 50, "fiber": 41, "fiction": 42, "field": [2, 4, 22, 27, 38, 39, 40, 52], "fig": [24, 25, 28, 30, 34, 35, 36, 39, 46, 49], "figsiz": [23, 24, 25, 26, 28, 30, 33, 34, 35, 36, 39, 40, 41, 46, 49], "figur": [4, 8, 11, 22, 23, 25, 29, 31, 33, 34, 35, 36, 39, 40, 41, 46], "file": [0, 1, 4, 5, 7, 8, 11, 19, 23, 27, 30, 33, 39, 41, 42, 49, 51], "filenam": 39, "fill": [25, 28, 29, 37, 46, 50, 52], "fill_diagon": 25, "fill_valu": [30, 31, 32, 33, 40, 49, 51], "film": [38, 42], "filter": [4, 22, 24, 35, 40, 44, 51, 52], "filterwarn": [25, 41, 50], "final": [6, 7, 10, 24, 26, 32, 34, 45, 47, 50], "final_estim": 32, "final_estimator_": [32, 50], "financ": [39, 40], "find": [7, 8, 10, 22, 23, 26, 29, 31, 32, 33, 35, 36, 37, 38, 42, 43, 48, 49, 52], "fine": [7, 26, 27, 30, 37, 39, 40, 50], "finish": [22, 31], "fira": [0, 1, 52], "firasm": [30, 49], "fireplac": [31, 33], "fireplacequ": [31, 33], "first": [4, 8, 10, 23, 25, 27, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 50, 52], "first_dai": 40, "first_day_retail": 40, "firth": 38, "fish": [30, 33], "fist": 40, "fit": [0, 22, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51], "fit_intercept": 30, "fit_predict": 36, "fit_resampl": 30, "fit_tim": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42], "fit_transform": [26, 27, 30, 32, 33, 34, 36, 37, 38, 40, 44, 49], "fittedcolumntransform": [27, 32], "fittedpipelin": [27, 29, 31], "fittedvotingclassifi": 32, "fitter": 41, "five": 29, "fix": [26, 27, 32, 41, 43, 46, 52], "flag": 41, "flagstaff": 42, "flaki": 30, "flashcard": 44, "flat": 36, "flatten": [32, 33, 36, 40, 50], "flatten_train": 39, "flatten_transform": 39, "flatten_valid": 39, "flaw": [24, 26], "flawless": 28, "flexibl": [7, 22, 34, 39, 44, 52], "flibbertigibbet": 38, "flickr_cat_000002": 39, "flight": 34, "flip": [10, 24, 30, 31], "flip_i": 30, "float": [8, 31, 34, 41, 42], "float32": [38, 39], "float64": [23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 40, 41, 51], "floatlogslid": [25, 46], "floatslid": [25, 30, 35, 36, 46], "floor": [22, 23], "flower": [25, 30, 46], "fmt": 29, "fn": 30, "fnlwgt": [30, 32, 33, 49], "focu": [10, 22, 26, 27, 28, 33, 36, 37, 38, 40, 44, 46, 47, 48, 49, 50, 52], "focus": [22, 28, 35, 38, 44, 51], "fold": [24, 26, 27, 29, 30, 31, 32, 46], "folder": [5, 6, 24, 26, 33, 42], "folk": [41, 52], "follow": [0, 5, 6, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 46, 52], "font": [22, 23, 24, 35, 36, 37, 40, 41], "font_scal": 33, "fontsiz": [23, 24, 25, 30, 32, 33, 35, 39, 45, 46], "food": [35, 38, 39, 52], "foot": [31, 33], "footag": 28, "footstal": 39, "forc": [30, 33, 46], "force_plot": 33, "forecast": [23, 41, 44, 51, 52], "forest": [30, 31, 39, 40, 41, 44, 50, 52], "forev": 40, "forg": [11, 30, 31, 32, 33, 38, 41, 42], "forget": [23, 27, 32, 50], "form": [10, 27, 30, 34, 36, 37, 38, 41, 44], "formal": 52, "format": [0, 10, 23, 30, 36, 38, 40, 41, 51], "former": 41, "formul": [4, 29], "formula": [28, 31, 39, 43], "forum": [6, 7], "forward": 41, "found": [7, 10, 24, 27, 29, 31, 35, 37, 38, 42, 44, 48, 50, 52], "foundat": [9, 10, 30, 31, 33, 52], "foundation_brktil": 31, "foundation_cblock": 31, "foundation_pconc": 31, "foundation_slab": 31, "foundation_ston": 31, "foundation_wood": 31, "fountain": 39, "four": [23, 24, 34, 36, 44], "fourth": 36, "foxhound": [22, 39], "foyer": 31, "fp": 30, "fpr": 30, "fpr_lr": 30, "fpr_svc": 30, "frac": [23, 28, 30, 31, 35, 38, 39], "fractal": 34, "fraction": [27, 30, 37], "fragment": 46, "frame": [26, 27, 30, 31, 34, 40, 41, 51], "framework": [23, 29], "fraud": [23, 30, 31, 35, 40, 49], "fraudul": [23, 30, 49], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 27, 31, 38, 41], "freedom": [0, 42], "french": [26, 38], "freq": [40, 51], "frequenc": [27, 38, 40, 41, 44, 51], "frequent": [23, 26, 37, 38, 41], "fresh": [37, 38], "fri": [10, 40], "fridai": [10, 52], "friend": [23, 24, 30, 33, 36, 37, 44, 52], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "from_block": 41, "from_estim": [30, 49], "front": 52, "frozen": 42, "fruit": 38, "frustrat": [4, 6, 29], "full": [29, 32, 39, 40, 41, 52], "fullbath": [31, 33], "fulli": 36, "fun": [30, 38, 39], "func": [8, 27, 28, 31], "function": [2, 22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 48, 49, 51], "functiontransform": [27, 41], "fund": 42, "fundament": [2, 9, 10, 15, 26, 28, 29, 31, 34, 39, 41, 52], "funni": [22, 32, 42], "furnish": 0, "furnitur": 44, "further": [30, 32, 34, 35, 38, 39, 41, 46, 48, 49], "futur": [24, 26, 29, 31, 41, 44, 48, 51, 52], "futurewarn": [24, 26, 31, 33, 43], "fyi": 41, "g": [6, 7, 8, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 51, 52], "g26r0dcx4b35vf3nk31216hc0000gr": [26, 33], "gain": [6, 23, 30, 32, 33, 49, 52], "game": [23, 33, 38], "gamma": [28, 29, 32, 46, 48], "gamma_log": [25, 46], "gamma_widget": [25, 46], "gap": [24, 40, 41, 44, 46], "garagearea": [31, 33], "garagecar": [31, 33], "garagecond": [31, 33], "garagefinish": [31, 33], "garagefinish_fin": 31, "garagefinish_miss": 31, "garagefinish_rfn": 31, "garagefinish_unf": 31, "garagequ": [31, 33], "garagetyp": [31, 33], "garagetype_2typ": 31, "garagetype_attchd": 31, "garagetype_bas": 31, "garagetype_builtin": 31, "garagetype_carport": 31, "garagetype_detchd": 31, "garagetype_miss": 31, "garageyrblt": [31, 33], "garlic": 35, "gauss": 38, "gaussian": 36, "gaussianmixtur": 36, "gave": [37, 40], "gbr": 8, "gca": [35, 36, 41], "gd": [22, 31, 33], "gdprv": [31, 33], "gdwo": [31, 33], "gelbart": [0, 1, 23, 38, 48], "gender": [22, 27, 30, 38, 40, 41, 49], "gender_femal": 41, "gender_mal": 41, "gener": [7, 9, 15, 23, 26, 27, 29, 30, 31, 33, 36, 38, 39, 40, 41, 43, 44, 46, 48, 49, 51, 52], "genet": 34, "genom": 34, "genr": 37, "gensim": 38, "gentl": 52, "geograph": 28, "geometr": 23, "georg": 38, "geq": 28, "ger": 8, "german": 38, "get": [4, 5, 6, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52], "get_avg_word_length": 42, "get_cmap": 26, "get_depth": 46, "get_dummi": 26, "get_featur": 39, "get_feature_names_out": [26, 27, 30, 31, 32, 33, 34, 38, 40, 41, 42, 49, 51], "get_length_in_word": 42, "get_lr_data_per_us": 37, "get_permutation_import": 33, "get_relative_length": 42, "get_season": 40, "get_senti": 42, "get_stat": 37, "get_user_profil": 37, "getattr": 41, "gif": [35, 36], "gift": 42, "gigaword": 38, "gini": [23, 33], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 22, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42, 48, 49], "githubusercont": 8, "gitlf": 30, "giulia": [0, 1], "give": [0, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 49], "given": [0, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 49, 51], "gladwel": 35, "glob": [22, 39], "global": [26, 30, 32, 35, 38, 44], "glove": [38, 52], "glq": [31, 33], "gmail": [22, 35], "go": [5, 7, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51], "goal": [2, 25, 26, 29, 30, 35, 36, 37, 38, 42, 48, 50, 51, 52], "goe": [2, 24, 25, 27, 30, 32, 33, 36, 37, 39], "gold": 8, "goldcoast": 40, "golden": [25, 44, 46], "good": [9, 11, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51], "googl": [4, 10, 22, 23, 32, 33, 34, 35, 38, 42], "google_news_vector": 38, "got": [25, 28, 29, 30, 31, 39], "gotten": [41, 50], "gov": [30, 32, 33], "govern": [38, 52], "gpe": 38, "gpt": [37, 38], "gpu": [32, 38, 39], "grad": [30, 32, 33, 49], "grade": [3, 7, 10, 22, 24, 27, 29, 44, 46, 47, 48, 49, 50, 51], "grader": 6, "grades_df": 44, "gradescop": [1, 6, 10, 52], "gradient": [19, 20, 44], "gradientboostingclassifi": 32, "gradientboostingregressor": 32, "gradientexplain": 33, "grading_concern": 6, "graduat": 39, "grai": 39, "grain": [28, 33], "gram": 38, "grammat": 38, "grandma": 34, "grandmoth": 30, "grant": 0, "grant_macewan": 38, "granular": 36, "graph": [10, 39, 40], "graphic": 39, "graphic_design": 38, "graphviz": [23, 45], "grasp": [44, 52], "grayscal": 39, "great": [22, 23, 25, 27, 28, 33, 34, 38, 39, 40, 42], "greater": [11, 34, 35], "greater_is_bett": 31, "greedili": 36, "green": [25, 29, 35, 43], "grei": 52, "grid": [28, 31, 40, 41, 44, 48, 51], "grid_search": [29, 48], "gridsearchcv": [25, 32, 33, 48, 50], "gridsearchcvifittedgridsearchcv": 29, "grip": 38, "grlivarea": [31, 33], "groak": 38, "groceri": [39, 42], "groin": 39, "ground": [24, 34, 36, 37, 52], "ground_truth_categori": 30, "group": [7, 23, 25, 27, 28, 32, 34, 44, 46, 47, 50, 52], "groupbi": [40, 51], "grow": [29, 32, 34], "grow_polici": 32, "growth": [40, 41], "groyn": 39, "grv": 31, "gt": [27, 28, 29, 30, 31, 32], "gtl": 33, "guarante": [29, 30, 32, 35, 39], "guenon": 39, "guess": [25, 26, 38, 42], "guid": [7, 9, 10, 34, 39, 52], "guidanc": 33, "guidelin": [33, 34], "guido": 10, "h": [30, 32, 33, 35, 38, 39, 41, 42, 49], "ha": [2, 5, 6, 10, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 46, 49, 50, 51, 52], "hab": 38, "habit": 27, "hacki": [39, 43], "had": [22, 26, 27, 28, 30, 37, 38, 39, 40, 41], "hadn": [38, 41], "hal": 10, "half": [6, 10, 23, 28, 34, 36], "halfbath": [31, 33], "halvingrandomsearchcv": 29, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 29, "ham": 22, "hand": [4, 9, 30, 37, 49, 52], "handi": 30, "handl": [32, 33, 36, 41, 42, 43, 44, 46, 52], "handle_unknow": 27, "handle_unknown": [26, 27, 29, 30, 31, 32, 33, 40, 41, 44, 48, 49, 50, 51], "handler": [30, 33], "handrail": 39, "handwritten": 30, "hang": 30, "happen": [4, 6, 22, 25, 27, 29, 32, 33, 34, 37, 40, 41, 44, 51, 52], "happi": [30, 35, 41], "happier": 52, "happydb": 30, "hard": [8, 22, 24, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 44, 50], "hardli": 37, "hardwar": 39, "harmon": 30, "harri": 38, "has_cupi": 42, "has_emoji": 42, "has_rais": 42, "hasn": [4, 37, 38, 41], "hassl": [8, 33, 40], "hat": [28, 31, 32], "have": [0, 4, 6, 7, 8, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "haven": [24, 38, 41, 44], "haylei": 23, "hazard": 52, "hc_truncation_toy_demo": 36, "hdbscan": 36, "he": [24, 27, 38, 52], "head": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51], "headlin": 38, "health": 38, "healthcar": 33, "healthi": 38, "heard": 24, "heart": [23, 42, 50], "heart_df": 50, "heartdiseas": 50, "heat": [29, 31, 33, 48], "heating_floor": 31, "heating_gasa": 31, "heating_gasw": 31, "heating_grav": 31, "heating_othw": [31, 33], "heating_wal": 31, "heatingqc": [31, 33], "heatmap": 33, "heavi": [32, 42], "heavili": [37, 39, 40, 49], "heeren": 38, "height": [23, 24, 30, 38, 42, 45], "hell": 42, "help": [3, 7, 11, 22, 24, 26, 27, 29, 30, 33, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 51, 52], "henc": [5, 30, 31, 33, 35], "her": [22, 37, 38], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52], "herebi": 0, "herself": [38, 42], "herta": 25, "heurist": [23, 29], "hi": [38, 46], "hidden": [34, 38, 39], "hide": [8, 39], "hier_label": 36, "hier_labels1": 36, "hier_labels2": 36, "hierarch": [44, 52], "hierarchi": [23, 36], "high": [6, 24, 25, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 52], "high_corr": 33, "higher": [23, 24, 25, 28, 30, 31, 32, 33, 34, 35, 37, 41, 46, 48, 49], "highest": [32, 33, 37, 38, 39, 43, 46, 49], "highland": 42, "highli": [10, 11, 26, 33, 37], "highlight": [4, 39, 44], "highwai": 28, "him": 38, "himself": 38, "hinder": 52, "hindi": 26, "hint": [33, 46], "hist": [26, 29, 31, 34, 41], "histgradientboostingclassifi": 32, "histgradientboostingregressor": 32, "histogram": 41, "histor": 44, "histori": [28, 37, 40, 52], "hit": [22, 29], "hitter": 42, "hl": [31, 33], "hmid": 30, "hmmm": 41, "hockei": 38, "hold": 48, "holder": 0, "holdout": 30, "holidai": [10, 37, 52], "home": [23, 28, 30, 39], "homemak": 38, "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 25, 28, 29, 38, 44, 52], "honour": 52, "hood": 24, "hope": 24, "hopefulli": 48, "hopeless": 34, "hopelessli": 25, "horizont": [23, 27], "host": [5, 41], "hot": [16, 24, 27, 33, 44, 51], "hound": [22, 39], "hour": [4, 11, 30, 32, 33, 34, 37, 40, 44, 49, 52], "hourli": [41, 44], "hous": [18, 31, 33, 34, 41, 46], "houseag": 28, "household": [26, 27, 28, 34, 47], "housestyl": [31, 33], "housestyle_1": 31, "housestyle_1stori": 31, "housestyle_2": 31, "housestyle_2stori": 31, "housestyle_sfoy": 31, "housestyle_slvl": 31, "housewif": 38, "housing_df": [23, 26, 27, 34, 46, 47], "housing_median_ag": [26, 27, 34, 47], "houston": 42, "how": [0, 3, 8, 11, 22, 27, 29, 30, 31, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "howard": 35, "howev": [2, 8, 26, 27, 30, 31, 33, 35, 37, 40, 41, 43, 46, 49], "hsjcy": 41, "hstack": 40, "html": [7, 9, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 41, 42, 45, 47, 49], "http": [0, 5, 8, 9, 11, 22, 23, 24, 26, 27, 28, 30, 31, 32, 39, 40, 41, 42, 49, 52], "hug": 37, "huge": [27, 31, 38, 39, 40, 41, 51], "human": [0, 22, 25, 26, 27, 28, 29, 30, 33, 34, 35, 38, 39, 49], "humidity3pm": [40, 51], "humidity3pm_lag1": [40, 51], "humidity9am": [40, 51], "hummu": [35, 38], "humour": [10, 38], "hundr": 28, "hurrai": 50, "hurrican": 22, "husband": [30, 32, 33], "hussar": [22, 39], "hw": 22, "hw1": [4, 10, 45], "hw2": [10, 25, 26, 48], "hw3": 10, "hw4": 10, "hw5": [10, 52], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 37, "hyperband": 29, "hyperopt": 29, "hyperparamet": [10, 24, 30, 36, 37, 38, 39, 48], "hyperparamt": [24, 29, 41], "hyperparlan": 28, "hyperplan": 28, "hypothesi": [38, 41], "hypothet": [28, 35], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 28, 31, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "i1": 32, "i2": 32, "ia": 42, "ibm": 42, "ic": 38, "icc": 52, "iclick": 10, "id": [22, 23, 31, 33, 37, 46], "idea": [8, 23, 24, 26, 29, 33, 35, 36, 37, 38, 39, 40, 41, 44, 46, 51], "ideal": [4, 30, 32, 34, 37, 41], "ident": [38, 39, 42], "identif": [22, 42], "identifi": [23, 24, 25, 26, 29, 30, 31, 35, 36, 38, 39, 40, 44, 49, 51, 52], "idf": 27, "idli": 38, "idx": 39, "idxmax": 25, "if_binari": [27, 30, 32, 33, 44, 47, 49, 50], "ifram": [24, 30], "igloo": 38, "ignor": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 41, 44, 48, 49, 50, 51], "ignore_index": 8, "ii": 30, "iii": 10, "ij": [28, 37], "ik": 32, "ill": 52, "illus": [30, 49], "illustr": [36, 40], "iloc": [8, 23, 24, 25, 26, 27, 32, 33, 38, 40, 42, 45, 50, 51], "im": 42, "imag": [7, 24, 30, 33, 34, 35, 36, 40, 44, 49, 52], "image_dataset": 39, "image_datasets_bw": 39, "image_s": 39, "imagefold": 39, "imagenet": 43, "imagenet1k_v1": 39, "imagenet_class": [22, 39], "imagin": [22, 23, 24, 26, 28, 30, 33, 34, 35, 38, 41, 44, 45, 49], "imaginari": [24, 38], "imbal": [18, 35, 41, 49], "imbalanc": [30, 31, 43], "imblearn": 30, "img": [22, 39], "img_classifi": 22, "img_path": 22, "img_t": 39, "immedi": [33, 37, 52], "imp": [26, 27, 40], "impact": [7, 27, 28, 32, 33, 36, 40, 46, 51, 52], "implement": [2, 4, 22, 26, 30, 31, 32, 34, 36, 37, 38, 41, 43], "impli": [0, 41], "implic": [26, 44, 52], "implicit": 38, "import": [8, 10, 21, 43, 47, 48, 49, 50, 52], "importance_typ": 32, "importances_mean": 33, "impos": 26, "imposs": 35, "impress": 33, "improv": [29, 30, 31, 32, 34, 35, 36, 37, 40, 41, 44, 48, 52], "impur": [23, 32], "imput": [16, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 44, 47, 48, 49, 50, 51], "imread": 39, "imshow": [22, 39], "inbox": 24, "inc": [33, 38], "incept": [37, 39], "inception": 39, "incl": 31, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 23, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52], "include_bia": [34, 40], "incom": [24, 28, 30, 32, 33, 49], "incomplet": 41, "inconsist": 27, "incorpor": [29, 31, 34, 41, 44], "incorrect": 41, "incorrectli": [22, 30], "increas": [8, 24, 25, 27, 28, 32, 33, 34, 35, 36, 39, 46, 48], "increasingli": 22, "incred": 39, "inde": 33, "independ": [8, 9, 23, 29, 31, 32, 34, 40, 52], "index": [22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 46, 49, 50, 51], "index_col": [8, 25, 26, 29, 30, 37, 48], "india": 38, "indian": 30, "indian_liver_pati": 22, "indic": [0, 27, 35, 37, 38, 39, 40, 41], "individu": [32, 33, 35, 37, 38, 41, 50, 52], "industri": [32, 34, 38, 39], "inequ": [30, 49], "inertia_": 35, "inertia_valu": 35, "inf": [25, 41], "infeas": 29, "infer": [23, 38, 39, 40, 45], "infin": 25, "infinit": 29, "inflamm": 9, "inflat": 33, "inflect": [35, 38], "influenc": [23, 24, 29, 33, 35, 37, 41, 46], "info": [1, 3, 8, 26, 27, 30, 31, 34, 38, 40, 41, 46, 50, 51], "infom": 38, "infor_m": 38, "inform": [1, 4, 7, 11, 23, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 46, 49, 50, 51, 52], "informa_t": 38, "informaion": 38, "informaiton": 38, "informationabout": 38, "informationon": 38, "inhabit": 52, "inher": [30, 40, 41, 49], "initi": [36, 39, 42], "initj": 33, "inject": [34, 37, 44], "inland": [26, 27, 34, 47], "inlin": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 45, 46, 48, 49, 50], "inner": [27, 29, 38], "inplac": [8, 22, 23, 29], "input": [8, 23, 26, 28, 32, 33, 36, 38, 39, 40, 42, 44, 51], "input_img": 39, "inputs_bw": 39, "insid": [9, 27, 30], "insight": [2, 25, 30, 33, 35, 52], "inspct": 30, "inspect": [33, 36], "inspir": [23, 30, 32], "instal": [22, 25, 30, 31, 32, 33, 35, 38, 39, 41, 42], "instanc": [22, 23, 24, 27, 28, 30, 35, 36, 37, 38, 39, 40, 43], "instanti": [29, 46], "instead": [5, 8, 11, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 48, 49, 50], "institut": [38, 42], "instruct": [3, 4, 5, 11, 25, 52], "instructor": [4, 6, 22, 52], "instrument": [25, 26, 29, 48], "int": [26, 27, 30, 32, 33, 38, 40, 42, 49, 50, 51], "int32": [25, 35, 36, 40], "int64": [23, 25, 27, 30, 31, 37, 38, 40, 41, 42], "integ": [8, 24, 26, 29, 32, 33, 40], "integr": 52, "intellig": [10, 38], "intelligen": 38, "intend": 0, "intens": 38, "inter": 42, "interact": [9, 25, 29, 30, 33, 35, 36, 37, 40, 42, 46], "interaction_constraint": 32, "interaction_onli": [34, 40], "interactive_plot": [25, 46], "interactiveshel": 42, "intercept": [33, 39, 43], "intercept_": [28, 32, 39, 43], "intercept_sc": 30, "interest": [2, 22, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 48, 50, 51], "interfac": 32, "intermedi": [36, 39], "intern": [0, 1, 23, 39, 40, 41, 42], "internet": 41, "internetservic": 41, "internetservice_dsl": 41, "internetservice_fib": 41, "internetservice_no": 41, "internship": 22, "interpret": [10, 11, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 49, 52], "interv": [40, 41, 44, 48, 52], "intrins": 40, "intro": [10, 19, 20, 38, 39], "introduc": [27, 30, 41], "introduct": [9, 10, 11, 13, 16, 40, 41, 46, 52], "intslid": [25, 46], "intuit": [25, 26, 27, 29, 31, 33, 35, 36, 41, 42, 52], "invalid": 29, "inventori": 44, "invers": [28, 31], "inverse_func": 31, "investig": [25, 33, 46], "involv": [2, 4, 29, 31, 32, 36, 38, 39], "io": [9, 26, 39, 41, 42], "io_loop": 42, "ipkernel": 42, "ipykernel": 42, "ipykernel_19402": 33, "ipykernel_32469": 26, "ipykernel_79734": 24, "ipykernel_86208": 42, "ipykernel_launch": 42, "ipynb": [7, 8], "ipython": [22, 23, 24, 25, 26, 27, 28, 30, 38, 42, 45, 47, 49], "ipywidget": [25, 46], "ir1": [31, 33], "ir2": [31, 33], "iri": [25, 46], "iris_df": [25, 46], "irregular": 52, "irregularli": 44, "irrelev": [25, 34, 38], "irrelevant_po": 38, "irrespect": [24, 28, 52], "is_avail": 39, "is_leap_year": [40, 51], "is_stop": 38, "is_year_end": [40, 51], "isinst": 41, "island": [26, 27], "isn": [24, 25, 30, 31, 32, 38], "isnul": 26, "isol": [11, 30, 31, 33], "issu": [4, 6, 7, 32, 37, 41, 44, 48, 52], "issubclass": 41, "isupp": 42, "itali": 38, "item": [22, 32, 33, 35, 37, 38, 39, 41, 44, 50], "item_inverse_mapp": 37, "item_kei": 37, "item_mapp": 37, "iter": [29, 34, 35, 36, 39], "iterable_with_config": 27, "iterrow": 37, "its": [8, 22, 24, 25, 27, 28, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 46, 48, 51, 52], "itself": [7, 30, 32, 36, 38], "j": [8, 28, 33, 34, 35, 37, 39], "j6": 42, "jackin": 29, "jackpot": 27, "jaguar": [22, 39], "jalebi": 38, "jam": 29, "jame": [38, 41, 42], "jan": 1, "januari": 40, "japan": 38, "jargon": 23, "jason": [10, 34], "javascript": 33, "jazz_musician": 38, "jellyfish": 39, "jennif": 42, "jerri": 37, "jet": 26, "jetti": 39, "jieba": 38, "jim": 37, "jmlr": 29, "joan_baez": 38, "job": [27, 40, 41, 51], "joblib": 27, "john": 32, "johnny_cash": 38, "join": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52], "jointli": 40, "joke": [22, 37], "jolen": 42, "joni_mitchel": 38, "joseph": 52, "journal": 38, "journei": [10, 36, 52], "jpg": 39, "ju": 22, "jubatu": [22, 39], "judg": 34, "juic": 38, "juli": 40, "jun": 52, "june": [10, 40], "junh": 52, "jupyt": [1, 7, 8, 9, 11, 22, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42], "jupyter_notebook": 41, "jupyterlab": 33, "jurafski": 38, "jurisdict": 38, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 46, 50, 51, 52], "justic": [33, 38, 52], "justif": 50, "k": [7, 10, 15, 24, 28, 30, 31, 32, 34, 38, 39, 41, 42, 43, 46, 52], "k_neighbor": 30, "k_valu": 25, "kaggl": [23, 26, 30, 31, 32, 33, 34, 39, 49, 50], "kaggler": 34, "kangaroo": 39, "kaplan": 52, "kaplanmeierfitt": 41, "kb": [27, 31, 41], "kbinsdiscret": 34, "kbinsdiscretizer__latitude_0": 34, "kbinsdiscretizer__latitude_1": 34, "kbinsdiscretizer__latitude_2": 34, "kbinsdiscretizer__latitude_3": 34, "kbinsdiscretizer__latitude_4": 34, "kbinsdiscretizer__latitude_5": 34, "kbinsdiscretizer__latitude_6": 34, "kbinsdiscretizer__latitude_7": 34, "kbinsdiscretizer__latitude_8": 34, "kbinsdiscretizer__latitude_9": 34, "kbinsdiscretizer__longitude_11": 34, "kbinsdiscretizer__longitude_12": 34, "kbinsdiscretizer__longitude_13": 34, "kbinsdiscretizer__longitude_14": 34, "kbinsdiscretizer__longitude_15": 34, "kbinsdiscretizer__longitude_16": 34, "kbinsdiscretizer__longitude_17": 34, "kbinsdiscretizer__longitude_18": 34, "kbinsdiscretizer__longitude_19": 34, "kbinsdiscretizerkbinsdiscret": 34, "kc_house_data": [22, 23, 46], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 30, 32, 33, 34, 35, 37, 38, 41, 46, 47, 52], "keep_empty_featur": 37, "kei": [9, 23, 24, 25, 26, 29, 30, 31, 32, 37, 38, 41, 48, 50, 52], "kelbowvisu": 35, "kellei": 28, "kelli": 52, "kept": 24, "kera": 33, "kernel": [7, 10, 15, 26, 28, 29, 33, 34, 46], "kernelapp": 42, "kernelbas": 42, "kernelexplain": 33, "keyword": [4, 29, 42], "kfold": 30, "kick": 38, "kilian": 33, "kill": 41, "kimia": 52, "kind": [0, 22, 23, 24, 26, 27, 28, 30, 31, 33, 35, 36, 37, 39, 40, 41, 43, 51], "king": [37, 38, 46], "kitchenabvgr": [31, 33], "kitchenqu": [31, 33], "kiwi": 38, "kk": 35, "km": [41, 44], "km_label": 35, "kmean": [35, 36, 44], "kmf": 41, "kmqfw": 41, "kneighborregressor": 26, "kneighborsclassifi": [26, 27, 28, 34, 46, 47], "kneighborsregressor": [26, 27, 28, 47], "kneighborsregressorkneighborsregressor": [26, 27], "knew": 35, "knn": [2, 15, 24, 25, 26, 27, 28, 33, 34, 37, 39, 43, 44, 50], "knn1": 25, "knn100": 25, "knn_pipe": 27, "knn_scale": 26, "knn_unscal": 26, "knn_valid_accuraci": 25, "knnimput": 37, "knob": 23, "know": [8, 10, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52], "knowledg": [8, 23, 27, 29, 34, 35, 38, 44], "knowleg": 44, "known": [37, 38, 41], "koala": 39, "kolhatkar": [0, 1, 38], "kr9rkqfj4w78h49djkz8yy9r0000gp": 24, "ksatr": 41, "kvarada": [11, 23, 24, 27, 29, 33, 38, 39, 41, 43], "kvarada01": 11, "kwantlen": 38, "kwarg": [24, 26, 27, 41, 42], "l": 11, "l1": [10, 41], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 30, "l2": [10, 30, 38, 41], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "lab": [11, 23, 24, 35, 37], "lab1": [23, 24, 27, 44], "lab2": [23, 24, 27, 44], "lab3": [23, 24, 27, 44], "lab4": [23, 24, 27, 44], "label": [7, 8, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 47], "label_": [38, 42], "label_encod": [32, 33], "label_n_clust": 36, "labelencod": [32, 33], "labels": [30, 35], "labels_": [35, 36], "lack": [24, 37], "lag": [41, 44], "lag_df": 40, "lakehead_univers": 38, "lakeshor": 39, "lakesid": 39, "lambda": [8, 23, 28, 36, 39, 40, 41, 42], "land": 41, "landcontour": [31, 33], "landcontour_bnk": 31, "landcontour_hl": 31, "landcontour_low": 31, "landcontour_lvl": 31, "landmark": 44, "landown": 42, "landscap": [35, 38], "landslop": [31, 33], "landslope_gtl": [31, 33], "landslope_mod": [31, 33], "landslope_sev": [31, 33], "langara_colleg": 38, "languag": [2, 9, 26, 27, 37, 39, 42], "language_enc": 26, "language_english": 26, "language_french": 26, "language_hindi": 26, "language_mandarin": 26, "language_spanish": 26, "language_vietnames": 26, "laptop": 22, "lar": 22, "larg": [22, 24, 25, 26, 28, 30, 31, 35, 36, 38, 39, 44, 46, 49], "larger": [23, 24, 25, 26, 28, 29, 31, 32, 33, 35, 36, 41], "largest": 31, "larvatu": [22, 39], "last": [8, 23, 24, 25, 26, 27, 30, 33, 37, 39, 40, 41, 42, 46, 48, 50, 51, 52], "last_row": 8, "lastp": 36, "lat": [22, 23], "late": [30, 52], "latent": [37, 38, 39], "latentdirichletalloc": 38, "later": [11, 23, 27, 30, 39, 40, 46], "latest": [27, 33, 41], "latex": [4, 7], "latin": [22, 30, 49], "latitud": [24, 25, 26, 27, 28, 34, 47], "latitude_0": 34, "latitude_1": 34, "latitude_10": 34, "latitude_11": 34, "latitude_12": 34, "latitude_13": 34, "latitude_14": 34, "latitude_15": 34, "latitude_16": 34, "latitude_17": 34, "latitude_18": 34, "latitude_19": 34, "latitude_2": 34, "latitude_3": 34, "latitude_4": 34, "latitude_5": 34, "latitude_6": 34, "latitude_7": 34, "latitude_8": 34, "latitude_9": 34, "latter": 31, "launch_inst": 42, "launch_new_inst": 42, "lauvagrand": 42, "law": 38, "lawsuit": 38, "layer": 39, "layout": [25, 46], "lazi": 25, "lbfg": 30, "lda": 39, "ldot": 29, "lead": [8, 10, 24, 28, 31, 36, 37, 38, 41], "leaf": [23, 36, 38], "leagu": 38, "leak": [26, 41, 44], "leakag": 44, "leaner": 24, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "learner": [24, 25, 32], "learning_method": 38, "learning_r": 32, "learnxinyminut": 9, "least": [4, 10, 24, 25, 30, 31, 33, 34, 35, 36, 50, 51, 52], "least_confident_i": 28, "least_confident_x": 28, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 36, 39, 41, 43], "lec11": 19, "lectur": [5, 7, 8, 11, 19, 44, 49], "lecun": 33, "lee": 33, "left": [7, 22, 29, 30, 31, 35, 36, 38, 40, 41, 52], "legal": [0, 38], "legend": [7, 8, 25, 28, 30, 31, 34, 35, 39, 40, 41, 43], "legendari": 42, "leisur": 30, "lemma": 38, "lemma_": 38, "lemmat": 38, "lemon": 35, "len": [24, 26, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42], "length": [23, 24, 25, 28, 31, 33, 35, 36, 38, 40, 41, 42, 46, 51], "leo": 32, "leopard": [22, 39], "leq": [34, 35], "less": [5, 6, 10, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 41, 44, 46, 49], "lesson": [9, 26, 42], "lesssim": 24, "let": [22, 23, 24, 28, 29, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "letter": [28, 42], "lev": 31, "level": [25, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 49, 52], "leverag": [33, 37], "lewi": 42, "lexic": 38, "lexicon": 42, "lg": 19, "lgbm": [32, 33, 44, 52], "lgbmclassifi": [22, 32, 33, 50], "lgbmclassifierifittedlgbmclassifi": [22, 33], "lgbmclassifierlgbmclassifi": 32, "lgbmregressor": [22, 32], "li": 28, "liabil": 0, "liabl": 0, "liao": 22, "lib": [23, 24, 27, 29, 33, 41, 42, 43], "librari": [4, 8, 11, 24, 30, 33, 34, 38, 39, 40, 42, 46], "licensor": 0, "life": [23, 28, 35, 37, 45, 52], "lifelin": [41, 52], "lifetim": 41, "lighter": 29, "lightgbm": [22, 33, 50], "lightweight": 38, "like": [2, 4, 7, 8, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52], "likelihood": 41, "likewis": 7, "lime": 33, "limit": [0, 22, 23, 24, 27, 32, 33, 42, 44, 45, 48, 52], "linalg": 38, "line": [4, 8, 11, 23, 27, 28, 29, 30, 31, 35, 38, 39, 40, 41, 42, 46, 48], "line2d": 8, "linear": [10, 17, 21, 29, 30, 32, 34, 36, 37, 39, 40, 41, 43, 44], "linear_model": [22, 28, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 49, 50, 51], "linear_svc": 28, "linearli": [28, 34, 40], "linearregress": [28, 31, 34, 41, 42], "linestyl": [35, 40, 51], "linewidth": 40, "linger": 25, "lingual": 38, "linguist": 27, "link": [0, 4, 5, 7, 10, 22, 23, 27, 28, 31, 32, 36, 41], "linkag": 36, "linkage_arrai": 36, "linkage_typ": 36, "linkedin": 37, "linspac": [28, 29, 31, 34, 48], "lion": 37, "list": [4, 7, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 41, 50, 52], "listedcolormap": 28, "liter": 42, "literatur": 32, "littl": [8, 30, 39], "live": [10, 11, 25, 26, 27, 29, 35, 41, 48], "liver": 23, "livestream": 52, "ll": [6, 7, 10, 11, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 51, 52], "llazx": 41, "llm": 10, "lo": 42, "load": [8, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 42, 46, 47, 49], "load_breast_canc": 34, "load_citibik": 40, "load_iri": [25, 46], "loan": [30, 49], "loc": [8, 25, 28, 30, 33, 37, 40, 41, 51], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 30, 32, 33, 34, 39, 42], "locat": [8, 27, 35, 37, 38, 40, 42, 50, 51, 52], "location_katherin": 40, "location_mountginini": 40, "location_townsvil": 40, "location_witchcliff": 40, "location_wollongong": 40, "lock": 24, "log": [25, 31, 32, 41, 46, 50, 52], "log10": 31, "log1p": 31, "log2": 41, "log_likelihood_ratio_test": 41, "logarithm": [25, 46], "logic": 34, "logical_xor": 34, "login": 37, "logisit": 39, "logist": [17, 32, 33, 40, 41, 42, 43, 44, 49, 50, 51], "logisticregress": [22, 28, 31, 32, 33, 34, 38, 39, 42, 43, 49, 50, 51], "logisticregressionifittedlogisticregress": 39, "logisticregressionlogisticregress": [30, 32, 39, 42], "logloss": 33, "lognorm": 29, "logspac": [29, 48], "loguniform": [29, 48], "lol": 27, "london": 42, "lone": 36, "long": [0, 22, 23, 28, 30, 32, 36, 37, 41, 44, 52], "longer": [7, 29, 30, 39, 41], "longest": 23, "longitud": [24, 25, 26, 27, 28, 34, 47], "longitude_0": 34, "longitude_1": 34, "longitude_10": 34, "longitude_11": 34, "longitude_12": 34, "longitude_13": 34, "longitude_14": 34, "longitude_15": 34, "longitude_16": 34, "longitude_17": 34, "longitude_18": 34, "longitude_19": 34, "longitude_2": 34, "longitude_3": 34, "longitude_4": 34, "longitude_5": 34, "longitude_6": 34, "longitude_7": 34, "longitude_8": 34, "longitude_9": 34, "look": [1, 11, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50], "lookatm": 22, "loop": [29, 32, 40, 43, 44], "loos": 36, "lose": [6, 27], "loss": [2, 30, 31, 32, 33, 38, 41, 49], "lot": [5, 9, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 36, 39, 40, 41, 48, 52], "lotarea": [31, 33], "lotconfig": [31, 33], "lotconfig_corn": 31, "lotconfig_culdsac": 31, "lotconfig_fr2": 31, "lotconfig_fr3": 31, "lotconfig_insid": 31, "lotfrontag": [31, 33], "lotshap": [31, 33], "lotshape_ir1": 31, "lotshape_ir2": 31, "lotshape_ir3": 31, "lotshape_reg": 31, "loud": [25, 26, 29, 44, 48], "loui": 40, "lourenzutti": 29, "love": 42, "low": [6, 24, 25, 29, 30, 31, 33, 34, 35, 36, 41], "lower": [24, 25, 30, 31, 33, 35, 37, 38, 41, 48, 52], "lowercas": [26, 27], "lowest": [46, 52], "lowqualfinsf": [31, 33], "lr": [28, 30, 31, 33, 39, 40, 41, 42, 43], "lr_1": 34, "lr_2": 34, "lr_3": 34, "lr_coef": [33, 40, 41, 51], "lr_coefs_landslop": 33, "lr_flatten_pip": 39, "lr_item": 37, "lr_pipe": [31, 33, 40], "lr_pred": [30, 31], "lr_scale": 33, "lr_schedul": 39, "lr_x": 37, "lr_y": 37, "ls15hb": 22, "lstm": 40, "lt": [24, 26, 27, 29, 30, 31, 32, 33, 34, 41], "ltorgo": 28, "lucki": [25, 29], "luckili": [48, 50], "lundberg": 33, "luster": 36, "lvert": 38, "lvl": [31, 33], "lwq": [31, 33], "lynx": [22, 39], "l\u00e9cuyer": 38, "m": [11, 22, 24, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "m_neighbor": 30, "ma": [29, 38], "macaqu": [22, 39], "macbook": 11, "mach": 38, "machin": [2, 9, 10, 11, 13, 14, 15, 26, 27, 29, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 46, 51, 52], "mackworth": 10, "made": [0, 6, 7, 8, 22, 23, 30, 32, 33, 37, 38, 39, 40, 48], "magazin": 38, "magnitud": [29, 31, 33, 38, 40, 51], "maguir": 37, "mahsa": 52, "mai": [0, 7, 8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52], "mail": 41, "main": [8, 11, 23, 25, 27, 32, 35, 36, 44, 52], "mainland": 28, "maintain": [32, 37, 44], "mainten": 32, "maj1": [31, 33], "maj2": [31, 33], "major": [2, 24, 25, 26, 27, 38, 44, 45, 50], "major_biologi": 27, "major_comput": 27, "major_econom": 27, "major_linguist": 27, "major_mathemat": 27, "major_mechan": 27, "major_phys": 27, "major_psychologi": 27, "make": [2, 4, 5, 6, 7, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52], "make_blob": [25, 35, 36, 39, 43], "make_circl": 36, "make_classif": [25, 30], "make_column_transform": [29, 30, 31, 32, 33, 34, 40, 41, 42, 47, 48, 49, 50, 51], "make_forg": 25, "make_grid": 39, "make_imb_pipelin": 30, "make_moon": 36, "make_num_tree_plot": 32, "make_pipelin": [22, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51], "make_scor": [31, 34, 42], "malcolm": [35, 37], "malcom": 35, "male": [30, 32, 33, 41, 49], "male_cm": [30, 49], "male_pr": [30, 49], "mall": 42, "man": [37, 38], "manag": [5, 40, 41, 44, 52], "mandarin": 26, "mango": 38, "mani": [2, 5, 8, 10, 22, 23, 24, 25, 26, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 48, 50, 51, 52], "manner": [0, 32], "manual": [11, 22, 27, 30, 34, 35, 36, 38, 48], "manufactur": 39, "map": [10, 23, 24, 27, 29, 37, 48], "mape": 44, "mape_scor": 31, "maple_leaf": 38, "mapper": 37, "march": 40, "marit": [30, 32, 33, 49], "mark": [6, 7, 29, 30, 36, 52], "marker": [25, 28, 35], "markers": [28, 30], "market": [22, 35, 39, 40], "markov": 38, "marri": [30, 32, 33], "martin": 38, "mask": 29, "massiv": [27, 29], "master": [8, 29, 30, 32, 33, 38, 49], "masvnrarea": [31, 33], "masvnrtyp": [31, 33], "masvnrtype_brkcmn": 31, "masvnrtype_brkfac": 31, "masvnrtype_miss": 31, "masvnrtype_ston": 31, "match": [27, 28, 30, 32, 33, 40, 50, 51], "materi": [8, 11, 19, 22, 23, 24, 25, 35, 38, 41, 44, 52], "matern": 34, "math": [2, 35, 37, 41], "mathcal": 25, "mathemat": [2, 27, 32, 44], "mathematician": 38, "mathia": 42, "matlab": 8, "matplotlib": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "matplotlibdeprecationwarn": 33, "matric": [25, 30, 37, 49], "matrix": [18, 27, 36, 38, 44, 49], "matter": [26, 27, 30, 32, 36, 44], "max": [8, 24, 26, 28, 29, 30, 31, 32, 35, 36, 40, 51], "max_bin": 32, "max_cat_threshold": 32, "max_cat_to_onehot": 32, "max_clust": 36, "max_colwidth": [22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 45, 46, 47, 48, 49], "max_delta_step": 32, "max_depth": [24, 25, 29, 32, 33, 45, 46], "max_depth_widget": [25, 46], "max_df": 27, "max_displai": 33, "max_featur": [22, 27, 29, 32, 48], "max_it": [22, 30, 32, 33, 34, 38, 39, 40, 41, 42, 43, 49], "max_leaf_nod": 23, "max_leav": 32, "max_opt": [25, 30, 35, 36], "max_row": 41, "maxclust": 36, "maxent": 43, "maxhr": 50, "maxim": [22, 30, 31, 35], "maximum": [23, 26, 31, 32, 35, 36, 46, 52], "maxosx": 11, "maxtemp": [40, 51], "may": 10, "mayb": [30, 33, 40, 52], "maybe_coerce_valu": 41, "mb": [26, 27, 30, 34, 40, 41, 51], "md": [11, 23, 38], "me": [8, 22, 29, 38, 42], "mean": [5, 6, 8, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52], "mean_absolute_percentage_error": 31, "mean_cv_error": 24, "mean_cv_scor": [25, 28, 29], "mean_fit_tim": [29, 31], "mean_scor": [24, 26, 29, 42], "mean_score_tim": [29, 31], "mean_squared_error": [31, 34, 42], "mean_std_cross_val_scor": [24, 26, 27, 32, 33, 41, 42], "mean_test_neg_mean_squared_error": 31, "mean_test_scor": [29, 31, 48], "mean_train_error": 24, "mean_train_neg_mean_squared_error": 31, "mean_train_scor": [25, 28, 29, 31], "meaning": [25, 27, 30, 33, 35, 38, 47, 52], "meaningless": 36, "measur": [0, 22, 23, 24, 25, 30, 31, 33, 35, 36, 37, 38, 40, 41, 44, 46, 50, 51], "mechan": [27, 44], "mechanical_engin": 38, "medal": 8, "median": [23, 26, 27, 28, 31, 33, 34, 40, 41, 51], "median_house_valu": [26, 27, 34, 47], "median_incom": [26, 27, 34, 47], "medic": [30, 35, 52], "medinc": 28, "medit": 30, "medium": [0, 25, 41, 44], "meet": 38, "meier": 52, "melbourneairport": [40, 51], "member": [28, 32, 52], "membership": [27, 35, 36], "memori": [8, 26, 27, 30, 31, 32, 34, 39, 40, 41, 44, 51], "mention": [0, 4, 28, 41], "menu": 11, "merchant": 0, "merg": [0, 5, 11, 36], "meshgrid": 34, "mess": [37, 41], "messag": [4, 6, 11, 24, 27], "messi": [34, 38], "met": 52, "meta": 32, "metacademi": 10, "method": [2, 23, 25, 26, 28, 30, 32, 33, 36, 37, 38, 39, 40, 41, 43, 44, 50, 51, 52], "methodologi": [26, 40], "metric": [10, 25, 27, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 49, 50, 52], "mexico": 30, "mglearn": [23, 24, 25, 26, 27, 28, 29, 30, 35, 38, 39, 40, 43, 45, 46, 48, 49], "mi": [22, 29, 30], "microsoft": 42, "midnight": 40, "midterm": [6, 10], "might": [6, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 46, 52], "mightn": 38, "mike": [0, 1, 9, 23, 48], "mikolov": 38, "milk": 38, "mill": 32, "millennia": 52, "million": 39, "min": [10, 28, 31, 36, 40, 51], "min1": [31, 33], "min2": [31, 33], "min_child_weight": 32, "min_df": 27, "min_sampl": 36, "min_samples_leaf": 23, "min_samples_split": 23, "min_token_len": 38, "min_token_length": 38, "mind": [24, 26, 27, 32, 33, 37, 41, 44, 52], "mine": 10, "minibatchkmean": 36, "miniconda": 11, "miniconda3": [11, 42], "miniforge3": [23, 24, 27, 29, 33, 41, 43], "minim": [5, 23, 31, 35, 36], "minimum": [8, 24, 26, 36, 38], "minmaxscal": [26, 27], "minor": [6, 41], "mintemp": [40, 51], "minut": [4, 23, 34, 41, 44], "miracl": 42, "miscalcul": 10, "miscfeatur": [31, 33], "miscfeature_gar2": 31, "miscfeature_miss": 31, "miscfeature_othr": 31, "miscfeature_sh": 31, "miscfeature_tenc": 31, "misclassifi": 49, "misconduct": 52, "miscval": [31, 33], "mislead": [24, 30], "miss": [11, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 40, 41, 44, 46, 48, 49, 51, 52], "mistak": [26, 32, 41, 46], "mit": [0, 1], "mitig": [37, 52], "mitlp": 41, "mitt": 38, "mitten": 38, "mix": 31, "mixtur": [36, 38, 39], "ml": [2, 9, 10, 14, 15, 23, 26, 32, 36, 38, 39, 52], "ml_experi": [23, 24, 27, 44], "mlpclassifi": 39, "mlpregressor": 39, "mm": [40, 51], "mmsto": 22, "mn": [31, 33], "mnprv": [31, 33], "mnww": [31, 33], "mo": 38, "mobil": [27, 39], "mobilenet": 39, "mod": [31, 33], "mode": [25, 26, 29, 48], "model": [2, 10, 19, 20, 21, 29, 30, 35, 36, 37, 40, 43, 45, 48, 51, 52], "model_nam": 37, "model_select": [22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51], "modern": [10, 25, 38], "modif": 41, "modifi": [0, 11, 30, 41, 52], "modul": [9, 10, 23, 24, 30, 42], "moe": 29, "mole": 39, "mom": 34, "moment": [30, 48, 50, 52], "mon": [10, 40], "monarch": 38, "monarchi": 38, "mondai": [10, 40, 52], "monei": [8, 41], "monitor": 38, "monkei": [22, 39], "monotone_constraint": 32, "montani": 42, "month": [24, 27, 31, 41, 51], "month_nam": [40, 51], "monthli": 41, "monthlycharg": 41, "montreal": [38, 42], "moon": 36, "moosvi": [0, 1, 38, 52], "moral": [0, 35], "more": [1, 2, 5, 6, 8, 10, 11, 14, 24, 29, 32, 33, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52], "morn": 22, "morpholog": 38, "moskowitz": 35, "mosold": [31, 33], "mosold_1": 31, "mosold_10": 31, "mosold_11": 31, "mosold_12": 31, "mosold_2": 31, "mosold_3": 31, "mosold_4": 31, "mosold_5": 31, "mosold_6": 31, "mosold_7": 31, "mosold_8": 31, "mosold_9": 31, "most": [7, 8, 11, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 50, 52], "most_confident_i": 28, "most_confident_x": 28, "most_frequ": [23, 25, 26, 30, 31, 33, 45], "most_similar": 38, "mostli": [8, 27, 40], "motiv": [19, 20, 21, 22, 27], "mountginini": 40, "move": [7, 12, 28, 33, 34, 45, 50, 52], "movi": [28, 38, 42], "movie_feats_df": 37, "movie_id": 37, "movie_nam": 37, "movies_rated_by_pat": 37, "movies_to_pr": 37, "movieto": 42, "mpimg": 39, "mri": 44, "mrtssm448usn": 40, "mse": [23, 37, 44], "msg": [27, 41], "mssubclass": [31, 33], "mssubclass_120": 31, "mssubclass_160": 31, "mssubclass_180": 31, "mssubclass_190": 31, "mssubclass_20": 31, "mssubclass_30": 31, "mssubclass_40": 31, "mssubclass_45": 31, "mssubclass_50": 31, "mssubclass_60": 31, "mssubclass_70": 31, "mssubclass_75": 31, "mssubclass_80": 31, "mssubclass_85": 31, "mssubclass_90": 31, "mszone": [31, 33], "mszoning_c": [31, 33], "mszoning_fv": 31, "mszoning_rh": 31, "mszoning_rl": 31, "mszoning_rm": 31, "much": [4, 5, 8, 23, 24, 25, 26, 27, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 46, 48, 52], "mueller": 10, "multi": [31, 33, 35, 38, 40], "multi_class": [30, 43], "multi_strategi": 32, "multiclass": [39, 43], "multicoliniar": 33, "multicultur": 38, "multilevel": 31, "multimod": 35, "multinomi": 43, "multipl": [7, 8, 24, 28, 29, 32, 33, 38, 39, 40, 41, 51], "multiplelin": 41, "multiplelines_no": 41, "multiplelines_y": 41, "multipli": [28, 29, 30, 32, 34, 41], "music": [37, 42], "musqueam": 52, "must": [0, 6, 7, 8, 23, 24, 26, 33, 36, 38, 41, 42, 52], "mustn": 38, "mutual": 36, "mwf": 52, "my": [6, 11, 22, 29, 30, 35, 38, 42, 52], "my_heatmap": [29, 48], "my_map": 31, "mypreprocessor": 38, "myself": [23, 38], "m\u00fcller": 9, "n": [10, 23, 25, 28, 29, 31, 32, 33, 34, 36, 37, 38, 40, 42, 43, 46, 51], "n_bin": 34, "n_class": [25, 30, 49], "n_cluster": [35, 36], "n_clusters_per_class": 30, "n_compon": 38, "n_constitu": 32, "n_estim": [34, 40, 41], "n_exampl": 35, "n_feat": 25, "n_featur": [25, 30, 35, 48], "n_features_to_select": 34, "n_inform": 30, "n_init": 35, "n_iter": 48, "n_job": [27, 30, 31, 32, 48], "n_neighbor": [37, 46], "n_neighbors_selector": 25, "n_neighbors_widget": [25, 46], "n_redund": 30, "n_rental": 40, "n_rentalsin3hour": 40, "n_rentalsin6hour": 40, "n_repeat": 33, "n_resourc": 29, "n_sampl": [25, 30, 35, 36, 39, 43, 49], "n_split": 40, "n_threshold": 30, "n_topic": 38, "n_train": 40, "n_word": [38, 42], "na": [31, 33], "nafter": 38, "nah": 27, "naiv": 36, "name": [4, 5, 6, 7, 8, 11, 23, 25, 26, 27, 29, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 46, 50, 51, 52], "named_estimators_": 32, "named_step": [28, 30, 31, 32, 33, 34, 40, 42, 51], "named_transformers_": [27, 30, 31, 32, 33, 34, 40, 41, 42, 49, 51], "nan": [26, 27, 30, 31, 32, 33, 34, 37, 40, 41, 42, 44, 49, 51], "nanmean": 37, "nanosecond": 40, "narr": 38, "narrow": 37, "nasali": [22, 39], "nation": 52, "nativ": [30, 32, 33, 39, 43, 49], "natur": [2, 22, 27, 30, 32, 34, 39, 43, 52], "navig": [7, 11], "nbsp": [22, 26, 27, 29, 31, 32, 33, 34, 39], "nbviewer": [22, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42], "nc": 1, "ncol": 28, "ndarrai": [8, 27], "ndate": 42, "ndframe": [34, 41], "ndim": 8, "ne": [40, 51], "nearbi": [25, 35], "nearest": [15, 30, 36, 46], "necessari": [0, 7, 23, 29, 44, 47], "necessarili": [24, 31, 32, 37], "necvq": 41, "need": [5, 7, 8, 11, 22, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52], "needn": 38, "neg": [23, 24, 25, 28, 31, 32, 33, 38, 40, 41, 42, 46, 49], "neg_mean_absolute_percentage_error": 31, "neg_mean_squared_error": 31, "neg_root_mean_square_error": 31, "neg_root_mean_squared_error": 31, "neigh": 25, "neighbor": [25, 26, 27, 28, 30, 34, 36, 46, 47], "neighborhood": [28, 31, 33], "neighborhood_blmngtn": 31, "neighborhood_bluest": 31, "neighborhood_brdal": 31, "neighborhood_brksid": 31, "neighborhood_clearcr": 31, "neighborhood_collgcr": 31, "neighborhood_crawfor": 31, "neighborhood_edward": 31, "neighborhood_gilbert": 31, "neighborhood_idotrr": 31, "neighborhood_meadowv": 31, "neighborhood_mitchel": 31, "neighborhood_nam": 31, "neighborhood_noridg": [31, 33], "neighborhood_npkvil": 31, "neighborhood_nridght": [31, 33], "neighborhood_nwam": 31, "neighborhood_oldtown": [31, 33], "neighborhood_sawy": [31, 33], "neighborhood_sawyerw": [31, 33], "neighborhood_somerst": [31, 33], "neighborhood_stonebr": [31, 33], "neighborhood_swisu": [31, 33], "neighborhood_timb": [31, 33], "neighborhood_veenk": [31, 33], "neighbour": [15, 24, 33, 35, 36, 38, 46], "neighbourhood": [28, 34, 36, 47], "neither": [24, 27, 37], "neq": [33, 37], "ner": 38, "nervou": 23, "nest": [29, 44], "net": [39, 41], "netflix": [37, 42], "network": [10, 22, 27, 32, 34, 35, 37, 38, 40, 52], "neu": 42, "neural": [10, 34, 40, 52], "neutral": 42, "never": [30, 32, 33, 37, 39, 41], "new": [10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 47, 48, 50, 51], "new_cent": 35, "new_column": [31, 33, 40, 41, 51], "new_data": 41, "new_df": [40, 51], "new_exampl": [23, 35], "new_feature_nam": [40, 51], "new_valu": 41, "newaxi": 8, "newcastl": 42, "newer": 31, "newli": [26, 31, 34, 36], "newsgroup": 38, "newswir": 38, "next": [11, 23, 24, 25, 26, 27, 30, 31, 32, 38, 39, 40, 47, 48, 49, 50, 52], "nfeat": 25, "nfeats_accuraci": 25, "ng": [9, 10, 29, 34], "ngram": 34, "ngram_rang": 27, "nhl": 38, "nhqxu": 41, "nice": [4, 29, 30, 32, 33, 36, 39, 41], "nicki": 29, "night": [30, 40], "niki": 52, "nlemma": 38, "nlp": [27, 39, 42], "nltk": [38, 42], "nltk_data": [38, 42], "nn": [10, 26, 39, 42, 46], "nne": [40, 51], "nnw": [40, 51], "nnz": 27, "no_grad": 39, "nobodi": 22, "node": [23, 32, 36, 39, 45], "nois": [36, 44, 46], "non": [1, 8, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 34, 36, 37, 39, 40, 41, 44, 49, 51, 52], "noncommerci": 1, "none": [10, 24, 26, 27, 28, 29, 30, 32, 34, 36, 40, 41, 42, 50], "noninfring": 0, "nonzero": 27, "noqa": [29, 42], "nor": [7, 24, 27, 38], "norg": [38, 42], "norm": [29, 38], "normal": [6, 30, 31, 32, 33, 35, 36, 38, 39, 40, 42, 49, 50], "north": 38, "norvig": 10, "notat": 25, "note": [0, 3, 7, 9, 10, 11, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 43, 44, 48, 49, 51, 52], "notebook": [5, 7, 9, 11, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42, 47, 51], "notic": [0, 27, 28, 30, 31, 34], "notion": [25, 29, 35, 37], "notna": [40, 51], "noun": [38, 42], "nov": 40, "novel": 44, "novemb": 40, "novic": 9, "now": [8, 11, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50], "np": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "nperson": 42, "npie": 8, "npo": 38, "npr": [34, 38, 42, 44], "nsubj": 38, "ntest": [25, 29, 46], "ntoken": 38, "ntree": 32, "null": [26, 27, 30, 31, 34, 40, 41, 51], "null_distribut": 41, "num": [30, 32, 33, 49], "num_output_channel": 39, "num_parallel_tre": 32, "num_sent": 30, "num_work": 39, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 44, 46, 48, 51, 52], "number_test": 29, "numberbatch": 38, "numer": [2, 23, 26, 27, 28, 30, 31, 32, 37, 38, 40, 41, 46, 47, 49, 51], "numeric_feat": [27, 29, 34, 44, 48], "numeric_featur": [27, 30, 31, 32, 33, 40, 41, 42, 49, 50, 51], "numeric_looking_column": 31, "numeric_transform": [27, 30, 31, 32, 33, 40, 49, 50, 51], "numpi": [9, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "numpy_dtyp": 41, "nutrit": 38, "nw": [40, 51], "nwith": 25, "ny": 42, "o": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "obelisk": 39, "object": [24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 42, 44, 45, 46, 48, 49, 51], "observ": [22, 23, 24, 25, 32, 33, 35, 36, 40, 41, 46, 49, 50, 51], "obtain": [0, 28, 35, 36, 37, 41, 46, 48], "obviou": [36, 38], "occasion": 30, "occup": [30, 32, 33, 49], "occupation_farm": 33, "occupation_miss": 33, "occupation_priv": 33, "occupi": 52, "occur": [8, 23, 24, 27, 38, 41], "occurr": [38, 41], "ocean": [26, 27, 34, 47], "ocean_proxim": [26, 27, 34, 47], "ocean_proximity_": [26, 27], "ocean_proximity_inland": [26, 27], "ocean_proximity_island": [26, 27], "ocean_proximity_near": [26, 27], "oct": 28, "octob": 40, "oe": [27, 44], "oe_encod": 44, "off": [28, 29, 30, 31, 34, 35, 38, 39, 41, 44, 48, 52], "off_shelf": 50, "offens": 4, "offer": [8, 32, 37, 38, 41, 52], "offic": [4, 11, 44, 52], "offici": [38, 52], "offlin": 37, "offset": 28, "often": [8, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46], "ogunrind": 22, "oh": [33, 34, 39, 40, 41, 44, 48, 51], "ohe_column": [31, 33], "ohe_enc": 27, "ohe_encod": 44, "ohe_feature_nam": [33, 40, 51], "ohehotencod": 27, "ois": 36, "ok": [22, 25, 31, 40, 41, 44, 51], "okai": 35, "ola": 38, "old": [9, 32, 33], "old_cent": 35, "older": 31, "oldpeak": 50, "olymp": 8, "omit": 33, "omw": 38, "onc": [6, 7, 8, 11, 23, 24, 26, 27, 29, 34, 36, 37, 38, 39, 48, 49, 50, 52], "onca": [22, 39], "one": [6, 8, 9, 11, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52], "one_c": 25, "one_ex_preprocess": 33, "one_ex_preprocessed_perturb": 33, "one_exampl": 33, "one_example_perturb": 33, "onehot": [27, 34], "onehotencod": [26, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 44, 47, 48, 49, 50, 51], "onehotencoder__major_biologi": 27, "onehotencoder__major_comput": 27, "onehotencoder__major_econom": 27, "onehotencoder__major_linguist": 27, "onehotencoder__major_mathemat": 27, "onehotencoder__major_mechan": 27, "onehotencoder__major_phys": 27, "onehotencoder__major_psychologi": 27, "onehotencoderonehotencod": [27, 29, 31, 32], "ones": [8, 22, 25, 26, 32, 33, 35, 37, 38, 46, 50], "onevsoneclassifi": 43, "onevsrestclassifi": 43, "onli": [2, 4, 8, 11, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 52], "onlin": [3, 5, 7, 11, 23, 38, 52], "onlinebackup": 41, "onlinebackup_no": 41, "onlinebackup_y": 41, "onlinesecur": 41, "onlinesecurity_no": 41, "onlinesecurity_y": 41, "ontario": 38, "ontonot": 38, "op": 30, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 39, 52], "openporchsf": [31, 33], "oper": [4, 8, 11, 27, 34, 38], "operand": 8, "opinion": 32, "opportun": 37, "oppos": [31, 32], "opposit": [8, 31, 32, 33, 51], "opt": [11, 32], "optic": 41, "optim": [2, 10, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36, 39, 41, 48], "optimist": 29, "option": [7, 8, 10, 23, 31, 35, 38, 48, 50, 51], "oracl": 10, "orang": 28, "order": [5, 7, 8, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 44], "ordering_ordinal_oth": [31, 33], "ordering_ordinal_reg": [31, 33], "ordin": [31, 44, 47], "ordinal_feat": 27, "ordinal_featur": [30, 32, 33, 49], "ordinal_features_oth": [31, 33], "ordinal_features_reg": [31, 33], "ordinal_transform": [30, 32, 33, 49], "ordinal_transformer_oth": [31, 33], "ordinal_transformer_reg": [31, 33], "ordinalencod": [26, 27, 30, 31, 32, 33, 34, 40, 41, 42, 44, 47, 49, 50, 51], "ordinalencoderordinalencod": [27, 31, 32], "ordinari": 31, "oreilli": [39, 40], "org": [9, 22, 24, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 42], "organ": [22, 23, 26, 38], "orgin": 8, "orig_featur": [40, 51], "orig_pr": 33, "orig_scor": 30, "origin": [26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 46, 48, 51, 52], "original_hm": 30, "originaltweet": 42, "ornithorhynchu": 39, "oscar": 28, "ostblom": 38, "other": [0, 1, 4, 5, 6, 7, 11, 23, 24, 26, 27, 28, 29, 30, 32, 33, 36, 37, 39, 42, 43, 44, 46, 48, 49, 50, 51, 52], "otherwis": [0, 7, 27], "ounc": [22, 39], "our": [5, 6, 8, 11, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 48, 49, 50, 51, 52], "ourselv": [23, 30, 38, 39, 40], "out": [0, 4, 7, 8, 11, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 44, 46, 48, 50, 51, 52], "out_col": [24, 26, 42], "out_step": 30, "outcom": 12, "outer": 42, "outlier": [31, 36, 44], "outlook": 41, "output": [7, 8, 11, 22, 23, 24, 27, 28, 30, 32, 33, 38, 39, 40, 44, 50, 51, 52], "outsid": [7, 30, 32, 33, 37, 38, 40, 41], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 29, 31, 38, 39, 40, 41, 44, 52], "over_confident_i": 28, "over_confident_x": 28, "over_sampl": 30, "overal": [11, 30, 33, 35, 38, 39, 44, 49, 50, 52], "overallcond": [31, 33], "overallqu": [31, 33], "overconfid": [33, 34], "overfit": [10, 25, 28, 31, 32, 34, 39, 46, 48, 50, 52], "overflow": 7, "overhead": 27, "overlap": [2, 24, 35], "overli": [25, 29, 46], "overload": [37, 41], "overpredict": 31, "oversample_pip": 30, "overshadow": 38, "overus": 32, "overview": [35, 36, 37, 38], "overwhelm": 35, "overzeal": 6, "own": [4, 5, 8, 24, 26, 30, 31, 33, 34, 35, 36, 38, 39, 40, 42, 43, 51], "p": [28, 29, 36, 38, 41], "p_i": 35, "p_value_threshold": 41, "pace": [28, 35, 38, 52], "packag": [5, 8, 23, 24, 27, 29, 30, 33, 35, 36, 37, 38, 39, 41, 42, 43, 52], "pad": 39, "page": [1, 4, 10, 22, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 42, 50, 52], "pai": 33, "pain": [4, 39, 40, 51], "pair": [36, 38, 43], "pairwis": [25, 36], "panda": [9, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "pane": [25, 46], "panel": [25, 30, 33, 35, 36, 46], "panic": 42, "panther": [22, 39], "panthera": [22, 39], "paper": [7, 33, 34, 38, 39, 41, 42], "paperlessbil": 41, "paperlessbilling_no": 41, "paperlessbilling_y": 41, "paradigm": [22, 23, 35, 38], "paradox": 37, "paragraph": 38, "paraleg": 38, "parallel": [27, 29, 32], "param": [25, 27, 29, 31, 46], "param_columntransformer__countvectorizer__max_featur": 29, "param_dist": [29, 48], "param_distribut": [29, 48], "param_grid": [24, 25, 29, 31, 48], "param_grid1": [29, 48], "param_grid2": [29, 48], "param_grid3": 29, "param_grid4": 29, "param_ridge__alpha": 31, "param_svc__c": 29, "param_svc__gamma": 29, "paramet": [25, 26, 27, 31, 32, 33, 35, 36, 38, 40, 41, 42, 45, 46, 48, 49, 50, 51], "parametr": 36, "params_": 41, "params_str": 29, "paramter": 25, "pardu": [22, 39], "parent": [36, 42], "park": [34, 39, 42], "pars": 38, "parse_d": [8, 40, 51], "parser": 38, "part": [4, 9, 10, 11, 26, 27, 28, 29, 30, 32, 33, 34, 36, 38, 40, 42, 50, 52], "part1": 37, "part2": 37, "parti": 38, "partial": [4, 41], "particip": 52, "particular": [0, 9, 11, 26, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 46, 49], "particularli": [32, 37, 52], "partit": [27, 35, 36], "partner": [41, 52], "partner_no": 41, "partner_y": 41, "parton": 42, "pass": [8, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 46], "passthrough": [27, 29, 41, 42, 48, 50], "passthrough__ml_experi": 27, "passthrough_feat": [27, 29, 44, 48], "passthrough_featur": [41, 42, 50], "passthroughpassthrough": [27, 29, 42], "past": [23, 24, 32, 40, 41, 44], "pat": 37, "pat_i": 37, "pat_model": 37, "pat_x": 37, "pata": [22, 39], "path": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "patial": 36, "patient": [23, 50], "patio": 39, "patric": 33, "patrick": 52, "pattern": [22, 23, 24, 27, 29, 34, 35, 38, 40, 46, 51], "pav_bhaji": 38, "pave": [31, 33], "paveddr": [31, 33], "paveddrive_i": 31, "paveddrive_n": 31, "paveddrive_p": 31, "paymentmethod": 41, "paymentmethod_bank": 41, "paymentmethod_credit": 41, "paymentmethod_electron": 41, "paymentmethod_mail": 41, "pca": [30, 36, 37], "pcarter": 9, "pd": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "pdf": [7, 9, 19], "peac": 38, "pedest": 39, "pedro": [10, 24, 34], "peek": 51, "peer": [44, 52], "pembrok": [22, 39], "penal": [6, 41], "penalti": [30, 38, 52], "peopl": [4, 23, 24, 26, 28, 30, 32, 35, 37, 38, 39, 40, 41, 42, 44, 46, 49, 52], "per": [8, 28, 30, 31, 32, 33, 37, 39, 40, 43, 44, 48, 49, 51], "perceiv": 6, "percent": 31, "percent_error": 31, "percentag": [23, 30, 37], "perfect": [6, 23, 24, 30, 31, 33, 37, 41, 42], "perfectli": [2, 37, 38], "perform": [23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 45, 47, 48, 49, 50, 51, 52], "performac": 24, "perhap": [31, 40, 43], "perimet": 34, "period": [38, 40, 41, 42, 52], "perm_sorted_idx": 33, "perman": 8, "permiss": [0, 52], "permit": [0, 26, 30, 52], "permut": 33, "persist": 37, "person": [0, 4, 6, 10, 22, 30, 35, 38, 39, 40, 41, 42, 52], "perspect": [32, 37], "pertain": 5, "perthairport": [40, 51], "perturb": [33, 36], "perturbed_pr": 33, "pete_seeg": 38, "peter": 10, "ph": 38, "phascolarcto": 39, "phase": 24, "phd": 38, "phdei": 41, "phenomenon": [37, 41, 46], "philippin": 42, "philosoph": 38, "phone": [22, 41, 52], "phoneservic": 41, "phoneservice_no": 41, "phoneservice_y": 41, "photo": [42, 44], "photograph": 52, "phrase": 38, "physic": [27, 40], "pi": 8, "pick": [23, 28, 30, 32, 33, 34, 35, 36, 39, 43, 45, 46, 48, 49, 50], "pictur": [32, 33, 36, 38, 40], "pie": 8, "piec": [28, 41], "pil": [22, 39], "pin": 39, "pineappl": 38, "pip": [11, 33, 38, 39, 42], "pipe": [26, 27, 28, 29, 30, 32, 38, 39, 42, 48, 49], "pipe_bestalpha": 31, "pipe_bigalpha": 31, "pipe_catboost": 32, "pipe_dt": [32, 33, 50], "pipe_forward": 34, "pipe_knn": 50, "pipe_lgbm": [32, 33, 50], "pipe_lr": [30, 32, 33, 49, 50], "pipe_lr_all_feat": 34, "pipe_lr_balanc": [30, 49], "pipe_lr_model_bas": 34, "pipe_lr_weight": [30, 49], "pipe_rf": [32, 33, 50], "pipe_rf_demo": 32, "pipe_ridg": [28, 31], "pipe_sklearn_gb": 32, "pipe_sklearn_histgb": 32, "pipe_smallalpha": 31, "pipe_svc": 30, "pipe_svm": [29, 48], "pipe_xgb": [32, 33], "pipe_xor": 34, "pipelin": [2, 10, 16, 22, 24, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52], "pipeline__lab1": 27, "pipeline__lab2": 27, "pipeline__lab3": 27, "pipeline__lab4": 27, "pipeline__quiz1": 27, "pipeline__rooms_per_household": 34, "pipeline__university_year": 27, "pipelineifittedpipelin": [26, 27, 29, 30, 34, 39, 42], "pipelineinot": [27, 29, 31], "pipelinepipelin": 29, "pitfal": 40, "pixel": 33, "pizza": 38, "pkg": 11, "pla": 38, "place": [5, 38, 40, 52], "plagiar": 52, "plai": [23, 25, 29, 33, 36, 38, 45, 46], "plain": 35, "plan": [11, 22, 31, 34, 41, 42, 47, 50, 52], "plane": 28, "plant": 44, "plastic": 38, "platform": [4, 42], "platypu": 39, "player": [33, 38, 39], "pleas": [1, 4, 7, 11, 22, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42, 48, 52], "plinth": 39, "plot": [7, 23, 24, 25, 26, 28, 29, 30, 31, 34, 36, 37, 38, 39, 40, 46, 48, 49, 51], "plot_2d_scor": 28, "plot_2d_separ": [25, 28, 46], "plot_confusion_matrix": 30, "plot_confusion_matrix_exampl": 30, "plot_cross_valid": [24, 40], "plot_dbscan": 36, "plot_dbscan_with_label": 36, "plot_dendrogram_clust": 36, "plot_elbow": 35, "plot_example_dist": 35, "plot_fruit_tre": 23, "plot_grid_search_overview": 29, "plot_k_means_dbscan_comparison": 36, "plot_km_initi": 35, "plot_km_it": 35, "plot_km_iter": 35, "plot_kmean": 36, "plot_knn_clf": 25, "plot_knn_decision_boundari": 25, "plot_knn_regress": 25, "plot_lda_w_vector": 38, "plot_linkage_criteria": 36, "plot_logistic_regress": 28, "plot_logistic_regression_graph": 39, "plot_multiclass_lr_ovr": 43, "plot_original_clust": 36, "plot_partial_effects_on_outcom": 41, "plot_result": [25, 46], "plot_scal": 26, "plot_silhouette_dist": 35, "plot_single_hidden_layer_graph": 39, "plot_support_vector": 25, "plot_survival_funct": 41, "plot_svc_c": 25, "plot_svc_gamma": 25, "plot_time_spacing_distribut": [40, 51], "plot_train_test_point": 25, "plot_tree_decision_boundari": 24, "plot_tree_decision_boundary_and_tre": [23, 24, 45], "plot_two_hidden_layer_graph": 39, "plot_typ": 33, "plot_x_dendrogram": 36, "plotli": [34, 38], "plotting_funct": [23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 39, 43, 45, 46, 47, 48, 49, 50], "plotting_functions_unsup": [35, 36, 37, 38], "plt": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "plu": [28, 39], "plural": 27, "pm": [1, 10, 40, 51, 52], "pmltt": 10, "pn": [25, 30, 35, 36, 46], "po": [24, 26, 28, 31, 33, 38, 42], "pobox": 22, "poet": 38, "point": [4, 10, 22, 23, 24, 26, 27, 28, 29, 31, 34, 36, 41, 43, 44, 46, 49, 52], "point_ind": 35, "point_index": 35, "pointless": 48, "polarity_scor": 42, "pole": 39, "polici": [3, 4, 7, 52], "polit": [37, 38, 39], "poly_transform": 40, "polynomialfeatur": [34, 40], "pomegran": 39, "pool": 10, "poolarea": [31, 33], "poolqc": [31, 33], "poor": [27, 31, 34, 44, 47], "poorli": [25, 31, 36, 40], "pope": 38, "popul": [26, 27, 28, 34, 40, 47], "popular": [8, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 42, 52], "population_per_household": [26, 27, 47], "porter": 38, "porterstemm": 38, "portion": [0, 24, 26, 29, 31, 33, 50, 51, 52], "portug": [30, 33], "pos_": [38, 42], "pos_label": 31, "posit": [23, 24, 25, 26, 28, 31, 32, 33, 38, 40, 41, 42, 49], "posix": 41, "possibl": [4, 5, 6, 8, 22, 23, 24, 26, 29, 30, 32, 33, 34, 36, 37, 38, 39, 41, 44, 46, 47, 48, 49, 52], "possibli": [7, 38], "post": [4, 6, 8, 10, 38, 40, 52], "postprocess": 39, "potenti": [25, 26, 35, 38, 52], "powder": 38, "power": [8, 24, 32, 37, 38, 39], "pplicat": 36, "pr": 44, "practic": [0, 6, 9, 10, 24, 26, 34, 39, 44, 47, 48, 52], "prairielearn": [10, 52], "pre": [10, 11, 19, 22, 32, 34, 38, 42, 44], "precis": [18, 31, 44, 49, 52], "precision_lr": 30, "precision_recall_curv": 30, "precision_scor": 30, "precision_svc": 30, "precisionrecallcurvedisplai": 30, "precisionrecalldisplai": 30, "pred": [30, 31, 37, 40, 41], "pred_df": [22, 37], "pred_dict": 22, "pred_g": 37, "pred_lin_reg": 37, "pred_train": 31, "pred_x": 37, "prediciton": 41, "predict": [2, 17, 24, 25, 26, 29, 30, 31, 34, 35, 36, 38, 40, 42, 44, 46, 47, 48, 49, 50, 51, 52], "predict_expect": 41, "predict_for_usr": 37, "predict_proba": [30, 32, 33, 39, 43, 50], "predict_survival_funct": 41, "predicted_categori": 30, "predicted_n_rent": 40, "predicted_quiz2": 23, "predicted_sal": 40, "predicted_target": 22, "predictor": [23, 44], "prefer": [22, 32, 35, 37, 48], "prefix": 8, "preliminari": [26, 34], "prepar": [26, 34, 39], "prepend": 11, "preprocess": [10, 16, 18, 24, 25, 28, 29, 30, 32, 33, 34, 36, 37, 39, 41, 42, 46, 47, 48, 50, 52], "preprocess_featur": [40, 51], "preprocessing_fin": 41, "preprocessing_notenur": 41, "preprocessor": [27, 29, 30, 31, 32, 33, 40, 41, 42, 47, 48, 49, 50, 51], "preprocessor1": 34, "preprocessor2": 34, "preprocessor3": 34, "prerequisit": [2, 41, 52], "preschool": [30, 32, 33, 49], "presenc": [27, 33, 41], "present": [7, 24, 30, 37, 38, 39, 40, 41, 44, 46, 51], "preserv": [30, 35], "pressure3pm": [40, 51], "pressure9am": [40, 51], "pretend": [23, 24, 40], "pretrain": [38, 39, 42], "pretti": [23, 27, 28, 30, 32, 35, 38, 40, 41, 51], "prevent": [29, 38, 41, 52], "previou": [23, 31, 32, 35, 36, 40, 41, 44, 48, 49, 51], "previous": [37, 39, 40], "price": [8, 18, 26, 28, 31, 33, 34, 41, 46], "primari": [8, 19, 25], "primarili": [23, 33, 39], "prime": 22, "princ": 38, "princess": 38, "principl": [9, 23, 44, 52], "print": [7, 8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 49, 51], "print_top": 38, "prior": [35, 40, 44], "priorit": [34, 44], "privaci": [0, 35, 52], "privat": [7, 30, 32, 33], "privileg": 6, "prize": 27, "pro": [35, 39], "prob": [28, 32], "proba": 39, "probabilist": [2, 38], "probabl": [17, 22, 25, 26, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 44, 49, 50, 51], "problem": [4, 6, 10, 22, 27, 28, 30, 31, 32, 33, 35, 36, 38, 39, 41, 43, 44, 46, 48, 49, 50, 51, 52], "problemat": [30, 33, 41], "probosci": [22, 39], "proce": 52, "procedur": 32, "proceed": [24, 51], "process": [2, 5, 7, 23, 25, 26, 27, 29, 34, 35, 36, 39, 42, 46, 48, 52], "process_on": 42, "prod": [27, 29], "produc": [2, 7, 31, 33, 36, 41, 44, 46], "product": [5, 29, 37, 38], "prof": [30, 32, 33, 49], "profession": 37, "profil": 31, "profile_df": 37, "profilereport": 31, "program": [0, 4, 9, 11, 22, 38, 52], "programm": 38, "progress": 35, "project": [11, 26, 32, 34, 39, 44, 52], "promin": 38, "promis": [22, 38, 40], "promot": 41, "prompt": [11, 52], "pron": [38, 42], "prone": 29, "proper": [39, 45], "properli": [7, 41], "properti": [23, 31, 33, 34], "prophet": 40, "propn": [38, 42], "proport": [23, 24, 27, 28, 30, 31, 32, 33, 49, 52], "proportional_hazard_test": 41, "prostitut": 38, "prototyp": 44, "prove": 30, "provid": [0, 5, 7, 11, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 44, 48, 49, 50, 51, 52], "provinc": [27, 38], "provinci": 38, "proxi": 24, "proxim": [28, 38, 52], "prune": 34, "psychologi": [27, 44], "pt": [28, 29, 39], "public": [0, 4, 7, 38, 42], "publish": [0, 10, 28, 38], "puck": 38, "pud": 31, "pull": [11, 28, 38], "punct": [38, 42], "punctuat": [27, 38], "punkt": 42, "punkt_tab": 42, "purchas": [22, 37], "pure": [23, 40], "purpos": [0, 23, 24, 26, 37, 38, 40, 44, 45, 46, 50, 52], "push": [7, 33], "put": [7, 8, 11, 23, 24, 26, 27, 34, 35, 36, 37, 48], "px": [34, 38], "py": [23, 24, 26, 27, 29, 32, 33, 35, 36, 41, 42, 43], "pybind11": 42, "pybo": 29, "pydata": 34, "pyplot": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "pysurviv": 41, "python": [3, 4, 10, 22, 29, 31, 37, 38, 39, 40, 41, 42, 52], "python3": [9, 23, 24, 27, 29, 33, 41, 42, 43], "pythonwarn": 31, "pytorch": [22, 39], "pytorch_1711403226120": 42, "pyviz": 30, "q": 10, "qualiti": [30, 33, 35, 36], "quantifi": [30, 49], "queen": 38, "queen_consort": 38, "queri": [26, 30, 32, 35, 37, 38, 40, 41, 49, 51, 52], "query_point": 25, "quest": 34, "question": [6, 7, 52], "quick": [4, 38, 52], "quickli": [23, 25, 26, 29, 36, 41, 44, 52], "quickstart": 9, "quirk": 24, "quit": [6, 22, 23, 26, 29, 30, 31, 33, 34, 36, 38, 39, 40, 41, 42], "quiz": [1, 10, 38], "quiz1": [23, 24, 27, 44], "quiz2": [24, 27, 44], "quizz": 23, "r": [23, 27, 28, 30, 40, 50, 52], "r1": 32, "r2": [31, 32, 44, 46], "r2_score": [31, 34, 42], "r4": 32, "race": [27, 30, 32, 33, 49, 52], "radial": 25, "radiu": [34, 36], "rail": 39, "rain": [40, 51], "rain_df": [40, 51], "rain_df_modifi": [40, 51], "rainfal": [40, 51], "rainfall_lag1": [40, 51], "rainfall_lag2": [40, 51], "rainfall_lag3": [40, 51], "raintodai": [40, 51], "raintoday_miss": [40, 51], "raintoday_no": [40, 51], "raintoday_y": [40, 51], "raintomorrow": [40, 51], "rais": [6, 27, 30, 40, 41, 51], "rand": [8, 32], "randint": [29, 48], "randn": [28, 34], "random": [6, 8, 24, 25, 28, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 50, 52], "random_forest_data": 32, "random_search": [29, 48], "random_st": [22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50], "randomforestclassifi": [33, 34, 40, 50, 51], "randomforestclassifierrandomforestclassifi": 32, "randomforestregressor": [31, 32, 33, 34, 40, 41, 42, 50], "randomhorizontalflip": 39, "randomizedsearchcv": [25, 32, 33, 48, 50], "randomizedsearchcvifittedrandomizedsearchcv": 29, "randomli": [24, 28, 29, 30, 32, 41, 49], "randomoversampl": 30, "randomresizedcrop": 39, "randomst": [34, 36], "randomundersampl": 30, "rang": [4, 8, 24, 25, 26, 27, 28, 32, 35, 37, 38, 39, 40, 41, 42, 48, 52], "rangeindex": [27, 34, 40, 41, 51], "rank": [30, 34, 37, 38, 41, 49], "rank_test_mape_scor": 31, "rank_test_neg_mean_squared_error": 31, "rank_test_scor": [29, 31], "ranking_": 34, "rare": [27, 30, 31, 35, 38, 44], "rate": [22, 28, 30, 32, 35, 41, 44, 49], "rated_item": 37, "rather": [22, 27, 29, 30, 31, 32, 33, 35, 38, 39], "ratings_df": 37, "ratio": [30, 32, 38, 41], "ravel": [30, 44], "raw": [8, 27, 30, 33, 34, 38, 39, 43, 49], "raw_model_output": 28, "raw_scor": 33, "rbf": [10, 15, 24, 26, 28, 29, 32, 33, 34, 44, 46, 48], "rcparam": [22, 23, 24, 30, 35, 36, 37, 39, 40, 41, 45, 51], "re": [4, 7, 8, 11, 22, 23, 24, 27, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 44, 45, 51], "reach": [6, 35, 52], "read": [1, 4, 7, 10, 25, 26, 27, 30, 31, 32, 33, 38, 40, 50, 51], "read_csv": [8, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 52, "readi": [7, 24, 25, 26, 28], "readlin": 39, "readm": 41, "readthedoc": 41, "real": [24, 25, 26, 27, 28, 30, 33, 35, 36, 37, 38, 39, 42, 44], "realdonaldtrump": 42, "realist": [26, 40, 51], "realiti": [24, 31, 41], "realli": [8, 24, 28, 29, 32, 34, 36, 37, 39, 40, 41], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 29, 30, 31, 33, 35, 37, 38, 40, 41, 44, 52], "rebuild": 42, "rec": [31, 33], "recal": [18, 23, 24, 25, 26, 27, 28, 31, 35, 40, 44, 49, 52], "recall_lr": 30, "recall_scor": 30, "recall_svc": 30, "receiv": [6, 7, 27, 36, 39, 40], "recent": [8, 11, 22, 27, 34, 37, 38, 40, 41, 42], "recip": 24, "recogn": [24, 36, 40, 52], "recognit": [22, 23, 25, 30, 38, 52], "recommend": [2, 4, 8, 10, 11, 22, 24, 25, 29, 30, 35, 38, 39, 50, 52], "record": [23, 41], "recreat": 51, "rectangular": 35, "recurr": 40, "recurs": 52, "red": [23, 25, 30, 33, 34, 35, 40], "redbon": 29, "redefin": 41, "redistribut": 0, "reduc": [7, 8, 22, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 43, 46, 49, 52], "reduct": [2, 30, 32, 34, 35], "redund": [28, 33], "ref": [30, 41, 49], "refer": [8, 23, 24, 25, 26, 27, 28, 30, 33, 35, 37, 38, 39, 46, 52], "referenc": 52, "referenti": 38, "refin": [25, 46], "refit": 31, "reflect": [25, 31, 33, 38, 46, 48, 52], "reflection_period": 30, "reg": [23, 32, 50], "reg_model": 23, "regard": 52, "regardless": 7, "regex": 38, "region": [23, 30, 36, 40, 43, 48, 51], "region_data": [40, 51], "regist": 52, "registered_nurs": 38, "registri": 42, "regrad": 6, "regress": [2, 10, 17, 22, 26, 27, 33, 34, 37, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52], "regression_df": 23, "regressor": [23, 26, 27, 31, 40, 50], "regular": [25, 27, 28, 32, 38, 40, 41, 44], "regulatori": 33, "reinforc": [22, 35], "reject": [30, 49], "rel": [28, 33, 36, 38, 42, 43, 49], "rel_char_len": 42, "relabel": 35, "relat": [2, 6, 11, 22, 28, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 50, 52], "relationship": [30, 32, 33, 34, 38, 40, 42, 44, 45, 46, 49, 51, 52], "relationship_husband": 33, "relationship_own": 33, "releas": [7, 10], "relev": [4, 8, 10, 23, 25, 26, 29, 33, 40, 52], "reli": [24, 25, 34, 36, 37, 40, 46], "reliabl": [22, 35], "religi": 38, "remain": [5, 31, 34, 37, 40], "remaind": 6, "rememb": [7, 25, 27, 29, 30, 33, 34, 36, 39, 40, 41, 45, 46, 48, 51], "remind": 45, "remix": 0, "remov": [7, 26, 30, 32, 33, 34, 38, 39, 41, 43, 48, 49, 51], "renam": [22, 30, 33, 40], "render": [4, 7, 22, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 42], "rent": 40, "rental": 40, "rentals_df": 40, "rentals_lag5": 40, "rentals_lag5_i": 40, "rentals_lag5_x": 40, "rentals_model": 40, "repair": [30, 32, 33], "repeat": [8, 34, 35, 36, 39, 48, 49, 50], "repeatedli": 6, "replac": [22, 26, 30, 32, 33, 37, 41, 49], "reply_cont": 42, "repo": [10, 30], "report": [6, 23, 29, 31, 34, 40, 42, 49], "repositori": [0, 5, 10, 11, 28, 30, 52], "repres": [23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 50], "represent": [22, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 44], "reproduc": [4, 24, 29, 32, 52], "republ": 33, "request": [6, 38, 52], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 46, 51], "rerun": [22, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42], "res_mean": 24, "resampl": 30, "research": [22, 24, 29, 37, 38], "reserv": [40, 52], "reset_index": 22, "reshap": [8, 28, 29, 39, 40, 48], "resid": 28, "residu": 32, "resiz": 39, "resnet": 39, "resolut": 38, "resolv": 52, "resort": 28, "resourc": [3, 5, 10, 23, 32, 33, 38, 39, 44], "respect": [28, 29, 30, 32, 33, 48], "respons": [4, 7, 23, 35, 38, 52], "rest": [28, 29, 39, 41, 44, 51], "restart": [7, 11], "restaur": 37, "restingbp": 50, "restingecg": 50, "restrict": [0, 31, 32, 38], "result": [2, 7, 8, 10, 11, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 46, 48, 49, 50, 51, 52], "result_block": 41, "result_img": 39, "results_df": [24, 25, 28, 46], "results_dict": [24, 25, 26, 27, 29], "results_single_valid_df": 46, "retail": [42, 44], "retail_df": 40, "retail_df_test": 40, "retail_df_train": 40, "retail_lag_5": 40, "retail_model": 40, "retail_test_5": 40, "retail_test_5_pr": 40, "retail_train_5": 40, "retail_train_5_d": 40, "retail_train_5_i": 40, "retail_train_5_x": 40, "retent": 41, "retrain": [29, 48], "return": [5, 8, 11, 23, 24, 25, 26, 27, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 48, 51], "return_gener": 27, "return_train_scor": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 46, 48, 50], "reus": [30, 52], "revenu": 37, "revers": [27, 31], "review": [4, 10, 28, 35, 42, 44, 48, 49, 50, 52], "revisit": [30, 44], "revok": 0, "reward": [22, 27, 35], "rf": [40, 41], "rf_imp_df": 33, "rfe_cv": 34, "rfe_pip": 34, "rfecv": 34, "rgb": 22, "rhode_island": 38, "rich": [33, 38, 41, 44], "rico": 33, "rid": [11, 27, 32, 33, 38, 41], "ridg": [33, 34, 37, 40, 41, 42], "ridge__alpha": 31, "ridge_pr": 31, "ridge_tun": 31, "ridgecv": [34, 42], "ridgecv_pip": 31, "ridgeridg": [31, 34], "right": [0, 10, 22, 28, 29, 30, 31, 34, 35, 36, 37, 38, 44, 48, 49, 52], "rightarrow": [23, 25, 28, 30, 31, 32, 35, 36, 37, 38, 44], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 38, "rise": [34, 38], "risk": [10, 30, 34, 46, 50], "river": 28, "rl": [31, 33], "rmse": [37, 44], "rng": [34, 36], "rnn": 40, "ro": 30, "roast": 35, "robot": [37, 38], "robust": [22, 24, 25, 26, 29, 32, 36, 46, 48], "roc": [44, 52], "roc_auc": 30, "roc_auc_scor": 30, "roc_curv": 30, "roc_lr": 30, "roc_svc": 30, "roccurvedisplai": 30, "rodolfo": 29, "rodr\u00edguez": 38, "roger": 34, "role": [28, 29, 33, 39], "roman": 37, "romanc": 37, "romant": 37, "ronald": 28, "roof": 33, "roofmatl": [31, 33], "roofmatl_clytil": [31, 33], "roofmatl_compshg": [31, 33], "roofmatl_membran": 31, "roofmatl_met": 31, "roofmatl_rol": 31, "roofmatl_tar": 31, "roofmatl_wdshak": 31, "roofmatl_wdshngl": [31, 33], "roofstyl": [31, 33], "roofstyle_flat": 31, "roofstyle_g": 31, "roofstyle_gambrel": 31, "roofstyle_hip": 31, "roofstyle_mansard": 31, "roofstyle_sh": 31, "room": [22, 23, 28, 31, 34, 42, 52], "rooms_per_household": [26, 27, 34, 47], "rooms_per_household_0": 34, "rooms_per_household_1": 34, "rooms_per_household_10": 34, "rooms_per_household_11": 34, "rooms_per_household_12": 34, "rooms_per_household_13": 34, "rooms_per_household_14": 34, "rooms_per_household_15": 34, "rooms_per_household_16": 34, "rooms_per_household_17": 34, "rooms_per_household_18": 34, "rooms_per_household_19": 34, "rooms_per_household_2": 34, "rooms_per_household_3": 34, "rooms_per_household_4": 34, "rooms_per_household_5": 34, "rooms_per_household_6": 34, "rooms_per_household_7": 34, "rooms_per_household_8": 34, "rooms_per_household_9": 34, "root": [11, 23, 25, 37, 39, 44], "rose": 38, "rostin": 52, "rotat": [40, 51], "rough": 4, "roughli": [5, 24, 38, 44], "round": [8, 25, 26, 29, 30, 32, 36, 39, 46], "rout": [5, 23, 40], "row": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 50, 51, 52], "rry": 38, "rsh": 29, "ru": [8, 30], "rubric": 28, "rule": [1, 8, 22, 23, 25, 28, 30, 32, 38, 44, 46, 49], "run": [4, 5, 7, 10, 11, 22, 24, 25, 27, 29, 30, 31, 33, 35, 36, 38, 39, 42, 43, 45, 46, 48, 50], "run_ast_nod": 42, "run_cel": 42, "run_cell_async": 42, "run_cod": 42, "run_forev": 42, "runner": 42, "runpi": 42, "runtimewarn": 29, "ruscorpora": 38, "rush": 34, "russel": 10, "rv": 29, "rv_continuous_frozen": 29, "rv_discrete_frozen": 29, "rvert_2": 38, "s1": [8, 38], "s19": 26, "s2": [8, 38], "s_lag": [40, 51], "sa": 1, "sabr": 38, "sabrina": 10, "sadli": 38, "safe": 26, "safeti": 39, "sai": [8, 23, 25, 26, 27, 30, 31, 32, 33, 38, 40, 44, 49], "said": [24, 26, 28, 33, 36, 37, 38], "sal": [31, 33], "sale": [8, 30, 31, 40, 46], "salecondit": [31, 33], "salecondition_abnorml": 31, "salecondition_adjland": 31, "salecondition_alloca": 31, "salecondition_famili": 31, "salecondition_norm": 31, "salecondition_parti": 31, "salepric": [31, 33], "sales_data": 40, "salesforc": 42, "saleswoman": 38, "saletyp": [31, 33], "saletype_cod": 31, "saletype_con": 31, "saletype_conld": 31, "saletype_conli": 31, "saletype_conlw": 31, "saletype_cwd": 31, "saletype_new": 31, "saletype_oth": 31, "saletype_wd": 31, "salt": [28, 33], "sam": 37, "same": [6, 7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 49, 51], "samosa": 38, "sampl": [23, 25, 26, 28, 29, 33, 36, 39, 40, 41, 45, 46, 49, 50, 51], "sample_df": 30, "sample_text": 42, "sampling_strategi": 30, "samuel": 22, "sand": 39, "sandbar": 39, "saniti": [23, 41], "sarah": 10, "sat": 40, "satisfactori": 35, "satisfi": [35, 52], "saturdai": 40, "save": [7, 8, 27, 29, 33, 38, 39, 40, 42, 47, 48, 51], "saw": [26, 28, 29, 30, 36, 44], "sb": 34, "scalabl": [22, 36], "scalar": 8, "scale": [16, 24, 25, 27, 29, 30, 31, 32, 34, 36, 39, 41, 44, 46, 47, 48], "scale_pos_weight": 32, "scaler": [26, 33, 34], "scan": 44, "scatter": [26, 31, 33, 34], "scatter_3d": 34, "scatterplot": 34, "scc": 38, "scenario": [24, 27, 32, 33, 34, 36, 40, 41, 44, 52], "schedul": [41, 44], "schmidt": 29, "school": [22, 30, 32, 33, 37, 49], "schoolteach": 38, "scienc": [2, 9, 10, 11, 27, 35, 40, 44, 46, 52], "scientif": [37, 38], "scientist": [9, 10, 36], "scikit": [9, 11, 16, 17, 23, 25, 28, 29, 30, 32, 35, 36, 39, 40, 42, 43, 48, 49, 52], "scipi": [11, 29, 36, 38, 48], "scm": 5, "scope": [38, 40], "score": [17, 18, 22, 25, 26, 27, 32, 33, 36, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "score_func": 31, "score_lr_print_coeff": [40, 51], "score_param": 27, "score_tim": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42], "scorer": [27, 31], "scores_averag": 50, "scores_dict": 28, "scores_imag": 28, "scores_stack": 50, "scoring_method": 41, "scoring_metr": [32, 33, 42], "scotland": 38, "scratch": [2, 39], "screen": 7, "screennam": 42, "screenplai": 38, "screenporch": [31, 33], "script": 11, "scroog": 42, "sd": 19, "sdng": 31, "se": [40, 41, 51], "sea": 39, "seaborn": [33, 34, 35, 36, 37], "seacoast": 39, "search": [4, 5, 11, 31, 38, 44, 48], "search_multi": 31, "seashor": 39, "season": 51, "season_autumn": 40, "season_fal": 40, "season_summ": 40, "season_wint": 40, "seat": [39, 52], "seattl": 42, "seawal": 39, "second": [4, 6, 23, 28, 32, 33, 36, 39, 40], "secondari": 22, "secpompeo": 42, "section": [7, 11, 23, 24, 34, 50, 52], "secur": [33, 52], "see": [1, 4, 6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 45, 46, 48, 49, 50, 51, 52], "seed": [28, 29, 35, 36], "seem": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 40, 41, 42, 43, 46, 48, 49], "seemingli": [30, 49], "seen": [8, 22, 24, 25, 26, 27, 28, 34, 36, 37, 41, 44, 46, 48, 50], "sefa": 52, "segment": [30, 38, 39, 41, 44, 52], "select": [5, 6, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 39, 40, 41, 52], "select_dtyp": 31, "select_knn": 34, "select_rf": 34, "select_svc": 34, "selectfrommodel": 34, "self": [22, 27, 41, 42, 52], "sell": [0, 8, 23], "semant": [35, 36, 38, 52], "semest": 52, "semi": [10, 38], "semicolon": 8, "semilogx": 31, "send": [4, 22, 42], "senior": 41, "seniorcitizen": 41, "sens": [6, 24, 27, 28, 30, 31, 33, 34, 35, 37, 38, 40, 41, 43], "sensibl": 7, "sensit": [24, 26, 29, 30, 31, 35, 41], "sent": [22, 38], "sent_token": 38, "sentenc": 38, "sentiment": [23, 28, 38, 42], "sentimentintensityanalyz": 42, "sepal": [25, 46], "separ": [23, 24, 26, 27, 28, 30, 34, 35, 37, 38, 40, 43, 44, 45, 46, 47, 48, 49], "septemb": 40, "sequenc": [24, 27, 39, 40], "sequenti": [23, 32, 40, 41, 44], "sequentialfeatureselector": 34, "ser": [24, 26, 41], "seri": [2, 10, 24, 26, 27, 30, 34, 39, 41, 42, 52], "serial": 32, "seriou": [6, 30, 37, 38, 41, 52], "serv": [5, 23, 33, 52], "server": 5, "servic": [32, 33, 37, 41, 42], "session": [35, 44, 52], "set": [7, 8, 9, 10, 22, 23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51], "set_config": [29, 32], "set_index": [24, 25, 29, 30, 31], "set_opt": [22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 45, 46, 47, 48, 49], "set_properti": 22, "set_titl": [25, 28, 30, 39, 46, 49], "set_xlabel": [25, 28, 35, 46], "set_ylabel": [25, 28, 35, 46], "settl": [48, 49], "setup": [3, 7, 11, 45], "setup_default_warn": 42, "sev": [31, 33], "sever": [11, 26, 28, 35, 36, 38, 39, 40, 43, 51, 52], "sex": [30, 32, 33, 34, 49, 50], "sexual": 52, "sfu": 38, "shadab": 52, "shadow": 19, "shaikh": 52, "shall": [0, 38], "shallow": 32, "shan": 38, "shape": [23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 49, 51], "shape_df": 24, "shape_dict": 24, "share": [0, 34, 52], "sharealik": 1, "sharex": 26, "shashwat": 52, "she": [22, 37, 38, 42], "shed": [31, 33], "sheet": [9, 44], "shelf": [32, 38, 48], "shell": [5, 9, 42], "shelv": 42, "shift": [40, 51], "shit": 42, "shng": 31, "shop": 37, "short": [10, 11, 24, 29, 32, 38, 52], "shorter": 41, "shorthand": 26, "shot": 34, "should": [5, 7, 8, 11, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52], "shouldn": [30, 32, 38, 46], "show": [4, 7, 11, 22, 24, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 48, 50, 51], "show_plot": 41, "showcas": 38, "shown": [7, 11, 22, 23, 25, 30, 32, 35, 36, 40], "shrink": [29, 34], "shuffl": [24, 39, 40, 51], "si": 22, "sibl": 34, "sick": [35, 42], "sid": 42, "side": [6, 39], "sift": 37, "sigma": 39, "sign": [4, 31, 33, 39, 46, 48, 50, 52], "signal": [24, 38], "signific": [26, 39, 52], "significantli": [27, 30, 37], "sigoptsearchcv": 29, "silhouett": 36, "silhouettevisu": [35, 36], "sim": 33, "sim_word": 38, "simard": 33, "similar": [10, 11, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 43], "similarity_": 38, "similarli": [33, 35, 41], "simon_fras": 38, "simp": 40, "simpl": [10, 23, 25, 26, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 44, 45, 49], "simplefilt": [32, 33], "simpleimput": [26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 44, 47, 48, 49, 50, 51], "simpleimputersimpleimput": [26, 27, 31, 32, 34], "simpler": [28, 29, 46], "simplest": 27, "simpli": [26, 34, 35, 38], "simplic": [23, 27, 37], "simplist": [25, 33, 46], "simul": 34, "sin": 8, "sinc": [5, 28, 31, 33, 34, 35, 37, 39, 40, 41, 43, 44, 45, 51], "singer_songwriter_bob_dylan": 38, "singl": [8, 25, 26, 28, 29, 30, 32, 33, 36, 40, 41, 44, 45, 46, 48, 49], "sit": 52, "sitarist_ravi_shankar": 38, "site": [5, 23, 24, 27, 29, 33, 41, 42, 43, 52], "situat": [6, 22, 30, 32, 35, 39, 41, 52], "six": [24, 32, 40], "size": [22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 50, 51, 52], "skew": 31, "skill": [32, 52], "skin": 42, "skip": 49, "skipna": 41, "sklearn": [10, 22, 24, 25, 28, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "sklearn_gb": 32, "sklearn_histgb": 32, "sktime": 40, "skyblu": [40, 51], "skyscrap": 40, "sl": 38, "slate": 51, "slice": 8, "slide": [9, 10, 19, 26, 39, 52], "slightli": [27, 28, 30, 32, 41], "slope": 28, "sloppi": 26, "slot": 52, "slow": [25, 32, 34, 39], "slower": [32, 35], "slowest": 50, "sm": [22, 27], "smac": 29, "small": [11, 24, 25, 27, 29, 31, 32, 33, 34, 35, 37, 39, 41, 44, 46, 48, 50], "small_citi": 25, "small_train_df": 25, "smallalpha_coeff": 31, "smaller": [25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 40, 41, 46, 48], "smallest": [28, 31, 35, 36], "smart": [35, 42], "smile": 42, "smooth": [25, 46], "smoothli": 11, "smote_pip": 30, "sms_df": 22, "sn": [33, 35, 36], "snake": [28, 39], "snake_length": 28, "snakes_df": 28, "snbf": 32, "snippet": 7, "snow": [22, 39], "snp": 34, "so": [0, 4, 5, 7, 8, 10, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52], "social": [35, 36, 37, 40], "societ": 52, "societi": [30, 38, 49], "sofist": 46, "soft": [28, 32, 50], "softmax": 44, "softwar": [1, 5, 11, 41], "solar": 37, "sold": [8, 31], "sole": [30, 36], "solidifi": 44, "solut": [22, 23, 24, 32, 35, 41, 42, 44, 52], "solv": [4, 22, 23, 25, 34, 38, 46, 52], "solver": 30, "some": [4, 6, 7, 8, 11, 22, 24, 25, 26, 27, 28, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52], "someon": [22, 23, 24, 34, 41], "someth": [4, 7, 11, 23, 27, 30, 31, 32, 33, 35, 40, 41, 44, 52], "sometim": [6, 23, 24, 27, 28, 29, 32, 33, 38], "somewhat": 31, "somewher": [22, 31], "song": [25, 26, 37, 42, 48], "song_titl": [25, 26, 29, 48], "soo": 52, "soon": [22, 25, 26, 40], "sopha": 22, "sophist": [29, 33, 38], "sort": [5, 10, 23, 24, 26, 33, 37, 38, 39, 40, 51], "sort_index": [8, 29, 31, 40, 51], "sort_valu": [26, 27, 28, 29, 31, 32, 33, 34, 40, 41, 42, 50, 51], "sound": [33, 34], "soundtrack": 38, "sourc": [11, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 45, 48, 52], "south": 27, "space": [25, 28, 29, 34, 35, 36, 38, 42, 51, 52], "spaci": 34, "spacymoji": 42, "spam": [24, 30, 35], "spam_predict": 22, "span": [38, 40], "spanish": 26, "spars": [25, 28, 32, 37, 38, 44], "sparse_output": [26, 27, 30, 31, 32, 33, 40, 41, 44, 49, 50, 51], "spatial": 28, "speak": 5, "spearmint": 29, "speci": [25, 44, 46], "special": [22, 27, 37, 38, 39, 40, 41, 46, 52], "specialti": [30, 32, 33], "specif": [8, 23, 24, 29, 30, 33, 35, 37, 38, 39, 40, 41, 44, 46, 48, 50, 52], "specifi": [8, 23, 24, 27, 29, 30, 35, 36, 39, 48, 50], "spectrogram": 34, "speech": [34, 38, 42], "speechi": [25, 26, 29, 48], "speed": [8, 23, 32, 39], "spell": 22, "spend": [22, 26, 34, 42, 52], "spent": [6, 26, 34], "spheric": [36, 44], "spici": 35, "spini": 39, "spit": 39, "split": [15, 23, 25, 27, 28, 29, 31, 32, 34, 37, 38, 41, 42, 44, 49, 50, 51, 52], "split0_test_r2": 31, "split0_test_scor": 29, "split0_train_neg_mean_squared_error": 31, "split0_train_scor": 29, "split1_test_r2": 31, "split1_test_scor": 29, "split1_train_neg_mean_squared_error": 31, "split1_train_scor": 29, "split2_test_r2": 31, "split2_test_scor": 29, "split2_train_neg_mean_squared_error": 31, "split2_train_scor": 29, "split3_test_r2": 31, "split3_test_scor": 29, "split3_train_neg_mean_squared_error": 31, "split3_train_scor": 29, "split4_test_scor": 29, "split4_train_neg_mean_squared_error": 31, "split4_train_scor": 29, "spoken": 27, "sport": [38, 39, 40], "spot": [30, 31, 46], "spotifi": [25, 37, 48], "spotify_df": [25, 26, 29, 48], "spotlight": [5, 11], "spous": [30, 32, 33], "spread": 36, "spring_month": 40, "sqft": 33, "sqft_abov": [22, 23], "sqft_basement": [22, 23], "sqft_live": [22, 23], "sqft_living15": [22, 23], "sqft_lot": [22, 23], "sqft_lot15": [22, 23], "sqrt": [25, 31, 33, 37, 38], "squar": [8, 23, 25, 28, 33, 37, 41, 42, 44, 52], "squash": [28, 39], "squeez": [8, 41], "src": [24, 30], "sse": [40, 51], "ssw": 40, "st": [40, 42], "st_slope": 50, "stabil": 11, "stabl": [24, 30, 32, 46], "stack": [7, 44, 52], "stack_method": 50, "stacking_model": [32, 50], "stacking_model_tre": 32, "stackingclassifi": [32, 50], "stackingregressor": 32, "staff": 6, "stai": [30, 41], "stakehold": 52, "stale": 35, "stand": [25, 29, 38], "standard": [4, 6, 24, 26, 29, 32, 33, 34, 38], "standardscal": [27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51], "standardscalerstandardscal": [26, 27, 29, 30, 31, 32, 34, 39, 42], "stanford": 38, "star": [25, 35, 37, 42], "start": [7, 8, 11, 23, 24, 25, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51], "startswith": 33, "starttim": 40, "stat": [29, 41, 48], "state": [6, 8, 24, 30, 32, 33, 37, 38, 42, 49], "statement": [7, 24, 25, 26, 27, 28, 29, 30, 31, 34, 39, 41], "station": 40, "statist": [9, 10, 23, 28, 33, 37, 38, 41, 52], "statistician": 25, "statlib": 28, "statsmodel": [40, 41], "statu": [30, 32, 33, 49], "status_marri": 33, "status_nev": 33, "std": [24, 25, 26, 30, 31, 39, 40, 42, 43, 51], "std_cv_error": 24, "std_cv_score": 25, "std_fit_tim": [29, 31], "std_score": [24, 26, 42], "std_score_tim": [29, 31], "std_test_neg_mean_squared_error": 31, "std_test_scor": [24, 29], "std_train_error": 24, "std_train_neg_mean_squared_error": 31, "std_train_scor": [24, 25, 29], "stdki": 41, "stem": 38, "step": [7, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 48, 50, 52], "stereotyp": 38, "stick": 40, "still": [4, 11, 29, 30, 31, 32, 34, 35, 40, 41, 42, 46, 47, 48, 49], "stochast": [34, 35], "stock": [22, 40], "stop": [8, 35, 38, 39, 41, 46], "stop_word": [29, 30, 38, 42, 48], "stopword": 38, "storag": 25, "store": [7, 8, 25, 26, 27, 29, 30, 32, 33, 36, 37, 38, 39, 40, 41, 42], "stori": [31, 32, 42], "storylin": 38, "str": [29, 33, 38, 40, 41, 42, 51], "straight": 41, "straightforward": 33, "strain": 7, "strang": [33, 41], "strata": 41, "strategi": [23, 25, 26, 27, 30, 31, 33, 35, 37, 40, 41, 44, 45, 49, 51], "stratif": 41, "stratifi": 41, "stratifiedkfold": [24, 30], "stream": [41, 42], "streamingmovi": 41, "streamingmovies_no": 41, "streamingmovies_y": 41, "streamingtv": 41, "streamingtv_no": 41, "streamingtv_y": 41, "street": [31, 33], "street_grvl": 31, "street_pav": 31, "strength": [38, 44], "stress": 35, "strftime": [40, 41], "string": [8, 11, 25, 30, 31, 32, 33, 38, 40, 41, 46, 50], "strip": [33, 39], "strong": [32, 41, 44], "stronger": 32, "strongli": 32, "structur": [8, 35, 38, 39], "struggl": [35, 40], "stuart": [10, 32], "stuck": [4, 8], "student": [4, 5, 6, 7, 22, 23, 28, 30, 31, 33, 34, 35, 36, 37, 39, 42, 52], "studi": [22, 27, 34, 38, 41], "stuff": [25, 39, 41], "stump": [23, 24, 25, 32, 45], "stupid": 42, "style": [22, 31, 34, 35, 37, 38, 39, 42], "sub": [29, 35, 38, 41, 44], "subdirectori": 33, "subgroup": 41, "subject": [0, 41, 52], "sublicens": 0, "submiss": [3, 52], "submit": [8, 10, 52], "subplot": [24, 25, 28, 30, 35, 39, 41, 46, 49], "subplot_kw": 24, "subprocess": 31, "subscrib": 41, "subscript": [40, 41], "subset": [23, 24, 29, 32, 39, 40, 43, 46], "substanti": 0, "substitut": 0, "subtl": 38, "subtleti": [24, 31], "subtract": [25, 30, 33], "suburb": 42, "subword": 38, "succe": [34, 52], "success": [5, 8, 11, 22, 30, 32, 37, 38, 39, 40], "successfulli": [11, 22, 42], "sudo": 5, "suei": 29, "suffer": 29, "suffici": [7, 38], "suggest": [0, 10, 23, 37, 41], "suicid": 38, "suit": 37, "suitabl": [11, 22, 35, 37, 44, 50, 52], "sultan": 38, "sum": [8, 25, 26, 27, 28, 32, 33, 35, 39, 42], "sum_": [25, 31, 35, 38, 39], "sum_i": [33, 38], "sum_prob_ex1_class_0": 32, "sum_prob_ex1_class_1": 32, "summar": [10, 22, 28, 30, 31, 35, 38], "summari": [0, 43, 44, 46], "summary_plot": 33, "summat": 32, "summer": [1, 37, 40], "summer_month": 40, "sun": [38, 40], "sundai": 40, "sundial": 39, "sunshin": [40, 51], "super": [27, 42, 44], "superfici": 25, "superior": 52, "supermarket": 42, "supervis": [26, 27, 29, 30, 31, 34, 36, 38, 40, 41, 44, 51, 52], "suppli": 52, "support": [11, 15, 23, 26, 30, 32, 33, 34, 36, 38, 42, 43, 46, 52], "support_": [25, 34], "suppos": [22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 44, 45], "suppress": 8, "suprem": 38, "supr\u00eam": 38, "sure": [4, 7, 8, 11, 24, 25, 27, 30, 31, 32, 33, 36, 39, 40, 46, 49, 50, 51, 52], "surgeri": 41, "suri": 52, "surpris": [33, 37], "surprisingli": [27, 28], "surround": [4, 52], "survei": 35, "surviv": [2, 10, 52], "survival_function_": 41, "suscept": 36, "suspect": 29, "svc": [25, 26, 27, 28, 29, 32, 33, 34, 39, 42, 46, 47, 48, 50], "svc__c": [29, 48], "svc__gamma": [29, 48], "svc_pipe": 29, "svc_pred": 30, "svcsvc": [27, 29, 30], "svm": [10, 24, 26, 27, 29, 32, 33, 34, 39, 40, 42, 43, 44, 46, 47, 48, 50], "svm_estim": 30, "svr": [25, 27, 33], "svr_c_pipe": 27, "svr_pipe": 27, "sw": [40, 51], "swai": 22, "swamp": 25, "swan": 39, "swcarpentri": 9, "sweep": 30, "sweet": 42, "switch": [33, 35, 40, 41, 51], "sy": [22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50], "sydnei": 40, "syllabu": [3, 7, 10, 12], "symbol": 23, "symmetri": 34, "sync": 5, "synonym": 38, "synopsi": 38, "syntact": 38, "syntax": [4, 8, 22, 34, 41], "synthet": [34, 43], "system": [2, 4, 5, 6, 10, 11, 22, 24, 25, 27, 30, 33, 35, 40, 49, 52], "systemat": [23, 27, 29, 33, 38], "t": [4, 5, 7, 8, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 50, 51, 52], "ta": [7, 22, 31, 33, 45, 46, 47, 48, 49, 50, 51], "tabbi": [22, 39], "tabl": [7, 50], "tabular": [8, 22, 39, 40], "tackl": [24, 26, 30, 36, 46], "taco": 34, "tag": [4, 38, 42], "tail": [8, 40], "tailor": [35, 52], "take": [2, 4, 5, 6, 11, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52], "taken": [40, 43, 48, 52], "talk": [23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 52], "tall": 38, "target": [24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 39, 40, 41, 44, 46, 47, 48, 49, 50, 51], "target_column": [32, 33, 41, 50], "target_nam": 30, "target_names_toi": 30, "tariff": 38, "task": [26, 27, 28, 29, 33, 34, 35, 37, 39, 40, 41, 42, 44, 48, 51, 52], "tast": [35, 37], "taught": [27, 38, 52], "tba": 10, "tbd": [19, 52], "teach": [4, 22, 26, 38, 44], "team": [4, 8, 22, 32, 33, 38, 50], "tech": [25, 30, 33], "technic": 52, "techniqu": [10, 25, 29, 34, 37, 39, 41, 43, 44, 52], "technolog": 0, "technologi": 38, "techsupport": 41, "techsupport_no": 41, "techsupport_y": 41, "ted": 35, "tediou": 36, "telco": 41, "telecom": 41, "telephon": 38, "tell": [24, 25, 26, 28, 30, 33, 34, 37, 38, 40, 41, 46, 48, 51], "temp3pm": [40, 51], "temp9am": [40, 51], "temperatur": 23, "tempo": [25, 26, 29, 48], "tempor": [41, 44, 51], "tend": [24, 25, 28, 32, 34, 37, 40, 41, 52], "tendenc": 24, "tensor": 39, "tensor_numpi": 42, "tensorflow": [11, 33, 39], "tent": 52, "tenur": [41, 44], "tenure_lm": 41, "tenure_predict": 41, "term": [0, 2, 23, 25, 27, 28, 30, 33, 34, 37, 38, 41, 44], "termin": [5, 11, 23, 35], "terminologi": [14, 24, 30, 44, 45], "terrac": 39, "terribl": [31, 37], "territori": 52, "tesoro": 29, "test": [1, 7, 8, 11, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 36, 41, 43, 44, 46, 48, 49, 50, 51, 52], "test_accuraci": 30, "test_average_precis": 30, "test_df": [22, 26, 27, 28, 30, 31, 32, 33, 34, 40, 41, 42, 47, 49, 50, 51], "test_df_churn": 41, "test_df_nan": [30, 32, 33, 49], "test_df_sort": 40, "test_df_surv": 41, "test_exampl": 32, "test_f1": 30, "test_format": 25, "test_g50k": 32, "test_imag": [22, 39], "test_l50k": 32, "test_mape_scor": 31, "test_nam": 41, "test_neg_mean_squared_error": 31, "test_neg_root_mean_square_error": 31, "test_point": [25, 43], "test_precis": 30, "test_r2": 31, "test_recal": 30, "test_roc_auc": 30, "test_sampl": 50, "test_scor": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 46], "test_shap_valu": 33, "test_siz": [22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 42, 43, 46, 47, 48, 49, 50], "test_sklearn": 31, "test_statist": 41, "test_x": 41, "text": [7, 10, 16, 17, 22, 23, 28, 29, 30, 31, 32, 33, 34, 37, 39, 44, 48, 52], "text_feat": [29, 48], "text_featur": 42, "text_pp": 38, "textbook": [3, 9], "textrm": 24, "textual": 52, "textur": 34, "tf": 27, "tfidfvector": 28, "th": [28, 37, 52], "than": [6, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 49, 50, 52], "thank": [22, 38, 46], "thankfulli": [40, 51], "thei": [7, 8, 10, 23, 24, 25, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 50, 51, 52], "theirs": 38, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 45, 46, 48, 49, 50, 52], "theme": 38, "themselv": [35, 36, 38], "theoret": [26, 30, 32, 44], "theori": 33, "thepopbreak": 42, "therefor": 46, "thermostat": 23, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "thick": 35, "thinc": 42, "thing": [5, 7, 8, 10, 23, 24, 25, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 50, 51], "think": [4, 22, 23, 24, 25, 27, 28, 30, 31, 33, 34, 35, 37, 39, 40, 41, 44, 45, 46, 48, 49, 51, 52], "third": 36, "thk": 22, "thorough": [11, 50], "thoroughli": 44, "those": [5, 8, 11, 26, 31, 32, 33, 37, 38, 41, 52], "though": [24, 27, 28, 35, 36, 37, 42], "thought": [4, 25, 33, 41, 44], "thousand": [28, 36, 37], "thrasher": 38, "threahold": 34, "threaten": 42, "three": [8, 23, 26, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 43, 44, 49, 52], "thresh": 8, "threshold": [23, 28, 32, 34, 36, 38, 41], "thresholds_lr": 30, "thresholds_svc": 30, "through": [7, 11, 23, 30, 31, 34, 36, 37, 38, 39, 52], "throughout": 24, "throw": [27, 39, 41, 44], "thu": [6, 29, 40, 41], "thumb": [23, 42], "thursdai": 52, "ti": 27, "tick": 40, "tick_label": 33, "tick_param": 35, "tiffin": 38, "tiger": [22, 39], "tight": [25, 36, 46], "tight_layout": 39, "tightrop": [25, 46], "tile": 33, "till": [25, 38, 41], "timber": 38, "time": [2, 4, 8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 45, 46, 48, 49, 50, 52], "time_diff": [40, 51], "time_signatur": [25, 26, 29, 48], "timedelta": [40, 51], "timeit": [8, 43], "timeseri": [39, 40], "timeseriessplit": [40, 41, 44, 51], "timestamp": [40, 51], "timezon": [10, 41], "tinder": 37, "tini": [7, 24, 30, 36], "tip": 38, "tire": 42, "titan": 37, "titi": 22, "titl": [7, 24, 25, 28, 31, 34, 36, 39, 40, 41, 46, 51], "tn": 30, "to_datetim": [40, 51], "to_html": [22, 23, 24], "to_notebook_ifram": 31, "to_numpi": [25, 37, 40], "to_str": [22, 39], "toarrai": [27, 33, 40], "tobago": [32, 33], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 37, 39, 40, 41, 44, 50, 51], "todens": [33, 34], "togeth": [5, 8, 23, 25, 26, 27, 35, 38, 46, 52], "toi": [8, 24, 25, 34, 35, 36, 37, 40, 44], "toilet": [39, 42], "token": [7, 42, 52], "token_pattern": 27, "tol": [30, 34], "told": [5, 52], "tolist": [22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 51], "tomasbeuzen": 8, "tomorrow": [23, 40, 41, 44, 51], "ton": 29, "tone": 42, "too": [6, 7, 24, 25, 27, 29, 31, 32, 33, 38, 40, 41, 46, 48, 51, 52], "took": 40, "tool": [7, 8, 10, 11, 27, 28, 30, 31, 33, 36, 37, 39, 40, 41, 44, 52], "toolbox": [25, 32, 38], "toolkit": 38, "top": [23, 27, 29, 30, 36, 40, 51], "topi": 38, "topic": [2, 8, 10, 23, 30, 31, 35, 37, 39, 44, 52], "topic2vec": 38, "topics_per_chunk": 38, "topn": [22, 39], "torch": [39, 42], "torchvis": [22, 39], "tornado": 42, "toronto": [38, 42], "tort": 0, "total": [8, 10, 23, 26, 27, 30, 31, 32, 33, 34, 38, 40, 41, 51], "total_bedroom": [26, 27, 34, 47], "total_bilirubin": 22, "total_protien": 22, "total_room": [26, 27, 34, 47], "total_second": [40, 51], "totalbsmtsf": [31, 33], "totalcharg": 41, "totem": 39, "totensor": 39, "toti": [0, 1, 38], "totrmsabvgrd": [31, 33], "toward": [28, 33, 38, 49, 52], "towardsdatasci": [39, 41], "town": 42, "townsvil": 40, "toy_clust": 38, "toy_clust_df": 35, "toy_df": [27, 38], "toy_lda_data": 38, "toy_movie_feat": 37, "toy_rat": 37, "toy_spam": 27, "toy_x": 38, "tp": 30, "tpot": 29, "tpr": 30, "tpr_lr": 30, "tpr_svc": 30, "tr_score": 46, "traceback": [4, 8, 27, 41, 42], "track": [27, 52], "trade": [28, 30, 34, 35, 44, 52], "tradeoff": [15, 25, 26, 28, 31, 34, 35, 39], "tradit": [22, 37, 39, 41, 52], "tradition": 52, "trail": 8, "train": [7, 25, 26, 29, 31, 32, 33, 34, 35, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51], "train_accuraci": 30, "train_dataload": 39, "train_df": [22, 26, 27, 28, 30, 31, 32, 33, 34, 40, 41, 42, 47, 49, 50, 51], "train_df_churn": 41, "train_df_nan": [30, 32, 33, 49], "train_df_ord": [40, 51], "train_df_sort": 40, "train_df_surv": 41, "train_df_surv_not_churn": 41, "train_f1": 30, "train_flatten": 39, "train_for_usr": 37, "train_load": 39, "train_mape_scor": 31, "train_mat": 37, "train_mat_imp": 37, "train_neg_mean_squared_error": 31, "train_neg_root_mean_square_error": 31, "train_precis": 30, "train_r2": 31, "train_recal": 30, "train_scor": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 46], "train_shap_valu": 33, "train_sklearn": 31, "train_test_split": [22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51], "train_x": 37, "traitlet": 42, "transact": [23, 30, 40, 49], "transfer": 41, "transfer_learning_tutori": 39, "transform": [0, 25, 29, 30, 32, 33, 36, 38, 39, 40, 41, 42, 44, 46, 47, 51], "transformed_exampl": 32, "transformed_oh": 26, "transformedtargetregressor": [31, 34, 42, 44], "transformedtargetregressortransformedtargetregressor": 31, "transformerdecod": 42, "transformerencod": 42, "translat": [9, 10, 22], "transpar": [30, 44], "transpos": [34, 39], "trasform": 26, "trash": 45, "traumat": 52, "treat": [8, 24, 26, 27, 30, 31, 37, 40, 41, 44, 49, 51], "treati": 52, "treatment": 27, "tree": [2, 10, 14, 19, 20, 24, 25, 26, 27, 28, 29, 31, 34, 36, 39, 40, 41, 43, 44, 45, 47, 48, 50], "tree1": 32, "tree2": 32, "tree3": 32, "tree_numeric_transform": 33, "treeexplain": 33, "trend": [41, 44, 52], "tri": [32, 33, 43, 48, 49, 50], "trial": [29, 41], "triangl": [25, 35], "trick": [5, 31], "tricki": [27, 29, 33, 37], "trigger": [25, 42], "trigram": 38, "trivial": 36, "troubl": 11, "true": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51], "truli": [31, 38], "truncat": 36, "truncate_mod": 36, "truncation_mod": 36, "trust": [22, 26, 27, 29, 30, 31, 32, 33, 34, 37, 39, 42], "trustworthi": [36, 50], "truth": [32, 34, 35, 36, 37, 40], "try": [4, 5, 8, 10, 11, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52], "tsa": 40, "tscv": 40, "tslearn": 40, "tsunami": 22, "ttr": 31, "ttr_pipe": 31, "tue": 40, "tuesdai": [10, 34, 40, 51, 52], "tuggeranong": 40, "tumor": 44, "tune": [24, 29, 32, 36, 37, 39, 48, 50], "turn": [4, 24, 38, 39, 41, 47, 48, 52], "tusker": 39, "tutori": [4, 5, 9, 10, 11, 37, 39, 44, 52], "tweak": [25, 46], "tweet": [38, 42], "tweetat": 42, "twice": [8, 24, 27, 28], "twist": 38, "twitter": 38, "twitter_allowed_char": 42, "two": [4, 6, 7, 8, 9, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 47, 49, 52], "two_citi": 25, "two_song": 26, "two_songs_subset": 26, "tx": [28, 42], "txt": [22, 39], "typ": [31, 33], "type": [4, 8, 11, 23, 25, 26, 27, 29, 32, 34, 36, 37, 38, 39, 42, 44, 46, 47, 48, 51, 52], "typeerror": 41, "typic": [2, 7, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 35, 37, 40, 48], "u": [4, 11, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51], "u6": 23, "u_1": 25, "u_2": 25, "u_i": 25, "u_n": 25, "ubc": [0, 4, 5, 8, 9, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47, 48, 49, 50, 51, 52], "ubc_img": 39, "ubc_okanagan": 38, "ubco": 38, "ubyssei": 38, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 31, "ufv": 38, "ultim": [4, 24], "ultralyt": 39, "uluru": [40, 51], "umbrella": 37, "un": [31, 41], "unabl": [22, 26, 27, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 52], "unambigu": 38, "unassign": [35, 36], "unbalanc": 49, "unbias": [30, 49], "unced": 52, "uncertain": [28, 50], "uncertain_indic": 50, "uncertainti": [28, 30], "unchang": 33, "uncia": [22, 39], "uncomfort": 37, "uncorrel": 33, "under": [0, 1, 7, 23, 24, 31, 38, 39, 41], "under_sampl": 30, "underestim": 41, "underfit": [25, 28, 29, 39, 46, 48], "underli": [2, 33, 34, 35], "underneath": 7, "underpredict": 31, "undersample_pip": 30, "understand": [0, 1, 4, 7, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 49, 52], "understood": 30, "unemploi": 41, "unexpect": [27, 28, 29, 38], "unexplain": 31, "unf": [31, 33], "unfinish": 31, "unfortun": [6, 29, 33, 35, 36, 48], "uniform": [29, 30, 36, 48], "unimport": [29, 33], "uninstal": 11, "uninterpret": 33, "unintuit": 8, "union": 8, "uniqu": [26, 27, 30, 31, 32, 33, 37, 38, 40, 41, 49, 51], "unit": [28, 30, 31, 32, 33, 38, 39, 41, 42], "unitless": 31, "univers": [1, 9, 38], "university_year": [27, 44], "unix": [5, 40], "unknown": [6, 38, 44], "unlabel": [22, 24, 36], "unless": [7, 52], "unlik": [8, 24, 25, 27, 31, 33, 35, 36], "unlimit": 40, "unlucki": 24, "unmarri": [32, 33], "unnam": 22, "unoffici": 52, "unqualifi": [30, 49], "unreason": [6, 31], "unreli": 24, "unscal": 26, "unseen": [23, 34, 35, 39, 46], "unsqueez": 39, "unstructur": 38, "unsupervis": [22, 37, 38, 39, 52], "unsur": 7, "until": [4, 23, 24, 29, 34, 35, 36, 38, 41], "unus": 46, "unwieldi": [23, 26], "unzip": 33, "uoft": 38, "up": [7, 8, 22, 23, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 48, 52], "uparrow": 36, "upcom": 35, "updat": [10, 11, 25, 26, 27, 32, 35, 46], "update_cent": 35, "update_plot": [25, 46], "update_z": 35, "upei": 38, "upgrad": [38, 42], "upload": 7, "upon": [0, 23, 24, 27, 30, 32, 33, 34, 35, 36, 38], "upper": [30, 41], "uppercas": 42, "upto": 40, "ur": 22, "urgent": [27, 38], "url": [4, 24, 30, 41, 49], "us": [0, 2, 4, 5, 10, 11, 28, 29, 33, 36, 37, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51], "usa": [8, 24, 25, 28, 38], "usag": [26, 27, 30, 31, 34, 38, 40, 41, 51], "usec_": 41, "useless": [29, 33, 34], "user": [11, 22, 23, 24, 26, 27, 29, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 48], "user_global_n": 42, "user_id": 37, "user_inverse_mapp": 37, "user_kei": 37, "user_mapp": 37, "user_n": 42, "user_nam": 37, "usernam": 42, "userwarn": [23, 24, 27, 32, 33, 42], "usf": 27, "using_copy_on_writ": 41, "using_cow": 41, "usual": [10, 11, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 51, 52], "utc": [40, 41], "utcnow": 41, "util": [5, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 39, 41, 42, 44, 45, 46, 47, 48, 50], "utilities_allpub": 31, "utilities_nosewa": 31, "utility_mat": 37, "uvic": 38, "v": [3, 7, 10, 27, 28, 36, 38, 40, 41, 44], "v1": [22, 30], "v10": 30, "v11": 30, "v12": 30, "v13": 30, "v14": 30, "v15": 30, "v16": 30, "v17": 30, "v18": 30, "v19": 30, "v2": [22, 30], "v20": 30, "v21": 30, "v22": 30, "v23": 30, "v24": 30, "v25": 30, "v26": 30, "v27": 30, "v28": 30, "v3": 30, "v4": 30, "v5": 30, "v6": 30, "v7": 30, "v8": 30, "v9": 30, "v_1": 25, "v_2": 25, "v_i": 25, "v_n": 25, "vacat": 28, "vaccin": 42, "vada_pav": 38, "vader": 42, "vader_lexicon": 42, "vader_senti": 42, "vain": 29, "val": [37, 41], "valenc": [25, 26, 29, 42, 48], "valid": [10, 15, 23, 25, 27, 31, 32, 33, 34, 35, 37, 39, 41, 42, 44, 47, 48, 49, 50, 51], "valid_dataload": 39, "valid_flatten": 39, "valid_load": 39, "valid_mat": 37, "valid_sample_df": 32, "valid_sample_i": 32, "valid_sample_x": 32, "valid_scor": 46, "valid_x": 37, "valu": [7, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51], "valuabl": [34, 36, 52], "value_count": [23, 27, 30, 32, 33, 40, 41, 42, 49, 50, 51], "value_throttl": [25, 46], "valueerror": [8, 26, 27, 41], "values_format": [30, 49], "vancouv": 38, "vancouver_canuck": 38, "vanilla": 28, "var": [24, 26, 33, 42, 48], "var_": 33, "varada": [0, 1], "vari": [23, 29, 32, 36, 41, 46, 52], "variabl": [7, 8, 23, 26, 27, 28, 29, 31, 33, 34, 40, 41, 46, 51], "varianc": [31, 33, 36, 40, 46], "variant": [33, 36], "variat": [24, 28, 30, 31, 34], "varieti": [22, 32, 38], "variou": [22, 25, 31, 33, 39, 40, 41, 44, 46, 48, 52], "vault": 24, "ve": [7, 8, 22, 24, 25, 30, 31, 33, 37, 38, 39, 40, 43, 51], "vec": [27, 38, 39], "vec1": 38, "vec1_i": 38, "vec2": 38, "vec2_i": 38, "vec8": 27, "vec8_binari": 27, "vec_binari": 27, "vecom": 29, "vector": [15, 23, 28, 30, 37, 39, 46, 50], "verb": [38, 42], "verbos": [22, 30, 32, 33], "veri": [2, 4, 5, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 51, 52], "verifi": 49, "versa": [31, 46, 49], "version": [4, 5, 7, 8, 11, 24, 26, 28, 29, 31, 33, 36, 38, 40, 41, 42, 43, 49, 51, 52], "versu": 9, "vert": 33, "vertic": [23, 30, 40], "vgg": 39, "vgg16": 39, "vgg16_weight": 39, "via": [1, 4, 7, 11, 30, 34, 52], "vice": [31, 46, 49], "video": [1, 7, 8, 9, 10, 11, 19, 37, 39, 41, 46, 49, 52], "vietnames": 26, "view": [6, 7, 11, 22, 23, 33, 36, 39, 40, 41], "viewpoint": 37, "vif": 33, "vikski": 38, "violat": [26, 27, 41, 52], "virginia": 39, "viridi": [29, 48], "visibl": 48, "vision": [10, 43], "visit": [8, 52], "visual": [10, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 44, 47, 48, 52], "viu": 38, "voc": [30, 32, 33, 49], "vocab": 38, "vocabulari": [27, 28, 38], "vocabulary_": 27, "voic": 22, "volcano": 22, "vote": [25, 26, 32, 43, 50], "voting_ndt": 32, "votingclassifi": [32, 50], "votingclassifierinot": 32, "votingregressor": 32, "w": [11, 27, 28, 31, 35, 38, 40, 51, 52], "w_0": 28, "w_1": 28, "w_1x_1": 28, "w_2x_2": 28, "w_3x_3": 28, "w_4x_4": 28, "w_d": 28, "w_dx_d": 28, "w_j": 28, "wa": [4, 5, 11, 23, 24, 26, 28, 30, 32, 33, 37, 38, 39, 41, 42, 43, 45, 46, 48, 51, 52], "wa_fn": 41, "wai": [0, 2, 6, 8, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 51, 52], "wait": [4, 22, 23, 25, 27, 41, 52], "waitlist": 52, "waiv": 52, "walk": [25, 30, 46], "walker": [22, 39], "wallabi": 39, "want": [4, 6, 7, 8, 11, 22, 23, 24, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 47, 48, 49, 51, 52], "war": 37, "ward": 36, "warm": 26, "warm_start": 30, "warn": [6, 24, 25, 27, 31, 32, 33, 41, 43, 50], "warranti": 0, "washington": 42, "washroom": 52, "wasn": 38, "wast": [4, 27], "watch": [10, 11, 25, 28, 37, 38, 44], "waterfal": 33, "waterfront": [22, 23], "wavelet": 34, "wd": [31, 33], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "weak": 44, "weather": [23, 40], "weatherau": [40, 51], "web": [5, 38, 44], "weblog": 38, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21], "wed": [10, 40], "wednesdai": [10, 40, 52], "week": [6, 13, 14, 24, 25, 26, 27, 30, 31, 32, 33, 37, 38, 40, 49, 52], "weekdai": 40, "weekend": [8, 40], "weekli": 42, "weight": [25, 32, 34, 37, 38, 39, 49, 52], "weighted_averag": 30, "weinberg": 33, "weird": 31, "welcom": [45, 52], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 48, 51, 52], "welsh": [22, 39], "went": [31, 42, 48, 50], "were": [0, 6, 27, 28, 30, 31, 38, 39, 40, 41, 48, 50, 52], "weren": 38, "what": [7, 8, 9, 23, 25, 29, 36, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "whatev": 34, "when": [4, 6, 7, 11, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52], "wher": 42, "where": [0, 7, 10, 11, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 44, 46, 49, 51], "wherea": [2, 23, 28, 29, 31, 33, 36], "whether": [0, 4, 7, 8, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 45, 50, 51, 52], "which": [4, 6, 8, 11, 24, 25, 26, 27, 28, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52], "whichev": 32, "while": [23, 24, 28, 29, 30, 32, 33, 35, 37, 38, 41, 42, 48], "white": [30, 32, 33, 36, 38], "whitespac": [38, 41], "who": [4, 5, 6, 22, 30, 33, 35, 36, 38, 40, 41, 42, 44, 52], "whole": [24, 29, 31, 33, 37, 48], "whom": [0, 38, 42], "whose": 4, "why": [8, 24, 25, 30, 31, 32, 35, 36, 38, 40, 41, 44, 45, 46, 47, 48], "wid": 30, "wide": [11, 28, 29, 32, 34, 37, 39], "wider": [25, 46], "widespread": 38, "widget": [25, 30, 35, 36, 46], "width": [23, 24, 25, 30, 38, 45, 46], "wife": [22, 30, 32, 33], "wiki": 38, "wiki_df": 38, "wiki_dict": 38, "wikipedia": [38, 39], "wikipedia2vec": 38, "wild": [22, 24, 39], "willing": 30, "win": [25, 27, 32, 33, 34, 37, 43], "wind": 23, "winddir3pm": [40, 51], "winddir3pm_miss": [40, 51], "winddir3pm_ss": [40, 51], "winddir3pm_ssw": [40, 51], "winddir3pm_sw": [40, 51], "winddir3pm_w": [40, 51], "winddir3pm_wnw": [40, 51], "winddir3pm_wsw": [40, 51], "winddir9am": [40, 51], "windgustdir": [40, 51], "windgustspe": [40, 51], "window": [10, 41], "windsor": 42, "windspeed3pm": [40, 51], "windspeed9am": [40, 51], "wine_1": 8, "winter": 40, "winter_month": 40, "wire": 37, "wisdom": 32, "wish": [22, 23, 35, 52], "within": [23, 26, 28, 32, 34, 35, 36, 41, 44, 48], "without": [0, 7, 22, 23, 30, 32, 33, 34, 37, 39, 40, 41, 48, 52], "wnw": [40, 51], "wolv": 36, "woman": 38, "wombat": 39, "won": [5, 11, 23, 24, 25, 27, 28, 34, 37, 38, 39, 40, 41, 42], "wonder": [22, 24], "wooddecksf": [31, 33], "word": [22, 28, 29, 30, 34, 35, 36, 37, 39, 40, 41, 44, 48, 52], "word1": 38, "word2": 38, "word2vec": [38, 39, 52], "word3": 38, "word_pair": 38, "word_token": [38, 42], "wordnet": 38, "wordnetlemmat": 38, "work": [0, 4, 5, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 50, 51, 52], "work_of_art": 42, "workclass": [30, 32, 33, 49], "workclass_feder": [32, 33], "workclass_loc": [32, 33], "workclass_miss": 33, "workclass_nev": [32, 33], "workclass_priv": [32, 33], "workclass_self": 33, "workclass_st": 33, "workclass_without": 33, "workflow": [23, 52], "world": [25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 44], "worm": 39, "worri": [22, 35, 36, 37, 50], "wors": [23, 29, 31, 32, 41, 45, 48, 49], "worst": [30, 34, 35], "worth": [23, 25, 30, 31, 49], "worthi": 28, "would": [4, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52], "wouldn": [27, 29, 38, 41], "wow": 33, "wrap": 27, "wrapper": 34, "write": [4, 7, 22, 29, 33, 34, 35, 38, 42, 46, 50, 52], "written": [7, 27, 33, 40, 51], "wrong": [11, 24, 28, 31, 34, 35, 41, 48], "wrote": [38, 40, 51], "wsw": [40, 51], "www": [9, 28], "x": [4, 8, 11, 24, 25, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49], "x0": 34, "x0_male": 30, "x1": [34, 37], "x139": 52, "x1x2": 34, "x2": [34, 36, 37], "x27": [26, 27, 29, 30, 31, 32, 34, 39, 42], "x_": 28, "x_1": [28, 34, 35], "x_1x_2": 34, "x_2": [28, 34, 35], "x_binari": 23, "x_citi": 25, "x_count": 27, "x_d": 28, "x_femal": [30, 49], "x_hour": 40, "x_hour_week": 40, "x_hour_week_onehot": 40, "x_hour_week_onehot_poli": 40, "x_hour_week_onehot_poly_lag": 40, "x_i": [28, 37], "x_imp_ohe_train": 26, "x_init": 35, "x_int": 27, "x_label": [23, 24, 25, 45], "x_lag_featur": 40, "x_lag_features_imp": 40, "x_male": [30, 49], "x_mask": 27, "x_multi": 43, "x_n": 34, "x_orig": 36, "x_re": 30, "x_small_citi": 25, "x_spotifi": [25, 29, 48], "x_subset": [23, 24], "x_test": [22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50], "x_test_big": 29, "x_test_enc": [33, 40, 41, 51], "x_test_happi": 30, "x_test_imp": 26, "x_test_multi": 43, "x_test_pr": 40, "x_test_predict": 26, "x_test_scal": 26, "x_test_transform": 26, "x_toi": [25, 26, 27, 40], "x_toy_oh": 26, "x_toy_ord": [26, 27], "x_tr": 46, "x_train": [22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50], "x_train_big": [30, 49], "x_train_enc": [30, 31, 33, 40, 41, 49, 51], "x_train_happi": 30, "x_train_hous": 34, "x_train_imp": 26, "x_train_imp_sc": 26, "x_train_multi": 43, "x_train_oversampl": 30, "x_train_perm": 33, "x_train_pp": 27, "x_train_predict": 26, "x_train_scal": [26, 34], "x_train_subsampl": 30, "x_train_tini": 29, "x_train_transform": 26, "x_train_usr": 37, "x_transform": 27, "x_valid": [30, 37, 46, 49], "x_vari": 36, "x_xor": 34, "xanni": 29, "xavier": [34, 37], "xcode": 5, "xgbclassifi": [32, 33], "xgbclassifierxgbclassifi": 32, "xgboost": 33, "xgbregressor": [22, 32], "xia": 52, "xlabel": [8, 23, 24, 25, 28, 29, 30, 31, 33, 36, 39, 40, 41, 43, 45, 48, 51], "xlim": 41, "xor": [28, 34], "xt": 27, "xtick": [24, 30, 40, 51], "xticklabel": [29, 48], "xticks_rot": 30, "xwm\u0259\u03b8kw\u0259y": 52, "xx": [34, 35], "y": [8, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51], "y_": 37, "y_citi": 25, "y_femal": [30, 49], "y_hat": [28, 32], "y_i": [31, 32, 34, 37], "y_init": 35, "y_label": [23, 24, 25, 45], "y_male": [30, 49], "y_mat": 37, "y_multi": 43, "y_pred": [30, 40], "y_pred_lower_threshold": 30, "y_pred_toi": 30, "y_pred_train": 40, "y_re": 30, "y_small_citi": 25, "y_spotifi": [29, 48], "y_test": [22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51], "y_test_big": 29, "y_test_happi": 30, "y_test_multi": 43, "y_test_num": [32, 33], "y_toi": [25, 40], "y_tr": 46, "y_train": [22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51], "y_train_big": [30, 49], "y_train_happi": 30, "y_train_hous": 34, "y_train_multi": 43, "y_train_num": [32, 33], "y_train_ord": [40, 51], "y_train_oversampl": 30, "y_train_subsampl": 30, "y_train_tini": 29, "y_train_usr": 37, "y_true_toi": 30, "y_valid": [30, 37, 39, 46, 49], "y_vari": 36, "y_xor": 34, "yale": 38, "yann": 33, "ycxmx": 41, "ye": [4, 22, 23, 26, 27, 33, 35, 36, 37, 39, 40, 42, 44, 51], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 37, 38, 39, 40, 41], "yearbuilt": [31, 33], "yearremodadd": [31, 33], "yellow": 29, "yellowbrick": [35, 36], "yesterdai": [40, 51], "yet": [10, 11, 28, 33, 37, 40, 41, 46, 52], "yield": 48, "yifei": 52, "yjh": [22, 23, 27, 28, 31, 32], "ylabel": [8, 23, 24, 25, 28, 29, 30, 31, 36, 39, 40, 41, 43, 45, 46, 48, 51], "ylim": 41, "yml": 11, "yolo": 39, "yolo8": 39, "yolo_input": 39, "yolo_result": 39, "yolo_test": 39, "yolov8n": 39, "york": [40, 42], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 33, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "your": [0, 2, 4, 6, 7, 8, 10, 11, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "your_miniconda_path": 42, "your_nam": 11, "yourself": [4, 27, 30, 37, 38, 52], "yourselv": 38, "youtub": [1, 10, 37, 38, 52], "yr_built": [22, 23], "yr_renov": [22, 23], "yrpxn": 41, "yrsold": [31, 33], "ytick": [24, 30], "yticklabel": [29, 48], "yy": [34, 40, 51], "yyyi": [40, 51], "z": [8, 28, 34, 35, 36, 37, 39, 41], "z_i": 39, "z_j": 39, "z_km": 35, "z_train": 39, "z_valid": 39, "zachari": 41, "zarei": 52, "zero": [8, 24, 27, 29, 37, 38], "zero_divis": 30, "zhu": 52, "zip": [25, 28, 37, 46], "zipcod": [22, 23, 46], "zmqshell": 42, "zone": [40, 51], "zoom": [7, 48, 52], "\u0259m": 52, "\u03bc": 43}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [22, 24, 25, 26, 27, 30, 31, 33, 40], "0": 32, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51], "10": [18, 31, 50], "11": [20, 32], "12": [21, 32, 33], "13": 34, "14": [34, 35], "15": [35, 36], "16": [36, 37], "17": [37, 38], "18": 39, "19": [39, 40], "1a": 13, "1b": 14, "1c": 15, "2": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 41, 44, 45, 46, 47, 48, 49, 50, 51], "20": 41, "2025s1": 1, "21": 41, "2a": 16, "2b": 17, "3": [15, 22, 23, 24, 26, 34, 35, 36, 41, 45, 46, 47, 48, 49, 50, 51], "330": [1, 2, 3, 6, 8], "340": 2, "3a": 18, "3b": 19, "3c": 20, "4": [15, 23, 24, 25, 45, 46, 47, 48, 49, 50, 51], "4a": 21, "5": [8, 16, 23, 24, 25, 26, 27, 30, 33, 34, 35, 38, 39, 41, 46, 47, 48, 49, 50, 51], "6": [16, 27, 46, 48, 49, 50, 51], "7": [17, 28, 48, 50, 51], "8": [17, 29, 48, 50], "9": [18, 30, 50], "A": [4, 30, 36, 40, 42], "No": 8, "Not": 44, "One": [26, 40, 43], "The": [24, 28, 29, 32, 34, 35, 50], "__": 29, "about": [8, 34, 37], "academ": 52, "access": [7, 28, 52], "accommod": 52, "acknowledg": 52, "activ": [30, 33, 34, 35, 38, 49], "actual": 27, "ad": 8, "addit": [7, 33], "address": 30, "advantag": 29, "advic": 34, "ai": 52, "algorithm": [23, 25, 34, 35], "all": [22, 23, 26, 28, 30, 35, 36, 37], "alpha": [28, 31], "altern": [23, 26], "an": [32, 42], "analogi": 25, "analysi": [40, 41, 44, 46, 51], "announc": [23, 25, 27, 28, 32], "answer": 41, "ap": 30, "api": 26, "appendix": [42, 43], "appli": [1, 8, 26, 27, 31], "applic": 35, "applymap": 8, "approach": [37, 40, 41, 43], "approxim": 24, "ar": [5, 22, 23, 26, 28, 30, 35, 36, 37], "area": 30, "argument": [24, 25], "arrai": 8, "articl": 9, "ask": 4, "assign": [7, 52], "associ": 28, "assum": 41, "attent": [23, 25], "attribut": 33, "auc": 30, "autom": 29, "averag": [30, 32, 37, 50], "avoid": 24, "b": [35, 43], "backward": 34, "bad": 29, "bag": [27, 42], "balanc": 30, "base": [25, 32, 34, 37, 40, 51], "baselin": [23, 26, 30, 32, 33, 37, 46], "basic": 38, "befor": 26, "best": 34, "better": [24, 29, 30, 34], "between": [23, 25, 45], "beyond": [33, 37], "bia": [24, 29], "big": [23, 24, 26], "binari": 30, "book": 10, "boost": 32, "bootstrap": 32, "boundari": [23, 25, 28, 45], "bow": 27, "box": 39, "break": [8, 23, 24, 25, 26, 27, 34, 38, 39, 41], "broadcast": 8, "build": [22, 23, 31, 37], "c": [25, 29], "calcul": 28, "california": [27, 28, 47], "can": [8, 24, 26, 32, 33, 34, 35], "canada": [23, 45], "care": 37, "carri": [26, 34], "case": [27, 28, 36], "catboost": 32, "categor": [26, 27, 33, 40], "categori": 27, "censor": 41, "centr": 52, "certain": 27, "cfa": 52, "chang": 30, "charact": 22, "characterist": 30, "cheatsheet": 8, "choos": [25, 35], "churn": 41, "cite": 7, "citi": 28, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 29, 30, 31, 32, 33, 37, 39, 43, 52], "class_attend": 27, "class_weight": 30, "classif": [23, 30, 39, 44], "classifi": [23, 28, 32, 42], "clearli": 34, "cluster": [35, 36, 44], "co": 52, "code": [11, 52], "coeffici": [28, 33], "color": [45, 46, 47, 48, 49, 50, 51], "column": [8, 26, 27, 40], "columntransform": [27, 47], "combin": 32, "come": [24, 25], "command": 5, "comment": [23, 29, 30, 31, 35, 36, 37], "common": [26, 35], "commonli": 38, "commun": 44, "compact": 26, "companion": 9, "complet": 37, "complex": 24, "complic": [40, 51], "compon": 28, "comprehens": 47, "comput": [39, 44], "con": [25, 36, 44], "concern": 6, "concess": 52, "conda": 11, "conduct": 52, "confid": 28, "confus": 30, "consid": 41, "construct": 32, "content": 37, "context": 38, "continu": 23, "conveni": 27, "correct": 35, "correl": 33, "countri": [23, 45], "countvector": 27, "cours": [9, 10, 22, 52], "cover": [37, 41], "cox": 41, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 23, 24, 27, 37], "credit": [11, 52], "cross": [24, 26, 30, 34, 40, 46], "cross_val_scor": 24, "cross_valid": [24, 31], "csv": 8, "curs": 25, "curv": [30, 41], "custom": [35, 41], "cv": 29, "dai": 40, "data": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 42, 46, 51], "datafram": [8, 27], "dataset": [7, 23, 26, 27, 28, 29, 30, 31, 39, 40, 47, 50, 51], "date": [10, 40], "datetim": [40, 51], "dbscan": 36, "deal": [27, 30], "debug": 11, "decis": [23, 25, 28, 33, 46], "decisiontreeclassifi": [23, 32], "decreas": 30, "deep": [39, 40], "defin": 34, "definit": 22, "deliver": 10, "demo": [34, 40, 42], "demonstr": 30, "dendrogram": 36, "depend": 34, "deploy": [24, 44], "descript": 52, "desktop": 5, "detail": [30, 31, 36], "detect": 39, "df": 8, "did": [24, 26, 27, 30, 31, 37, 41], "differ": [26, 29, 30, 31, 33, 44], "dimens": 25, "dimension": 25, "discuss": [29, 30, 37, 38, 49], "diseas": 22, "distanc": [25, 35], "distribut": 29, "do": [26, 27, 29, 30, 32, 33, 34], "document": [3, 8, 35], "doe": [23, 28, 36], "domain": 34, "drop": 8, "due": 10, "dummi": 42, "dummyclassifi": [23, 32, 40, 41], "dummyregressor": [23, 26, 31], "eda": [26, 30, 31, 46], "effect": 32, "elbow": 35, "element": 8, "elimin": 34, "embed": 38, "encod": [26, 27, 34, 40], "engin": [34, 40, 42, 44], "ensembl": [32, 44], "environ": 11, "error": [24, 29, 30, 31, 37], "estim": [26, 32], "ethic": 44, "euclidean": 25, "eva": [22, 24], "evalu": [30, 36, 37, 41, 44, 49], "evalut": 30, "event": 41, "everyon": 41, "exactli": 28, "exam": [44, 52], "examin": [27, 31, 44], "exampl": [22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 41, 42], "exercis": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 39, 41, 45], "exhaust": 29, "explain": 33, "explan": 33, "explor": [25, 35], "exploratori": [40, 46, 51], "extract": [27, 40], "extractor": 39, "f1": 30, "failur": 36, "fair": [30, 49], "fancier": 29, "faster": 8, "fastest": 8, "featur": [22, 23, 25, 26, 27, 28, 31, 33, 34, 37, 39, 40, 42, 44, 51], "feature_importances_": 33, "few": [30, 36], "fictiti": 22, "figur": 7, "filter": [8, 37], "final": [23, 29, 35, 36, 37, 40, 44, 46, 52], "find": [25, 34], "first": 26, "fit": [23, 26, 32], "flatten": 39, "follow": [22, 23, 24, 35, 36, 37], "font": [45, 46, 47, 48, 49, 50, 51], "forecast": 40, "forest": [32, 33], "format": [7, 8], "formul": 37, "forum": 4, "forward": 34, "from": [8, 42], "function": [8, 28, 31], "fundament": [24, 25, 32, 44], "further": [40, 42], "futur": 40, "gamma": 25, "garbag": 34, "gener": [4, 6, 24, 25, 28, 32, 34], "geometr": 25, "get": 33, "git": [5, 11], "github": 5, "given": [22, 23], "global": 37, "goal": 24, "golden": [24, 26, 27], "good": 30, "grade": [4, 6, 23, 52], "gradescop": 7, "gradient": 32, "grid": 29, "gridsearchcv": [29, 31], "group": [30, 35, 49], "guid": 44, "guidelin": [4, 6, 7], "ha": 22, "halv": 29, "handl": 30, "have": [32, 33], "hazard": 41, "heatmap": 29, "help": [4, 34], "here": 24, "hierarch": 36, "home": 36, "homework": 7, "hot": [26, 34, 40], "hous": [22, 23, 26, 27, 28, 47], "how": [4, 7, 23, 24, 25, 26, 28, 32, 33, 34, 36], "hyper": 29, "hyperparamet": [23, 25, 27, 28, 29, 31, 32, 35, 44, 46], "i": [22, 24, 26, 27, 29, 30, 32, 33, 34, 35, 37, 38, 42], "iclick": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 52], "idea": [25, 30, 32, 34], "identifi": [27, 33], "imag": [22, 39], "imagenet": 39, "imbal": [30, 31, 32, 33], "import": [1, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 51], "improv": 42, "imput": [26, 37], "incorpor": 27, "increas": 30, "index": 8, "inertia": 35, "info": 7, "inform": [33, 40], "initi": 35, "inject": 32, "input": [22, 35], "instal": [5, 11], "instruct": [0, 7], "interact": 34, "intercept": 28, "interim": [30, 33, 34, 40], "interpret": [28, 33], "intra": 35, "intro": 37, "introduct": [8, 22, 33, 34, 35, 36, 38, 39, 44], "intuit": 28, "involv": 40, "jupyterlab": 11, "k": [25, 26, 35, 36, 37], "kaplan": 41, "kei": 33, "kernel": 25, "kind": 32, "kneighborsclassifi": 25, "label": [22, 35], "lag": [40, 51], "land": 52, "languag": 38, "larg": 29, "late": 7, "latitud": [23, 45], "lda": 38, "learn": [1, 5, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 52], "least": 28, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 52], "lecture03": 15, "let": [25, 26, 27, 30, 31, 33], "licens": [0, 1], "lightgbm": 32, "limit": [6, 28, 36], "line": 5, "linear": [28, 31, 33], "link": 1, "list": 9, "liver": 22, "ll": 24, "lo": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 39, 40], "logist": [28, 30, 39], "logisticregress": [30, 40, 41], "longitud": [23, 45], "look": [30, 35], "loop": 8, "lower": 29, "mac": 5, "machin": [1, 22, 23, 24, 25, 30, 35], "maco": 11, "macro": 30, "magnitud": 28, "mai": 34, "main": [28, 37], "make": [8, 28], "make_column_transform": 27, "make_pipelin": 26, "mani": [27, 29], "manual": 29, "mape": 31, "materi": [0, 9, 10], "matplotlib": 8, "matric": 27, "matrix": [30, 37], "max_depth": 23, "mean": [31, 35, 36, 38], "measur": 34, "media": 38, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 52], "meier": 41, "messag": [22, 36], "meta": 43, "method": [8, 29, 34, 35], "metric": [30, 31, 44], "midterm": [35, 52], "might": 41, "min": [8, 23, 24, 25, 26, 27, 30, 33, 34, 35, 38, 39, 41], "minor": 30, "misc": [9, 10], "miscellan": 37, "ml": [22, 24, 25, 30, 33, 44, 49], "model": [22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 38, 39, 41, 42, 44, 46, 49], "model_select": 29, "month": 40, "more": [23, 25, 26, 27, 28, 30, 31, 34, 36, 40, 51], "most": 28, "motiv": [24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40], "movi": 37, "mse": 31, "much": 29, "multi": [30, 39, 43], "multiclass": 44, "multipl": [25, 27, 31], "multipli": 8, "n_estim": 32, "n_iter": 29, "n_job": 29, "n_neighbor": 25, "name": [24, 31, 37], "natur": 38, "nearest": [25, 26, 35, 37], "need": [26, 29], "neg": 30, "neighbour": [25, 26, 37], "nest": 8, "netflix": 32, "network": 39, "neural": 39, "nlp": [38, 44], "nn": 25, "non": [25, 27, 33], "notat": 8, "note": [8, 24, 40, 46], "now": 41, "number": [32, 35, 40], "numer": [33, 34], "numpi": 8, "object": [23, 32, 38, 39, 40, 41, 52], "observ": 30, "occasion": 26, "off": [24, 25, 32], "oh": [26, 27], "ok": [26, 27], "onc": 30, "one": [27, 34], "onehotencod": 27, "onli": [27, 41], "onlin": [9, 10], "oper": 30, "optim": [29, 44], "option": [11, 25, 26, 29, 30, 32, 34, 41], "ordin": [26, 27, 33, 52], "other": [8, 25, 31, 34, 35, 38, 40, 41], "our": [7, 24, 26, 42], "out": [26, 34, 39], "outcom": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37], "outlin": [45, 46, 47, 48, 49, 50, 51], "output": 35, "over": [8, 25, 28, 30], "overfit": [24, 29], "oversampl": 30, "overview": [25, 30], "ovo": 43, "ovr": 43, "packag": [11, 40], "panda": 8, "pandas_profil": 31, "paper": [30, 32], "paradigm": 26, "paramet": [23, 28, 29, 30, 44], "parametr": 25, "pars": [40, 51], "part": 44, "pass": [29, 52], "patient": 22, "perfect": 35, "permutation_import": 33, "persona": 22, "pick": [24, 29], "pictur": [23, 24, 26], "pipelin": [26, 38], "plan": 36, "playground": [25, 46], "plot": [8, 33, 35, 41], "point": [25, 30, 33, 35, 40], "polici": 6, "poll": 35, "popular": 22, "posit": 30, "posix": 40, "possibl": [27, 31, 35, 42], "post": 9, "pr": 30, "practic": [23, 25], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 39], "precis": 30, "predict": [22, 23, 27, 28, 32, 33, 37, 39, 41, 43, 45], "predict_proba": 28, "prepar": [7, 44], "preprocess": [26, 27, 31, 38, 40, 44, 49, 51], "preval": 22, "price": [22, 23], "prize": 32, "pro": [25, 36, 44], "probabl": [28, 29], "problem": [23, 24, 25, 26, 29, 34, 37, 40, 42], "procedur": 30, "process": 38, "product": 22, "profil": 37, "program": 23, "project": 42, "proport": 41, "python": [8, 9, 11], "q": 4, "qualiti": 34, "queri": [8, 25], "question": [4, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51], "quick": 25, "quiz": 23, "quiz2": 23, "quot": 34, "r": 31, "random": [29, 32, 33], "random_st": 24, "randomforestclassifi": [32, 41], "randomizedsearchcv": [29, 31], "rang": 29, "rate": 37, "raw": 28, "rbf": 25, "read": [8, 23, 29, 39], "real": [23, 45], "realist": 27, "reason": 6, "recal": 30, "recap": [23, 25, 36, 41, 45, 47], "receiv": 30, "recommend": [26, 37, 44], "record": 52, "recurs": 34, "red": [45, 46, 47, 48, 49, 50, 51], "refer": [9, 10, 41], "reflect": [23, 24, 35, 36], "registr": 52, "regress": [23, 25, 28, 30, 31, 32, 39], "regressor": 25, "relat": [4, 23, 25], "relev": [9, 30, 32, 34], "remark": 40, "rememb": 35, "remind": [23, 37], "remov": 8, "renam": 8, "report": [7, 30], "repositori": 7, "represent": [27, 39], "requir": 52, "rescu": 24, "resourc": [9, 29, 30, 34, 35, 36, 37], "rest": 43, "result": 29, "retail": 40, "review": 19, "rfe": 34, "ridg": [28, 31], "ridgecv": 31, "right": 41, "rmse": 31, "roc": 30, "root": 31, "row": 8, "rule": [24, 26, 27], "run": 26, "same": 8, "sampl": [30, 32, 35], "sauc": 35, "save": 22, "scale": [22, 26, 28, 33], "schedul": [10, 52], "scheme": 52, "scikit": [24, 26, 27, 31], "score": [23, 24, 28, 29, 30, 31, 34, 35, 42], "search": [25, 29, 34], "season": 40, "segment": 35, "select": [22, 23, 34, 35, 36, 37, 44], "separ": [31, 33], "seri": [8, 40, 44, 51], "set": [5, 11, 24, 29, 30], "set_config": 27, "shap": 33, "shape": [8, 36], "shaplei": 33, "short": 9, "should": [32, 37], "show": 33, "sigmoid": [28, 39], "sign": 28, "silhouett": 35, "similar": 25, "simpl": [24, 42], "simplefeatur": 33, "simul": 50, "singl": 24, "size": 8, "sklearn": [23, 26, 27, 29, 30, 32, 33], "slide": [13, 14, 15, 16, 17, 18, 20, 21], "slowest": 8, "smote": 30, "social": 38, "softmax": 39, "softwar": [0, 39, 40], "solv": 29, "some": [23, 29, 30, 32, 34], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 40, "spaci": [38, 42], "spaghetti": 35, "spam": [22, 27], "spars": 27, "specif": [4, 34], "split": [24, 26, 30, 40, 46], "spotifi": [26, 29], "squar": 31, "stack": [32, 50], "standardscal": 26, "statement": [22, 23, 35, 36, 37], "step": [23, 38, 47], "strategi": [32, 43], "stratifi": 30, "strength": [28, 32], "studi": 44, "submiss": 7, "submit": 7, "success": 29, "summari": [8, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "summer": 10, "supervis": [22, 23, 24, 25, 35, 37], "support": 25, "surviv": [41, 44], "svc": 30, "svm": [25, 28], "syllabu": [1, 52], "syntax": [26, 27, 29], "synthet": 30, "system": [37, 44], "ta": 52, "tabular": [23, 25], "tackl": 31, "take": 36, "target": [22, 23, 27, 31, 35], "task": 38, "teach": [10, 52], "team": 52, "techniqu": [26, 30], "templat": 7, "tempor": 40, "ten": 10, "tent": 10, "terminologi": [23, 39], "test": [5, 24, 29, 40], "test_df": 24, "test_siz": 24, "text": [27, 38, 42], "than": [27, 29, 34], "thei": 32, "them": 8, "thi": [8, 22, 26, 27, 33], "thing": 26, "threshold": 30, "time": [6, 22, 40, 41, 44, 51], "tip": 44, "todai": [24, 26, 27, 30, 31], "toi": [23, 27, 30, 38], "token": 38, "tool": 38, "topic": 38, "trade": [24, 25, 32], "tradeoff": [24, 30, 32], "tradit": [23, 40], "train": [22, 23, 24, 27, 28, 30, 39, 40, 49], "train_df": 24, "train_siz": 24, "transfer": 39, "transform": [26, 27, 31, 34], "transpar": 33, "tree": [23, 32, 33, 46], "trend": 40, "true": [22, 35, 36, 37], "try": [26, 31], "tune": [31, 35, 46], "tutori": [45, 46, 47, 48, 49, 50, 51], "two": 27, "type": [22, 24, 30, 31, 33, 35, 40, 41], "typic": [24, 38], "ubc": 1, "ubuntu": 5, "under": 30, "underfit": 24, "undersampl": 30, "unequ": 40, "unknown": 27, "unlabel": 35, "unseen": [22, 24], "unsupervis": [23, 35], "up": [5, 11, 24, 25], "updat": 7, "url": 8, "us": [7, 8, 22, 23, 24, 25, 26, 27, 30, 31, 32, 34, 35, 38, 39, 43, 45, 52], "usa": [23, 45], "user": [5, 37], "usual": 34, "util": 37, "v": [2, 23, 24, 25, 30, 33, 35, 39, 43], "valid": [24, 26, 29, 30, 40, 46], "varianc": 24, "vector": [8, 25, 38], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 35, 36, 38], "view": [25, 27], "violat": 24, "virtual": 11, "vision": [39, 44], "visual": [9, 29], "wai": [29, 34], "want": [27, 33, 41], "warn": [23, 34], "we": [8, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 41], "weak": 32, "weight": [28, 30], "what": [5, 11, 22, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 41], "when": [8, 26, 29], "where": [27, 41], "whether": 22, "which": [22, 23, 30, 32, 35, 36, 37], "why": [11, 22, 27, 29, 33, 34, 37, 39], "window": [5, 11], "wise": 8, "without": 35, "word": [27, 38, 42], "work": [23, 32, 36], "workflow": [22, 24, 30], "would": 24, "wrapper": 43, "write": 23, "x": [22, 23, 31, 33], "xgboost": 32, "y": [22, 23, 31, 33], "ye": 41, "yield": 29, "you": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41], "your": [5, 23]}})