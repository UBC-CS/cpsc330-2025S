Search.setIndex({"alltitles": {"(Optional) Changing the data": [[32, "optional-changing-the-data"]], "(Optional) Evaluation": [[43, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[32, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[31, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[31, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[31, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[34, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[36, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[32, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[27, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[31, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[34, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[36, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[36, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[31, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Some more details": [[32, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[24, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[36, "id1"]], "(iClicker) Exercise 21.1": [[43, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[43, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[27, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[27, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[28, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[28, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[28, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[29, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[29, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[30, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[30, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[31, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[37, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[37, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[37, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[37, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[38, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[38, "id2"]], "16.3 Select all of the following statements which are True": [[38, "select-all-of-the-following-statements-which-are-true"]], "<font color='red'>Question 10</font>": [[52, "question-10"]], "<font color='red'>Question 1</font>": [[47, "question-1"], [48, "question-1"], [50, "question-1"], [51, "question-1"], [52, "question-1"], [53, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[48, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[47, "question-2"], [50, "question-2"], [51, "question-2"], [52, "question-2"], [53, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[48, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[47, "question-3"], [50, "question-3"], [51, "question-3"], [52, "question-3"], [53, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[48, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[47, "question-4"], [50, "question-4"], [51, "question-4"], [52, "question-4"], [53, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[48, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[50, "question-5"], [51, "question-5"], [52, "question-5"], [53, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[48, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[50, "question-6"], [51, "question-6"], [52, "question-6"], [53, "question-6"]], "<font color='red'>Question 7</font>": [[50, "question-7"], [52, "question-7"]], "<font color='red'>Question 8</font>": [[50, "question-8"], [52, "question-8"]], "<font color='red'>Question 9</font>": [[52, "question-9"]], "<font color='red'>Recap Questions</font>": [[47, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[49, "recap-comprehension-questions"]], "A few comments on PR curve": [[32, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[38, "a-few-comments-on-clustering-evaluation"]], "AP score": [[32, "ap-score"]], "AP vs. F1-score": [[32, "ap-vs-f1-score"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[54, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[30, "accessing-learned-parameters"]], "Activity (~5 mins)": [[35, "activity-5-mins"], [35, "id3"]], "Activity: Context and word meaning": [[40, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[36, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[32, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[31, "advantages-of-randomizedsearchcv"], [31, "id1"]], "Alternative and more compact syntax: make_pipeline": [[28, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[25, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[34, "an-effective-strategy"]], "An example from a project": [[44, "an-example-from-a-project"]], "An example of a bootstrap samples": [[34, "an-example-of-a-bootstrap-samples"]], "Analogy-based algorithms in practice": [[27, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[27, "analogy-based-models"]], "Announcements": [[30, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[44, null]], "Appendix B: Multi-class, meta-strategies": [[45, null]], "Applying feature transformations": [[33, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[43, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[43, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[43, "approach-3-survival-analysis"]], "Are we doing better with class_weight=\"balanced\"?": [[32, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[32, "area-under-the-curve-auc"]], "Assignments": [[54, "assignments"]], "Attention": [[25, null], [25, null], [25, null], [27, null]], "Automated hyperparameter optimization": [[31, "automated-hyperparameter-optimization"], [31, "id3"]], "Averaging": [[34, "averaging"]], "Averaging simulation": [[52, "averaging-simulation"]], "Bad range for hyperparameters": [[31, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[29, "bag-of-words-bow-representation"]], "Bag-of-words model": [[44, "bag-of-words-model"]], "Baseline": [[32, "baseline"], [35, "baseline"]], "Baseline Approaches": [[39, "baseline-approaches"]], "Baselines": [[25, "baselines"], [34, "baselines"]], "Baselines [video]": [[25, "baselines-video"]], "Basic text preprocessing [video]": [[40, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[36, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[39, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[26, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[25, "big-picture-and-datasets"]], "Big picture and motivation": [[26, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Break (5 min)": [[8, "break-5-min"], [25, "break-5-min"], [26, "break-5-min"], [27, "break-5-min"], [28, "break-5-min"], [29, "break-5-min"], [36, "break-5-min"], [40, "break-5-min"], [41, "break-5-min"], [43, "break-5-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a supervise machine learning model": [[24, "building-a-supervise-machine-learning-model"]], "Building decision trees with sklearn": [[25, "building-decision-trees-with-sklearn"]], "Building user profiles": [[39, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[37, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[28, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[29, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[34, "catboost"]], "Categorical features": [[35, "categorical-features"]], "Categorical features [video]": [[28, "categorical-features-video"]], "Categorical features with only two possible categories": [[29, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[43, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[54, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[32, "changing-the-training-procedure"]], "Characters in this course?": [[24, "characters-in-this-course"]], "Choosing K [video]": [[37, "choosing-k-video"]], "Choosing n_neighbors": [[27, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Meeting 4B": [[22, null]], "Class Meeting 4C": [[23, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"], [22, "class-slides"], [23, "class-slides"]], "Class imbalance in training sets": [[32, "class-imbalance-in-training-sets"]], "Class meetings": [[54, "class-meetings"]], "Classification report": [[32, "classification-report"]], "Classification vs. Regression": [[25, "classification-vs-regression"]], "Clustering": [[46, "clustering"]], "Clustering Activity (~5 mins)": [[37, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[37, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[37, "clustering-input-and-possible-output"]], "Code of conduct": [[54, "code-of-conduct"]], "Coefficients and intercept": [[30, "coefficients-and-intercept"]], "ColumnTransformer example": [[29, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[29, "columntransformer-on-the-california-housing-dataset"], [49, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[29, "columntransformer-transformed-data"]], "Coming up \u2026": [[26, "coming-up"]], "Coming up:": [[27, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[37, "common-applications"]], "Common preprocessing techniques": [[28, "common-preprocessing-techniques"]], "Communication": [[46, "communication"]], "Completing the utility matrix with content-based filtering": [[39, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[30, "components-of-a-linear-classifier"]], "Confusion matrix (video)": [[32, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[32, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[27, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[39, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[29, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[54, "course-learning-objectives"]], "Course co-ordinator": [[54, "course-co-ordinator"]], "Course description": [[54, "course-description"]], "Cox proportional hazards model": [[43, "cox-proportional-hazards-model"]], "Create X and y": [[25, "create-x-and-y"]], "Create a classifier object": [[25, "create-a-classifier-object"]], "Create a column transformer": [[29, "create-a-column-transformer"]], "Creating train_df and test_df": [[26, "creating-train-df-and-test-df"]], "Creating utility matrix": [[39, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[32, "cross-validation-with-different-metrics"]], "Cross-validation": [[42, "cross-validation"], [42, "id4"]], "Cross-validation [video]": [[26, "cross-validation-video"]], "Cross-validation to the rescue!!": [[26, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[26, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[27, "curse-of-dimensionality"]], "Customer churn": [[43, "customer-churn"]], "Customer segmentation": [[37, "customer-segmentation"]], "DBSCAN [video]": [[38, "dbscan-video"]], "DBSCAN introduction": [[38, "dbscan-introduction"]], "DBSCAN: failure cases": [[38, "dbscan-failure-cases"], [38, "id1"]], "Data": [[29, "data"], [30, "data"], [34, "data"], [35, "data"], [35, "id1"]], "Data Splitting [video]": [[26, "data-splitting-video"]], "Data and main approaches": [[39, "data-and-main-approaches"]], "Data exploration": [[37, "data-exploration"]], "Data splitting": [[48, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[41, "dataset"]], "Dataset [video]": [[33, "dataset-video"]], "Dataset for demonstration": [[32, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[28, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[32, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[29, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[25, "decision-boundary"]], "Decision boundary for max_depth=1": [[25, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[25, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[25, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[27, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[30, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[25, "decision-tree-algorithm"]], "Decision tree feature importances": [[35, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[25, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[25, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[25, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[25, "decision-trees-video"]], "Decision trees with continuous features": [[25, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[34, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[25, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decreasing the threshold": [[32, "decreasing-the-threshold"]], "Deep learning": [[42, "deep-learning"]], "Deep learning software": [[41, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of feature engineering with numeric features": [[36, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[42, "demo-a-more-complicated-dataset"]], "Dendrogram": [[38, "dendrogram"]], "Deployment (Not examinable)": [[46, "deployment-not-examinable"]], "Different models": [[35, "different-models"]], "Different range for hyperparameters yields better results!": [[31, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[33, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[27, "dimensions-in-ml-problems"]], "Discussion question": [[40, "discussion-question"]], "Distance between feature vectors": [[27, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[29, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[34, "do-we-have-class-imbalance"], [35, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[35, "do-we-have-correlated-features"]], "Document clustering": [[37, "document-clustering"]], "Domain-specific transformations": [[36, "domain-specific-transformations"]], "Dummy classifier": [[44, "dummy-classifier"]], "DummyClassifier": [[25, "dummyclassifier"], [42, "dummyclassifier"], [43, "dummyclassifier"]], "DummyClassifier baseline": [[34, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[25, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[25, "dummyregressor"], [33, "dummyregressor"]], "EDA": [[28, "eda"], [32, "eda"], [33, "eda"]], "EDA: Exploratory Data Analysis": [[48, "eda-exploratory-data-analysis"]], "Encoding text data": [[29, "encoding-text-data"]], "Encoding time as a number": [[42, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[42, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[46, "ensembles"]], "Ethics": [[46, "ethics"]], "Euclidean distance": [[27, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[38, "evaluating-dbscan-clusters"]], "Evaluation": [[39, "evaluation"], [39, "id3"]], "Evaluation metrics": [[46, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[32, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[32, "evalution-metrics-overview"]], "Examining the preprocessed data": [[33, "examining-the-preprocessed-data"]], "Example": [[30, "example"], [34, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[24, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[37, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[25, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[25, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[24, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[24, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[35, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[36, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[24, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[37, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[25, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[25, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[32, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[28, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[24, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[39, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[39, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[25, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[25, "exercise-2-4"]], "Exercise 8.2": [[31, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[47, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[31, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[35, "explaining-a-prediction"]], "Exploratory data analysis": [[42, "exploratory-data-analysis"], [53, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[29, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[42, "extracting-date-and-time-information"]], "F1-score": [[32, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[36, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[42, "feature-engineering"]], "Feature engineering and selection": [[46, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[42, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[42, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[36, "feature-engineering-motivation"]], "Feature importances": [[35, "feature-importances"], [46, "feature-importances"]], "Feature importances in linear models": [[35, "feature-importances-in-linear-models"], [35, "id2"]], "Feature interactions and feature crosses": [[36, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[33, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[36, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[28, "feature-transformations-and-the-golden-rule"]], "Feature types": [[33, "feature-types"], [33, "id1"]], "Feature vectors": [[27, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[31, "final-comments-and-summary"], [39, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[25, "final-comments-summary-and-reflection"], [37, "final-comments-summary-and-reflection"], [38, "final-comments-summary-and-reflection"]], "Final exam": [[54, "final-exam"]], "Final exam preparation: guiding questions": [[46, null]], "Final note": [[48, "final-note"]], "Final remarks": [[42, "final-remarks"]], "Finding the distances to a query point": [[27, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[27, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[42, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[42, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[39, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "Garbage in, garbage out.": [[36, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[36, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[34, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[27, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[36, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[26, "generalization-video"]], "Generalization: Fundamental goal of ML": [[26, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[30, "generalizing-to-more-features"]], "Generalizing to unseen data": [[26, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[27, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[39, "global-average-baseline"]], "Golden rule violation: Example 1": [[26, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[26, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[34, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[34, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[54, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[32, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[26, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[38, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[30, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[26, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[35, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[34, "how-do-they-work"]], "How do we carry out feature selection?": [[36, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[25, "how-does-fit-work"], [25, "id2"]], "How does it work?": [[38, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[30, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[25, "how-does-predict-work"]], "How to approximate generalization error?": [[26, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[28, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[27, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[26, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[30, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[46, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[31, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[37, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[27, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[31, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[29, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[41, "imagenet"]], "Import": [[44, "import"]], "Importance of scaling": [[30, "importance-of-scaling"]], "Important hyperparameters": [[34, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[29, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[37, "important-points-to-remember"]], "Imports": [[24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [53, "imports"]], "Imports and LO": [[31, "imports-and-lo"], [33, "imports-and-lo"], [41, "imports-and-lo"], [42, "imports-and-lo"]], "Imports and LOs": [[32, "imports-and-los"]], "Imports and learning outcomes": [[37, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[25, "imports-announcements-los"]], "Imports, Announcements, and LO": [[29, "imports-announcements-and-lo"], [30, "imports-announcements-and-lo"]], "Imports, LOs": [[26, "imports-los"], [28, "imports-los"], [35, "imports-los"]], "Imports, announcements, LOs": [[34, "imports-announcements-los"]], "Imports, announcements, and LOs": [[27, "imports-announcements-and-los"]], "Imputation": [[28, "imputation"]], "Imputation and scaling [video]": [[28, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[29, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[32, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[37, "inertia"]], "Initialization of K-Means": [[37, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[34, "inject-randomness-in-the-classifier-construction"]], "Input data": [[24, "input-data"]], "Input features X and target y": [[24, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interim summary": [[32, "interim-summary"], [35, "interim-summary"], [36, "interim-summary"], [42, "interim-summary"]], "Interpretation of coefficients": [[30, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[30, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[35, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[38, "introduction"], [46, "introduction"]], "Introduction to NLP": [[46, "introduction-to-nlp"]], "Introduction to computer vision": [[41, "introduction-to-computer-vision"]], "Introduction to neural networks": [[41, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[37, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[44, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[32, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[29, "is-this-a-realistic-representation-of-text-data"]], "Is \u201cRelevance\u201d clearly defined?": [[36, "is-relevance-clearly-defined"], [36, "id2"], [36, "id3"], [36, "id4"], [36, "id5"], [36, "id6"], [36, "id7"]], "K-Means algorithm": [[37, "k-means-algorithm"]], "K-Means clustering [video]": [[37, "k-means-clustering-video"]], "K-Means example": [[37, "k-means-example"]], "K-Means limitations": [[38, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[38, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[38, "k-means-recap"]], "K-Means: failure case 1": [[38, "k-means-failure-case-1"]], "K-Means: failure case 2": [[38, "k-means-failure-case-2"]], "K-Means: failure case 3": [[38, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[43, "kaplan-meier-survival-curve"]], "Key point": [[35, "key-point"]], "LDA topics in social media": [[40, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[37, "labeled-vs-unlabeled-data"]], "Lag-based features": [[42, "lag-based-features"], [42, "id5"], [53, "lag-based-features"]], "Land acknowledgement": [[54, "land-acknowledgement"]], "Large datasets solve many of these problems": [[31, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[30, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[40, "learning-objectives"], [41, "learning-objectives"], [42, "learning-objectives"], [43, "learning-objectives"]], "Learning outcomes": [[24, "learning-outcomes"], [25, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [38, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[39, "learning-outcomes"]], "Least confident cases": [[30, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[33, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[34, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[35, null]], "Lecture 13": [[22, "lecture-13"]], "Lecture 13: Feature engineering and feature selection": [[36, null]], "Lecture 14": [[23, "lecture-14"]], "Lecture 14: K-Means Clustering": [[37, null]], "Lecture 15": [[23, "lecture-15"]], "Lecture 15: More Clustering": [[38, null]], "Lecture 16: Recommender Systems": [[39, null]], "Lecture 17: Introduction to natural language processing": [[40, null]], "Lecture 18: Multi-class classification and introduction to computer vision": [[41, null]], "Lecture 19: Time series": [[42, null]], "Lecture 1: Course Introduction": [[24, null]], "Lecture 20: Survival analysis": [[43, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[25, null]], "Lecture 3: Machine Learning Fundamentals": [[26, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[27, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[28, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[29, null]], "Lecture 7: Linear Models": [[30, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[31, null]], "Lecture 9: Classification metrics": [[32, null]], "Lecture learning objectives": [[34, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[38, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[54, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[28, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[29, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[27, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[28, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[35, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[32, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[33, "let-s-separate-x-and-y"], [35, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[33, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[28, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[34, "lightgbm"]], "Limitations of linear models": [[30, "limitations-of-linear-models"]], "Linear SVM": [[30, "linear-svm"]], "Linear models [video]": [[30, "linear-models-video"]], "Linear regression": [[30, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Logistic regression [video]": [[30, "logistic-regression-video"]], "Logistic regression intuition": [[30, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[30, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[41, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[42, "logisticregression"], [43, "logisticregression"]], "MAPE": [[33, "mape"]], "ML fairness activity": [[51, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[32, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[46, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[24, "machine-learning-workflow"], [32, "machine-learning-workflow"]], "Magnitude of the coefficients": [[30, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[30, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[30, "main-hyperparameters"]], "Manual hyperparameter optimization": [[31, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[37, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[37, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[33, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[24, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[37, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[37, "method-2-the-silhouette-method"]], "Midterms": [[54, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[39, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[33, "model-building"]], "Model complexity and training error": [[26, "model-complexity-and-training-error"]], "Model interpretability beyond linear models": [[35, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[24, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[51, "model-training-and-evaluation"]], "Model-based selection": [[36, "model-based-selection"]], "More comments on tackling class imbalance": [[33, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[38, "more-details-on-dbscan"]], "More on feature transformations": [[29, "more-on-feature-transformations"]], "More on k-NNs [video]": [[27, "more-on-k-nns-video"]], "More terminology [video]": [[25, "more-terminology-video"]], "More than one ordinal columns?": [[29, "more-than-one-ordinal-columns"]], "Most confident cases": [[30, "most-confident-cases"]], "Motivating example": [[30, "motivating-example"]], "Motivation": [[31, "motivation"], [42, "motivation"]], "Motivation [video]": [[34, "motivation-video"]], "Motivation and big picture [video]": [[28, "motivation-and-big-picture-video"]], "Motivation and context": [[40, "motivation-and-context"]], "Motivation and distances [video]": [[27, "motivation-and-distances-video"]], "Movie features": [[39, "movie-features"]], "Multi-class classification": [[41, "multi-class-classification"]], "Multiclass classification and computer vision": [[46, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[29, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[26, null], [26, null], [42, null]], "Number of trees and fundamental trade-off": [[34, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[29, "ohe-with-many-categories"]], "Object detection": [[41, "object-detection"]], "Observations": [[32, "observations"]], "One Vs. One approach": [[45, "one-vs-one-approach"]], "One Vs. One prediction": [[45, "one-vs-one-prediction"]], "One vs. Rest": [[45, "one-vs-rest"]], "One-hot encoding (OHE)": [[28, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[42, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[42, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[29, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[32, "operating-point"]], "Optimization bias of hyper-parameter learning": [[31, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[31, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[31, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[31, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[31, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[28, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[35, "ordinal-features"]], "Other applications": [[37, "other-applications"]], "Other approaches / what did we not cover?": [[43, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[40, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[33, "other-possible-preprocessing"]], "Other software package": [[42, "other-software-package"]], "Other tools for preprocessing": [[40, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[40, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[27, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[36, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[26, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[47, "outline"], [48, "outline"], [49, "outline"], [50, "outline"], [51, "outline"], [52, "outline"], [53, "outline"]], "Over confident cases": [[30, "over-confident-cases"]], "Overfitting": [[26, "overfitting"]], "Overfitting of the validation data": [[31, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[31, "overfitting-of-the-validation-error"]], "Oversampling": [[32, "oversampling"]], "Overview": [[27, "overview"]], "POSIX time feature": [[42, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[32, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[25, "parameters"]], "Parameters and hyperparameters: Summary": [[25, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[42, "parsing-datetimes"], [53, "parsing-datetimes"]], "Part 1": [[46, "part-1"]], "Part 2": [[46, "part-2"]], "Passing Requirements": [[54, "passing-requirements"]], "Pipelines": [[28, "pipelines"]], "Playground": [[27, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[25, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 13 Videos": [[22, "pre-lecture-13-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[32, "precision"]], "Precision and recall: toy example": [[32, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[32, "precision-recall-f1-score-video"]], "Precision-recall curve": [[32, "precision-recall-curve"], [32, "id1"]], "Precision/Recall tradeoff": [[32, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[24, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[30, "predicting-probability-scores-video"]], "Predicting with learned weights": [[30, "predicting-with-learned-weights"]], "Prediction": [[43, "prediction"]], "Prediction of linear regression": [[30, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[30, "prediction-with-learned-parameters"]], "Predictions": [[41, "predictions"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[29, "preprocessing"], [42, "preprocessing"], [46, "preprocessing"], [51, "preprocessing"], [53, "preprocessing"]], "Preprocessing the targets?": [[29, "preprocessing-the-targets"]], "Prevalence of ML": [[24, "prevalence-of-ml"]], "Problem formulation": [[39, "problem-formulation"]], "Problem: Different transformations on different columns": [[28, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[31, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[26, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[27, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[46, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[27, "question"]], "Question for you": [[38, "question-for-you"]], "Questions for class discussion": [[39, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[31, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[27, "quick-recap"]], "RFE algorithm": [[36, "rfe-algorithm"]], "R^2 (not in detail)": [[33, "r-2-not-in-detail"]], "Random forest feature importances": [[35, "random-forest-feature-importances"]], "Random forests": [[34, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[34, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[34, "randomforestclassifier"], [43, "randomforestclassifier"]], "Randomized hyperparameter search": [[31, "randomized-hyperparameter-search"]], "Range of C": [[31, "range-of-c"]], "Raw scores": [[30, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[25, "reading-the-data"], [41, "reading-the-data"]], "Real boundary between Canada and USA": [[25, "real-boundary-between-canada-and-usa"], [47, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[32, "recall"]], "Recap": [[43, "recap"]], "Recap and motivation [video]": [[38, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[25, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[32, "receiver-operating-characteristic-roc-curve"]], "Recommender systems": [[46, "recommender-systems"]], "Recommender systems intro and motivation": [[39, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[39, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[36, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[43, "references"]], "Registration": [[54, "registration"]], "Regression scoring functions": [[33, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[27, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[27, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[27, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[34, "relevant-papers"]], "Relevant papers and resources": [[32, "relevant-papers-and-resources"]], "Relevant resources": [[36, "relevant-resources"]], "Reminder": [[39, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Report format": [[7, "report-format"]], "Resources": [[37, "resources"], [38, "resources"], [39, "resources"]], "Ridge": [[30, "ridge"]], "Ridge on the California housing dataset": [[30, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[33, "ridgecv"]], "Root mean squared error or RMSE": [[33, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[35, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[35, "shap-plots"]], "SMOTE idea": [[32, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[32, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[27, "svm-regressor"]], "Saving time and scaling products": [[24, "saving-time-and-scaling-products"]], "Scaling": [[28, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[28, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[54, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[27, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[42, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[24, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[41, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[30, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[37, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[27, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[44, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[26, "simple-train-test-split"]], "SimpleFeature correlations": [[35, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[34, "some-important-hyperparameters"]], "Some quotes on feature engineering": [[36, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[25, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[31, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[29, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[34, "stacking"], [52, "stacking"]], "Step 1": [[49, "step-1"]], "Step 2": [[49, "step-2"]], "Step 3": [[49, "step-3"]], "Step 4": [[49, "step-4"]], "Step 5": [[49, "step-5"]], "Steps to train a classifier using sklearn": [[25, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[32, "stratified-splits"]], "Strengths and weaknesses": [[34, "strengths-and-weaknesses"]], "Strengths of linear models": [[30, "strengths-of-linear-models"]], "Study tips": [[46, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[24, "summary"], [27, "summary"], [34, "summary"], [40, "summary"], [41, "summary"], [43, "summary"]], "Summary and reflection": [[26, "summary-and-reflection"]], "Summary of linear models": [[30, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[26, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[38, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[39, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[37, "supervised-learning"]], "Supervised learning (Reminder)": [[25, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[25, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[24, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[27, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[27, "support-vectors"]], "Survival analysis": [[46, "survival-analysis"]], "Survival plots": [[43, "survival-plots"]], "Syllabus": [[1, "syllabus"], [54, null]], "TAs": [[54, "tas"]], "Tabular data": [[25, "tabular-data"]], "Take-home message": [[38, "take-home-message"]], "Teaching Team": [[54, "teaching-team"]], "Terminology": [[41, "terminology"]], "Terminology [video]": [[25, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[34, "the-netflix-prize"]], "The __ syntax": [[31, "the-syntax"]], "The best features may be dependent on the model you use.": [[36, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[52, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[26, "the-golden-rule"]], "The random forests classifier": [[34, "the-random-forests-classifier"]], "The sigmoid function": [[30, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[26, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[37, "the-perfect-spaghetti-sauce"]], "Time series": [[46, "time-series"]], "Time series analysis on a more complicated dataset": [[53, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[43, "time-to-event-and-censoring"]], "Tokenization": [[40, "tokenization"]], "Topic modeling": [[40, "topic-modeling"]], "Topic modeling motivation": [[40, "topic-modeling-motivation"]], "Topic modeling pipeline": [[40, "topic-modeling-pipeline"]], "Topic modeling toy example": [[40, "topic-modeling-toy-example"]], "Toy datasets": [[25, "toy-datasets"]], "Traditional time series approaches": [[42, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[42, "train-test-split-for-temporal-data"]], "Train/test splits": [[42, "train-test-splits"]], "Train/validation/test split": [[26, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[24, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[30, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[26, "training-error-vs-generalization-error"]], "Training models with transformed data": [[29, "training-models-with-transformed-data"]], "Transfer learning": [[41, "transfer-learning"]], "Transformations on the toy data": [[29, "transformations-on-the-toy-data"]], "Transforming the targets": [[33, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[35, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[34, "tree-based-ensemble-models"]], "Tree-based models": [[34, "tree-based-models"]], "Tuning alpha hyperparameter of Ridge": [[33, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[47, null]], "Tutorial 2": [[48, null]], "Tutorial 3": [[49, null]], "Tutorial 4": [[50, null]], "Tutorial 5": [[51, null]], "Tutorial 6": [[52, null]], "Tutorial 7": [[53, null]], "Types of censoring": [[43, "types-of-censoring"]], "Types of errors": [[26, "types-of-errors"]], "Types of machine learning": [[24, "types-of-machine-learning"], [37, "types-of-machine-learning"]], "Types of problems involving time series": [[42, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[43, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[26, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[26, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[32, "undersampling"]], "Unequally spaced time points": [[42, "unequally-spaced-time-points"]], "Unsupervised learning": [[37, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[54, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[45, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[32, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[37, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[33, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[41, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[41, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[33, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[29, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[31, "visualizing-the-parameter-grid-as-a-heatmap"]], "Warning": [[25, null]], "Warnings about feature selection": [[36, "warnings-about-feature-selection"], [36, "id8"]], "Weaknesses": [[34, "weaknesses"]], "What all transformations we need to apply on the dataset?": [[28, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[28, "what-are-the-options"]], "What are we exactly learning?": [[30, "what-are-we-exactly-learning"]], "What did we cover?": [[39, "what-did-we-cover"]], "What did we learn today?": [[26, "what-did-we-learn-today"], [28, "what-did-we-learn-today"], [29, "what-did-we-learn-today"], [32, "what-did-we-learn-today"], [33, "what-did-we-learn-today"]], "What if we apply OHE?": [[29, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[40, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[39, "what-is-a-recommender-system"]], "What is clustering?": [[37, "what-is-clustering"]], "What is feature engineering?": [[36, "what-is-feature-engineering"]], "What is feature selection?": [[36, "what-is-feature-selection"]], "What is model interpretability?": [[35, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[24, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[32, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[34, "what-kind-of-estimators-can-we-combine"]], "What to look for in these plots?": [[37, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[28, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When is it OK to do things before splitting?": [[28, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[31, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[34, "which-model-should-i-use"]], "Which type of error is more important?": [[32, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[31, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[35, "why-do-we-want-this-information"]], "Why feature selection?": [[36, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[24, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[35, "why-model-transparency-interpretability"]], "Why neural networks?": [[41, "why-neural-networks"], [41, "id1"]], "Why not neural networks?": [[41, "why-not-neural-networks"], [41, "id2"]], "Why should we care about recommendation systems?": [[39, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[29, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[40, "word-embeddings"]], "Word vectors with spaCy": [[40, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[25, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[34, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[32, "class-weight-balanced"]], "cross_val_score": [[26, "cross-val-score"]], "cross_validate": [[26, "cross-validate"]], "fit and transform paradigm for transformers": [[28, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[25, "fit-the-classifier"]], "fit, predict , and score summary": [[25, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[54, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[33, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[33, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[34, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[34, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[36, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[41, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[25, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[25, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[25, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[26, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[26, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[32, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[32, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[27, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[39, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[31, "n-iter"]], "n_jobs=-1": [[31, "n-jobs-1"]], "pandas_profiler": [[33, "pandas-profiler"]], "predict the target of given examples": [[25, "predict-the-target-of-given-examples"]], "predict_proba": [[30, "predict-proba"]], "random_state argument": [[26, "random-state-argument"]], "score your model": [[25, "score-your-model"]], "sklearn API summary: estimators": [[28, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[28, "sklearn-api-summary-transformers"]], "sklearn set_config": [[29, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[29, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[35, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[35, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[44, "spacy"]], "test score vs. cross-validation score": [[26, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[26, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[26, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[32, "questions-for-group-discussion"], [51, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[24, "questions-for-you"], [25, "questions-for-you"], [25, "id1"], [25, "id3"], [26, "questions-for-you"], [26, "id1"], [27, "questions-for-you"], [27, "id1"], [28, "questions-for-you"], [28, "id1"], [28, "id2"], [29, "questions-for-you"], [29, "id1"], [30, "questions-for-you"], [30, "id1"], [30, "id2"], [31, "questions-for-you"], [31, "id2"], [32, "questions-for-you"], [32, "id2"], [33, "questions-for-you"], [33, "id2"], [34, "questions-for-you"], [34, "id1"], [34, "id2"], [36, "questions-for-you"], [37, "questions-for-you"], [37, "id2"], [38, "questions-for-you"], [38, "id3"], [39, "questions-for-you"], [39, "id1"], [39, "id2"], [41, "questions-for-you"], [42, "questions-for-you"], [42, "id1"], [42, "id2"], [42, "id3"], [43, "questions-for-you"], [43, "id1"], [43, "id2"], [43, "id3"], [43, "id4"]], "\ud83e\udd14 Eva\u2019s questions": [[24, "eva-s-questions"], [26, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/classes/class4B", "lectures/classes/class4C", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/classes/class4B.md", "lectures/classes/class4C.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 30, 31, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "0": [0, 1, 7, 8, 10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "00": [10, 24, 25, 27, 29, 30, 31, 32, 35, 38, 39, 42, 43, 53, 54], "000": [24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 40, 41, 43, 44], "0000": [28, 30, 32, 40, 44], "00000": [31, 42, 53], "000000": [25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 42, 43, 53], "00000000e": 35, "000000e": 31, "000001": 33, "00000e": 27, "000010": 33, "000011": 32, "000021": 28, "000036": 32, "000057": 28, "000065": 31, "000067": 31, "000077": 31, "000087": 30, "000089": 30, "0001": [30, 32, 33, 43], "000100": [28, 33], "000108": 30, "000113": 32, "000114": 31, "000117": 33, "000130": 30, "000136": 41, "000137": 31, "000145": 31, "000146": 30, "000147": 31, "000149": 28, "000150": 30, "000151": 31, "000155": [28, 32], "000159": 31, "000163": 31, "000166": [30, 31], "000177": [28, 42], "000180": 28, "000181": 31, "000182": 30, "000183": 30, "000187": 30, "000188": 28, "000190": 42, "000192": 42, "000194": 30, "000195": 28, "000198": 32, "000201": 31, "000206": 31, "000208": 28, "000210": 31, "000212": 36, "000213": 30, "000218": 30, "000221": 33, "000226": 33, "000227": 32, "000231": 28, "000232": 41, "000234": [27, 31], "000235": [28, 32], "000240": 28, "000245": 31, "000247": 41, "000255": 30, "000256": 42, "000259": 28, "000260": 28, "000271": 42, "000273": 41, "000274": 41, "000281": 30, "000283": 30, "000285": 30, "000286": 31, "000289": 28, "000294": 31, "000312": 32, "000332": 33, "000336": 41, "000339": 31, "000348": 31, "000353": 31, "000354": 31, "000363": 41, "000366": 32, "000370": 31, "000371": 30, "000373": 33, "000378": 30, "00038": 31, "000397": 33, "000399": 41, "000433": 33, "000435": 41, "000437": 41, "000452": 28, "000459": 30, "000471": 42, "000472": 41, "000489": 31, "000492": 32, "000498": 42, "000503": 31, "000508": 31, "000520": 33, "000575": 42, "00058": 31, "000580": 27, "000630": 32, "000633": 27, "000637": 41, "000647": 27, "000650": 27, "000651": 27, "000652": 33, "000655": 27, "000661": 27, "000671": 27, "000678": 31, "000713": 33, "000726": 32, "000737": 42, "000747": 31, "000748": 28, "000752": 27, "000758": 41, "000765": 28, "000774": 28, "000786": 32, "000787": 27, "00079": 31, "000794": 27, "000795": 27, "000797": 27, "000803": 33, "000829": 27, "000831": 27, "000832": 33, "000867": 28, "000869": 42, "000873": 27, "000889": 27, "000891": 32, "000917": 31, "000927": 32, "000936": 27, "000945": 36, "000960": 41, "000964": 36, "000976": 31, "000977": 27, "000982": 31, "001": [24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 41, 43, 44], "0010": 30, "00100": 31, "001000": [31, 33], "001002": 26, "001006": 26, "001010": 26, "001011": [27, 33], "001014": 26, "001016": 26, "001017": 26, "001026": 26, "001027": 26, "001029": 26, "001038": 26, "001040": 32, "001043": 28, "001057": [26, 31], "001060": 28, "001063": 26, "001064": 41, "001068": 35, "001071": 26, "001078": 26, "001086": 26, "001087": 36, "001103": 26, "001111": 26, "001139": 27, "001149": 26, "001155": 36, "001162": [31, 36], "001174": 26, "001205": 32, "001220": 30, "001224": 27, "001226": 41, "001236": 31, "001239": 32, "001266": 33, "001279": 36, "001286": 32, "001294": 26, "001299": 26, "001305": 26, "001307": 26, "001315": 26, "001317": 26, "001322": 26, "001323": 26, "001325": 27, "001329": 26, "001337": 26, "001338": 30, "001347": 31, "001352": 26, "001361": 30, "001362": 30, "001365": 27, "001371": 29, "001390": 26, "001391": 26, "001392": 27, "001400": 29, "001406": 33, "001407": 26, "001412": 31, "001414": 27, "001422": 33, "001423": 31, "001429": 26, "001433": 33, "001441": 26, "001448": 29, "001453": 26, "00146": 31, "001466": 29, "001467": 31, "001492": 31, "001495": 27, "001563": 29, "001566": 33, "001585": 31, "001586": 27, "001591": 29, "001594": 31, "001595": 27, "001600": 27, "001604": 29, "001606": 29, "001608": 31, "001616": 31, "001620": 31, "001629": 31, "001641": 41, "001645": 30, "001647": 29, "001679": 31, "001682": 31, "001693": 36, "001699": 26, "0017": 32, "001700": 32, "001710": 30, "001715": 29, "001740": 33, "001769": 31, "001773": 27, "001776": 26, "001790": 33, "001792": 31, "001847": 36, "001850": 30, "001877": 27, "001894": 33, "001900": 27, "001920": 29, "001922": 29, "001933": 33, "001949": 36, "001952": 27, "0019627889": 40, "001968": 26, "001994": 36, "002": [26, 30, 34, 35, 40, 43], "002003": 31, "002022": 29, "002030": 27, "002045": 31, "002057": [28, 29], "002083": 27, "002096": 41, "002105": 31, "002116": 29, "002118": 27, "002123": 31, "002143": 26, "002146": 31, "002158": 36, "002159": 31, "002197": 31, "002221": 33, "002321": 30, "00234": 31, "002355": 36, "002385": 33, "002441": 36, "002460": 41, "002525": 41, "002561": 31, "002646": 36, "002664": 36, "002675": 31, "002682": 41, "002690": 28, "002692": 31, "002704": 31, "002711": 41, "002746": 33, "002783": 31, "002788": 29, "002789": 29, "002807": 29, "002835": 31, "002858": 29, "002867": 36, "002889": 32, "0029": 43, "002910": 29, "002934": 30, "002940": 41, "002948": 27, "002962": 41, "002986": 41, "002999": 31, "003": [31, 34], "003013": 29, "003014": 31, "003015": 31, "003027": 31, "003038": 31, "003083": 31, "003086": 29, "003115": 29, "003124": 33, "003133": 33, "003146": 29, "003148": 30, "003166": [28, 36], "003181": 28, "003183": 36, "003185": 43, "003186": 29, "003188": [28, 29], "003194": 30, "003212": 28, "003242": 41, "003257": 41, "003273": 26, "003283": 41, "003288": 33, "003300": 28, "00332": 31, "003324": 28, "003365": 29, "003401": 36, "003421": 31, "003423": 36, "003427": 36, "003472": 31, "003477": 41, "003479": 31, "003483": 31, "003493": 36, "003528": 31, "003529": 31, "003547": 33, "003563": 31, "003633": 31, "003647": 41, "00369": 31, "003748": 31, "003757": 31, "003785": 33, "003885": 31, "003919": 31, "003919287722401839": 31, "00392157": 41, "003923": 29, "003924": 36, "003933": 31, "003998": 31, "004": [27, 31, 34, 35, 41], "004057": 31, "004065": 42, "004082": 42, "004121": 33, "004143": 33, "004264": 26, "004293": 31, "004305": 31, "004337": 31, "00435173": 37, "004352": 37, "004398": 35, "004402": 31, "004466": 31, "004496": 31, "004521": 33, "004529": 35, "004556": 31, "004574": 33, "004602": 33, "00461": 31, "004714": 31, "004723": 35, "004761": 35, "004770": 28, "004801": [28, 29], "004807": 29, "004826": 33, "004829": 33, "004854": 33, "004884": 41, "004919": 31, "004934": 32, "004952": 31, "004959": 31, "00496": 31, "005": [24, 34, 35, 43], "005067": 28, "005074": 41, "005093": 28, "005098": 33, "005114": 33, "005126": 31, "005151": 31, "005157": 28, "005167": 33, "005196": 31, "005241": 33, "00525962": 28, "005269": 33, "005288": 29, "005335": 31, "005336": 33, "005387": 32, "005423": 31, "005426": 31, "00543825": 28, "005440": 41, "005478": 35, "00548": 31, "005538": 33, "005579": 33, "005641": 33, "005674": 33, "005699": 26, "005708": 31, "00573": 31, "005734": 31, "005735": 31, "005767": 31, "005809": 42, "005834": 31, "005836": 28, "005888": 28, "006": [34, 35, 43], "006012": 31, "006046": 33, "006055": 31, "006067": 33, "006106": 31, "006110": [27, 31, 33], "006236": 33, "006244": 31, "006435": 31, "006452": 30, "006476": 33, "006505": 41, "006531": 26, "006545": 31, "006546893270012566": 30, "006557": 30, "006578": [28, 29], "006652": 31, "006667": 31, "00667": 31, "006744": 33, "006805": 26, "006861": 31, "006904": 31, "00691": 31, "006973": 28, "007": [28, 34, 35, 43, 44], "007068": 36, "00715": 31, "00720988e": 35, "007228": 33, "007291": 29, "007316": 26, "007361": 32, "007362": 31, "007434": 35, "007458": [28, 29], "007517": 33, "007544": 31, "007563": 31, "007588": 37, "00758803": 37, "00759438": 35, "007655": 31, "007666": 32, "00767": 31, "007737": 33, "007776": 33, "007818": 31, "007938": 26, "007986": 33, "008": [34, 35, 44], "008040": 42, "008120": 33, "008153": 31, "008167": [28, 29], "00830586": 29, "008306": 29, "008322e": 43, "008333": 29, "008346": 33, "008377": 31, "008472": 33, "008577": 41, "008581": 33, "008606": 33, "008617": 33, "008667": 31, "00871": 31, "008735": 27, "008785": 33, "009": [29, 34, 43], "009059": 26, "009063": 31, "009082": 31, "009090": 33, "009132": 31, "009140": 33, "009297": 31, "009305": 31, "009339": 33, "009422": 26, "009512": 31, "009514e": 33, "009664": 33, "009692": 41, "009724": 36, "01": [27, 28, 30, 31, 32, 33, 35, 41, 42, 43, 45, 53], "010": [24, 30, 31, 43, 44], "0100": 30, "01000": 31, "010000": [28, 31, 33], "010027": 30, "010183": [28, 29], "0102": [27, 31], "010208": 36, "010294": 26, "010650": 26, "010679": 26, "010688": 36, "010715": 31, "010750": 36, "011": [24, 29, 41, 43], "011210": 36, "011234": 32, "011248": 33, "011252": 36, "011269e": 33, "011287": 36, "011332": 43, "011336": 27, "011440": 33, "011617": 31, "011678": 32, "011767": 33, "011773": 34, "012": [28, 29, 34, 35, 41, 43, 44], "012019": 26, "012030": 36, "012232": 33, "012240": 36, "012252": 31, "012616": 31, "012624": 33, "012707": 32, "012758": 33, "013031": 33, "01311996071": 33, "013120": 35, "013157": 31, "013161": 31, "013433": 27, "013629": 31, "013706928443177698": 31, "013707": 31, "013863": 31, "013888": 31, "014": [26, 28, 34, 35, 43], "014030": 33, "014081e": 33, "01409912": 40, "014305": 33, "01432486e": 35, "014481": 31, "014503": 31, "014650": 43, "014730": 29, "01473536": 27, "014758": 43, "015": [24, 28, 29, 34, 43, 44], "015003": 31, "015039": 32, "015056": 31, "015165": 33, "015372": 31, "015724": 36, "015755": 31, "015819": 31, "016263": 31, "016372": 31, "01647": 31, "016525": [33, 35], "016555": 30, "016587": 32, "016598": 31, "016602": 31, "016607": 31, "016676": 37, "016688": [28, 36], "016693": 33, "016807": 30, "016815": 31, "016918": 32, "016944": 27, "017": [29, 41], "017185": 31, "017226": 33, "017308": 31, "017427": 31, "017610": 35, "017696": 35, "017737": 35, "017741": 35, "017829": [42, 53], "017837": 31, "01784": 31, "017927": 31, "017959e": 33, "017972": 28, "018": 34, "018014": 35, "018046": 32, "018077": 31, "018178": 27, "018243": 31, "018310": 27, "018434": [42, 53], "018459e": 33, "018487": 30, "0185": 30, "018505": 31, "018507e": 33, "018558": 31, "018581": 33, "018653": 31, "018745": 24, "018789": 31, "018846": 31, "018854": 32, "019": 34, "019012": 31, "019163": 31, "019381838999846482": 31, "019382": 31, "019396": 31, "019444": 29, "019446": 31, "019531": 32, "019556": 43, "0195598": 30, "019574": 31, "019839": 31, "02": [27, 28, 29, 30, 31, 33, 35, 36, 42, 43, 49, 53], "02000e": 27, "020123": 33, "020403": 31, "020414": 31, "020641": 35, "020648": 33, "020653": 26, "020833": 39, "020862": 33, "020873": 28, "021": [34, 44], "021043": 32, "021100": 28, "021281": 31, "021305": 27, "021345": 31, "021523": 32, "021603": 41, "021721": 31, "021746": 31, "021813": 32, "021862": 31, "021900": [27, 31], "022039": 32, "022331": 35, "022433": 31, "022629": 31, "022686": 31, "022848": 26, "022866": 32, "023": [34, 41], "023086": 43, "023105": [42, 53], "023305": 33, "023366": 36, "023367": 32, "023511": 31, "023554": 33, "023636": 32, "023666": 31, "023810": 44, "024": 34, "024028": 31, "024122": 31, "024291": 42, "024351e": 33, "024390": 36, "02446630e": 35, "024540": 28, "025": [28, 32], "025381": 35, "025391": [28, 29], "025396": 31, "025489": 35, "025689": 31, "025910": 27, "025998": [28, 29], "026": 43, "0261": [27, 31], "026620": 31, "026777": 31, "02677733855112973": 31, "026793": [33, 35], "026972": 33, "027070": 33, "027112": [42, 53], "027321": 36, "027484": 33, "027578": 33, "028023": 32, "02807617": 40, "028337": 31, "028351": 31, "028420": 33, "028672": 36, "028772": 33, "029": 40, "029137": 32, "029146": 32, "029164": [42, 53], "029198": 31, "029264": 33, "029409": 33, "029475": 33, "029909": 26, "029950e": 33, "02d": 42, "03": [30, 31, 33, 35, 41, 42, 43, 44, 53], "030": 35, "03017665e": 35, "030200": 28, "030343": 33, "030349": 33, "030408": 27, "03049217": 27, "0305": 27, "030739733331869412": 30, "030786": 33, "030805": 33, "031": 29, "031070": 33, "031385": 27, "031483": 33, "031564": 28, "031794": 33, "031863": 33, "0319": 40, "031994": 33, "032140": 33, "032280": 32, "032324": 31, "032404": 31, "032566": 29, "03256625": 29, "032656": 27, "032874": 27, "033165": 33, "033222": 43, "033267": 42, "033279": 35, "033305": 41, "033322": 33, "033459": 27, "0335": 31, "033723": 33, "033739": 33, "033780": 43, "033833": 32, "0339": 28, "034071": 32, "03411038e": 35, "034132": 33, "0344": [27, 31], "034894": 35, "034977": 33, "034979e": 33, "035": 41, "0351": 28, "03516073": 35, "035161": 35, "035223": 33, "035230": [42, 53], "035722": 33, "036": [28, 34, 41], "036136": 36, "0362": 28, "036646": 33, "036749": 32, "036764": 32, "036886": 34, "0370": 28, "0373": 28, "037414": [42, 53], "037785": 32, "0378": [28, 43], "038102": 30, "038609": 33, "038707": 35, "038948": 33, "039": 41, "039498": 30, "039741": 27, "0399": 28, "04": [28, 29, 31, 33, 35, 42, 43, 49, 53], "040": 34, "040129": 43, "040497": 32, "040698e": 33, "040954": 43, "040984": 42, "041": [34, 41], "041031": 32, "04108378": 30, "041084": 30, "041129": 27, "041201": 32, "041488": 33, "041704": 35, "041769": 33, "042081": 35, "042382": 36, "042743": 33, "042957": [28, 29], "043": 31, "043257": 29, "043319": 35, "043509": 31, "0437": [25, 26, 27, 47], "043890": 27, "044": [27, 31], "044029": [28, 29], "044166": 30, "044253": 35, "044313": 28, "044409": 33, "044614": 31, "044873": 26, "045": [25, 41], "045267": 42, "045280": 32, "045304": 27, "045415": 28, "045481": [42, 53], "046": 41, "04600e": 27, "046020": 27, "046116": 31, "046193e": 33, "046216": 31, "046638": 29, "0468": 43, "0469": 28, "046945": 31, "04709519e": 35, "0474": 30, "047567": 33, "04774884": 37, "047749": 37, "048": [26, 29], "048378": 26, "04861878": 37, "048630": 42, "048860": 28, "048889": 33, "049": [29, 41], "05": [27, 28, 31, 32, 33, 38, 42, 43, 53], "050": [24, 41], "050110e": 33, "050132": [28, 29], "051": 41, "051269": [28, 29], "05137470e": 35, "051392": 41, "051472": 27, "051620": 28, "051824": 33, "051925": 31, "052": 28, "052349": 28, "052607": 32, "052790": 32, "052819": 32, "05290827e": 35, "053156": 37, "05350962": 45, "0537": 31, "053763": 26, "053918": 31, "054054": 32, "054461": 32, "054653": 29, "05465323": 29, "054669": [33, 35], "054784": 29, "05478443": 29, "055": [26, 28, 29], "055100": 31, "055915e": 33, "05598498": 29, "055985": 29, "056": 41, "056478": [28, 29], "05656664": 40, "056703": 32, "057": [28, 41], "057003": 27, "057082": 33, "057254": 43, "057296": 32, "057331": 33, "057646": 27, "057729": 32, "057732e": 43, "057793": [28, 29], "057910": [28, 29], "058": 34, "0580": [26, 30], "058298": 33, "058311": 32, "059": [24, 28], "059077": 32, "0591": 28, "059242": [28, 29], "059360": 41, "059588": 31, "059863": 27, "06": [28, 31, 33, 38, 40, 41, 42, 43, 45, 53], "060": 41, "060477": 33, "060543": 36, "061100": 28, "061206": 32, "061241": 27, "061312": 33, "061313": 41, "061937": 27, "062": [24, 27, 31], "062043": 31, "062449": 43, "062658e": 33, "062723": 26, "062792": 27, "062793": 40, "063004": 36, "063110": [28, 29], "063173": 35, "064": [31, 35], "06405": 31, "064050": 31, "064200": 27, "064307": 36, "064452": 27, "065": 41, "065169": 31, "065199": 32, "065449": 33, "065463": 32, "066166": 43, "066251": 26, "066605": 31, "066667": 28, "0667579112160865": 30, "066810": 43, "066944": 31, "067119": 28, "067120": 26, "06797961": 33, "067991": 28, "068": 24, "068214": [30, 31], "068291": 41, "068498": 31, "068775": 31, "068891": 31, "069150": 35, "06915047": 35, "069188": 43, "0694": [27, 31], "069530": 27, "07": [31, 33, 36, 42, 43, 53], "070081": 31, "070195": 31, "070850": 32, "070898": 31, "070907": 26, "070929": 32, "071": 41, "071330": [42, 53], "071541": [28, 29], "071654": 36, "07174469222": 33, "071745": 35, "071975": 36, "072": 34, "072043": 31, "072243": 35, "0723": 28, "072396": 31, "07245741": 33, "072595": 31, "072707": 26, "073058": 28, "073233": 30, "073366": 28, "074": [28, 34], "0741": 27, "074141": 27, "07418": 31, "074327": 34, "074418": 41, "074475": 28, "074719": 29, "07471942": 29, "075000": 39, "075170": 42, "075453": 43, "075467": 43, "075747": 31, "076104": 33, "0762": 28, "076284": 37, "07639": 31, "076533": 33, "076798": 27, "077": [34, 41], "077204": 35, "077749": 40, "077761": 43, "077803": 31, "078": [30, 34], "0780": [25, 26, 47], "078052": 32, "07808506982896266": 33, "078243": 31, "078387": 43, "078552": 31, "078740": 31, "07877994e": 45, "078880": 29, "079": 31, "079282": 31, "079377": 43, "0794": [27, 31], "079471e": 33, "079852e": 33, "08": [28, 31, 33, 36, 38, 41, 42, 43, 53], "080": 41, "08002986030": 29, "080084": 31, "080165": 31, "080319": 29, "08031924": 29, "080694": 35, "080734": 26, "0808": 31, "081": 24, "08116": 31, "081167": 43, "081292": 42, "08151507e": 35, "081837": 43, "082": 28, "082100": 31, "082251": 30, "082265e": 43, "082749": 27, "082835": 35, "082949": 27, "083": [27, 31, 34], "083123": [28, 29], "083338": 26, "08338644": 40, "083545": 32, "083615": 31, "083813": [28, 29], "084288": 31, "084746": [28, 29], "085150": 42, "085415": 35, "085477": 32, "085508": 33, "085546": 33, "085550": 33, "085551": 33, "085693": 31, "085698": 33, "08613": 31, "08642578": 40, "086461": 36, "086932": 26, "087": 29, "087128": 31, "08740234": 40, "087668": 31, "08791477": 40, "087996e": 31, "088": 41, "0880": 28, "088543": 31, "088948": 27, "089294": 31, "089313": 31, "089485": 26, "09": [26, 29, 31, 33, 42, 43, 53], "090000": 32, "09009799": 33, "090231": 35, "090376e": 33, "090453": 32, "090473": 31, "09058097218": 24, "090785": 33, "091": 41, "091243": 31, "091625": 36, "091819": 26, "092": 34, "092072": 31, "092123": 31, "0922": [27, 31], "092204": 26, "09245358900622544": 31, "092454": 31, "092604": 26, "092660": 43, "092670": 31, "092729": 31, "092930": 29, "093051": 31, "0931": 31, "093228": 36, "093390": 27, "09345386": 29, "093454": 29, "093624": 26, "093787": 31, "093893": 31, "094": [24, 40], "094290": 43, "09430199": 29, "094302": 29, "094581": 29, "094586": 32, "094725": 31, "094863": 31, "095018": 31, "09503409246217484": 33, "095177": 31, "095345": 31, "09573445": 31, "09619141": 40, "096462": 33, "096692": 28, "096722": 31, "096858": 31, "096927": 32, "096960": 33, "096990": 26, "096997": 41, "097": 41, "09706504": 41, "097088": 43, "097184": 31, "097293": [28, 29], "097516": 28, "097707": 31, "097763": 31, "098": [30, 41], "098152": 31, "098307": 33, "098326": [27, 41], "098559": 31, "098629e": 31, "098663": 31, "0989147678053208": 30, "098915": 30, "098950": 31, "098966": 28, "099": 34, "099230": 35, "099240": [28, 29], "099454": 31, "099558": [28, 29], "099685": 33, "099723": 28, "099729": 31, "099749": [42, 53], "099802": 31, "099869": 31, "0x1227a36e0": 8, "0x1577111f0": 31, "0x16888d4c0": 31, "0x168921100": 31, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 35, 40, 42, 44, 45, 54], "10": [4, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 54], "100": [25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 50, 53], "1000": [26, 27, 29, 30, 31, 32, 33, 35, 36, 41, 42, 43, 44, 45, 50, 51], "10000": [25, 29, 30, 31, 33, 42, 53], "100000": [27, 29, 30, 31, 33, 42, 53], "1000000": 31, "100103": 42, "100105": 31, "100139": 29, "100146": 42, "100248": 27, "100275": 36, "1004": 27, "1005": [42, 53], "1006": [42, 53], "1007": [42, 53], "1008": [42, 53], "100882": 32, "1009": [42, 53], "10092665203438746": 33, "101": [9, 10, 37, 41, 43], "1010": [42, 53], "1012": [42, 53], "101259": 33, "1014": [31, 41], "1015": [41, 42, 53], "1016": [41, 42], "101688": 31, "1017": [41, 42, 53], "101796": 33, "1018": [41, 42, 53], "101810": 26, "101832": 31, "101894": 32, "1019": [41, 42, 53], "102": [32, 33, 52], "1020": [31, 36, 41, 42, 53], "102044": 36, "1021": [41, 42, 53], "102135": 32, "1022": [41, 42, 53], "1023": [41, 42, 53], "1024": [29, 41, 42], "102435": [27, 33], "102474": 29, "10247431": 29, "1025": [42, 53], "10254": 42, "1026": [30, 42], "1027": [42, 53], "10273": 33, "10274": 32, "1028": [42, 53], "1029": [42, 53], "103": 43, "103023": 31, "1031": 42, "103219": 36, "103222": 41, "1034": 36, "103439": 29, "1039": [42, 53], "104": [27, 28, 34, 37, 41], "1040": 28, "104070": 33, "1041": [33, 35, 42, 44, 53], "10416666666666667": 39, "1042": 31, "1044": 24, "104596": 31, "104643": 33, "105": 34, "1050": 25, "105080": 36, "105089": 29, "10513": 42, "1053": 44, "105314": 42, "10556679": 37, "105656": 35, "10584063": 41, "106000": 28, "106023": 33, "106112": 42, "106180": 42, "106319": 42, "106322": 42, "106424": 42, "10644531": 40, "106452": 27, "10645223": 27, "10653": [42, 53], "106705": 42, "106764": 31, "1068": 44, "106816": 42, "1069": 44, "10693359": 40, "106996": 31, "107": 34, "1070": 36, "107050": 42, "107292": 42, "1075": 44, "107502": [42, 53], "1076": 29, "107718": 31, "10781": [34, 35], "107917": [42, 53], "10793260e": 41, "107947": 33, "107985": 33, "107991": 32, "108": 24, "1080": 24, "10800": 24, "1085": 30, "10868": 42, "108681": 27, "1089": 33, "10910": 42, "10931": 29, "109526": 32, "1099": 33, "10_000": 43, "10th": [31, 32, 34, 35, 51], "10x": 32, "11": [1, 10, 11, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 53, 54], "110": [30, 41], "110316": [42, 53], "110319": [42, 53], "1104": 27, "11057": 42, "1106": 36, "110645": 33, "110915e": 33, "111": [28, 31, 32, 33, 43, 51], "11121453": 37, "111215": 37, "111220": 42, "111438": 36, "111543": 33, "112": 27, "1122": [33, 35, 44], "1123": [31, 44], "112441": 31, "112490": 31, "112527": 35, "112848": 33, "11331": 44, "11336331e": 35, "113600": [28, 29, 49], "1138": 36, "113837": 33, "1139": [33, 35], "113949e": 43, "114": 28, "1140": [24, 33, 35], "114000": [28, 36], "114079": 31, "114214": 31, "114507": 41, "11457": [33, 35], "114766": 35, "114836": 36, "114966": 35, "115": 29, "1150": 24, "115083": 28, "115089": 42, "11509": 33, "115090": 42, "115091": 42, "115092": 42, "115183": 31, "115276": 43, "115401": 33, "115406": 27, "115428": [42, 53], "115956": 30, "116": 28, "116145": 36, "116167": 30, "116443": 36, "116497": 33, "11664": 44, "11693": 33, "117": [28, 29, 30, 36, 49], "117058": 30, "117379": 31, "117380": 28, "117412": 33, "117528": 36, "11758": [42, 53], "117612": 41, "117712": 42, "117816": 28, "117899e": 33, "1179": 28, "118": [28, 29, 30, 33, 35, 36], "1180": 25, "118182": [28, 29], "118347": 33, "118450": 32, "118563": 36, "11886432": 31, "118874": 33, "118934": 32, "11898": 32, "119": [28, 29, 30, 36, 42, 49, 53], "1190": 28, "119049": [42, 53], "11909976": 37, "119100": 37, "11914062": 40, "119400": 28, "119570": 36, "119911": [42, 53], "11th": [32, 34, 35, 51], "12": [10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54], "120": [27, 28, 30, 33, 34, 41, 42, 45], "1204": 27, "120769e": 33, "121": [24, 28, 29, 30, 31, 34, 36, 42], "1210": 31, "121056e": 33, "121084e": 33, "121351": 35, "12138": 28, "1214": 33, "121438": 43, "12150684": 30, "121531": 32, "121599": 35, "121628": 27, "1217": 43, "12178": 36, "121846": 35, "121985": 33, "122": [24, 25, 26, 28, 29, 36, 41, 47, 52], "1220": [24, 28, 31], "1222": 31, "122307": [28, 29], "122331": 33, "122668": 31, "123": [4, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51], "123367": 33, "1235387316046016": 31, "123539": 31, "124": [28, 40], "1240": 24, "1241": [33, 36], "1243": 28, "12436984": 29, "124370": 29, "1247": 31, "12498": 35, "124982": 36, "125": [8, 33], "1250": [28, 29, 49], "12508": [33, 35], "125440e": 33, "125476": 27, "125523": [42, 53], "1256": 45, "125617": [42, 53], "125644": 33, "1258": 43, "126": 36, "126238": 36, "126398": [28, 29], "126488": 37, "12649": 28, "126500": 28, "126563": 31, "126808": [28, 29], "127": [26, 28, 30, 31], "127086": 28, "127087": 43, "1271": 34, "127107": 35, "127226": 29, "127242": 33, "1273": 35, "127326": 33, "1274": 36, "127418": 33, "127439": 33, "127441": 33, "127614": 33, "12761659": 33, "127878": 27, "1279": 33, "128": 44, "1280": [28, 31, 33], "1281": 33, "128188": [28, 29], "128384": 33, "128528": 33, "128820": 42, "128828": 42, "128829": 42, "128830": 42, "12890625": 40, "128984": 33, "129": [27, 30, 36, 43, 52], "1290": [28, 29], "12906": 24, "129257": 33, "12927": 24, "129300": [28, 29, 49], "129459": 36, "129600": 33, "129900": 32, "129904": 33, "129985": 28, "12th": [32, 34, 35, 51], "13": [8, 10, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 46, 49, 53], "130": [24, 25, 26, 27, 28, 29, 31, 33, 35, 36, 47, 49], "1300": [33, 35], "1302": 32, "130395": [42, 53], "1304": [27, 43], "130432": [42, 53], "130690e": 33, "1307": 33, "131": [28, 34, 42, 43], "131000": 33, "13107": 42, "131275": 32, "1313": 33, "1314": [33, 35], "131607": [33, 35], "131773": 43, "1319796954314723": 34, "132": 43, "1320": 36, "1321": 24, "132158": 33, "132292": 36, "13229595e": 35, "13255": 42, "132875": [28, 29], "132886": 42, "133": [31, 43], "133000": 33, "133210": 31, "133270": 33, "133337": 33, "133562": 43, "13392236": 41, "134": [25, 26, 29, 30, 47], "1340": 25, "134061": 36, "13407": 35, "134287": 32, "1346": [28, 33, 35, 36, 43, 44], "134615": 30, "134658": 28, "1347": 44, "13476562": 40, "134894": [42, 53], "135": [42, 43, 53], "135134": [42, 53], "135197": [42, 53], "13521135": 35, "135299": 36, "135305": [28, 29], "135384": 33, "135422": 33, "1357": 24, "136": [28, 29], "1360": 25, "13665": [28, 29, 49], "136714": 32, "1370": [24, 27, 31, 43], "13704": [33, 35], "137410": 37, "137500": [28, 29, 49], "1378": 33, "138": 44, "1380": 24, "138103": 41, "1383": 31, "138503": 36, "138528": 30, "138876": 43, "1389": [28, 33, 35], "139": [28, 44], "1390": 24, "139297": 32, "139317": 32, "139322": 32, "139349": 32, "13941": 32, "139554": 32, "1396": 31, "1397": 31, "14": [10, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 46, 53], "140": 28, "140185": 36, "1404": [27, 43], "1405": 36, "1406": [28, 33, 35], "140641": [42, 53], "140953": [42, 53], "141": [28, 30], "141232": [42, 53], "14159265358979323": 8, "14160": 32, "141851": [42, 53], "142": 34, "142193": [42, 53], "142199": [42, 53], "1423": 32, "142398": [42, 53], "142467": 26, "142806": [42, 53], "142857": 29, "14289": [28, 29, 49], "143": [31, 32], "143693": [42, 53], "143803": 36, "1438387200": 42, "1438398000": 42, "1438408800": 42, "1438419600": 42, "1438430400": 42, "1438441200": 42, "1438452000": 42, "1438462800": 42, "1438473600": 42, "1438484400": 42, "143975": [42, 53], "144": [24, 31], "144000": [33, 35], "1441": 44, "144199": [42, 53], "144686": 35, "14471": [28, 29, 49], "144729": 42, "144730": 42, "144731": 42, "144732": 42, "144733": [42, 53], "144750": 27, "14485": 33, "145": [42, 53], "1452": 36, "145425": 33, "145454": [42, 53], "145455": [42, 53], "145456": [42, 53], "145457": [42, 53], "145458": [42, 53], "145459": [42, 53], "145460": [42, 53], "1457": [28, 29, 43, 49], "14579": 36, "1458": [28, 29, 49], "145833": 39, "146": [24, 34], "1460": [33, 43], "14648438": 40, "1465": [28, 29, 49], "146656": [42, 53], "1467": 36, "146767": [32, 35], "146809": 32, "146830": 32, "14690": 29, "147": 35, "147166": [34, 35], "14716638": 35, "147641": 33, "1477": 44, "147737": 41, "147893": 28, "147898": 32, "148": [27, 31, 35, 45], "14813": 42, "148141": 34, "148343": 33, "148349": 43, "14841": 32, "149": 43, "14970": 28, "149788": 35, "149822": [28, 29], "14999": 28, "15": [8, 10, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 42, 43, 44, 46, 47, 51, 53], "150": [27, 31, 33, 41], "150000": [32, 39], "150115": 31, "15026771": 33, "150395": 27, "1504": 27, "1505": 28, "150mb": 32, "150p": 24, "151357": 36, "152": 42, "1520": 31, "152401": 32, "152859": 32, "1530": 24, "1534": 28, "15377": [28, 36], "1540": 24, "154076": [32, 35], "154105": 36, "15429": 42, "154386": [28, 29], "1545": 36, "154795": [33, 35], "154842": 43, "155": [24, 31], "15500": 33, "155178e": 33, "15559528e": 35, "155624": 33, "156": [28, 31, 32], "1562": 31, "156311e": 33, "1564": 31, "15661": 42, "157": [24, 31, 41], "157008": 33, "157157": 44, "157234": 36, "15725": [28, 36], "15775": 42, "1578": 35, "15795": [32, 35], "158": 31, "1580": 24, "1582": 35, "158867": [42, 53], "158982": 33, "159": 31, "1590": [27, 31], "15915": 42, "15992": 35, "16": [10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 40, 42, 43, 44, 46, 47, 53], "160": [26, 27, 30, 31, 33, 35], "160000": [33, 35], "160258": 26, "160282": 36, "1604": 27, "160506": 32, "160634": 41, "16063983": 29, "160640": 29, "160727": 35, "160729": [42, 53], "161": 28, "1610243052583638": 30, "16111330565237164": 30, "1613": 28, "16153": 42, "16157": 42, "16160": 42, "161606": [28, 29], "161782": 32, "1619": 31, "161931": [33, 35], "162": 24, "162000": 33, "162007": 44, "162330": 32, "162667": [32, 35], "1627": 36, "162904": 43, "1631": 31, "163195": [28, 29], "163397": [28, 29], "1634": [28, 29, 31, 49], "16358": 42, "164": [36, 41], "1645": 30, "16460": 36, "164679": 32, "165": [30, 33], "1650": [27, 31], "16507": [30, 36], "16508": [30, 36], "16509": [30, 36], "16510": [30, 36], "16511": [30, 36], "16512": [30, 36], "165198e": 33, "1652": [26, 30], "16533": 42, "165485": 35, "165617": 42, "165811": 31, "16630": 36, "166631": [28, 29], "167": 26, "167214": 27, "167241": 44, "167600": 36, "167620": 41, "168": 33, "1680": 25, "168151": 41, "168196": [28, 29], "168244": 35, "1687": 31, "169": [26, 30, 36], "1690": [24, 25], "169269e": 43, "169421": 31, "169693": 27, "169748": 30, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 25, 27, 28, 29, 30, 31, 32, 33, 36, 42, 43, 46, 49, 53], "170": [28, 38], "170100": [28, 29, 49], "170277": [34, 35], "1704": 27, "17054987": 41, "170670": 33, "170931": 41, "171": [24, 41], "17144": 42, "171468": [33, 35], "1715": 31, "171657": 26, "171899": 43, "1720": 28, "17205": 42, "1724668": 40, "172792": 32, "173": [27, 31], "173025": 31, "17393037": 8, "1739787032867638": 31, "173979": 31, "174": [24, 27, 31], "174590": 32, "174766": 36, "1750": 28, "175000": [33, 35], "17518": 42, "176": 28, "1766": 33, "176924": 43, "177": 36, "17730": [28, 36], "177709": 43, "178": [24, 33], "178494": 33, "17896": 42, "179": [34, 43], "179080": 32, "179123": 27, "179300": 28, "179730": 31, "17973005068132514": 31, "179802": 33, "18": [10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 42, 43, 44, 46, 49, 53], "180": [31, 33, 41], "1800": [24, 25, 27, 31], "18000": 42, "180000": 25, "180279e": 33, "180388": 27, "1804": 27, "18066406": 40, "180900": 36, "18096": 42, "181": 43, "18113": 42, "18116": 42, "1813": 31, "182": [42, 43], "18201414": 35, "18245": 42, "182639": 33, "182648": 33, "18311": 42, "18313": 42, "18317085": 8, "183179": 43, "183423": 27, "183471e": 33, "18365": 29, "18391": [28, 29], "184": [42, 43], "1840": 24, "184405": 35, "1847": 29, "185": 43, "185155": 35, "185175": 43, "18533": 42, "1854": 31, "185707": [27, 31], "18571": [28, 29], "18572": [28, 29], "18573": [28, 29], "18574": [28, 29], "18575": [28, 29], "18576": [28, 29], "1858": 36, "185868": 36, "185975": 35, "18597545": 35, "186024": 24, "186814": 32, "186899": 32, "187": [26, 30, 34], "1870": 31, "187000": 28, "1872": 33, "1875": [30, 40], "187503": 42, "187663": 27, "187700": 28, "188": [24, 26, 30], "1880": 31, "1886": 30, "1887": [32, 35], "18955": 42, "189981": 33, "19": [8, 10, 24, 25, 26, 27, 29, 31, 32, 33, 36, 39, 40, 43, 44, 46, 53], "190": [26, 33, 36], "19000e": 27, "1901": 24, "190319": 36, "19032": 42, "1904": 27, "190617": [28, 29], "191": [26, 28], "1911": 36, "191169": [33, 35], "191204": 36, "191250": 26, "191396": 27, "191700": 36, "1918": 29, "191k": 35, "1920": 24, "19213263": 29, "192133": 29, "19266": 42, "1927": 44, "1928": 44, "193": 41, "1930": 24, "193021": 32, "193122": 32, "193247": 36, "1933": 25, "193346": 35, "193427": 31, "19365": 42, "193704": [42, 53], "19380": 42, "1940": 29, "194002": 27, "194034": [42, 53], "194040": 28, "19422": 35, "19433594": 40, "1945": 33, "1946": [24, 33], "194710": 33, "19485": 28, "194985": 33, "195": 28, "1950": 33, "1951": 25, "195228": 29, "1953": [31, 33], "19536": 32, "1954": 40, "1955": 25, "195564": 36, "1957": 40, "1959": 24, "19591": 36, "1960": 25, "1962": 40, "1963": 31, "196385": 35, "1965": 25, "196599": 33, "1966": 33, "196717": 41, "196739": 42, "1968": 24, "1970": [30, 33, 42], "1972": 33, "197649": 36, "1977": [24, 43], "19777": [34, 35], "19781": 42, "198": [41, 44], "198127": 33, "1984": 33, "1985": 33, "198629": 41, "198645": 43, "1987": [24, 25], "1989": 24, "198924": [28, 29], "199": [24, 27, 32], "1990": [27, 30, 31], "1991": [25, 34], "1992": [42, 44], "1993": 33, "199364": 32, "1994": 24, "199412": 43, "199413": [27, 31], "19966": [28, 29, 36], "1997": [30, 31], "199771": 35, "1_000_000_000": 31, "1d": 41, "1e": [31, 33, 50], "1e3": [31, 50], "1e4": 31, "1h": [28, 29, 36], "1st": [8, 32, 34, 35, 42, 51], "1stflrsf": [33, 35], "1v": 45, "1v2": 45, "1v3": 45, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 34, 35, 36, 40, 41, 42, 44, 45, 54], "20": [4, 8, 10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 44, 45, 46, 48, 49, 53, 54], "200": [24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 40, 41, 47, 48, 49, 50, 51], "2000": [27, 31, 32, 33, 34, 35, 36, 41, 45, 50], "200000": [31, 42, 53], "200326e": 33, "2004": 33, "200475": 32, "2006": [33, 35], "2007": [33, 35, 42, 53], "2008": [33, 35, 42, 53], "200876": 29, "20087625": 29, "2009": [33, 35, 42], "200978": 27, "200k": 51, "201": [27, 54], "2010": [33, 35, 42], "20113": [28, 29, 49], "2012": [8, 28, 31], "2013": [40, 42, 53], "201332": 38, "2014": [24, 34, 42], "2015": [41, 42, 53], "20150630": [42, 53], "2016": [8, 41, 42], "20160101": 42, "2017": [35, 42, 53], "201810": 32, "201862": 36, "202": [27, 29], "2020": 44, "2022": 42, "2023": [10, 42], "2024": [0, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53], "20248": 28, "2024w1": 41, "2025": 1, "2025s1": [0, 11], "20274": 42, "202839": 32, "203": 27, "20310": 42, "20311": 36, "20319": 42, "203265": 35, "20334": 42, "203421": 33, "203500": 28, "20357847293371892": 30, "204": [25, 26, 27, 31, 40, 47], "204167": 26, "2043": 43, "204302": [42, 53], "20433": 36, "204583": 26, "2046": 29, "204600": [27, 31], "204692": 33, "204734": 32, "20485": 42, "205": [25, 26, 27, 44, 47], "205000": [28, 29, 33, 35, 49], "205059": 36, "20509": 42, "20514": 42, "205144": 36, "205323": [42, 53], "205479": 30, "205597": 33, "20564": 42, "206": [25, 26, 27, 31, 32, 47], "206041": 35, "206073": 32, "206099": 31, "20620": 42, "206292": 28, "20639": 36, "2064": 28, "20640": [30, 36], "206724": 43, "20683258": 30, "20694": 42, "207": [25, 26, 27, 28, 31, 40, 41, 47], "207039e": 33, "2071": 36, "207814e": 33, "20794": 42, "208": [25, 26, 27, 30, 31, 47], "209": [24, 25, 26, 27, 31, 47], "209583": 26, "209746": 32, "209903": 36, "20analysi": 43, "20assumpt": 43, "20hazard": 43, "20intro": 43, "20learn": 41, "20lifelin": 43, "20with": 43, "21": [10, 24, 25, 27, 28, 29, 32, 33, 36, 37, 39, 40, 42, 44, 53], "210": 31, "210001": 32, "210240": 31, "210272": 36, "210591": [28, 29], "210779": 42, "21086181023099526": 30, "211": 31, "2110": 28, "211250": 26, "211343": 36, "211544": 32, "211892": [28, 29], "212": [26, 31], "212385": 35, "212581": 36, "21274": 42, "212870": 33, "212975": 33, "213": [31, 41, 42], "2130": 24, "21353": 42, "21382972": 34, "21389": 42, "2139": [28, 29, 49], "214": [24, 29, 31], "21405": 42, "2144": 31, "214740": 28, "214769": 41, "214821": 42, "214852": 32, "215": 31, "215245": 33, "21530": 42, "215412": 33, "21549": 42, "21571": 42, "21581": 42, "21582031": 40, "215865": 35, "21596": 42, "216": 31, "21603": 42, "21605": 42, "216123": 43, "21613": 25, "21616484": 45, "21617": 42, "216346": 35, "21634631": 35, "216585": 28, "216596": [42, 53], "21668": 42, "21670": 42, "216718": 32, "216728": 28, "21694": 42, "21697": 42, "2170": 25, "217334": 29, "21733442": 29, "2173627": 40, "21767954": 35, "21768": [35, 42], "217680": [34, 35], "21774": 42, "218207": [28, 29], "21847": 42, "21872": [33, 35], "218760": 35, "218830": 28, "219": 36, "2190": 28, "2192": 31, "219512": 36, "219700": 36, "21972656": 40, "219845e": 33, "22": [10, 27, 28, 29, 31, 32, 33, 34, 35, 36, 40, 42, 43, 44, 45, 49, 53, 54], "220": 26, "22001": 35, "220392": 43, "22057": 42, "2206": 43, "22078": 42, "2210": 24, "22114": 42, "221329": 33, "221348": [42, 53], "2214": 44, "22154": 42, "221622": [28, 29], "22168237": 45, "221900": 25, "22219": 42, "22221894": 33, "222222": 28, "22225": 42, "222307": 28, "222500": 26, "22260": 42, "222647": [33, 35], "2229": 30, "222963e": 33, "22305705": 34, "22320": 42, "223333": 26, "223460": 43, "223750": 26, "223804": 35, "224": [31, 41], "22452": 42, "2246468746": 26, "224662": 33, "22471154513694713": 30, "224865": [33, 35], "225": 41, "225301e": 33, "2254": 28, "22550": 42, "226": 31, "226415": 28, "226789": 43, "2268": 34, "22697768": 29, "226978": 29, "2270": 31, "227143": 28, "2272": 32, "227304": 42, "22741": 36, "227559": [33, 35], "227836": 32, "22788": 42, "22811601": 30, "22826": 42, "228329": 32, "2285": 42, "22851562": 40, "228603": 33, "228750": 26, "229": 41, "229000": 28, "22910": 42, "229102": 35, "2293467570951035": 34, "2295": 42, "229583": 26, "229718": 35, "23": [10, 27, 28, 29, 30, 31, 32, 33, 36, 40, 42, 43, 49, 53], "230": [27, 31], "2300": 24, "23011": 35, "2305": 35, "2307": [26, 30], "2309": 42, "23091772": 34, "2310": 42, "2311": 42, "2312": 42, "2313": 42, "23175": 42, "231815": 35, "232143": 29, "232751": 43, "23290": 42, "233": 25, "234": 43, "234040": 32, "234436": 43, "235": 36, "235096": [28, 29], "235152": 27, "235417": 26, "235706": 36, "236": [27, 31, 43], "236096": 41, "236174": 36, "236210": 37, "23621041": 37, "23640124": 30, "236456": 28, "23654": [32, 35], "236960": 31, "237": [32, 43], "237895": 32, "237935": 35, "238": [32, 43], "238192": [32, 35], "2389": 29, "239": 43, "23902": 42, "23941": 42, "239944e": 33, "24": [1, 11, 24, 27, 28, 32, 33, 34, 35, 36, 40, 41, 42, 43, 53], "240": 43, "2401": 36, "240893": 36, "241": 43, "241489": 43, "241620": 32, "24182": 42, "242015": [34, 35], "242083": 26, "242169": 32, "242381": 42, "24295676": 29, "242957": 29, "242996": [28, 29], "243": 42, "243243": 33, "2435": 36, "2436": 36, "24395": [34, 35], "24397122221206388": 42, "244": 42, "244592": 27, "2447": 34, "244814": 43, "245": 42, "2451": 31, "245329": 33, "245521": 32, "245686": 32, "246": 42, "246332": 33, "246646": 31, "246646103936": 31, "246653": 31, "247": 42, "247119": 42, "247439": 37, "24743939": 37, "247690828913": 31, "247691": 31, "248": 42, "248328": 34, "248333": 26, "2484": 24, "248457": [33, 35], "248609": 33, "248664": 36, "2488": 27, "248999": 43, "249": 44, "2496": [26, 30], "249601e": 33, "249618e": 33, "249720": 27, "24h": 32, "25": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54], "2500": [8, 44], "250000": [28, 32, 33], "25031": 42, "25037": 42, "2506": [25, 26, 47], "250900": 33, "251093": 31, "251158e": 33, "2516": 34, "25176": 42, "251769": 41, "252042": 36, "25214": 42, "252160": 27, "252859": 35, "2530": 24, "2533": [26, 30], "253312": [28, 29], "253432": 35, "253724": 27, "253914": 33, "254380": 43, "254443": 32, "255": 28, "2551": 44, "255134": 41, "2556": 34, "255751": 36, "255889": [42, 53], "256": [24, 41], "25622": 42, "256263": [34, 35], "256333": 28, "256437": 36, "25658": 36, "256813": 27, "257": 25, "2570": [24, 25], "257024": 31, "257103": 32, "2574": 36, "2580": 24, "258225": 42, "25823": 32, "258387": 35, "2584": 40, "258427": 27, "258886": 32, "259": [33, 36], "25904": 42, "2590575478171884": 30, "259286": 27, "259500": 28, "26": [8, 10, 24, 27, 28, 31, 32, 33, 34, 35, 36, 37, 40, 42, 43, 53], "2600": [28, 29, 49], "260258": 36, "26048": 35, "260572": 33, "26063": 42, "260890": [33, 35], "261035": 33, "261953": [42, 53], "262": [33, 35, 43], "262079e": 33, "262156e": 33, "262269e": 33, "2623": 33, "262361": 36, "262500": 33, "263": 33, "2630": 28, "263541": 43, "263600": 28, "26370005": 30, "263736": 43, "263742e": 33, "26376": 42, "264195": 43, "264283e": 33, "26447953": 29, "264480": 29, "265": 34, "265273": 30, "266120": [42, 53], "266135": [28, 29], "2670": 31, "267612e": 33, "268": 31, "2683": 32, "26831": 42, "2691": [25, 26, 47], "26919": 36, "269689": 32, "269880": 27, "269972": [33, 35], "27": [8, 27, 29, 31, 32, 33, 40, 42, 43, 53], "270093": 31, "270093376167": 31, "27021": 42, "270270": 39, "27048": 32, "2705": 31, "271037": 36, "271287": 42, "271500": 36, "271738e": 33, "2720": 25, "27206": 42, "27263": 35, "272667": [28, 29], "2730": 28, "273382": [28, 29], "273606": [28, 29], "273890": 41, "273962": 36, "274": [28, 29, 42, 49], "274404": 28, "275008": [42, 53], "27502379069": 33, "275290": 32, "275352": 27, "275410": 30, "2759": 35, "276": 28, "27610135": 40, "27638": 42, "27652": 32, "276687": 33, "27676": 32, "27678": 32, "276943e": 33, "27697": 32, "2770": 31, "27705": 32, "27715": 32, "277381": 27, "2777": 43, "278441": [42, 53], "278634": 32, "27874871715903093": 30, "278755": 29, "27875502": 29, "2788": [26, 30], "2794": 30, "28": [10, 27, 28, 29, 30, 31, 32, 33, 36, 37, 40, 42, 43, 53], "280": [28, 36, 44], "2800": 8, "280028": 36, "280310": [28, 29], "2806": 31, "280618": 32, "2807": 43, "280801": 43, "281": 28, "28122025543": 33, "281583": 33, "2817": 35, "2820": 31, "282021e": 33, "2822": 35, "282600": 43, "283119e": 33, "28327": 42, "283421": 33, "2836": 35, "28362": 42, "283857": 27, "283921": 28, "284": [36, 42], "2845": 43, "2846": 44, "2847": 44, "285": [28, 29, 42, 49], "285263": 35, "28526302": 35, "285467": [33, 35], "28571429": 25, "286": [26, 27, 31, 42], "286000": 31, "286200": 36, "286416": 29, "2865025": 45, "286821": 27, "287": 42, "287031": [42, 53], "287079e": 33, "287344": [28, 29], "287500": 36, "28753559": 40, "288": 42, "288002": [42, 53], "288462": 30, "28854": 42, "28868": 32, "289": 42, "2890": [27, 31], "28953": 42, "289541": [33, 35], "289799": 27, "29": [8, 27, 28, 32, 33, 40, 42, 43, 44, 53], "290": 42, "290002": 32, "290424": 33, "29045704": 33, "290961e": 33, "291": [30, 42], "291667": 39, "292": 42, "292587": 43, "293": 42, "29324459": 41, "293663": 32, "294": [28, 40], "294251": 29, "2948": [28, 29, 49], "294855": 35, "2953863599856862": 30, "295397": 32, "29545": 33, "29572402": 40, "296": [28, 44], "296601": 36, "29691": 42, "297": 30, "29802": [32, 35], "298561": 43, "298612": [42, 53], "29881": 42, "298813": 32, "299": 41, "299164": 36, "2d": 41, "2d454e5fd9a5": 43, "2e": 10, "2f": [26, 31, 39, 42], "2nd": 30, "2ndflrsf": [33, 35], "2v": 45, "2v3": 45, "3": [7, 8, 10, 11, 14, 16, 17, 18, 27, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 44, 45, 46, 54], "30": [4, 10, 24, 26, 27, 30, 32, 33, 34, 35, 36, 40, 42, 43, 44, 53, 54], "300": [27, 38, 40, 45], "3000": 41, "300000": [28, 29, 42, 53], "3000000": 40, "300464": 36, "300837": 32, "301": 43, "3010": 36, "301200": 31, "3014": 36, "30146": 42, "301563": 33, "30167": 42, "301784": 43, "3019": [25, 26, 30, 47], "301952": 36, "302": [33, 35], "302131": 33, "30279": 42, "302801": 43, "302844": 43, "303": [33, 35], "303000": 28, "303004": 36, "303030": 30, "303109": 29, "303790": 31, "3038": 44, "3038344082": 35, "303916": 27, "304": 27, "3040": 42, "3041": 42, "3042": 42, "3043": 42, "3044": 42, "304784": 33, "305": 24, "30504657": 37, "305047": 37, "30530902": 27, "305346": 27, "305674": 36, "3057": [26, 30], "30573": 36, "306": 44, "306500": 27, "306564": 41, "307": 28, "3075": 44, "307516": 41, "307521": 30, "30792853": 40, "30798381": 40, "308120": 28, "30815": 33, "308216": 41, "308220": 32, "308448": 27, "3089": 31, "309": 36, "3092": [25, 26, 47], "309249": 41, "309859": 30, "31": [10, 24, 27, 28, 29, 30, 32, 33, 34, 35, 37, 40, 42, 43, 44, 49, 53], "310": 54, "310000": 28, "31000e": 27, "310284": 35, "31038074": 40, "310405": 32, "311": 28, "3110": 28, "311151": 43, "31127015": 35, "311310": 24, "311769": 36, "31196406381465247": 30, "3120": 28, "3125": 28, "312500": 39, "312501": [33, 35], "312696": 44, "3129": 44, "31297381": 29, "312974": 29, "31298589e": 41, "313": [29, 33], "3130": 44, "31384": 32, "314": 28, "3140": 28, "314000": 31, "31449687e": 35, "31454": 36, "314582": 35, "314840": 36, "314929": [42, 53], "315134": [42, 53], "315630": 32, "316164": 36, "316230": 36, "31634363": 40, "316363": 27, "316395e": 33, "316426": 36, "316552": 29, "31655231": 29, "316798": 36, "317": [28, 35], "317277": 36, "317761": 32, "318": 28, "3180": 31, "3180174485124284": 28, "318937": [28, 29], "319": [25, 28], "31908384": 41, "319630": 43, "31984311": 33, "31st": 42, "32": [8, 27, 28, 29, 30, 31, 33, 37, 40, 42, 43, 49, 53], "320": 28, "320155": 32, "320430": 33, "32064171": 34, "321": 35, "32127053": 33, "322": 36, "32240": [34, 35], "32247597e": 35, "322755": 27, "323045": [28, 29], "32323": 24, "32397724e": 35, "3245": 24, "3252": 36, "325319": 36, "32561": 32, "326": [28, 36], "326730": 32, "326741e": 43, "326933": [27, 31], "327188": 32, "3272": 43, "327283": 33, "32734": 36, "3274": 43, "327408": 32, "32791718": 40, "328": 36, "328077e": 33, "328799": 32, "328953": 27, "3298721": 41, "3299": [40, 44], "33": [8, 24, 27, 28, 29, 30, 31, 32, 33, 36, 40, 42, 43, 53], "330": [9, 10, 11, 24, 25, 41, 42, 44, 54], "33000e": 27, "330346": 43, "3310": 28, "33191802": 40, "332125": 32, "332130": 33, "33223002": 40, "3322447": 40, "33224516": 40, "33224759": 40, "332671": 35, "3327": 42, "332710": 33, "332746": 43, "332791": 43, "332824": 33, "3330": 28, "33308783": 29, "333088": 29, "333139": 32, "333333": [25, 28, 31, 39], "3333333333333333": [39, 41], "333340": 27, "3334": 44, "33380649": 40, "33380754": 40, "33380761": 40, "33381373": 40, "33394593": 40, "3339473": 40, "33394769": 40, "33395626": 40, "33397112": 40, "334": 36, "33400489": 40, "33411086": 40, "33425967": 40, "33435326": 40, "33439238": 40, "33440682": 40, "334411": 27, "334576": 33, "33462759": 40, "33476534": 40, "335": 34, "335309": 33, "3355": [28, 29, 49], "3356700488_183566145b": 41, "33590": 42, "336389": 35, "33641142": 35, "3364114233677307": 35, "336411423367732": 35, "336735": 31, "336826": 29, "33682642": 29, "33683087": 30, "336831": 30, "337034": 36, "33726089": 33, "33732465": 40, "33782315": 40, "33797555": 40, "338": [27, 31], "33888659": 8, "339": 32, "339368": 43, "339889": 43, "34": [24, 27, 28, 29, 30, 32, 33, 36, 40, 42, 43, 49], "340": [3, 10, 25, 34, 36, 41, 42, 43], "34000e": 27, "340988": 32, "341109": 33, "341300": 36, "341571": 43, "34161762": [33, 35], "341712": [42, 53], "34182": 35, "3420": 28, "342200": 36, "342605e": 33, "3436": [42, 53], "3437": 44, "3438": 44, "344": 28, "3442": 43, "34426571": 33, "34441": 33, "345": 35, "345136": 27, "345386e": 33, "3454": [43, 44], "3455": 44, "345831": 24, "346": [28, 29, 49], "346850": 32, "34691": 42, "347523": 31, "348": [28, 36], "34806": 33, "34900": 33, "34924955": 40, "35": [27, 28, 30, 32, 33, 34, 35, 40, 42, 43, 44, 48, 52, 53], "350": 24, "3500": 48, "350000": 28, "351351": 39, "351366": 32, "3515": 43, "3517": 44, "351821": 43, "3520": 43, "3521": 24, "352100": 36, "352930": [28, 29], "353": 41, "35375221": 45, "353961": 31, "354114": [33, 35], "354604": 32, "3547": 36, "354759e": 33, "35561437": 40, "356689": [34, 35], "35671794": 35, "357": 28, "3573886": 40, "357500": [28, 29], "3576": 24, "3577": 44, "35771821": 40, "357823": 24, "358": [24, 31], "358032": 35, "3582": [43, 44], "358264": [33, 35], "3583": 44, "358333": 27, "358500": 36, "358913": 29, "3589134": 29, "359": [27, 31], "3590": 31, "359784": 31, "359887": 37, "359992": 27, "35p": 24, "36": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 43, 53], "360": 29, "360172": 32, "360918": [42, 53], "361": 43, "361718": 32, "362": [43, 44], "362009": 42, "362185e": 33, "362553": 36, "36269995": 29, "362700": 29, "363": 43, "363192": 27, "363913": 32, "364": [42, 43], "364352": 30, "365": 42, "36525": 35, "365420": 44, "365603": 30, "365623": 27, "366": [29, 42, 43], "366005": 32, "3663": 43, "366626": 27, "36695134": 40, "367": 42, "367329e": 43, "367423": 31, "368": [42, 44], "3681": 35, "368304": 30, "3684": 43, "368922": 38, "369": 33, "369875": 27, "369896": 41, "37": [28, 29, 30, 33, 36, 40, 42, 43, 44, 49, 53], "37050406": 8, "370643": 32, "371": [36, 42, 53], "3717": 35, "371722": 35, "372": 28, "372706": [42, 53], "372763": [33, 35], "373031": 27, "373275": [42, 53], "373656": 42, "374": 28, "374584": 41, "37546": 35, "376": [28, 33], "376089": 33, "37647072": 34, "3768": 44, "3769": 44, "377032": 33, "377619": 31, "377619120792": 31, "37797291": 29, "377973": 29, "37807203": 40, "378159": 33, "378764": 27, "378971e": 33, "37906": 32, "379416e": 33, "379875e": 33, "38": [8, 27, 28, 30, 32, 33, 36, 40, 42, 43, 53], "3803": 43, "380436": 29, "38043616": 29, "380495": 27, "380504": [28, 29], "380643": 27, "381190": 36, "3814": 29, "381416e": 43, "381428": [33, 35], "381676": 27, "38192364": 37, "381924": 37, "382558": 32, "3828125": 40, "383": [28, 36], "384111": 44, "384127": 27, "384613e": 31, "3851": 32, "3856": 27, "385639": 37, "386": 31, "386071e": 33, "386530": 35, "387": 31, "388023": 32, "388169": 36, "38853": 33, "3889": 29, "389": [31, 36], "389065": 35, "389349": 36, "389736": [28, 29], "39": [27, 31, 32, 33, 37, 40, 42, 52, 53], "390428669205": 31, "390429": 31, "390725": 33, "39095422e": 35, "391": 28, "3912": 43, "39163": 32, "391996": 41, "392": [24, 43], "392082": 35, "392221": 30, "392385": 43, "392612": 33, "392893": [27, 31], "393": [25, 29], "3932": 43, "39375": 42, "394113e": 33, "394920": 28, "395282e": 33, "395686e": 33, "395688": 43, "395697e": 33, "396": [28, 43], "396266": 41, "396752e": 33, "396991": [28, 29], "397": 43, "398": 36, "398495": [42, 53], "39896994": 29, "398970": 29, "399": 28, "3990": [25, 26, 47], "3991": 33, "39931": 35, "399827": 32, "39x15": 40, "3blue1brown": 41, "3d": [36, 41], "3f": [25, 26, 27, 28, 32, 33, 39, 40, 44], "3h": 42, "3m": 41, "3rd": 40, "3ssnporch": [33, 35], "3v": 45, "4": [0, 1, 8, 9, 10, 14, 16, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 54], "40": [8, 24, 27, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 48, 53, 54], "400": [25, 28, 31, 50], "40000": [41, 42, 53], "400000": [31, 42, 53], "400047": 43, "400157": 36, "400164": 41, "400649628005": 31, "400650": 31, "401": [27, 31], "4011": 40, "401102": 42, "401541": 32, "401623": 33, "401830": 35, "401895": 31, "402": 24, "402808": 35, "404": [27, 36], "405": 34, "405227e": 33, "405415": 27, "405650": 33, "406": 41, "406202": 31, "40689": 36, "407": 32, "407234": 41, "40725012": 41, "407510": 32, "40756124": 34, "407862": 43, "4084": 43, "40_000": 41, "40b5a809b05a": 43, "41": [27, 28, 32, 33, 35, 36, 37, 39, 42, 43, 53], "410": 28, "410240": [32, 35], "410599": 36, "411412": 33, "41150573": 33, "412": [24, 27, 31], "41210938": 40, "412500": 36, "413050": 41, "413718": 43, "413796": 33, "413958": 32, "414": 44, "4143": 43, "4151": 34, "4153": 36, "4158382658": 28, "416": 35, "4165": 34, "4169": 43, "418": 40, "418031": 27, "418069": 31, "41901484361": 31, "419015": 31, "419355": 30, "4195": 35, "4197": [25, 26, 30, 47], "419973": 32, "42": [24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 47, 48, 51, 52], "420": 31, "420000": 24, "42060": 36, "421": 41, "42104086": 35, "421215": 37, "42121526": 37, "421875": 30, "422": 33, "4234": 35, "4236": 35, "4238": 32, "423852": 32, "424222": 33, "424337e": 33, "425": 34, "425365": 43, "42541681": 45, "425419": 33, "426067": 28, "426410": 27, "427": 43, "428": 43, "429": [33, 35], "429217": 32, "429634": 43, "4296875": 40, "43": [27, 30, 31, 32, 33, 42, 43], "430": [31, 33, 35, 43], "430323": 28, "430571": 32, "430704": 37, "4307043": 37, "430868": 30, "431": [26, 43], "4310": [27, 28, 31], "431137": 30, "4314": 32, "432": 43, "433": 43, "433514": [42, 53], "433814": 43, "434": [27, 30, 31, 43], "43445": 36, "435": 43, "435186": 27, "435489": 32, "435792": 31, "436": 43, "436492": 33, "43697758253484614": 30, "437": 44, "4372": 37, "437367": [28, 29], "4375": [36, 39], "437500": 39, "437684": 42, "438": 39, "438231": 41, "438275": 29, "43827545": 29, "43833466": 33, "438592": 35, "438906": 35, "439": 28, "4390": [27, 31], "439209": 32, "439360": 28, "439779": 32, "44": [26, 27, 28, 30, 32, 33, 36, 40, 42, 43, 44, 53], "440": [31, 42], "441": 33, "441404": 41, "441445": 36, "442377e": 33, "442806": 27, "4430": 43, "44311": 36, "4432": 36, "443317": 27, "443419": [33, 35], "444297": 36, "444444": 28, "4448": 36, "445": 31, "445111e": 33, "445124e": 33, "44586935": 34, "44586935141902073": 34, "446216": 36, "446284e": 33, "446869": 36, "447": [28, 35], "447461": [42, 53], "447517": 35, "44787197": 40, "4482": 24, "4484": 27, "448757": 43, "449": 44, "449666": 27, "44966612": 27, "45": [8, 25, 26, 27, 30, 32, 33, 40, 42, 43, 47, 53, 54], "450000": 39, "450132": [42, 53], "450739": 33, "450822": 36, "451888": 32, "452600": 36, "453367": 36, "4537": 43, "454427": [28, 29], "454677": 37, "45467725": 37, "454788": 35, "454966": 32, "455": 29, "4552": 35, "45555535": 35, "45587": [42, 53], "45588": [42, 53], "45589": [42, 53], "45590": [42, 53], "45591": [42, 53], "456": 41, "456419": 36, "45653693": 29, "456537": 29, "456904786": 44, "457435": [42, 53], "45756": 44, "458": 28, "458333": 39, "458524": 43, "459": 33, "4591": 28, "459214e": 33, "459873": 43, "459937": 40, "45a": [42, 53], "45am": [42, 53], "46": [8, 25, 26, 27, 28, 29, 30, 32, 33, 42, 43, 44, 47, 49, 53], "460047": 43, "46019608e": 35, "46021": 44, "46075": 44, "4608": [25, 26, 47], "460950": 37, "461": [28, 31], "462060": 43, "462545": 35, "462963": 30, "46299": 44, "463": 32, "463582": 34, "464104e": 33, "465279e": 33, "46530779": 29, "465308": 29, "466246": 41, "4664": 24, "46729488": 33, "467379": 35, "467628": 36, "468": [27, 31, 35], "468232": [42, 53], "4687": 36, "46880": 44, "469": [28, 32], "469383": 32, "4695": 32, "469571": 36, "47": [10, 24, 25, 26, 27, 28, 30, 31, 33, 36], "470": [28, 44], "4700": 31, "470060": 33, "470666": 33, "471032": 35, "472": 44, "47242662": 45, "4726": 43, "472603": 33, "472790": 32, "473": 40, "473691": 27, "474": 32, "474552": 27, "47491": 32, "475099": 35, "475540": 40, "476": 25, "4760": 31, "47606": 36, "476092": [33, 35], "476406": 35, "476412": 37, "47641249": 37, "477": 31, "477291": 36, "47799": 44, "478060": [42, 53], "479109": 27, "479132": 36, "479773": 40, "48": [25, 26, 27, 30, 32, 33, 39, 42, 43, 47, 53], "480": 33, "4800": 24, "480249": 27, "4806334": 40, "48073598": 37, "4809": 31, "481": 28, "4813": [26, 30], "481514": 33, "481793": 28, "481893": 32, "481960": 32, "4822": 43, "483751": 27, "48390": 44, "48407": 44, "484937": 30, "485": 41, "48535": 44, "4854": 35, "485722": 40, "486": 35, "4861": [28, 29, 49], "486266": 28, "486664": 40, "487": 28, "48721": 44, "487740": 40, "4879": 44, "488": 28, "488163": 40, "488753": [42, 53], "489130": 30, "489593": 40, "49": [27, 30, 32, 33, 36, 42, 43, 52, 53], "490": [36, 45], "490000": 28, "490033": 33, "490568": 31, "490797": 40, "490930": 40, "491217": 32, "491366": 35, "491379": [28, 36], "491968": 40, "492": [28, 32], "492270": 29, "492307": 40, "492551": 40, "493": [25, 26, 28], "493489": 40, "493544": 28, "493921": 29, "494": [27, 28, 31], "4943": 31, "49575": 32, "496": 36, "496213": 33, "496757": 35, "497143": 40, "497386": 27, "497787": 33, "497949": 40, "498": 32, "498133e": 33, "498562": 27, "499900": 28, "4f": [27, 29, 32, 40], "4m": 41, "4th": [32, 34, 35, 51], "4x": 54, "5": [4, 10, 24, 30, 31, 33, 34, 38, 39, 42, 44, 45, 46, 47, 54], "50": [10, 24, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 50, 51, 53, 54], "500": [24, 28, 32, 34, 35, 36, 51], "5000": [24, 25], "50000": [42, 53], "500000": [28, 29, 32, 33, 38, 42, 44, 53], "500000e": 31, "500001": 28, "5002": 33, "500625": 27, "50062e": 27, "500924": [28, 29], "501": [28, 44], "501071": 41, "501191": 40, "501250": 27, "501304e": 33, "501875": 27, "5024752475247525": 31, "502500": 27, "502985": 32, "503000": 28, "503090": 32, "503125": 27, "503750": 27, "503807": 40, "504": [27, 36], "504231": 43, "504375": 27, "504429": 29, "504644": 31, "50475372e": 35, "504fde4fcf8": 43, "505180": 40, "505335": 32, "505592e": 33, "505625": 27, "5057": 33, "50596432e": 45, "506023": 34, "506035e": 33, "506079e": 33, "506084e": 33, "506211": [28, 31], "506410": 30, "506875": 27, "507130": 31, "507359": [28, 31], "507500": 27, "50774": 31, "507740": 28, "50775": 31, "507750": 31, "507752": [28, 31], "507995": 30, "508": [28, 33], "508125": 27, "508133": [28, 31], "508371": 31, "508534": 40, "508741": 40, "50884": 36, "50899": 31, "509000": 24, "509001": 33, "509317": [28, 31], "5098": 40, "509859": 40, "509930": [42, 53], "50k": [32, 34, 35, 51], "51": [27, 28, 29, 31, 32, 33, 35, 37, 42, 43, 49, 53], "510000": [25, 27, 31], "510421": 40, "510505": 40, "5106": 44, "510836": 31, "5109": 35, "511": 9, "5112": 25, "51137414e": 35, "51143": 36, "51150": 32, "511620e": 33, "5118": 35, "512": 41, "5120": 24, "512000": [27, 31], "51226051": 37, "5123": 40, "512319": 28, "512408": [33, 35], "512897": 27, "512x640": 41, "513": 28, "5131": 40, "513678": 43, "514150": 40, "514155": [28, 29, 33], "514347": 40, "514598e": 33, "5146": 30, "515000": 27, "51503393": 29, "515034": 29, "515351e": 33, "5156": [28, 36], "515848": 36, "516199": 40, "516394": 36, "516858": 40, "517273": 40, "517346": 32, "518113": 40, "519029": 32, "52": [27, 28, 30, 32, 33, 36, 42, 43, 44, 53], "520495": 40, "52061": 42, "520700": 40, "520782": 40, "5208": 25, "520857": 32, "5209": 33, "5212": 33, "521284e": 33, "521567e": 33, "521578e": 33, "521743e": 33, "521772": 40, "522": 33, "522563e": 33, "5227966": 40, "523595": 40, "523684": 40, "5238095238095238": 25, "52398": 36, "524": [25, 39], "524364": 43, "5253": 35, "525554": 36, "525757": 27, "526046": 40, "526078": [28, 29], "526214": 35, "526596": 36, "526602": 33, "5274": 43, "527500": 28, "528": 33, "5282": 43, "528403": 27, "52881619": 27, "529210": 32, "529388e": 33, "5294": 34, "529412": 28, "53": [30, 33, 42], "530052": 31, "530978": 32, "531116e": 33, "531353": 41, "5315": 31, "532034": 33, "533454": 41, "533498": 27, "534": 44, "534114": 31, "534342": 36, "535": [28, 36], "535014": 28, "53520104": 27, "535604": 28, "535622": 36, "536362": 37, "53636249": 37, "537267": 28, "537732": 40, "538000": 25, "538702": 27, "538816": 32, "5390": [32, 35], "5391": [28, 36], "539116": [42, 53], "539376": 43, "539459": 44, "54": [33, 42, 43, 52, 53], "540": 42, "540000": 28, "540039": 40, "540359": 36, "541117": 33, "541347": 40, "541488": 36, "54152": 32, "541667": 29, "541795": 32, "54240": 32, "542624": 35, "542873": [28, 29], "543297": 31, "543351": 35, "543464": 40, "544": 31, "544462": 35, "545": [33, 44], "546": 28, "5461": 33, "546473": 30, "546610": 27, "54676006e": 35, "547": [31, 33, 35], "547090": 40, "547993": 32, "548831": 35, "549": 44, "549682": 32, "5498": 27, "549946": 40, "55": [25, 26, 27, 30, 32, 33, 34, 35, 42, 43, 47], "55000": 31, "550000": [28, 29, 31], "550004": 34, "550616": 32, "55101": 42, "5513": 31, "5514": [34, 35], "5515": 43, "551579e": 33, "551862e": 33, "551975": 33, "552": [28, 33], "552721": 34, "553965": 35, "553979": 32, "5540": 43, "5541306485809793": 34, "55413065": 34, "554180": [42, 53], "554463": 40, "554621": 36, "5551": 30, "555740": 27, "5566": [28, 29, 49], "557197": 41, "557242": 32, "557739": 33, "558": [33, 35, 36], "558564": 32, "55862988e": 35, "55873324": 41, "5588": 24, "558824": 32, "558889": 33, "559": [31, 33, 35], "56": [27, 29, 32, 33, 42, 43, 52, 53], "560225": 28, "560768": 33, "561": [10, 27, 31, 35, 36], "561467": [28, 29], "561602": 35, "561645e": 33, "562112": 28, "5623062252998352": 40, "562712": 40, "563": 10, "5630224174651539": 30, "5630921721458435": 40, "563314": [33, 35], "563467": 28, "5644": 33, "564483": 36, "565": 36, "5650": 25, "565062": 43, "56521734": 8, "565679": 32, "565746": 43, "565888": 28, "566": 28, "566092": 28, "566222": 41, "5667": 32, "567724": 41, "567856e": 33, "568": 41, "568009": 27, "56804591": 33, "568663": 33, "5690201394302518": 35, "56902014": 35, "569375": 27, "5694": 36, "57": [27, 28, 29, 32, 33, 35, 42, 43, 49, 53], "57000": 43, "570015": 33, "570449": 32, "570473": 36, "5707": 43, "570739": 36, "571": [37, 45], "571431": 40, "571500": 36, "571901e": 33, "571969": 36, "572": 10, "572105": 27, "572549": 28, "572962": 43, "573": 45, "573050": 32, "573129": [33, 35], "5732": 32, "573542": 36, "573818": 32, "57415": [42, 53], "574260": 36, "575000": 39, "57510": 36, "5755444169044495": 40, "575907": 36, "576": 28, "57640869": 29, "576409": 29, "576921": 40, "578523": 30, "578654": 32, "5789": 33, "579091": 36, "579245": 40, "579432": 30, "579559e": 33, "579660": 34, "5798": 34, "57994": 32, "58": [25, 26, 27, 30, 33, 42, 43, 47], "580": 41, "5804311633110046": 40, "580539e": 33, "581": 35, "58137177": 29, "581372": 29, "5814": 24, "581687": 36, "581787": 43, "582": [24, 34], "582090": 32, "5824530720710754": 40, "582469": 33, "58387198": 37, "583872": 37, "584": 28, "584615": [28, 36], "585": 28, "585513": 30, "5857": 43, "586095": [28, 29], "587773": 32, "588": [27, 31], "588125": 27, "588235": 30, "588307": 28, "589286": 44, "59": [1, 27, 33, 42, 43], "590243": 40, "59049": 32, "59050": 32, "590618": 36, "59082668": 29, "590827": 29, "5915": 29, "592": 44, "592401": 24, "59243876": 34, "5925410985946655": 40, "59300": 36, "5931": 33, "593370": 33, "593508": 37, "5938": 28, "594": 28, "594595": 27, "594982": 32, "594995": 32, "5950": 28, "595427": 41, "595569e": 33, "596088e": 33, "596151": 36, "596810": 27, "596864": 33, "5970": 34, "59700": 32, "597015": 30, "59708": 32, "597326": 32, "597555": 24, "597924": [33, 35], "598": 28, "59810": 32, "598100": 30, "598149": [33, 35], "598750": 27, "599": 44, "5993570685386658": 40, "599492": 30, "599860": 27, "599894": [42, 53], "5fin": 33, "5th": [32, 34, 35, 51], "5unf": 33, "6": [8, 10, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54], "60": [8, 24, 28, 32, 33, 35, 36, 37, 39, 40, 42, 43], "600": [28, 30, 40], "60000": [42, 53], "600000": [26, 27, 31, 42, 53], "600193": 32, "60023631": 33, "600k": 33, "601": 31, "601042": 24, "601504": 30, "601712": 32, "601790": 30, "602": [28, 29, 49], "602000": 28, "602649": 27, "6028": 32, "602941": 32, "602954": 34, "6031432151794434": 40, "60319915": 45, "603684e": 31, "603970": 43, "604": 27, "6040": [27, 31], "604000": 25, "604032": 32, "60429913": 33, "604320": 30, "60455": [42, 53], "604619": 30, "604797": 30, "6048": 42, "604807": 43, "60495488": 27, "605060": 32, "6051": [28, 29, 49], "605100": 30, "605101": 30, "605102": 30, "605263": 27, "605625": 27, "605696": 30, "606": 28, "606061": 30, "6063088774681091": 40, "606557": 30, "606567": 30, "606811": 31, "606875": 27, "606902": 30, "607062": [42, 53], "608050": 30, "608125": 27, "6082": 28, "608468": 30, "608532": 41, "608565": 43, "60860": 28, "6086405515670776": 40, "609": 28, "6092": 24, "6093292236328125": 40, "609375": 27, "60943": 32, "60k": 33, "61": [27, 29, 30, 32, 33, 37, 42, 43], "61029914": 33, "610407": 32, "610931": 38, "611": 29, "611007": 41, "6111123561859131": 40, "611178": [42, 53], "612349": 29, "61234944": 29, "6124": 43, "612546": 32, "612621": 30, "612755": 27, "613507": 30, "613738": 31, "613738418384": 31, "614": 28, "61420598": 29, "614206": 29, "614567": 36, "615": 28, "6154": 36, "615730": 34, "616": 31, "616099": 31, "6168": 25, "617342": 43, "617431": 38, "6176": 32, "617647": 32, "618": 28, "618012": 31, "6186580061912537": 40, "618967": 40, "619": 44, "61912405": 35, "62": [27, 31, 32, 33, 42, 43, 53], "622255": 28, "622454": 31, "622500": 27, "6226": 36, "622612": 32, "622709": 30, "623000": 28, "62320": 42, "62352928": 34, "624049": 33, "6241": 24, "624375": 27, "624450e": 33, "624615": 33, "6250": 28, "625387": 31, "6257": 43, "626206": 33, "62657": 42, "626875": 27, "62688064": 35, "627": 43, "6273": 31, "6275": [25, 26, 47], "627722": 35, "627966": 28, "628032": 36, "628139": 32, "62873917": 35, "629792e": 33, "63": [27, 31, 32, 33, 42, 43, 44, 53], "6303": [28, 29, 49], "6306": [28, 36], "631899": 43, "632": 44, "6320": 30, "6320979595184326": 40, "6322": 36, "632353": 32, "632786": [42, 53], "63316788": 45, "63362": 33, "633933424949646": 40, "634397": 30, "634490": 29, "634686": 32, "635": 28, "635200": 36, "635239": [28, 29], "635648": 30, "636": [24, 28, 29, 43, 49], "636364": 44, "636410": 34, "636849e": 33, "637": 41, "637982": 27, "638169": 35, "6389": [28, 36], "6391518364256": 43, "6392": 36, "639754": 33, "64": [11, 27, 30, 33, 41, 42, 43], "640": [31, 41, 44], "6400": 28, "640000": [32, 44], "640266": [28, 29], "640x480": 27, "641216": 42, "641538": 43, "641873": 33, "642676": 42, "642965": 32, "643": 31, "6431": 36, "643311e": 33, "644106": 32, "64417243": 41, "64454": 32, "644770": 38, "645519": 32, "6458": [25, 26, 47], "645963": 31, "646050": 35, "6464": 43, "647796": 36, "648": [27, 28, 31], "6480": 34, "648195": 32, "648550": 41, "649658": 35, "64994": [42, 53], "65": [25, 29, 33, 43], "650": 32, "65000": 31, "650000": 31, "65000e": 27, "65013704": 37, "65125032": 45, "6513": 35, "651446": 42, "65243": 33, "652487": 36, "6526853": 33, "652828": 31, "652986": 36, "653": 28, "653205": 31, "653205232272": 31, "654": 28, "65424895": 33, "65486": 40, "656297e": 33, "656349": 27, "656827": 32, "657675": 36, "658047": 30, "658645": 30, "659056": 33, "66": [25, 26, 28, 30, 32, 33, 41, 42, 47, 53], "6601256728172302": 40, "660171": 27, "6604": [28, 29, 49], "660714": 29, "661023": 40, "66214339": 27, "66221": 42, "6622507572174072": 40, "662450": 32, "662541e": 33, "662745": 28, "662879": 34, "66368": 35, "663680": [33, 35], "6637": 43, "6638": 43, "663822": 35, "6639": 43, "6639009118080139": 40, "6641": 43, "6642": 43, "664207": 32, "6643": 43, "6644": 43, "6645": 43, "664625": 40, "664707": 30, "66473": [42, 53], "665": 28, "665307": 40, "665351e": 33, "665625": 27, "665882": 34, "666": [28, 29], "666166": [42, 53], "6666666666666666": 41, "666667": [26, 28, 39], "666754": 41, "667450": 42, "668": 40, "668787": 27, "6688": 24, "669614": 32, "669725": 32, "669805e": 33, "67": [25, 26, 29, 30, 32, 33, 42, 43], "670344": 27, "6709133982658386": 40, "67186503136": 33, "6731126308441162": 40, "673277": 31, "6733849048614502": 40, "6734487414360046": 40, "6744": 35, "674490": 31, "674721": 34, "675000": 24, "67501": 42, "67512181": 33, "67562658": 29, "675627": 29, "675676": 39, "675814": 27, "676250": 27, "676373": 32, "67672595": 33, "677": 28, "6771429181098938": 40, "6772": 43, "677268": 43, "677579": 27, "677601": 31, "677629": 27, "6778583526611328": 40, "678": [27, 31], "678689": 30, "679478": 28, "679877": [33, 35], "68": [25, 26, 27, 29, 32, 33, 35, 37, 38, 42, 43, 45, 53], "680000": 24, "6800296306610107": 40, "680657": 28, "681223": 27, "681716": 40, "683015": 34, "683171": 32, "68323": 31, "68339": [42, 53], "684211": 27, "684447": 28, "684960": [28, 29], "685103e": 33, "68523": 42, "685786": 34, "6858": 30, "686": 28, "686348e": 33, "687": 33, "687055": 32, "687307": 31, "687500": 26, "687504": 40, "688": 31, "6880359361853475": 30, "688043475151062": 40, "688135": 31, "689338": [33, 35], "69": [25, 26, 27, 29, 33, 37, 42, 43, 53], "690": 44, "69027185e": 35, "690402": 31, "690778": 35, "691241": 32, "691617": 40, "691640": 27, "691877": 31, "691924": 37, "69192445": 37, "692308": 28, "693": 28, "693498": 31, "693590": 29, "6938": [24, 42], "693890": 42, "693898": 42, "693936": 29, "69393613": 29, "69411": 36, "694155": 27, "694334": 34, "6950": 35, "695532": 28, "695783": 40, "696034e": 33, "6962": 28, "6963": 35, "696373": 28, "696429": 32, "696712": 42, "696859": 31, "696875": 27, "696970": 30, "69698010e": 35, "697": [28, 36], "697248": 32, "6973": 28, "698": 28, "698167": [42, 53], "698206": 33, "698384608345687": 31, "698385": 31, "6984": 36, "698857": 31, "699224": 27, "699706": 41, "699901396097971": 38, "6th": [32, 34, 35, 51], "6x6": 50, "7": [10, 11, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 54], "70": [25, 26, 29, 32, 33, 37, 38, 42, 43, 53], "70000": [42, 53], "700000": [42, 53], "700855": 32, "701128": [42, 53], "701173": 31, "701186e": 33, "70162085e": 35, "7017": 43, "701863": 31, "702703": 27, "703406": 43, "704": [27, 28, 33], "704099": 29, "7041": 40, "7042": 43, "7043": 43, "7046136400143138": 30, "70472": 36, "704969": 31, "705000": 28, "705470": 40, "705511": 31, "70560276": 29, "705603": 29, "70568": 33, "705696": 27, "705882": [26, 31], "70588235": 26, "705898": 36, "706": 29, "706128": 27, "706444": 32, "706783": 29, "70678332": 29, "706966": 42, "707681": 27, "707712": 43, "707899": 37, "70789903": 37, "70799": 31, "708": [28, 29, 31, 34, 49], "708075": 31, "708527": 28, "708978": 31, "709185": 27, "70978": 36, "709874": 31, "709880": 31, "709893": 42, "7099": 36, "71": [24, 25, 26, 29, 30, 32, 33, 37, 42, 43, 53], "710000": 28, "710031": 35, "710526": 27, "710896": 32, "71096": 36, "711": [29, 31], "711077": 28, "711086": 31, "711717": 31, "711754": [28, 29], "711819": 40, "711852": 36, "71199006": 33, "712": 28, "712074": 31, "71219761": 29, "712198": 29, "712324": 31, "712402": 34, "7129": 31, "713": 29, "71327467": 33, "714": 41, "714077": [28, 29], "714286": 31, "714402": 32, "715072": 41, "71517": 31, "7153": 43, "715424": 31, "715728": 32, "715992": 41, "716157": 32, "716655": 31, "716657": 31, "716792": 32, "716985": 27, "717289": 31, "717391": 31, "717829": 28, "718242": 31, "718266": 31, "718524": 42, "71866979": 33, "718750": 27, "7188": 29, "719": [24, 28, 36], "719056": 34, "719427e": 33, "719500": 27, "719747": 32, "72": [25, 26, 27, 32, 33, 42, 43, 47, 50], "720357": [42, 53], "72036": 42, "720497": 31, "720859": 28, "720893": 43, "720904": 42, "7210": 25, "721006": 31, "721008": 31, "7212512828409691": 30, "721616": 31, "721705": 28, "7218": [25, 26, 47], "721818": 36, "721921": 28, "722": 28, "722241": 31, "722249": 31, "723": 28, "72345029": 33, "723602": 31, "723613": 27, "7242": 25, "724458": 31, "724539": [42, 53], "724891": 32, "725": [30, 31], "7250894": 45, "726": [28, 32, 36], "726412": [28, 29], "726474": 41, "726573": 31, "726583": 31, "726634": 32, "7266666666666667": 45, "726788": 33, "727014": 42, "727198": 31, "727273": 27, "727554": 31, "7277854625841886": 43, "727821": 31, "7278214718381631": 31, "727829": 31, "728": [28, 32], "728235": [28, 29], "7283": 32, "728324": 32, "728777": 27, "729": 31, "729109": 44, "729143": 32, "7292": 36, "729814": 31, "73": [25, 26, 29, 30, 31, 32, 33, 38, 42, 43], "730383": 32, "731498": 43, "7315": 30, "7315558717766282": 31, "731572": 30, "731583": 27, "73183": 40, "7328": 28, "732919": 31, "733102": [28, 29], "733333": [26, 28, 29], "733746": 31, "734": [31, 33, 43], "734011": 31, "734385": 32, "734816": 42, "735": 33, "735043": 32, "735261": 31, "7352614272253524": 31, "7356575131416321": 40, "735879": 31, "736285": 32, "7363681793212891": 40, "736498": 31, "736900": 28, "7379": 25, "738": [28, 33], "738564": 42, "738701": [28, 29], "738715": 43, "738839": 30, "738977": 31, "739": 44, "739264": [28, 36], "7395977155164125": 31, "739598": 31, "739938": 31, "74": [25, 26, 28, 29, 30, 31, 32, 33, 38, 49], "740542": 24, "740844": 31, "741": 43, "741037": [42, 53], "741250": 27, "741463": 31, "7418": 35, "741935": 44, "742084": 31, "742088": 31, "742703": 31, "742981": 32, "743": [27, 28, 31, 43, 44], "743133": 27, "743135": 32, "743321": 31, "743323": 31, "743324": 31, "743391": 27, "743555": 35, "7436": [25, 26, 47], "743917": [28, 29], "7440": 24, "744201": 32, "744565": 31, "745": 34, "745178": 31, "746114": 34, "746328": 27, "747": 24, "74720920774": 33, "74798624e": 35, "748510": 32, "748725": 43, "748749e": 31, "748797": 30, "749118": 35, "75": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 42, 43, 49, 53], "750": 24, "7500": 33, "750000": 33, "7503": 25, "7504": 44, "750401": 40, "751": 44, "7524": 42, "753286": [28, 29], "754": 28, "754165": 44, "754386": 32, "754874": 36, "755": 43, "755000": 33, "7551": 31, "755364": 27, "755418": 31, "755477": 27, "756": 43, "7562": 24, "75625": [42, 53], "757": 32, "7574257425742574": 31, "75745416": 37, "757545": 33, "757591": 42, "757932": 43, "757985": [34, 35], "758": [34, 35, 43], "758062e": 33, "75826": [34, 35], "758514": 31, "7588186": 41, "7588527798652649": 40, "759561": 37, "75956122": 37, "7599": 30, "76": [26, 28, 30, 31, 32, 33, 35, 36, 43], "760": 43, "760262": 31, "760678": 42, "76161": 31, "761945e": 33, "762": [26, 43], "7620": 24, "762093e": 33, "76270194": 35, "763": 28, "7639": 25, "764052": 36, "76470588": 26, "764706": [26, 27, 31], "765": 32, "765591": 32, "765601": 33, "766317e": 33, "766423": 33, "766430": 27, "767": [33, 35], "767742": 30, "767802": 31, "767819": 42, "767852": 27, "768": [28, 29, 33, 35, 49], "768176": 43, "768512": 32, "76908228": 34, "769231": 28, "77": [25, 26, 29, 30, 32, 33, 38, 42, 43, 46, 52], "770": 25, "7706532429048965": 34, "770833": 39, "770898": 31, "771": 28, "771969": 27, "772532": 32, "773017": [33, 35], "7736": 31, "773851": 42, "774261": 42, "774844": 29, "77484447": 29, "7750553478074826": 42, "775270": 33, "7752884548630529": 30, "775311": 35, "77536150e": 35, "7758": 31, "776": 31, "7763": [28, 36], "776427": 43, "77694295": 34, "77709": 31, "777934": 27, "778": 44, "7781845435415525": 42, "779": [28, 36], "779271": 36, "78": [24, 25, 26, 28, 29, 32, 33, 36, 37, 42, 43, 46], "7800": 31, "780000": 34, "780296": 33, "780298": 33, "780316": 33, "780497": 33, "78058051e": 35, "780864": 32, "781": 28, "781004": 27, "781531": 32, "7816": 33, "782183": 33, "782219": 27, "7827": 32, "783282": 31, "783582": 27, "783784": 39, "783789": 27, "784424": 30, "784573": 36, "785": 29, "785105": 33, "785108": 33, "785134": 33, "78521263": 40, "785399": 33, "785483": [42, 53], "785714": 28, "786115": 36, "78617028": 34, "786555": 33, "787": 28, "787574": 33, "787879": [27, 30], "787933": 33, "788": 26, "788374": 41, "788647472858429": 40, "7887": 35, "7891381897690047": 30, "789436": 28, "789657": [42, 53], "79": [25, 26, 28, 29, 30, 32, 33, 42, 43, 47], "790": 32, "790000": 28, "79041": 33, "790731": 30, "791017": 43, "791467": 28, "792": 45, "792023": 35, "79250": 28, "792577": 33, "792603": 27, "792828": 33, "793": 36, "793243": 28, "79378": 32, "7938": 29, "794": 43, "794118": 27, "794236": 28, "794820": 28, "795": [27, 31], "79500e": 27, "7951": 31, "7951559890417761": 33, "795902": [42, 53], "796": 28, "7964215270662811": 30, "797": 28, "797355": [28, 29], "7978563117812038": 28, "798": 28, "7982": 27, "7986546": 33, "799983": 27, "79998417": 45, "7f688092391a": 41, "7pm": 36, "7th": [32, 34, 35, 51], "8": [9, 10, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 53], "80": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 42, 43, 46, 53], "800": [24, 26, 31, 40, 50], "800000": [31, 42, 53], "8001": 30, "800190": 27, "80062924": 27, "801219e": 33, "801666": 32, "801863": 27, "802502": 36, "802902": 33, "802987": 27, "803": [27, 28, 44], "803617": 32, "804": [27, 43, 44], "804818": [28, 29], "80482065": 29, "804821": 29, "805198": 33, "805342": 42, "805970": [27, 30], "806": 29, "8062": 25, "806899": 41, "8076": 33, "807684": 27, "807735": 32, "8078": 24, "808": 43, "8080": 25, "808208": 32, "808958": 27, "809": 28, "8098": 43, "81": [25, 26, 27, 29, 30, 31, 32, 33, 35, 37, 42, 43, 53], "810073": [33, 35], "810098": 36, "810368": 27, "81071706": 31, "810811": 39, "8112": 24, "812272": 33, "812363": 33, "812500": 26, "812593": 41, "812875": 43, "813": 28, "813586": 32, "815669": 32, "816717791411044": 43, "817": 34, "817034": 44, "817558": [28, 29], "8180": 28, "818041": 43, "818868": 28, "819152": 27, "819213": 43, "8195": 30, "819549": 27, "819584": 27, "81970188": 29, "819702": 29, "82": [25, 29, 31, 32, 38, 42, 43, 53], "820": 27, "820033": 33, "820143": 30, "82025568e": 35, "820564": 33, "821040": 35, "821327": 40, "821807": 33, "8219": 28, "8221": 29, "8225": 44, "82273995": 29, "822740": 29, "823511": 32, "823529": [26, 27, 30], "82352941": 26, "823543": 36, "824849": 32, "824884": 33, "825": 28, "825123": 36, "8253": 27, "825306": 31, "825470": 43, "825697": 33, "826142": 33, "826203": 30, "826216": 33, "826513": [42, 53], "826553": 33, "82670": [42, 53], "826739": 33, "826758": 33, "826760": 33, "827039": 30, "827068": 30, "827130": 32, "827261": 33, "827842": 30, "827907": 31, "8280229354283182": 33, "82804": 31, "828332": [33, 35], "828358": 27, "828405": 42, "828682": 31, "82869879": 40, "828891": 31, "828976": 31, "83": [25, 26, 29, 31, 32, 38, 39, 40, 42, 43, 46, 53], "830382": 32, "830712e": 33, "831135": 27, "831611": [33, 35], "831989": 31, "832": 28, "832320": 30, "832370": 32, "832866": 33, "833": [27, 31], "83320": 42, "8334": 35, "8340": 27, "834109": 31, "834356e": 33, "83437": 33, "834455": 27, "8356": 35, "835651": 31, "835749": [33, 35], "83603": [33, 35], "8361313": 33, "836189": 27, "836735": 32, "836878e": 33, "836880e": 33, "837022e": 33, "837838": 27, "837848": 27, "838": [27, 31], "83848729e": 41, "83876": 31, "8388866943476283": 30, "838951": 33, "8389756947416362": 30, "839225": 33, "84": [25, 26, 29, 42, 43, 44, 45, 46], "840": 28, "84002795": 29, "840028": 29, "840074": 26, "840183": 33, "840492": [33, 35], "84062193": 35, "841": 33, "841208": 31, "841886": 31, "841983": 31, "842": 28, "842028": 32, "842064": 43, "842105": 27, "843": 34, "843281": 35, "843284": [27, 30], "843842": [28, 29], "843992": [33, 35], "844409": 29, "84440919": 29, "844921": 37, "845": 31, "846154": [28, 44], "8462": 36, "846260e": 33, "846650": 33, "84679073": 27, "84698489": 41, "847178": 32, "847287": 31, "8475": 42, "84772": 32, "847799": 31, "847808": 32, "8478316682480326": 42, "848": [34, 35], "8481": 44, "84893192": 31, "849": [34, 35], "849102e": 33, "849438e": 33, "849612": 31, "85": [25, 26, 29, 32, 33, 34, 35, 36, 42, 43, 46, 53], "850": [24, 34, 35], "8502": 31, "850283": [42, 53], "850503": 31, "850746": 27, "851460": 33, "851852": 30, "852": [43, 44], "852053": 31, "852104": 33, "852941": 30, "853125": 27, "853399": 32, "854129": 33, "854167": 39, "854500": 43, "8546143543902771": 43, "854744525547446": 43, "854749": 42, "85545875": 27, "85597188": 29, "855972": 29, "856": 31, "856175": 28, "856589": 31, "857": 33, "857874": 31, "858": 30, "8580": [28, 29, 49], "858209": [27, 30], "858915": 31, "859": 34, "859318": 33, "859439": 37, "85943906": 37, "859455": 43, "85969": 31, "859799": 31, "86": [25, 27, 29, 30, 31, 32, 36, 42, 43], "860": [32, 35], "86000e": 27, "8601643854446082": 33, "860677": 32, "861": 28, "86102": [42, 53], "861348": 31, "862432": 33, "862552": 28, "8625888648969532": 43, "86267067": 29, "862671": 29, "862997": 36, "863014": 30, "863889": 42, "863941": 33, "864": 34, "86400": [42, 53], "8641864337292489": 43, "864205": 35, "865562": 43, "8661": 44, "866110": 30, "866667": [26, 32], "866980": 33, "867434": 41, "867558": 36, "868003": 33, "868281": 33, "868305": 33, "868308": 33, "869077": 29, "86907725": 29, "869094": 31, "8691": 29, "869531": 27, "869964": 31, "87": [25, 28, 29, 32, 42, 43], "870": [34, 35], "870503": 41, "871": [31, 34], "871094": 42, "8711": 32, "872": [34, 35], "872093": 31, "872603": 41, "872722908439952": 35, "8727229084399575": 35, "872961060": 33, "8729610607986": 33, "873": 34, "8731": [33, 35], "873103": 27, "873182": 42, "873356": 27, "873643": 31, "873704": 33, "874062": 29, "87406235": 29, "874305": 42, "874516": 31, "874532": 33, "874767e": 33, "875": 32, "8750": [28, 36], "875000": 26, "876065": 31, "876540": 43, "876574": [28, 29], "87681182": 40, "877046": 36, "877390": 35, "877519": 31, "877551": 32, "878183": 27, "87844893": 33, "87849316": 30, "879": 28, "87907": 31, "879938": 31, "88": [25, 26, 28, 29, 30, 32, 36, 43, 44, 49], "880": 36, "8801": 40, "880348": 31, "880831": [42, 53], "881395": 31, "881720": 32, "883138": 31, "884586": 31, "885": [24, 29], "885044": [33, 35], "885968": 43, "886047": 31, "886759": 30, "887": 34, "887017": 32, "887159": [42, 53], "8873": 32, "887324": 32, "887343": 27, "887597": 31, "887701": 32, "8878117": 29, "887812": 29, "888": [31, 34, 35], "888066": 35, "888372": 31, "888513": 32, "888811": 31, "888889": [28, 30], "888961": 35, "889086": 33, "889147": 31, "889429": 42, "889921": 42, "89": [25, 26, 29, 32, 38, 42, 43, 46, 53], "890": 34, "890457": 33, "890933": 43, "891001": 32, "891557": 31, "892476": 32, "892477": 27, "892491": 28, "89270": 36, "892733": 42, "892961": 36, "893000": 28, "893260": 29, "8937442459553657": 35, "894": 28, "895": 34, "895349": 31, "895541": 33, "89572": [42, 53], "895833": 32, "895963": 30, "897010": [28, 29], "89706451e": 35, "897674": 31, "898": 35, "898016": 31, "898703e": 33, "899": [28, 29, 31, 34, 49], "8994": 35, "8997": 33, "899969": [42, 53], "8m": 41, "8th": [32, 34, 35, 51], "9": [4, 10, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 53, 54], "90": [8, 24, 25, 26, 27, 29, 32, 33, 38, 39, 42, 43, 46], "900": [29, 31, 32], "90000": [42, 53], "900000": [26, 42, 53], "900662": 26, "901085": 30, "9010852321946792": 30, "901262": 42, "90159483": 37, "901595": 37, "902401": 31, "903101": 31, "904": [27, 31], "90403853": 29, "904039": 29, "904226": 27, "9047619047619048": 25, "904902": 41, "905": [27, 28], "905327": 42, "906667": 26, "90669": 36, "906865": 26, "907": 43, "907143": 44, "907595": 42, "908": 28, "908140": [28, 29], "908215": 33, "909091": 28, "90982": 36, "91": [25, 26, 28, 29, 31, 32, 36, 37, 42, 46, 53], "910": 25, "9100": 42, "910018": 33, "910174": 33, "9103": 42, "910456e": 33, "91063776": 35, "910714": 44, "910843": 33, "911615": 33, "911846": 33, "912": 28, "912395": 35, "913333": 26, "913767": 33, "913849": 33, "914003": 35, "914451894267": 33, "914585": 35, "91515735": 33, "915714e": 33, "915952": 33, "916254": 27, "916722": 35, "917526": 32, "917837": 32, "918": 34, "918124": 32, "918191": 41, "9182": 42, "919198": 35, "9196": 24, "92": [25, 26, 29, 32, 38, 41, 42, 43, 46], "920000": 26, "9203": 31, "920305": 36, "920462": 35, "92120500e": 45, "921422": 43, "921438": 33, "921850": 33, "92195464": 35, "921955": 35, "922": 29, "923077": 32, "923283": [28, 29], "923432": 35, "924485": 36, "9245": [26, 30], "925272e": 33, "925288e": 33, "925593": 27, "925768": 32, "926657": 33, "926733e": 33, "926829": 32, "928": 31, "92809": 36, "92852376": 27, "929": 31, "9295": 31, "93": [25, 26, 29, 30, 31, 37, 42, 43, 46], "930000": 28, "930123": 27, "930561": 27, "931439e": 33, "931786": 30, "932": 28, "932070": 43, "932124": 27, "932143": 44, "93279": 42, "9336": 28, "934205": 27, "934269": [28, 29], "934783": 32, "9351": 36, "935512": 43, "935802": 27, "93665": [42, 53], "9375": 26, "937500": [26, 29], "938": 32, "9383": [27, 30], "93869659": 29, "938697": 29, "939006": 32, "9391": 33, "939394": [27, 30], "94": [25, 26, 28, 29, 30, 31, 32, 33, 42, 46, 49], "9401": 42, "9406": [25, 26, 47], "941": 43, "941176": [26, 29], "94117647": 26, "943609": 36, "944": 24, "944092": 32, "944354": 29, "946783": 27, "947": [28, 31, 44], "9471": 31, "948482": 43, "94888": 32, "949": 28, "9490": 28, "9492": 33, "94933723": 33, "94959681": 29, "949597": 29, "95": [25, 26, 29, 32, 38, 42, 43], "950000": 28, "950088": 36, "9505": 35, "950564": 36, "9506": 35, "950696": 43, "950733": 27, "951294": 33, "951574": 36, "951644": 36, "951669": 36, "951696": 27, "953": 34, "95511263": 27, "955113": 27, "9558": 42, "956": 28, "956966": 36, "957075": 36, "9573": 42, "9576": 24, "957886": 41, "957919": 27, "957987": 27, "9583333333333334": 41, "958393": [28, 36], "95886206e": 41, "959": 28, "959139": 35, "959402e": 33, "959870": 32, "959873": 43, "96": [25, 29, 30, 31, 32, 36, 42], "960": 30, "961106": 32, "961109802000133": 38, "961404": [28, 29], "961498": [33, 35], "961771": 30, "961898": 30, "962776": 32, "96319": 42, "96320": 42, "96321": 42, "96322": 42, "96323": 42, "96325": 42, "963689": 36, "96554": 36, "9661": 33, "966131": [28, 29], "9664": [25, 26, 47], "966491": 32, "967102": 32, "967907": 32, "968": 28, "968233": 36, "96833": 40, "96834506": 27, "968493": 43, "968514e": 33, "96875": 41, "969048e": 33, "9691": 33, "9692602666681306": 30, "96965253": 35, "969653": 35, "97": [25, 26, 29, 30, 31, 35, 38, 42, 43], "970518": 32, "970683": 36, "971": 29, "97203586": 29, "972036": 29, "97217": 42, "972198": 31, "97223953": 29, "972240": 29, "972440": 32, "97253": 42, "9730": 29, "973225": 32, "973280": 29, "97328024": 29, "973482e": 31, "973750": 27, "974": 28, "974480": 36, "9748": 30, "974801e": 33, "975895": 42, "976": [28, 32, 34], "977": [28, 42, 53], "977278": 36, "9773": [25, 26, 27, 47], "978": 30, "9781449369880": 42, "9781789957211": 41, "97823755": 30, "9785299": 40, "978738": 36, "979": [34, 35], "979562": 43, "98": [25, 28, 29, 30, 33, 35, 37, 40, 42, 43], "980": [42, 53], "98007": 24, "98028": 25, "98045": 24, "98052": 24, "98055": 24, "980634": 43, "98072": 24, "98074": 25, "98075": 24, "9808": 30, "98107": 24, "98112": 24, "98116": 24, "981195": 42, "98125": 25, "98136": 25, "981735": 30, "98178": 25, "982": 29, "982184": 31, "982570": 43, "983": 41, "9837": [26, 30], "984": 31, "984653": 30, "984664": 33, "985283": 31, "9854": [25, 26, 30, 47], "985457": 43, "985816": 26, "986047": 31, "9862": 44, "986207": 31, "987": [31, 41], "987062": 33, "987597": 31, "9876": [34, 35], "987681": 36, "988": 36, "9881": [25, 26, 47], "988381": 31, "988841": 31, "988901": 33, "989": 25, "989147": 31, "989156": 31, "989443": 43, "989922": 31, "989973": 30, "99": [25, 26, 28, 29, 31, 32, 42, 51, 53], "990631": [42, 53], "990754": 42, "9912": [27, 30], "9915": [42, 53], "991966": 43, "992": [26, 31], "992254": 31, "99240562": 35, "992406": 31, "9926": 29, "992857": 26, "992908": 26, "993023": 31, "993029": 31, "993065": 43, "9931": [25, 26, 47], "9934531067299874": 30, "993666": 35, "993969": [33, 35], "994": 24, "994266": 31, "994574": 31, "994764": 42, "995": [36, 41], "9950": 36, "9951": [25, 26, 47], "99515": 42, "995434": 33, "996588e": 33, "996765": 35, "996788": 43, "996820": 43, "996899": 31, "99744241e": 35, "9977957422135844": 35, "998": [32, 43, 44], "9983": 32, "998302": 32, "99845": 31, "998451": 31, "999": [30, 44], "99907": 31, "999122": 32, "999147": 32, "999172": 32, "999183": 32, "999185": 32, "999192": 32, "999210": 32, "999214": 32, "999221": 32, "999223": 32, "999225": 31, "999254": 32, "999298": 32, "999317": 32, "99931882": 33, "999335": 32, "999535": 31, "999577": 42, "999622": 28, "9am": 36, "9th": [32, 34, 35, 51], "A": [0, 8, 9, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 45, 46, 53, 54], "AND": [0, 33], "AS": 0, "And": [24, 25, 31, 33, 40, 42, 43, 47, 48], "As": [4, 26, 29, 31, 33, 34, 35, 39, 42, 43, 45, 48, 50, 52, 54], "At": [4, 24, 26, 30, 32, 34, 36, 37, 41, 42], "BE": [0, 40], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 27, 35, 46, 48], "Being": 41, "But": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 48, 50, 52, 53, 54], "By": [24, 26, 27, 29, 32, 34, 37, 40, 41, 43, 48, 50, 54], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 50, 51, 52, 53, 54], "IN": [0, 26, 30], "IT": 30, "If": [4, 5, 6, 7, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54], "In": [6, 7, 8, 9, 10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54], "Ines": 44, "It": [2, 4, 7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 48, 50, 52, 54], "Its": 43, "NEAR": [28, 29, 36, 49], "NO": 0, "NOT": [0, 8, 29, 30], "No": [0, 24, 25, 33, 34, 35, 36, 38, 42, 43, 46, 53], "Not": [32, 33, 34, 35, 36, 37, 39, 42, 43, 51], "OF": 0, "OR": [0, 8, 33], "Of": [9, 29, 31], "On": [4, 7, 24, 28, 29, 31, 32, 33, 34, 35, 36, 38, 41, 43, 44], "One": [5, 8, 16, 25, 26, 29, 30, 31, 32, 35, 37, 38, 43, 46, 51, 53], "Or": [27, 29, 31, 48], "Such": [6, 39, 42], "THE": [0, 26], "TO": [0, 40], "That": [25, 26, 28, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 51], "The": [0, 1, 2, 5, 7, 8, 10, 24, 25, 27, 28, 29, 32, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54], "Their": 5, "Then": [25, 30, 34, 37, 42, 51], "There": [2, 5, 8, 9, 10, 11, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 54], "These": [4, 11, 25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 39, 42, 52, 54], "To": [8, 11, 24, 25, 26, 27, 28, 29, 30, 33, 34, 36, 38, 40, 41, 42, 44, 48, 50, 52, 53, 54], "WITH": 0, "Will": [32, 43, 44, 46, 51], "With": [0, 24, 25, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 43, 45, 48, 54], "_": [34, 40, 41, 43, 44], "__call__": 29, "__class__": [30, 42], "__finalize__": 43, "__getitem__": [26, 28], "__init__": 44, "__name__": [30, 42], "__testing_word2vec": 40, "_arg": 44, "_array_api": 44, "_astype_nansaf": 43, "_c": 44, "_california_housing_dataset": 30, "_call_func_on_transform": 29, "_callback": 44, "_column_transform": 29, "_constructor_from_mgr": 43, "_context": 44, "_data": 31, "_distn_infrastructur": 31, "_encod": 29, "_get_default_devic": 44, "_get_sequential_output": 29, "_i": 41, "_logist": 45, "_mgr": 43, "_proba": 34, "_pseudo_sync_runn": 44, "_run": 44, "_run_cel": 44, "_run_cod": 44, "_run_module_as_main": 44, "_run_onc": 44, "_score": 29, "_scorer": 29, "_set_output": 29, "_temp": 44, "_time_fit_was_cal": 43, "_transform": 29, "_transform_on": 29, "_valid": 29, "ab": [30, 32, 33, 35], "abbrevi": 40, "abil": [24, 29, 31, 35, 40, 42, 48], "abl": [8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 48, 50, 54], "about": [2, 4, 7, 10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54], "abov": [0, 5, 8, 11, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 48, 50, 53, 54], "absenc": [29, 35, 39], "absolut": [30, 32, 33, 35, 37, 44, 54], "abspath": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53], "academ": [7, 36], "accept": [5, 8, 32, 33, 40], "accept_spars": 29, "access": [10, 11, 26, 28, 31, 34, 37, 39, 40, 42, 50], "accessori": 42, "accident": [27, 28], "accommod": 7, "accompani": [7, 24, 25], "accord": [30, 32, 33, 36, 39, 43, 50, 51, 52, 54], "account": [7, 10, 26, 32, 36, 39, 43, 46, 51], "accur": [24, 26, 34, 35, 36, 39, 43, 46, 47], "accuraci": [25, 26, 27, 28, 31, 32, 34, 35, 36, 38, 41, 43, 44, 46, 47, 51, 52, 54], "accuracy_scor": 32, "acdm": [32, 34, 35, 51], "acf": 42, "achiev": [8, 27, 32, 50, 52, 53], "acinonyx": [24, 41], "acoust": [27, 28, 31, 50], "acquir": 54, "acquisit": 39, "across": [24, 25, 26, 28, 32, 35, 41, 54], "act": [30, 54], "action": [0, 24, 34, 35, 37, 39, 40, 43, 54], "activ": [4, 11, 24, 31, 44, 46, 54], "actor": [39, 40], "actual": [7, 24, 30, 32, 34, 35, 37, 39, 40, 42, 43, 50, 52], "ad": [29, 30, 31, 32, 34, 35, 36, 38, 40, 41, 43, 44, 50, 53], "adapt": [0, 28, 29, 32, 34, 40, 42, 44], "add": [7, 8, 11, 28, 29, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 49, 51, 52, 53], "add_pip": 44, "addit": [0, 4, 33, 39, 51, 54], "addition": [47, 48, 54], "address": [18, 38, 51], "adelaid": [42, 53], "adj": [40, 44], "adject": 40, "adjust": [27, 31, 38, 42, 48], "adm": [32, 34, 35], "admin": 54, "administr": 1, "admit": 26, "adopt": [6, 39], "adp": [40, 44], "adult": [32, 34, 35, 51], "adult_df_larg": [34, 35], "adv": 40, "advanc": [29, 31, 37, 38, 39, 40, 41, 47, 54], "advantag": [28, 29, 30, 34, 38, 39, 40, 46, 54], "advic": 43, "advis": 24, "advisor": 54, "af": 35, "affect": [11, 27, 28, 30, 31, 32, 37, 42, 43, 44, 48], "affix": 40, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 46, 52, 53, 54], "ag": [24, 30, 32, 33, 34, 35, 36, 39, 51, 52], "again": [11, 25, 26, 28, 38, 39, 40, 41, 43, 48, 51, 52, 53], "against": [39, 40, 42, 50], "agenc": [40, 44], "agent": 10, "agglomerativeclust": 38, "aggress": 40, "agnost": 35, "ago": [41, 42], "agre": 48, "agreement": [43, 54], "ahead": 51, "ai": [7, 9, 32, 36, 40, 41, 51], "aight": 24, "aim": 46, "ain": 40, "airport": 32, "aka": [30, 43], "al": [34, 40], "alamine_aminotransferas": 24, "alan": 10, "alaska": 30, "alberta": 40, "album": 31, "albumin": 24, "albumin_and_globulin_ratio": 24, "alburi": [42, 53], "alexnet": 41, "algebra": [39, 40], "algorithm": [2, 15, 24, 26, 28, 29, 32, 33, 34, 35, 38, 40, 41, 47, 48, 49, 51, 54], "align": [8, 24, 25, 26], "align_kei": 43, "alkaline_phosphotas": 24, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 26, 27, 29, 31, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54], "all_cap": 44, "all_featur": [42, 53], "allei": [33, 35], "allen": 44, "alley_grvl": 33, "alley_miss": 33, "alley_pav": 33, "alloc": [8, 40, 41], "allow": [5, 7, 11, 26, 28, 31, 32, 36, 40, 42, 43, 47, 48, 50, 53, 54], "allpub": [33, 35], "almost": [30, 31, 33, 36, 38, 39, 40, 51], "along": [7, 25, 29, 32, 41, 42, 47], "alpha": [27, 28, 42, 48, 53], "alpha_": 33, "alphabet": 30, "alphago": [24, 37], "alq": [33, 35], "alreadi": [4, 8, 11, 32, 33, 35, 37, 40, 42, 43, 44, 47, 50, 53, 54], "also": [2, 4, 5, 7, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "altar": 41, "altern": [8, 31, 37, 50, 54], "although": [26, 34, 37, 39, 43], "alwai": [24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 44, 46, 47, 48, 50, 54], "am": [28, 37, 40, 44], "amatriain": 39, "amazon": [24, 37, 39, 44], "ambigu": 40, "amer": 32, "america": [29, 40], "american": 37, "aml": 28, "among": [24, 25, 31, 32, 34, 35, 39, 52], "amongst": 44, "amount": [4, 24, 26, 30, 31, 32, 33, 35, 37, 41, 42, 43, 50, 53], "amp": [34, 35], "amplifi": [32, 40, 51], "amuel": 28, "an": [0, 2, 4, 6, 7, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 49, 50, 52, 53, 54], "anaconda": [11, 35, 44], "analogi": [15, 38, 40], "analysi": [2, 9, 10, 25, 32, 33, 37, 38, 40, 51, 54], "analyt": 42, "analyz": [32, 36, 42, 43, 53, 54], "anatinu": 41, "anca": 54, "ancestor": 36, "ancestr": 54, "ancuta": 54, "andrea": [9, 10], "andrew": [9, 10, 31, 36], "anemon": 41, "angel": [43, 44], "ani": [0, 11, 25, 26, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54], "anim": [32, 41], "animal_fac": 41, "anneal": 36, "annot": [35, 37], "announc": 7, "annoyingli": 33, "annual": 44, "anomali": [32, 33, 37], "anonym": 42, "anoth": [8, 11, 25, 27, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 43, 46, 47, 49, 52, 53], "answer": [4, 6, 7, 24, 25, 26, 31, 34, 37, 39, 40, 42, 45, 47, 48, 51, 52, 53, 54], "anteat": 41, "anti": 43, "anymor": [33, 37, 39, 48], "anyth": [0, 26, 29, 32, 39, 40, 43, 50], "anytim": 54, "anywher": 29, "ap": [46, 54], "ap_lr": 32, "ap_svc": 32, "apart": [27, 38], "apeendixa": 36, "api": [32, 40, 42, 46], "app": [25, 44, 46], "appeal": 40, "appear": [2, 7, 29, 34, 48, 52, 54], "append": [4, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48, 49, 50, 51, 52], "appendix_b": 40, "appendixb": 41, "appl": 40, "appli": [0, 2, 6, 9, 10, 24, 25, 26, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 54], "applic": [0, 5, 24, 29, 31, 32, 33, 35, 36, 40, 43, 44, 46, 51, 54], "appreci": [37, 54], "approach": [10, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 48, 53, 54], "appropri": [0, 4, 11, 25, 26, 29, 32, 33, 37, 38, 42, 43, 46, 54], "approv": [32, 51, 54], "approx": [27, 35], "approxim": [25, 31, 36], "april": 42, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 31, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "arang": [8, 26, 27, 30, 31, 32, 33, 48, 50], "arbitrari": [35, 37, 38, 42], "architectur": 41, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "area": [31, 33, 34, 36, 37, 50], "aren": [7, 33, 36, 37, 40, 41, 42, 44, 53], "arena": 36, "arg": [26, 29, 44], "argh": 43, "argmin": [26, 27, 32, 37], "argsort": [35, 40], "argu": [37, 40, 50], "argument": [8, 25, 29, 31, 32, 33, 35, 44, 46, 49], "arima": 42, "arima_model": 42, "aris": [0, 24, 40], "aristotl": 27, "arithmet": 8, "around": [7, 27, 29, 32, 33, 42, 43, 47], "aroundn": 24, "arr": 43, "arr1": 8, "arr2": 8, "arrai": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50], "array_equ": 8, "arriv": 36, "arthur": 24, "articl": [10, 25, 26, 28, 32, 37, 39, 40, 41], "articul": 46, "artifici": [10, 40], "artist": [27, 28, 31, 50], "as_fram": [27, 48], "ascend": [8, 29, 30, 31, 33, 34, 35, 36, 42, 43, 46, 52], "ased": 38, "asi": 44, "asia": 29, "asid": [4, 26, 34, 48], "ask": [3, 7, 11, 24, 25, 26, 27, 29, 32, 36, 37, 39, 40, 43, 44, 47, 54], "asleep": 30, "aspartate_aminotransferas": 24, "aspect": [30, 35, 36, 38, 39, 43, 46], "assault": 54, "assert": [7, 29, 32, 34, 35, 51], "assess": [6, 10, 24, 25, 26, 28, 32, 35, 37, 54], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 49, 51, 53], "assist": 24, "assoc": [32, 34, 35, 51], "associ": [0, 24, 26, 27, 32, 33, 35, 36, 37, 40, 41, 42, 43, 46, 52, 54], "assum": [24, 25, 29, 30, 32, 33, 38, 39, 40, 42, 46, 51], "assumpt": 43, "asterisk": 31, "astyp": [8, 42, 43, 53], "astype_arrai": 43, "astype_array_saf": 43, "async_": 44, "async_help": 44, "asyncio": 44, "asyncio_loop": 44, "atabak": 54, "atratu": 41, "attack": 25, "attempt": [26, 50, 51], "attend": 54, "attent": [6, 40], "attic": 33, "attract": 40, "attribut": [0, 1, 24, 25, 27, 28, 30, 31, 36, 37, 40, 41, 50, 52], "attrit": 43, "auc": [43, 46, 51, 54], "audienc": [51, 54], "audio": [41, 54], "audit": 54, "auditor": 54, "augment": 32, "august": 42, "austin": 40, "australia": [42, 53], "authent": 37, "author": [0, 40, 54], "auto": [24, 31, 32, 36, 37], "autocorrel": 42, "autom": [25, 33, 40], "automat": [28, 29, 33, 36, 40, 42, 43, 53], "autoregress": 30, "autumn": 42, "autumn_month": 42, "aux": [40, 44], "av": [33, 35, 40], "avail": [0, 1, 7, 9, 10, 11, 26, 29, 31, 32, 33, 38, 39, 40, 41, 42, 43, 46, 51, 52, 53, 54], "avebedrm": 30, "aveoccup": 30, "averag": [26, 27, 29, 30, 31, 33, 35, 37, 38, 40, 43, 44, 46, 48, 54], "average_precis": 32, "average_precision_scor": 32, "average_word_length": 44, "averaging_model": [34, 52], "averaging_model_ndt": 34, "averoom": 30, "avg": [32, 39, 42], "avg_sent_emb": 40, "avoid": [7, 8, 25, 28, 32, 33, 38, 42, 43, 45, 46, 48, 51, 54], "awai": [4, 6, 25, 30, 37, 39, 41, 43, 46], "await": 44, "awar": [29, 43, 54], "award": 54, "awesom": 9, "ax": [26, 27, 30, 32, 37, 38, 41, 43, 48, 51], "axi": [7, 8, 24, 25, 26, 28, 29, 30, 35, 37, 38, 40, 41, 42, 53], "axvlin": 37, "az": 44, "b": [8, 10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43], "b3": [28, 35], "babe": 24, "babi": [36, 40], "bachelor": [32, 34, 35, 51], "back": [8, 28, 31, 40, 46], "backdrop": 42, "background": [25, 54], "bad": [8, 25, 26, 27, 29, 32, 33, 34, 35, 36, 37, 41, 42], "badgeryscreek": 42, "bag": [36, 40, 41, 46, 50], "bai": [28, 29, 36], "baidu": 26, "bal_scor": 32, "balanc": [6, 27, 34, 37, 39, 45, 51, 52], "ballarat": [42, 53], "balust": 41, "balustrad": 41, "bambi": 39, "banist": 41, "bank": [32, 35, 42, 43, 51], "bannist": 41, "bar": [32, 33, 35, 41, 42, 43, 53], "baranski": 44, "barbu": 54, "barri": 30, "base": [5, 8, 11, 15, 25, 26, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 43, 44, 46, 47, 50, 51, 52, 54], "base_ev": 44, "base_scor": 34, "base_valu": 35, "baseblockmanag": 43, "baselin": [14, 43, 46, 47, 49, 50, 53], "baseline_hazard_": 43, "bash": 5, "basi": [25, 27], "basic": [2, 8, 25, 31, 36, 39, 41, 43, 44, 52, 53], "batch": [40, 41], "batch_siz": 41, "batch_t": 41, "bath": 24, "bathroom": [24, 25, 30], "bayesian": 31, "bayesopt": 31, "beagl": [24, 41], "bear": 41, "beat": [34, 43], "beauti": [39, 40], "becam": 41, "becaus": [7, 8, 10, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 51, 53, 54], "becom": [4, 26, 27, 30, 31, 32, 35, 36, 37, 40], "bed": 32, "bedroom": [24, 25, 30], "bedroomabvgr": [33, 35], "bedrooms_per_household": [28, 29, 49], "beef": 40, "been": [4, 6, 10, 24, 25, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 54], "befor": [4, 10, 11, 24, 25, 26, 27, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 43, 47, 48, 50, 51, 52, 53], "begin": [25, 30, 36, 39, 42, 43, 46], "beginn": 41, "behav": [31, 35], "behavior": [26, 28, 32, 39], "behaviour": [29, 51, 52], "behind": [24, 30, 54], "being": [4, 24, 26, 28, 32, 33, 34, 35, 38, 40, 43, 48, 54], "believ": [31, 35, 42], "bell": 41, "belong": [25, 30, 38, 47], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54], "bench": 41, "benchmark": 41, "bendigo": [42, 53], "benefici": 29, "benefit": [4, 27, 34, 38, 40, 46], "bengio": 31, "ber": 40, "bergstra": 31, "berri": 40, "bertop": 40, "best": [2, 25, 26, 27, 31, 32, 33, 34, 35, 37, 38, 39, 43, 47, 48, 50, 52], "best_alpha": 33, "best_depth": 26, "best_estimator_": [31, 33], "best_n_neighbour": 27, "best_param": 31, "best_paramet": 31, "best_params_": [31, 33, 50], "best_scor": 31, "best_score_": [31, 33, 50], "bestalpha_coeff": 33, "better": [6, 24, 25, 27, 28, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 54], "between": [2, 8, 11, 24, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 54], "bewar": 40, "beyond": [26, 31, 36], "bia": [30, 32, 35, 43, 46, 51], "bias": [32, 35, 40, 43, 51, 54], "bicycl": [25, 42], "big": [7, 27, 29, 31, 32, 34, 36, 37, 38, 39, 40, 41, 43, 48], "bigalpha_coeff": 33, "bigger": [27, 29, 30, 33, 35, 38, 40, 41, 42], "biggest": [33, 36, 53], "bike": 42, "bill": 41, "billboard": 42, "billie_holidai": 40, "billion": 33, "billionth": 42, "bin": [28, 31, 33, 36, 42, 43, 44, 47], "binar": [25, 29], "binari": [25, 28, 29, 30, 41, 43, 45, 46, 51], "binary_feat": 29, "binary_featur": [32, 34, 35, 51, 52], "binary_transform": [32, 34, 35, 51, 52], "bincount": [32, 34, 51], "bind": [27, 48], "binomi": 31, "biolog": 36, "biologi": 29, "bit": [11, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 41, 42, 43, 50, 51, 53], "black": [27, 35, 37, 41, 42, 53], "blackhawk": 40, "bld": 44, "bldgtype": [33, 35], "bldgtype_1fam": 33, "bldgtype_2fmcon": 33, "bldgtype_duplex": 33, "bldgtype_twnh": 33, "bldgtype_twnhs": 33, "blei": 40, "blend": 40, "blindli": [32, 33], "blob": 45, "block": [30, 43], "blog": [40, 42], "bloomberg": [9, 10], "blq": [33, 35], "blue": [25, 27, 31, 32, 35, 36, 37, 42], "bluesman": 40, "bmatrix": [36, 39], "board": 4, "boathous": 41, "bob_dylan": 40, "bodi": 44, "boggl": 34, "bond": 32, "bonu": 34, "book": [1, 9, 32, 33, 39, 40, 42, 54], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "bool": [33, 42], "boom": 44, "boost": [19, 20, 40, 46], "booster": 34, "bootstrap": 11, "border": [25, 30, 38, 40, 45, 47], "bore": 30, "boston": 30, "both": [2, 6, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 49, 50, 51, 54], "bother": 35, "bottom": 38, "bought": 39, "bound": [36, 43], "boundari": [26, 38, 40, 48], "bow_df": 29, "box": [9, 35, 46], "boxplot": 35, "boyc": 25, "br": 40, "bracket": 8, "brain": [36, 41], "branch": [25, 38, 40, 43], "break": [32, 46, 48], "breakwat": 41, "breath": 46, "breathtak": 40, "breed": 46, "breiman": 34, "brief": [4, 30, 34], "briefli": [24, 32, 34, 36], "bring": [6, 35, 38, 44, 46], "british": [1, 40], "british_columbia": 40, "broad": [27, 40, 48], "broadcast": 40, "broader": [2, 34, 40], "broadest": 40, "broadli": [25, 27, 30, 32, 34, 37, 38, 40], "brownle": 36, "browser": 11, "brush": 41, "bsmtcond": [33, 35], "bsmtexposur": [33, 35], "bsmtfinsf1": [33, 35], "bsmtfinsf2": [33, 35], "bsmtfintype1": [33, 35], "bsmtfintype2": [33, 35], "bsmtfullbath": [33, 35], "bsmthalfbath": [33, 35], "bsmtqual": [33, 35], "bsmtunfsf": [33, 35], "btw": 35, "bubbl": [39, 41], "bucket": [36, 44], "budget": [31, 39], "bug": [4, 8], "bui": 39, "build": [0, 2, 11, 26, 28, 29, 34, 36, 37, 40, 42, 45, 48, 53, 54], "built": [8, 24, 25, 26, 30, 31, 35, 42, 53], "bullshit": [10, 43], "bulwark": 41, "bunch": [8, 11, 25, 33, 34, 41, 43, 48], "bundl": [7, 11], "bureau": 30, "busi": [32, 37, 43, 44], "businesswoman": 40, "bustl": 42, "butterfli": 38, "buzz": 24, "bypass": 54, "c": [0, 5, 8, 9, 10, 11, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 48, 50, 54], "c1": 38, "c2": 38, "c_1": 37, "c_2": 37, "c_3": 37, "c_log": [27, 48], "c_widget": [27, 48], "ca": [5, 9, 44, 54], "ca_transform": 29, "cal_hous": 30, "calcul": [7, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 48, 51, 53], "calgary_flam": 40, "california": [28, 36], "california_h": 36, "californian": 28, "call": [8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 52, 53], "callback": 34, "calm": 46, "came": 42, "camera": 29, "campu": [36, 54], "can": [4, 6, 7, 10, 11, 24, 25, 27, 29, 30, 31, 32, 33, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "canada": [5, 26, 27, 29, 30, 40, 44, 46], "canada_usa_c": [25, 26, 27, 30, 47], "canadian": 40, "canadien": 40, "canberra": [42, 53], "cancel": 54, "cancer": [24, 36], "candid": [31, 34, 40, 48], "cannot": [0, 8, 26, 27, 31, 32, 34, 35, 36, 38, 42, 43, 44, 54], "canuck": 40, "canva": [1, 7, 10], "capabl": 9, "capit": [32, 34, 35, 51], "caption": [7, 41], "captiv": 40, "captur": [26, 28, 30, 34, 36, 38, 39, 40, 42, 43, 46, 54], "car": [24, 40, 41], "card": [24, 25, 32, 43, 51], "care": [5, 7, 26, 28, 31, 32, 33, 35, 36, 37, 42, 43, 46, 50, 52, 53], "carefulli": [1, 32, 33, 51, 54], "carpentri": 5, "carri": [25, 26, 27, 29, 31, 32, 33, 34, 37, 39, 40, 42, 44, 48, 50, 53], "caruana": 35, "case": [6, 11, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 45, 46, 53, 54], "cash": 24, "cast": [31, 39, 44], "castl": 41, "cat": [24, 32, 34, 40, 41, 44, 46], "catamount": [24, 41], "catboost": [35, 46, 54], "catboostclassifi": 34, "catboostregressor": 34, "catch": [32, 54], "categor": [25, 31, 32, 33, 34, 36, 37, 39, 40, 43, 46, 48, 49, 51, 53], "categori": [27, 28, 32, 33, 34, 35, 36, 37, 41, 46, 51], "categorical_feat": [29, 31, 46, 50], "categorical_featur": [29, 32, 33, 34, 35, 42, 43, 51, 52, 53], "categorical_transform": [29, 32, 33, 34, 35, 42, 51, 52, 53], "categories_": [28, 29], "cater": 37, "caus": [32, 35, 36, 39, 43, 50], "causal": [35, 36], "caution": 42, "cbar": 30, "cbtf": [10, 54], "cc": [0, 1], "cc_df": [32, 51], "cconj": 40, "cell": [7, 8, 24, 28, 29, 31, 32, 33, 34, 35, 36, 39, 41, 43, 44, 47, 48, 50, 52], "cell_nam": 44, "censor": [10, 46, 54], "censu": [30, 32, 34, 35, 51], "census_df": [32, 51], "cent": 33, "center": [27, 37, 38, 41, 45], "centercrop": 41, "centers_idx": 37, "central": 5, "centralair": [33, 35], "centralair_i": 33, "centralair_n": 33, "centric": 54, "centroid": [37, 38], "centroids_idx": 37, "centroids_idx_init": 37, "centuri": 40, "certain": [11, 27, 30, 31, 32, 35, 36, 37, 40, 43, 51], "certainli": 47, "certainti": 32, "cezannec": 41, "chaat": 40, "chage": 50, "chain": 29, "challeng": [6, 26, 36, 37, 39, 41, 42, 46, 52, 54], "chanc": [25, 26, 31, 32, 33, 36, 37, 43, 51], "chang": [0, 5, 7, 8, 11, 25, 26, 27, 28, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 47, 48, 50, 51, 52, 53, 54], "channel": [1, 11, 41], "chapter": 10, "charact": [29, 32, 40], "characterist": [25, 26, 30, 50], "charg": [0, 24, 43], "charl": 30, "charm": 40, "chart": [35, 42, 43, 53], "chat": 54, "chatgpt": 40, "che210d": 9, "cheaper": 36, "cheat": 9, "check": [4, 7, 10, 11, 24, 25, 26, 28, 30, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 48, 51, 52, 53], "check_assumpt": 43, "check_invers": 29, "checklist": 46, "checkmark": 39, "checkout": 31, "cheetah": [24, 41], "chest": 26, "chestpaintyp": 52, "chetah": [24, 41], "chi": 43, "chicago": 44, "chicken": 37, "child": [32, 35], "children": 39, "chines": 40, "chn": 8, "choic": [2, 31, 33, 34, 35, 37, 38, 39, 42, 44, 48, 49, 50], "cholesterol": 52, "choos": [24, 31, 32, 34, 38, 46, 48], "chop": [31, 40], "choreograph": 44, "chosen": [26, 31, 32, 43, 46, 52], "chrbv": 43, "christin": 44, "christma": 44, "chunki": 37, "churn": 46, "ciml": 10, "cinematographi": 40, "cinereu": 41, "circl": [27, 32], "circumst": 7, "citat": 7, "cite": 43, "citi": [25, 26, 27, 40, 42, 46, 47], "citibik": 42, "cities_df": [27, 30], "citizen": 43, "cityscap": 42, "civ": [32, 34, 35], "clai": 35, "claim": [0, 31, 32], "clarif": 37, "clarifi": 46, "clariti": 54, "class": [4, 5, 11, 24, 25, 26, 27, 28, 29, 30, 36, 37, 40, 42, 43, 47, 48, 51, 52, 53], "class_attend": [25, 26, 46], "class_attendance_enc": 29, "class_attendance_level": 29, "class_label": 32, "class_labels_fil": 24, "class_nam": [25, 27, 34, 41], "class_sep": 32, "class_weight": [34, 51], "classes_": [30, 32, 34, 35, 41, 45], "classic": [27, 41, 45], "classif": [2, 10, 26, 27, 28, 29, 30, 33, 34, 35, 36, 39, 40, 42, 43, 45, 47, 48, 50, 51, 52, 54], "classifi": [26, 27, 28, 29, 31, 32, 35, 41, 45, 47, 49, 51, 52], "classification_df": [25, 26], "classification_report": [32, 41, 51], "classifiers_ndt": 34, "classify_imag": [24, 41], "classmat": [6, 48, 49, 50, 51, 52, 53, 54], "classroom": 10, "clean": [2, 24, 38, 53, 54], "clean_text": 40, "cleaned_hm": 32, "cleaner": [32, 35], "clear": [7, 32, 37, 48, 54], "clearli": [4, 6, 7, 31, 34, 35, 42], "cleric": [32, 34, 35], "clf": [24, 25, 27, 30, 41], "click": [5, 7, 10, 32, 39], "client": 39, "clinic": 25, "clip": 24, "clone": [5, 7, 11], "close": [2, 26, 27, 30, 31, 32, 37, 38, 40, 42, 44, 45, 48, 54], "close_default_lr": 32, "close_zero_svm": 32, "closer": [27, 28, 30, 39, 47, 50, 54], "closest": [27, 28, 32, 37, 38, 40, 42], "cloth": 42, "cloud": [24, 25, 29, 30, 31, 33, 34, 44], "cloud3pm": [42, 53], "cloud9am": [42, 53], "clust_label": 37, "cluster": [2, 10, 39, 40, 42, 54], "cluster_cent": 37, "cluster_centers_": 37, "cluster_std": [38, 41], "clutter": 25, "cm": [27, 30, 32, 35, 39, 48, 51], "cmap": [28, 31, 32, 35, 41, 50], "cmn": 33, "cmp": 43, "cnn": [41, 42], "co": [29, 40], "coast": 41, "code": [4, 7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53], "code_ast": 44, "code_obj": 44, "codecademi": 9, "coef": [42, 43, 44, 53], "coef_": [30, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 52], "coef_df": [30, 35], "coef_nonzero": 42, "coeff": 30, "coeff_df": 42, "coeffici": [33, 34, 36, 39, 41, 42, 43, 44, 45, 46, 52, 53], "coefs_df": 36, "coher": 37, "col": [25, 29, 30, 39, 42, 46], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 28, "colinear": 35, "collabor": [5, 39, 54], "collaps": 35, "colleagu": [8, 9], "collect": [24, 25, 28, 29, 32, 34, 35, 36, 39, 40, 41, 42, 43, 46, 52, 54], "colleg": [32, 34, 35, 51], "collinear": 36, "color": [19, 23, 30, 35, 36, 37, 38, 42], "color_continuous_scal": 36, "color_threshold": 38, "colorbar": [28, 30], "colour": [29, 30, 31, 35, 37, 38, 41], "colsample_bylevel": 34, "colsample_bynod": 34, "colsample_bytre": 34, "columbia": [1, 9, 40], "column": [7, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "column_nam": 29, "column_stack": 36, "columntranform": 49, "columntransform": [10, 16, 17, 28, 31, 32, 33, 34, 35, 36, 42, 43, 44, 50, 51, 52, 53], "columntransformer__countvectorizer__max_featur": [31, 50], "columntransformercolumntransform": [29, 31, 33, 34, 36, 44], "columntransformerifittedcolumntransform": [29, 33], "columntransformerinot": [29, 34], "com": [0, 5, 8, 9, 11, 24, 25, 29, 30, 32, 33, 34, 41, 42, 43, 44, 51], "comat": 40, "combin": [25, 28, 29, 31, 32, 36, 39, 41, 42, 43, 47, 48, 50, 52], "come": [11, 24, 25, 28, 29, 32, 36, 39, 40, 41, 42, 43, 47], "comedi": 39, "comfort": 5, "command": [4, 11, 32, 40], "comment": [8, 9, 53], "commerci": 0, "commit": [7, 32, 54], "common": [1, 8, 25, 26, 27, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 48, 54], "commonli": [25, 28, 31, 32, 37, 43], "commonwealth": 40, "commun": [2, 10, 11, 29, 31, 33, 54], "commut": 8, "comp_dict": 32, "compact": [31, 36], "compani": [32, 37, 39, 40, 43, 44, 51], "compar": [8, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 46, 50, 51, 52, 53, 54], "comparison": [38, 41, 43, 46], "compassion": 54, "compat": [8, 35, 44], "compatibitl": 8, "compel": 42, "compet": 44, "competit": [34, 41, 45], "compil": 44, "complain": [6, 44], "complaint": [6, 54], "complement": 40, "complet": [1, 6, 7, 24, 28, 31, 34, 35, 36, 38, 40, 43, 47, 48, 51, 52, 54], "complex": [25, 27, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 48, 54], "compli": 0, "complic": [4, 25, 26, 31, 33, 36], "compon": [29, 32, 39, 42, 54], "components_": 40, "compos": [27, 29, 31, 32, 33, 34, 35, 36, 41, 42, 43, 44, 49, 50, 51, 52, 53], "composit": 29, "compound": [40, 41, 43, 44], "comprehend": 40, "comprehens": [37, 46, 54], "compress": [29, 37, 40], "compris": [24, 25, 37], "comput": [7, 9, 10, 11, 24, 29, 31, 32, 34, 35, 36, 37, 38, 40, 42, 45, 51, 52, 54], "computation": 36, "compute_class_weight": 32, "computer_programm": 40, "coms4995": 28, "con": [37, 40, 41], "concat": [24, 27, 28, 29, 30, 35], "concaten": [29, 40], "concav": 36, "concensu": 26, "concentr": [31, 46], "concept": [10, 25, 26, 35, 36, 37, 42, 46, 48, 54], "conceptnet": 40, "conceptu": 34, "concern": [4, 29, 34, 54], "concess": 7, "concis": 25, "concord": 43, "concordance_index": 43, "concordance_index_": 43, "concret": 24, "conda": [24, 32, 33, 34, 35, 37, 40, 43, 44], "condit": [0, 24, 25, 29, 36, 40, 43, 54], "condition1": [33, 35], "condition1_arteri": 33, "condition1_feedr": 33, "condition1_norm": 33, "condition1_posa": 33, "condition1_posn": 33, "condition1_rra": 33, "condition1_rran": 33, "condition1_rrn": 33, "condition1_rrnn": 33, "condition2": [33, 35], "condition2_arteri": 33, "condition2_feedr": 33, "condition2_norm": 33, "condition2_posa": 33, "condition2_posn": [33, 35], "condition2_rra": 33, "condition2_rran": 33, "condition2_rrnn": 33, "conditional_aft": 43, "confer": 40, "confid": [24, 26, 35, 43, 46, 48, 51, 52], "confidenti": 32, "config": [11, 44], "configur": [31, 33, 34], "confirm": 11, "conflict": [11, 38, 54], "confound": 36, "confus": [8, 18, 27, 29, 33, 37, 48, 51], "confusion_matrix": [32, 41, 43], "confusionmatrixdisplai": [32, 51], "congrat": 29, "conjunct": 36, "connect": [0, 25, 38, 39], "connot": 40, "conort": 36, "consciou": 54, "consecut": 42, "consequ": [7, 24, 29, 32, 39, 51], "consid": [4, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 46, 48, 54], "consider": [2, 32, 34, 37, 39, 43, 54], "consist": [6, 7, 25, 26, 28, 37], "const": 40, "constant": [25, 32, 33, 34, 35, 42, 43, 51, 53], "constitu": 34, "constitut": [40, 54], "construct": 39, "constructor": [25, 28], "consult": [27, 48, 54], "consum": [24, 36, 37, 39, 46], "consumpt": 42, "contact": [24, 54], "contain": [8, 11, 19, 23, 24, 25, 28, 29, 30, 33, 39, 40, 41, 44, 45, 54], "content": [1, 4, 11, 37, 40, 41, 46, 54], "contest": 6, "context": [25, 28, 30, 31, 32, 34, 35, 36, 38, 39, 41, 42, 46, 48, 54], "contextu": 54, "contin": 29, "conting": 38, "continu": [15, 29, 31, 33, 34, 36, 40, 42, 53], "contract": [0, 43], "contract_month": 43, "contract_on": 43, "contract_two": 43, "contrast": [46, 54], "contribut": [27, 30, 35, 41, 52, 54], "control": [5, 8, 25, 26, 27, 29, 30, 33, 34, 41, 54], "convei": 54, "conveni": [8, 31, 32, 37, 40, 42, 43], "converg": 37, "convers": [32, 33, 35, 40, 50], "convert": [24, 28, 29, 30, 34, 35, 36, 40, 42, 43, 53], "convinc": 29, "convolut": [36, 41], "convolutional_neural_network": 41, "cooccurrencematrix": 40, "cook": 37, "cool": 41, "coolwarm": 30, "coordin": 54, "copi": [0, 7, 8, 11, 25, 31, 34, 35, 37, 39, 41, 42, 43, 52, 53, 54], "copy_arrai": 44, "copyright": 0, "cor": 35, "coral": 41, "core": [9, 26, 28, 29, 31, 32, 33, 36, 38, 39, 42, 43, 44, 46, 53, 54], "corefer": 40, "corgi": [24, 41], "coro": 44, "corona_nlp_test": 44, "coronapocalyps": 44, "coronaviru": 44, "corpor": [5, 44], "corpora": [29, 40], "corpu": [29, 32, 40], "corr": 35, "corr_df": 35, "correct": [7, 24, 25, 26, 27, 32, 34, 35, 43, 47, 48, 52], "correctli": [10, 11, 25, 26, 32], "correl": [42, 46], "correspond": [10, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 37, 39, 42, 48, 50], "cosin": 40, "cosine_similar": 40, "cost": [8, 24, 41, 54], "cost_rep": 8, "costco": 40, "costli": 32, "cot": 41, "cote": 41, "could": [6, 8, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 39, 40, 42, 43, 48, 50, 51, 53, 54], "couldn": 40, "count": [8, 25, 28, 29, 32, 33, 36, 40, 41, 42, 43, 44, 45, 48, 50, 51, 53, 54], "counter": 32, "counti": 48, "countri": [26, 27, 29, 30, 32, 34, 35, 40, 51, 54], "country_columbia": 35, "country_dominican": 35, "country_guatemala": 35, "country_hondura": 35, "country_hong": 35, "country_hungari": 35, "country_india": 35, "country_iran": 35, "country_miss": [34, 35], "country_puerto": 35, "country_scotland": 35, "country_south": 35, "country_taiwan": 35, "country_thailand": 35, "country_trinadad": [34, 35], "country_unit": [34, 35], "country_vietnam": [34, 35], "country_yugoslavia": [34, 35], "countvector": [24, 30, 31, 32, 40, 44, 46, 50], "countvectorizercountvector": [29, 31, 44], "countvectorizeroriginaltweet": 44, "countvectorizersong_titl": 31, "coupl": [4, 25, 31, 38, 44, 53], "cour": 40, "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50], "coursera": [9, 10], "coursework": 54, "court": 40, "covari": [25, 43], "cover": [8, 32, 34, 37, 41, 42, 54], "coverag": 32, "covid": 44, "covid2019": 44, "cox": 54, "coxph_fitt": 43, "coxphfitt": 43, "cph": [43, 46], "cph_param": 43, "cpp": 44, "cpsc": [9, 10, 11, 24, 25, 34, 36, 40, 41, 42, 44, 54], "cpsc330": [0, 11, 24, 25, 26, 29, 31, 35, 40, 41, 43, 44, 54], "cpsc330env": 11, "cpu": [31, 41, 44], "craft": [27, 32, 34, 35, 37, 48], "crash": [10, 44], "crate": 41, "creat": [8, 9, 11, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "create_lag_df": 42, "create_lag_featur": [42, 53], "create_y_from_r": 39, "creativ": [1, 40], "credit": [0, 25, 32, 34, 40, 42, 43, 51], "creditcard": [32, 51], "crime": 30, "crimin": 35, "criteria": [25, 38], "criterion": 38, "critic": 54, "cross": [15, 25, 27, 29, 31, 33, 34, 35, 37, 39, 43, 44, 46, 49, 50, 51, 52, 53], "cross_val": 34, "cross_val_predict": [32, 34, 43], "cross_val_scor": [28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44, 46, 49, 50, 51, 52, 53], "cross_valid": [27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53], "cross_validate_std": 26, "crowd": [34, 38], "crown": 54, "crown_princ": 40, "crucial": [24, 26, 30, 35, 37, 38, 39, 40], "crude": 40, "cs189": 9, "cs189_ch7": 9, "csrc": 44, "csv": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "ct": 29, "cuda": 41, "cui": 54, "cultiv": 54, "cultur": [41, 54], "cupi": 44, "curios": 24, "curiou": [24, 48], "current": [34, 40, 41, 42, 43, 44], "curriculum": 54, "curv": [7, 8, 37, 46, 48, 54], "custom": [5, 8, 24, 25, 29, 32, 33, 39, 44, 46], "custom_plot_tre": [25, 26, 34, 35], "customerid": 43, "customiz": 44, "cut": 38, "cv": [26, 29, 32, 33, 34, 35, 36, 42, 43, 46, 48, 50], "cv_feat": 44, "cv_results_": [31, 33, 50], "cv_score": [26, 33], "cv_train_scor": 48, "cv_valid_scor": 48, "cycl": 8, "cyclic": 42, "cycling_data": 8, "cygnu": 41, "d": [4, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 51, 52, 53], "d1b": 54, "d1c": 54, "d1e": 54, "d1f": 54, "d3": 37, "da": 24, "dabeaz": 9, "dad": 36, "dai": [4, 8, 10, 36, 41, 43, 46, 53, 54], "daili": [43, 46], "dall": 42, "damag": [0, 32], "dan": 40, "danceabl": [27, 28, 31, 50], "dark": 44, "darker": 31, "dashboard": [27, 48], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 38, 40, 43, 45, 46, 47, 49, 50, 51, 52, 54], "data_dict": 30, "data_dir": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53], "data_to_wrap": 29, "data_transform": 41, "data_transforms_bw": 41, "data_url": [32, 51], "datacamp": 9, "datafram": [24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 53], "dataload": 41, "dataloaders_bw": 41, "datapoint": 30, "dataquest": 9, "dataset": [8, 18, 24, 26, 27, 34, 35, 36, 37, 38, 43, 44, 45, 46, 48, 50, 51, 54], "dataset2": 37, "dataset_s": 41, "date": [7, 11, 24, 25, 39, 40, 43, 44, 46, 48, 53, 54], "date_rang": 42, "dates_rain": [42, 53], "datetim": 43, "datetime64": [42, 53], "datetimeindex": 42, "datum": 40, "daughter": 32, "daum\u00e9": 10, "daunt": 39, "dave": 40, "david": [10, 40], "day_nam": [42, 53], "daylight": [42, 53], "dayofweek": 42, "days_sinc": 42, "dbscan": 54, "dc": [42, 43, 44], "dcc": 30, "dd": [42, 53], "de": [40, 42], "deactiv": 11, "deadlin": 54, "deal": [0, 26, 27, 28, 33, 40, 43, 46, 49], "death": 54, "debat": [8, 35], "debbi": 44, "debug": [4, 35], "decad": 41, "decemb": [42, 53], "decid": [8, 25, 27, 30, 34, 35, 36, 37, 38, 40, 42, 43, 46], "decis": [2, 6, 10, 14, 26, 28, 31, 32, 34, 36, 41, 45, 46, 47, 49, 52, 54], "decision_boundari": 45, "decision_funct": 32, "decisiontreeclassifi": [26, 27, 28, 29, 30, 31, 35, 47, 48, 49, 50, 52], "decisiontreeclassifierdecisiontreeclassifi": 34, "decisiontreeregressor": [25, 33, 47, 48], "deck": 9, "declar": 54, "decomposit": [38, 39, 40], "decor": 44, "decreas": [26, 30, 31, 34, 35, 37, 48], "deduct": 7, "deem": 6, "deep": [2, 9, 31, 35, 36, 40, 43], "deepen": [46, 54], "deeper": [2, 31, 32, 33, 35], "deepexplain": 35, "def": [26, 27, 28, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 44, 48, 50, 53], "defalut": 50, "default": [5, 11, 25, 26, 29, 30, 31, 32, 33, 34, 37, 38, 41, 42, 43, 45, 50, 51, 54], "default_threshold": 32, "defaultdict": 39, "defin": [25, 27, 28, 29, 32, 34, 35, 37, 38, 39, 42, 53], "definit": [8, 27, 35, 37, 40, 42, 45, 46, 47], "degre": 32, "degrees_freedom": 43, "degrees_of_freedom": 43, "del": 34, "delai": [10, 11, 36], "deleg": 40, "delet": [4, 7, 28], "delgado": 34, "delight": 40, "deliver": 7, "delv": [40, 54], "demo": [10, 34, 54], "demograph": [25, 39], "demonstr": [25, 26, 28, 30, 31, 33, 34, 37, 39, 40, 41], "denomin": [33, 44], "denot": [25, 39], "dens": [38, 40], "densenet": 41, "densenet121": 41, "densenet121_weight": 41, "densiti": [35, 38, 46], "dep": 40, "department": 54, "departur": 36, "depend": [2, 8, 11, 25, 26, 27, 29, 31, 32, 33, 34, 35, 37, 38, 40, 42, 43, 52], "dependence_plot": 35, "dependents_no": 43, "dependents_y": 43, "deploi": [26, 32, 39, 46], "deploy": [35, 42, 54], "deprec": [26, 28, 32, 33, 43, 45], "deprecationwarn": [34, 43], "depth": [10, 25, 26, 31, 34, 38, 47, 48], "dequ": [34, 35, 52], "deriv": [0, 25, 30, 32, 39, 43, 46, 51], "descend": [8, 38, 41, 46], "descent": 42, "descr": 30, "describ": [8, 24, 25, 26, 27, 28, 30, 32, 33, 39, 40, 42, 48, 51, 53, 54], "descript": [33, 43, 44], "deserv": 6, "design": [25, 35, 38, 41, 50, 54], "desir": [32, 40, 43, 49], "desk": 54, "despit": [36, 40], "det": [40, 44], "detach": 41, "detail": [7, 27, 29, 34, 40, 41, 54], "detect": [24, 25, 32, 33, 37, 38, 42, 51], "determin": [27, 37, 38, 40, 43, 48, 52, 54], "detriment": [32, 39, 51], "dev": [26, 45], "develop": [9, 10, 24, 26, 28, 29, 31, 32, 33, 34, 40, 41, 44, 46, 54], "devianc": 43, "deviat": [6, 26, 28, 34, 35], "devic": [34, 41, 44], "deviceprotect": 43, "deviceprotection_no": 43, "deviceprotection_y": 43, "df": [24, 25, 26, 28, 29, 31, 32, 33, 35, 36, 41, 42, 43, 44, 47, 53], "df_concat": 24, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 42, "df_locat": [42, 53], "di": 43, "diagnos": [26, 35, 46], "diagnosi": 32, "diagnost": 43, "diagon": [27, 32, 35], "diagram": [29, 31, 34, 35], "dialogu": 40, "dict": [32, 39], "dict_kei": 34, "dictionari": [8, 28, 31, 32, 34, 35], "did": [6, 25, 27, 35, 37, 40, 42, 44, 48, 50, 51, 52, 54], "didn": [31, 34, 35, 38, 40, 42, 43], "die": 44, "diet": [25, 40], "diff": [42, 53], "differ": [2, 5, 7, 8, 10, 11, 24, 25, 26, 27, 29, 30, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54], "differenti": [24, 25, 54], "difficult": [4, 6, 7, 32, 36, 37], "difficulti": [37, 46], "dig": [32, 33], "digit": 42, "dilemma": 39, "dim": 41, "dimens": [8, 30, 36], "dimension": [2, 8, 30, 31, 32, 34, 36, 37, 40], "direct": [30, 35, 36, 38, 40, 44], "direct_bilirubin": 24, "directli": [8, 10, 29, 33, 41, 43, 54], "director": 39, "directori": [11, 25, 26, 28], "dirichlet": [40, 41], "disabl": 40, "disadvantag": [31, 34, 38, 39, 49], "disast": 24, "discard": [36, 40], "disciplin": [32, 36], "disclos": [44, 54], "discourag": 8, "discours": 39, "discov": [36, 37], "discoveri": 24, "discret": [25, 36, 54], "discrete_scatt": [25, 26, 27, 30, 37, 38, 41, 45, 47, 48], "discretization_feat": 36, "discrimin": 34, "discuss": [1, 4, 26, 27, 28, 30, 35, 36, 37, 38, 42, 46, 48, 49, 50, 52, 53, 54], "diseas": [25, 32, 43], "dispatch": 44, "dispatch_queu": 44, "dispatch_shel": 44, "displaci": [40, 44], "displai": [7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 38, 39, 41, 42, 43, 47, 48, 49, 50, 51, 53], "display_heatmap": [31, 50], "display_label": [32, 51], "displaystyl": 40, "disput": 40, "disrespect": 4, "dist": [27, 37, 38], "distanc": [8, 28, 36, 38, 39, 40], "distinct": [32, 36, 42], "distinguish": [25, 27, 29, 32, 48], "distract": 54, "distribut": [0, 11, 26, 32, 35, 36, 38, 40, 41, 42, 50, 53, 54], "district": [28, 30], "districtdatalab": 37, "disturb": 24, "dive": 35, "divers": [34, 37, 39, 42, 54], "divid": [30, 32, 34, 35, 42, 48], "divis": 35, "divorc": [34, 35], "dktal": 43, "dlwqn": 43, "dmp": 54, "do": [0, 4, 5, 6, 7, 8, 10, 11, 24, 25, 26, 27, 30, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "do_execut": 44, "dobj": 40, "doc": [8, 9, 35, 40, 41, 44, 54], "doc_id": 40, "doctor": [32, 34, 35, 51], "document": [0, 1, 7, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 50, 51, 52, 54], "document_top": 40, "documentari": 39, "doe": [5, 8, 11, 24, 26, 27, 28, 31, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54], "doesn": [7, 8, 26, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 46], "dog": [32, 41], "dollar": [4, 30, 33], "dolli": 44, "domain": [0, 24, 35, 37, 40], "domin": [28, 33, 41], "domingo": [10, 26, 36], "dominican_republ": 40, "don": [4, 24, 26, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "done": [5, 11, 26, 29, 31, 32, 41, 42, 46, 49, 51], "dont": 44, "door": 41, "dosa": 40, "dot": [27, 30, 32, 34, 35, 36, 38, 40], "dot_product": 40, "doubl": 31, "down": [26, 32, 35, 40, 43, 48, 52, 54], "downfal": 39, "downgrad": 44, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 32, 33, 35, 40, 41, 44, 48, 52], "dpi": 36, "dr": [40, 54], "draft": 10, "drag": 7, "drama": 39, "drastic": 32, "draw": [30, 31, 40], "drawback": [35, 39, 54], "drawn": 34, "dream": 41, "dreampharmaceut": 40, "drinker": 40, "drive": [24, 35], "driven": [11, 31, 32], "droit": 40, "drop": [7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54], "drop_dupl": [27, 31], "drop_feat": [29, 46], "drop_featur": [32, 33, 34, 35, 42, 43, 44, 51, 53], "dropdown": [19, 23], "dropdrop": [29, 33, 34, 44], "drope": 28, "dropna": [32, 42, 53], "dropoff": 37, "drug": 24, "dsci": [9, 10, 35, 45], "dsl": 43, "dt": 48, "dt88trtd17lf726d55bq16c40000gr": 44, "dt_best": 48, "dt_pipe": 31, "dtype": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 51, 52, 53], "dual": 32, "duan": 54, "duck": 41, "duckbil": 41, "due": [7, 30, 34, 36, 39, 54], "dummi": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 47, 49, 50, 51, 52, 53], "dummy_clf": [25, 47], "dummy_scor": 27, "dummy_valid_accuraci": 27, "dummyclassifi": [26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 41, 44, 47, 48, 49, 50, 51, 52, 53], "dummyregressor": [29, 34, 35, 36, 44, 49, 52], "dun": 24, "dunno": 24, "duplex": 33, "duplic": 8, "durat": [7, 36, 42, 43], "duration_col": 43, "duration_m": [27, 28, 31], "dure": [4, 8, 10, 24, 25, 27, 29, 30, 31, 34, 35, 36, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54], "dwell": 33, "e": [6, 7, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53, 54], "e737c5242822": 43, "e_": 26, "each": [7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54], "earli": [35, 43], "earlier": [28, 34, 36, 42, 43], "early_stopping_round": 34, "earn": 54, "earnest": 54, "easi": [7, 27, 28, 30, 34, 35, 36, 37, 38, 40, 44], "easier": [5, 7, 32, 35, 36, 39], "easiest": [35, 43, 44], "easili": [34, 36, 42, 47, 53], "echidna": 41, "econom": [29, 42], "ecosystem": 41, "ed": 1, "eda": [26, 40, 43, 46, 53], "edg": [25, 31], "edgecolor": [31, 42, 53], "edit": [31, 40], "edu": 9, "educ": [32, 34, 35, 39, 51], "education_level": [32, 34, 35, 51], "effect": [27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 46, 48, 51], "effici": 31, "effort": [4, 11, 31, 36, 37, 39, 41, 54], "egg": 37, "eghbal": 54, "either": [4, 25, 26, 27, 29, 32, 35, 37, 38, 40, 41, 42, 48, 50], "elast": 43, "elbow": 38, "elect": 40, "electr": [33, 35], "electrical_engin": 40, "electrical_fusea": 33, "electrical_fusef": 33, "electrical_fusep": 33, "electrical_miss": 33, "electrical_mix": 33, "electrical_sbrkr": 33, "electron": [43, 54], "eleg": [28, 40], "elegantli": 40, "element": [0, 9, 10, 26, 29, 40, 47], "eli5": 35, "elif": [25, 42, 43], "elimin": 54, "els": [25, 29, 32, 41, 42, 43, 44, 51], "email": [24, 26, 32, 54], "emb": [7, 27, 32, 37, 38], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 41, 46, 54], "emoji": 44, "emoticon": [36, 37], "emp": 35, "empathi": 40, "emphas": 54, "emphasi": 54, "emploi": [42, 43, 46], "employ": 39, "employe": 25, "empti": [30, 40, 41, 42, 53], "en": [42, 43, 44, 53], "en_core_web_lr": 40, "en_core_web_md": [40, 44], "enabl": [11, 39, 40, 42], "enable_categor": 34, "enable_halving_search_cv": 31, "enc": [28, 29, 42], "enclosedporch": [33, 35], "encod": [16, 17, 24, 26, 31, 32, 33, 35, 39, 43, 46, 49, 51, 53], "encompass": [43, 46], "encount": [29, 31], "encourag": [11, 54], "end": [4, 8, 24, 26, 27, 30, 31, 32, 36, 37, 38, 39, 40, 42, 43, 48, 54], "endors": 0, "endpoint": 43, "energi": [27, 28, 31, 42, 50], "engag": 54, "engin": [9, 10, 29, 32, 33, 37, 39, 40, 43, 53, 54], "england": 44, "english": [24, 28, 31, 32, 40, 41, 44, 50], "enhanc": 54, "enjoi": [10, 30], "enjoy_class": 29, "enjoy_cours": [29, 46], "enjoy_course_enc": 29, "enjoy_the_mo": 32, "enough": [7, 27, 29, 32, 33, 34, 37, 39, 46, 50, 51, 53], "ensembl": [10, 19, 20, 33, 35, 36, 38, 39, 42, 43, 44, 52, 53, 54], "ensiti": 38, "ensur": [7, 28, 34, 42, 53, 54], "ent": [40, 44], "enter": [29, 43, 50], "enterpris": 5, "entertain": 40, "enthusiast": 24, "entir": [4, 8, 26, 33, 41, 42, 44, 52, 54], "entiti": [36, 39, 40, 44], "entitl": 29, "entlebuch": [24, 41], "entri": [27, 28, 29, 30, 32, 33, 36, 39, 42, 43, 53], "entropi": 25, "enumer": 34, "env": [11, 25, 26, 29, 31, 35, 43, 44, 45], "environ": [3, 5, 8, 24, 28, 29, 31, 32, 33, 34, 35, 36, 40, 41, 43, 44, 54], "environemnt": 11, "environment": 46, "ep": [25, 26, 27, 30, 38, 47], "epoch": 42, "epsilon": 38, "equal": [8, 27, 29, 32, 33, 34, 35, 38, 39, 42, 46, 53, 54], "equat": [4, 30], "equip": [27, 43, 54], "equival": [8, 32, 34, 51], "erik": 40, "err": 40, "error": [4, 6, 7, 8, 11, 25, 27, 29, 30, 34, 35, 36, 40, 43, 44, 46, 48, 52, 54], "error_": 26, "erupt": 24, "erythrocebu": [24, 41], "es": [42, 53], "eskimo": 32, "esl": 10, "especi": [2, 25, 27, 31, 32, 34, 36, 39, 42], "essenti": [43, 46], "estat": 25, "estim": [26, 27, 29, 30, 31, 36, 37, 43, 46, 52], "estimators_": 34, "et": [34, 40], "etc": [2, 7, 8, 25, 36, 40, 41, 42, 43, 44, 54], "ethic": [10, 54], "euclidean": [37, 38, 40], "euclidean_dist": [27, 28, 37, 38, 40], "ev": 44, "eva": 39, "eva_model": 39, "eval": 41, "eval_metr": [34, 35], "eval_on_featur": 42, "evalu": [8, 10, 25, 26, 31, 33, 35, 37, 42, 48, 52, 54], "evapor": [42, 53], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 30, 31, 32, 36, 37, 38, 39, 42, 43, 44, 46, 48, 49, 51, 54], "event": [0, 32, 33, 44, 54], "event_col": 43, "event_observ": 43, "ever": [25, 45], "everi": [8, 25, 26, 34, 38, 42, 48], "everydai": [8, 40], "everyon": [6, 35, 46], "everyth": [29, 32, 39, 42, 52], "everywher": 42, "evict": 44, "evok": 40, "ex": [33, 35], "ex1_idx": 35, "ex2_idx": 35, "exact": [4, 43], "exactli": [7, 24, 26, 35, 48, 50], "exam": [6, 10], "examin": [26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 51, 53], "exampl": [0, 4, 5, 6, 7, 8, 11, 33, 38, 39, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54], "example1": 25, "example2": 25, "exceedingli": 48, "excel": [29, 30, 33, 35, 43, 46, 49], "except": [0, 7, 8, 26, 42, 43, 53, 54], "exception": 4, "exchang": [32, 46], "excit": 39, "exec": 44, "execut": [4, 7, 37], "execute_request": 44, "exercis": [7, 9, 10, 40, 44, 48, 49, 50, 51, 52, 53, 54], "exerciseangina": 52, "exhaust": 50, "exist": [8, 32, 36, 43, 51], "exp": [30, 43], "expand": [10, 25, 54], "expect": [1, 4, 7, 8, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54], "expected_valu": 35, "expenditur": 42, "expens": [24, 32, 33, 36, 37, 39], "experi": [24, 31, 39, 40, 54], "experienc": 54, "experiment": 31, "expert": [24, 25, 26, 31, 35, 36, 51], "explain": [4, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 51, 52, 54], "explan": [4, 26, 27, 46, 51], "explanatori": 25, "explicit": [32, 43], "explicitli": [8, 24], "exploit": 6, "explor": [25, 26, 29, 31, 32, 35, 36, 39, 40, 41, 48, 50], "exploratori": [33, 43, 46], "explos": 44, "expm1": 33, "expon": 31, "exponenti": 31, "export_graphviz": [25, 47], "exposur": 39, "express": [0, 8, 29, 30, 36, 40], "extend": [40, 41, 45, 54], "extend_block": 43, "extens": [27, 32, 35, 37, 38, 40, 42, 48, 54], "extent": [37, 40], "extercond": [33, 35], "exterior": 35, "exterior1st": [33, 35], "exterior1st_asbshng": 33, "exterior1st_asphshn": 33, "exterior1st_brkcomm": 33, "exterior1st_brkfac": 33, "exterior1st_cblock": 33, "exterior1st_cemntbd": 33, "exterior1st_hdboard": 33, "exterior1st_imstucc": [33, 35], "exterior1st_metalsd": 33, "exterior1st_plywood": 33, "exterior1st_ston": 33, "exterior1st_stucco": 33, "exterior1st_vinylsd": 33, "exterior1st_wd": 33, "exterior1st_wdsh": 33, "exterior2nd": [33, 35], "exterior2nd_asbshng": 33, "exterior2nd_asphshn": 33, "exterior2nd_brk": 33, "exterior2nd_brkfac": 33, "exterior2nd_cblock": 33, "exterior2nd_cmentbd": 33, "exterior2nd_hdboard": 33, "exterior2nd_imstucc": 33, "exterior2nd_metalsd": 33, "exterior2nd_oth": 33, "exterior2nd_plywood": 33, "exterior2nd_ston": 33, "exterior2nd_stucco": 33, "exterior2nd_vinylsd": 33, "exterior2nd_wd": 33, "exterqu": [33, 35], "extra": [4, 37, 42, 53, 54], "extract": [36, 37, 39, 40, 41, 44, 53, 54], "extractor": 46, "extrapol": [42, 43], "extratreesclassifi": 34, "extrem": [6, 29, 32, 34, 35, 39, 43, 44], "ey": 44, "f": [8, 11, 24, 25, 26, 27, 28, 29, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 48, 52, 53, 54], "f1": [18, 33, 46, 54], "f1_score": 32, "f403": 44, "fa": [33, 35], "face": [24, 25, 27, 39, 41], "facebook": [39, 40, 54], "facial": 27, "facil": 54, "facilit": [8, 54], "fact": [24, 31, 32, 34, 41, 42, 43, 53], "factor": [25, 31, 35, 36, 38, 39, 43], "fail": [7, 8, 10, 11, 26, 28, 29, 36, 38, 40, 43, 44], "failur": [7, 24, 43, 52, 54], "fair": [6, 26, 28, 33, 35, 37, 46, 54], "fairli": [26, 31, 32, 35, 51], "fake": 27, "fall": [27, 37, 40, 42], "fals": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 46, 51, 52, 53], "famili": [24, 31, 32, 33, 34, 35, 37, 54], "familiar": [8, 11, 25, 28, 48, 53, 54], "famou": [9, 10, 40, 41], "fanci": [4, 24, 31], "fancier": 36, "far": [25, 27, 28, 29, 30, 32, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 48, 50, 52], "farm": 32, "farthest": 25, "fashion": [34, 40], "fast": [26, 27, 30, 34, 35, 40, 43, 54], "faster": [24, 31, 34, 36, 41], "fastest": 34, "fastingb": 52, "fasttext": 40, "favourit": 40, "fc": 30, "fcluster": 38, "feat": [31, 42, 44], "feat1": 37, "feat2": 37, "feat_nam": [42, 44], "feat_vec": 39, "featur": [10, 16, 17, 21, 22, 23, 26, 32, 34, 37, 38, 40, 43, 45, 48, 49, 50, 51, 52, 54], "feature_extract": [24, 29, 30, 31, 32, 40, 44, 50], "feature_importances_": 36, "feature_nam": [25, 26, 30, 34, 35, 36, 40], "feature_names_out": 29, "feature_select": 36, "feature_typ": 34, "features_lag": 42, "features_nonzero": 42, "features_poli": 42, "februari": 42, "feder": [32, 35, 40, 42], "feedback": [25, 46], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 37, 46], "feli": [24, 41], "fell": 30, "femal": [32, 34, 35, 43, 51], "female_cm": [32, 51], "female_pr": [32, 51], "fenc": [33, 35, 41], "fernandez": 34, "fetch_california_h": 30, "few": [8, 10, 24, 30, 33, 34, 36, 39, 40, 41, 42, 43, 47, 52], "fewer": [11, 34, 36, 38], "fewest": 52, "fiber": 43, "fiction": 44, "field": [2, 4, 24, 29, 40, 41, 42, 54], "fig": [26, 27, 30, 32, 36, 37, 38, 41, 48, 51], "figsiz": [25, 26, 27, 28, 30, 32, 35, 36, 37, 38, 41, 42, 43, 48, 51], "figur": [4, 8, 11, 24, 25, 27, 31, 33, 35, 36, 37, 38, 41, 42, 43, 48], "file": [0, 1, 4, 5, 7, 8, 11, 19, 25, 29, 32, 35, 41, 43, 44, 51, 53], "filenam": 41, "fill": [27, 30, 31, 39, 48, 52, 54], "fill_diagon": 27, "fill_valu": [32, 33, 34, 35, 42, 51, 53], "film": [40, 44], "filter": [4, 24, 26, 37, 42, 46, 53, 54], "filterwarn": [27, 43, 52], "final": [6, 7, 10, 26, 28, 34, 36, 47, 49, 52], "final_estim": 34, "final_estimator_": [34, 52], "financ": [41, 42], "find": [7, 8, 10, 24, 25, 28, 31, 33, 34, 35, 37, 38, 39, 40, 44, 45, 50, 51, 54], "fine": [7, 28, 29, 32, 39, 41, 42, 52], "finish": [24, 33], "fira": [0, 1, 54], "firasm": [32, 51], "fireplac": [33, 35], "fireplacequ": [33, 35], "first": [4, 8, 10, 25, 27, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 54], "first_dai": 42, "first_day_retail": 42, "firth": 40, "fish": [32, 35], "fist": 42, "fit": [0, 24, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53], "fit_intercept": 32, "fit_predict": 38, "fit_resampl": 32, "fit_tim": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44], "fit_transform": [28, 29, 32, 34, 35, 36, 38, 39, 40, 42, 46, 51], "fittedcolumntransform": [29, 34], "fittedpipelin": [29, 31, 33], "fittedvotingclassifi": 34, "fitter": 43, "five": 31, "fix": [28, 29, 34, 43, 45, 48, 54], "flag": 43, "flagstaff": 44, "flaki": 32, "flashcard": 46, "flat": 38, "flatten": [34, 35, 38, 42, 52], "flatten_train": 41, "flatten_transform": 41, "flatten_valid": 41, "flaw": [26, 28], "flawless": 30, "flexibl": [7, 24, 36, 41, 46, 54], "flibbertigibbet": 40, "flickr_cat_000002": 41, "flight": 36, "flip": [10, 26, 32, 33], "flip_i": 32, "float": [8, 33, 36, 43, 44], "float32": [40, 41], "float64": [25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 42, 43, 53], "floatlogslid": [27, 48], "floatslid": [27, 32, 37, 38, 48], "floor": [24, 25], "flower": [27, 32, 48], "fmt": 31, "fn": 32, "fnlwgt": [32, 34, 35, 51], "focu": [10, 24, 28, 29, 30, 35, 38, 39, 40, 42, 46, 48, 49, 50, 51, 52, 54], "focus": [24, 30, 37, 40, 46, 53], "fold": [26, 28, 29, 31, 32, 33, 34, 48], "folder": [5, 6, 26, 28, 35, 44], "folk": [43, 54], "follow": [0, 5, 6, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 48, 54], "font": [24, 25, 26, 37, 38, 39, 42, 43], "font_scal": 35, "fontsiz": [25, 26, 27, 32, 34, 35, 37, 41, 47, 48], "food": [37, 40, 41, 54], "foot": [33, 35], "footag": 30, "footstal": 41, "forc": [32, 35, 48], "force_plot": 35, "forecast": [25, 43, 46, 53, 54], "forest": [32, 33, 41, 42, 43, 46, 52, 54], "forev": 42, "forg": [11, 32, 33, 34, 35, 40, 43, 44], "forget": [25, 29, 34, 52], "form": [10, 29, 32, 36, 38, 39, 40, 43, 46], "formal": 54, "format": [0, 10, 25, 32, 38, 40, 42, 43, 53], "former": 43, "formul": [4, 31], "formula": [30, 33, 41, 45], "forum": [6, 7], "forward": 43, "found": [7, 10, 26, 29, 31, 33, 37, 39, 40, 44, 46, 50, 52, 54], "foundat": [9, 10, 32, 33, 35, 54], "foundation_brktil": 33, "foundation_cblock": 33, "foundation_pconc": 33, "foundation_slab": 33, "foundation_ston": 33, "foundation_wood": 33, "fountain": 41, "four": [25, 26, 36, 38, 46], "fourth": 38, "foxhound": [24, 41], "foyer": 33, "fp": 32, "fpr": 32, "fpr_lr": 32, "fpr_svc": 32, "frac": [25, 30, 32, 33, 37, 40, 41], "fractal": 36, "fraction": [29, 32, 39], "fragment": 48, "frame": [28, 29, 32, 33, 36, 42, 43, 53], "framework": [25, 31], "fraud": [25, 32, 33, 37, 42, 51], "fraudul": [25, 32, 51], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 33, 40, 43], "freedom": [0, 44], "french": [28, 40], "freq": [42, 53], "frequenc": [29, 40, 42, 43, 46, 53], "frequent": [25, 28, 39, 40, 43], "fresh": [39, 40], "fri": [10, 42], "fridai": [10, 54], "friend": [25, 26, 32, 35, 38, 39, 46, 54], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "from_block": 43, "from_estim": [32, 51], "front": 54, "frozen": 44, "fruit": 40, "frustrat": [4, 6, 31], "full": [31, 34, 41, 42, 43, 54], "fullbath": [33, 35], "fulli": 38, "fun": [32, 40, 41], "func": [8, 29, 30, 33], "function": [2, 24, 25, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53], "functiontransform": [29, 43], "fund": 44, "fundament": [2, 9, 10, 15, 28, 30, 31, 33, 36, 41, 43, 54], "funni": [24, 34, 44], "furnish": 0, "furnitur": 46, "further": [32, 34, 36, 37, 40, 41, 43, 48, 50, 51], "futur": [26, 28, 31, 33, 43, 46, 50, 53, 54], "futurewarn": [26, 28, 33, 35, 45], "fyi": 43, "g": [6, 7, 8, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 53, 54], "g26r0dcx4b35vf3nk31216hc0000gr": [28, 35], "gain": [6, 25, 32, 34, 35, 51, 54], "game": [25, 35, 40], "gamma": [30, 31, 34, 48, 50], "gamma_log": [27, 48], "gamma_widget": [27, 48], "gap": [26, 42, 43, 46, 48], "garagearea": [33, 35], "garagecar": [33, 35], "garagecond": [33, 35], "garagefinish": [33, 35], "garagefinish_fin": 33, "garagefinish_miss": 33, "garagefinish_rfn": 33, "garagefinish_unf": 33, "garagequ": [33, 35], "garagetyp": [33, 35], "garagetype_2typ": 33, "garagetype_attchd": 33, "garagetype_bas": 33, "garagetype_builtin": 33, "garagetype_carport": 33, "garagetype_detchd": 33, "garagetype_miss": 33, "garageyrblt": [33, 35], "garlic": 37, "gauss": 40, "gaussian": 38, "gaussianmixtur": 38, "gave": [39, 42], "gbr": 8, "gca": [37, 38, 43], "gd": [24, 33, 35], "gdprv": [33, 35], "gdwo": [33, 35], "gelbart": [0, 1, 25, 40, 50], "gender": [24, 29, 32, 40, 42, 43, 51], "gender_femal": 43, "gender_mal": 43, "gener": [7, 9, 15, 25, 28, 29, 31, 32, 33, 35, 38, 40, 41, 42, 43, 45, 46, 48, 50, 51, 53, 54], "genet": 36, "genom": 36, "genr": 39, "gensim": 40, "gentl": 54, "geograph": 30, "geometr": 25, "georg": 40, "geq": 30, "ger": 8, "german": 40, "get": [4, 5, 6, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54], "get_avg_word_length": 44, "get_cmap": 28, "get_depth": 48, "get_dummi": 28, "get_featur": 41, "get_feature_names_out": [28, 29, 32, 33, 34, 35, 36, 40, 42, 43, 44, 51, 53], "get_length_in_word": 44, "get_lr_data_per_us": 39, "get_permutation_import": 35, "get_relative_length": 44, "get_season": 42, "get_senti": 44, "get_stat": 39, "get_user_profil": 39, "getattr": 43, "gif": [37, 38], "gift": 44, "gigaword": 40, "gini": [25, 35], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 24, 28, 29, 31, 32, 33, 34, 35, 36, 41, 44, 50, 51], "githubusercont": 8, "gitlf": 32, "giulia": [0, 1], "give": [0, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48, 51], "given": [0, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 51, 53], "gladwel": 37, "glob": [24, 41], "global": [28, 32, 34, 37, 40, 46], "glove": [40, 54], "glq": [33, 35], "gmail": [24, 37], "go": [5, 7, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53], "goal": [2, 27, 28, 31, 32, 37, 38, 39, 40, 44, 50, 52, 53, 54], "goe": [2, 26, 27, 29, 32, 34, 35, 38, 39, 41], "gold": 8, "goldcoast": 42, "golden": [27, 46, 48], "good": [9, 11, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "googl": [4, 10, 24, 25, 34, 35, 36, 37, 40, 44], "google_news_vector": 40, "got": [27, 30, 31, 32, 33, 41], "gotten": [43, 52], "gov": [32, 34, 35], "govern": [40, 54], "gpe": 40, "gpt": [39, 40], "gpu": [34, 40, 41], "grad": [32, 34, 35, 51], "grade": [3, 7, 10, 24, 26, 29, 31, 46, 48, 49, 50, 51, 52, 53], "grader": 6, "grades_df": 46, "gradescop": [1, 6, 10, 54], "gradient": [19, 20, 46], "gradientboostingclassifi": 34, "gradientboostingregressor": 34, "gradientexplain": 35, "grading_concern": 6, "graduat": 41, "grai": 41, "grain": [30, 35], "gram": 40, "grammat": 40, "grandma": 36, "grandmoth": 32, "grant": 0, "grant_macewan": 40, "granular": 38, "graph": [10, 41, 42], "graphic": 41, "graphic_design": 40, "graphviz": [25, 47], "grasp": [46, 54], "grayscal": 41, "great": [24, 25, 27, 29, 30, 35, 36, 40, 41, 42, 44], "greater": [11, 36, 37], "greater_is_bett": 33, "greedili": 38, "green": [27, 31, 37, 45], "grei": 54, "grid": [30, 33, 42, 43, 46, 50, 53], "grid_search": [31, 50], "gridsearchcv": [27, 34, 35, 50, 52], "gridsearchcvifittedgridsearchcv": 31, "grip": 40, "grlivarea": [33, 35], "groak": 40, "groceri": [41, 44], "groin": 41, "ground": [26, 36, 38, 39, 54], "ground_truth_categori": 32, "group": [7, 25, 27, 29, 30, 34, 36, 46, 48, 49, 52, 54], "groupbi": [42, 53], "grow": [31, 34, 36], "grow_polici": 34, "growth": [42, 43], "groyn": 41, "grv": 33, "gt": [29, 30, 31, 32, 33, 34], "gtl": 35, "guarante": [31, 32, 34, 37, 41], "guenon": 41, "guess": [27, 28, 40, 44], "guid": [7, 9, 10, 36, 41, 54], "guidanc": 35, "guidelin": [35, 36], "guido": 10, "h": [32, 34, 35, 37, 40, 41, 43, 44, 51], "ha": [2, 5, 6, 10, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 48, 51, 52, 53, 54], "hab": 40, "habit": 29, "hacki": [41, 45], "had": [24, 28, 29, 30, 32, 39, 40, 41, 42, 43], "hadn": [40, 43], "hal": 10, "half": [6, 10, 25, 30, 36, 38], "halfbath": [33, 35], "halvingrandomsearchcv": 31, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 31, "ham": 24, "hand": [4, 9, 32, 39, 51, 54], "handi": 32, "handl": [34, 35, 38, 43, 44, 45, 46, 48, 54], "handle_unknow": 29, "handle_unknown": [28, 29, 31, 32, 33, 34, 35, 42, 43, 46, 50, 51, 52, 53], "handler": [32, 35], "handrail": 41, "handwritten": 32, "hang": 32, "happen": [4, 6, 24, 27, 29, 31, 34, 35, 36, 39, 42, 43, 46, 53, 54], "happi": [32, 37, 43], "happier": 54, "happydb": 32, "hard": [8, 24, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 52], "hardli": 39, "hardwar": 41, "harmon": 32, "harri": 40, "has_cupi": 44, "has_emoji": 44, "has_rais": 44, "hasn": [4, 39, 40, 43], "hassl": [8, 35, 42], "hat": [30, 33, 34], "have": [0, 4, 6, 7, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "haven": [26, 40, 43, 46], "haylei": 25, "hazard": 54, "hc_truncation_toy_demo": 38, "hdbscan": 38, "he": [26, 29, 40, 54], "head": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53], "headlin": 40, "health": 40, "healthcar": 35, "healthi": 40, "heard": 26, "heart": [25, 44, 52], "heart_df": 52, "heartdiseas": 52, "heat": [31, 33, 35, 50], "heating_floor": 33, "heating_gasa": 33, "heating_gasw": 33, "heating_grav": 33, "heating_othw": [33, 35], "heating_wal": 33, "heatingqc": [33, 35], "heatmap": 35, "heavi": [34, 44], "heavili": [39, 41, 42, 51], "heeren": 40, "height": [25, 26, 32, 40, 44, 47], "hell": 44, "help": [3, 7, 11, 24, 26, 28, 29, 31, 32, 35, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 53, 54], "henc": [5, 32, 33, 35, 37], "her": [24, 39, 40], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54], "herebi": 0, "herself": [40, 44], "herta": 27, "heurist": [25, 31], "hi": [40, 48], "hidden": [36, 40, 41], "hide": [8, 41], "hier_label": 38, "hier_labels1": 38, "hier_labels2": 38, "hierarch": [46, 54], "hierarchi": [25, 38], "high": [6, 26, 27, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 54], "high_corr": 35, "higher": [25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 39, 43, 48, 50, 51], "highest": [34, 35, 39, 40, 41, 45, 48, 51], "highland": 44, "highli": [10, 11, 28, 35, 39], "highlight": [4, 41, 46], "highwai": 30, "him": 40, "himself": 40, "hinder": 54, "hindi": 28, "hint": [35, 48], "hist": [28, 31, 33, 36, 43], "histgradientboostingclassifi": 34, "histgradientboostingregressor": 34, "histogram": 43, "histor": 46, "histori": [30, 39, 42, 54], "hit": [24, 31], "hitter": 44, "hl": [33, 35], "hmid": 32, "hmmm": 43, "hockei": 40, "hold": 50, "holder": 0, "holdout": 32, "holidai": [10, 39, 54], "home": [25, 30, 32, 41], "homemak": 40, "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 27, 30, 31, 40, 46, 54], "honour": 54, "hood": 26, "hope": 26, "hopefulli": 50, "hopeless": 36, "hopelessli": 27, "horizont": [25, 29], "host": [5, 43], "hot": [16, 26, 29, 35, 46, 53], "hound": [24, 41], "hour": [4, 11, 32, 34, 35, 36, 39, 42, 46, 51, 54], "hourli": [43, 46], "hous": [18, 33, 35, 36, 43, 48], "houseag": 30, "household": [28, 29, 30, 36, 49], "housestyl": [33, 35], "housestyle_1": 33, "housestyle_1stori": 33, "housestyle_2": 33, "housestyle_2stori": 33, "housestyle_sfoy": 33, "housestyle_slvl": 33, "housewif": 40, "housing_df": [25, 28, 29, 36, 48, 49], "housing_median_ag": [28, 29, 36, 49], "houston": 44, "how": [0, 3, 8, 11, 24, 29, 31, 32, 33, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "howard": 37, "howev": [2, 8, 28, 29, 32, 33, 35, 37, 39, 42, 43, 45, 48, 51], "hsjcy": 43, "hstack": 42, "html": [7, 9, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 43, 44, 47, 49, 51], "http": [0, 5, 8, 9, 11, 24, 25, 26, 28, 29, 30, 32, 33, 34, 41, 42, 43, 44, 51, 54], "hug": 39, "huge": [29, 33, 40, 41, 42, 43, 53], "human": [0, 24, 27, 28, 29, 30, 31, 32, 35, 36, 37, 40, 41, 51], "humidity3pm": [42, 53], "humidity3pm_lag1": [42, 53], "humidity9am": [42, 53], "hummu": [37, 40], "humour": [10, 40], "hundr": 30, "hurrai": 52, "hurrican": 24, "husband": [32, 34, 35], "hussar": [24, 41], "hw": 24, "hw1": [4, 10, 47], "hw2": [10, 27, 28, 50], "hw3": 10, "hw4": 10, "hw5": [10, 54], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 39, "hyperband": 31, "hyperopt": 31, "hyperparamet": [10, 26, 32, 38, 39, 40, 41, 50], "hyperparamt": [26, 31, 43], "hyperparlan": 30, "hyperplan": 30, "hypothesi": [40, 43], "hypothet": [30, 37], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 30, 33, 38, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "i1": 34, "i2": 34, "ia": 44, "ibm": 44, "ic": 40, "icc": 54, "iclick": 10, "id": [24, 25, 33, 35, 39, 48], "idea": [8, 25, 26, 28, 31, 35, 37, 38, 39, 40, 41, 42, 43, 46, 48, 53], "ideal": [4, 32, 34, 36, 39, 43], "ident": [40, 41, 44], "identif": [24, 44], "identifi": [25, 26, 27, 28, 31, 32, 33, 37, 38, 40, 41, 42, 46, 51, 53, 54], "idf": 29, "idli": 40, "idx": 41, "idxmax": 27, "if_binari": [29, 32, 34, 35, 46, 49, 51, 52], "ifram": [26, 32], "igloo": 40, "ignor": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 42, 43, 46, 50, 51, 52, 53], "ignore_index": 8, "ii": 32, "iii": 10, "ij": [30, 39], "ik": 34, "ill": 54, "illus": [32, 51], "illustr": [38, 42], "iloc": [8, 25, 26, 27, 28, 29, 34, 35, 40, 42, 44, 47, 52, 53], "im": 44, "imag": [7, 26, 32, 35, 36, 37, 38, 42, 46, 51, 54], "image_dataset": 41, "image_datasets_bw": 41, "image_s": 41, "imagefold": 41, "imagenet": 45, "imagenet1k_v1": 41, "imagenet_class": [24, 41], "imagin": [24, 25, 26, 28, 30, 32, 35, 36, 37, 40, 43, 46, 47, 51], "imaginari": [26, 40], "imbal": [18, 37, 43, 51], "imbalanc": [32, 33, 45], "imblearn": 32, "img": [24, 41], "img_classifi": 24, "img_path": 24, "img_t": 41, "immedi": [35, 39, 54], "imp": [28, 29, 42], "impact": [7, 29, 30, 34, 35, 38, 42, 48, 53, 54], "implement": [2, 4, 24, 28, 32, 33, 34, 36, 38, 39, 40, 43, 45], "impli": [0, 43], "implic": [28, 46, 54], "implicit": 40, "import": [8, 10, 21, 22, 23, 45, 49, 50, 51, 52, 54], "importance_typ": 34, "importances_mean": 35, "impos": 28, "imposs": 37, "impress": 35, "improv": [31, 32, 33, 34, 36, 37, 38, 39, 42, 43, 46, 50, 54], "impur": [25, 34], "imput": [16, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 46, 49, 50, 51, 52, 53], "imread": 41, "imshow": [24, 41], "inbox": 26, "inc": [35, 40], "incept": [39, 41], "inception": 41, "incl": 33, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 25, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54], "include_bia": [36, 42], "incom": [26, 30, 32, 34, 35, 51], "incomplet": 43, "inconsist": 29, "incorpor": [31, 33, 36, 43, 46], "incorrect": 43, "incorrectli": [24, 32], "increas": [8, 26, 27, 29, 30, 34, 35, 36, 37, 38, 41, 48, 50], "increasingli": 24, "incred": 41, "inde": 35, "independ": [8, 9, 25, 31, 33, 34, 36, 42, 54], "index": [24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 48, 51, 52, 53], "index_col": [8, 27, 28, 31, 32, 39, 50], "india": 40, "indian": 32, "indian_liver_pati": 24, "indic": [0, 29, 37, 39, 40, 41, 42, 43], "individu": [34, 35, 37, 39, 40, 43, 52, 54], "industri": [34, 36, 40, 41], "inequ": [32, 51], "inertia_": 37, "inertia_valu": 37, "inf": [27, 43], "infeas": 31, "infer": [25, 40, 41, 42, 47], "infin": 27, "infinit": 31, "inflamm": 9, "inflat": 35, "inflect": [37, 40], "influenc": [25, 26, 31, 35, 37, 39, 43, 48], "info": [1, 3, 8, 28, 29, 32, 33, 36, 40, 42, 43, 48, 52, 53], "infom": 40, "infor_m": 40, "inform": [1, 4, 7, 11, 25, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 48, 51, 52, 53, 54], "informa_t": 40, "informaion": 40, "informaiton": 40, "informationabout": 40, "informationon": 40, "inhabit": 54, "inher": [32, 42, 43, 51], "initi": [38, 41, 44], "initj": 35, "inject": [36, 39, 46], "inland": [28, 29, 36, 49], "inlin": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 47, 48, 50, 51, 52], "inner": [29, 31, 40], "inplac": [8, 24, 25, 31], "input": [8, 25, 28, 30, 34, 35, 38, 40, 41, 42, 44, 46, 53], "input_img": 41, "inputs_bw": 41, "insid": [9, 29, 32], "insight": [2, 27, 32, 35, 37, 54], "inspct": 32, "inspect": [35, 38], "inspir": [25, 32, 34], "instal": [24, 27, 32, 33, 34, 35, 37, 40, 41, 43, 44], "instanc": [24, 25, 26, 29, 30, 32, 37, 38, 39, 40, 41, 42, 45], "instanti": [31, 48], "instead": [5, 8, 11, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 48, 50, 51, 52], "institut": [40, 44], "instruct": [3, 4, 5, 11, 27, 54], "instructor": [4, 6, 24, 54], "instrument": [27, 28, 31, 50], "int": [28, 29, 32, 34, 35, 40, 42, 44, 51, 52, 53], "int32": [27, 37, 38, 42], "int64": [25, 27, 29, 32, 33, 39, 40, 42, 43, 44], "integ": [8, 26, 28, 31, 34, 35, 42], "integr": 54, "intellig": [10, 40], "intelligen": 40, "intend": 0, "intens": 40, "inter": 44, "interact": [9, 27, 31, 32, 35, 37, 38, 39, 42, 44, 48], "interaction_constraint": 34, "interaction_onli": [36, 42], "interactive_plot": [27, 48], "interactiveshel": 44, "intercept": [35, 41, 45], "intercept_": [30, 34, 41, 45], "intercept_sc": 32, "interest": [2, 24, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 50, 52, 53], "interfac": 34, "intermedi": [38, 41], "intern": [0, 1, 25, 41, 42, 43, 44], "internet": 43, "internetservic": 43, "internetservice_dsl": 43, "internetservice_fib": 43, "internetservice_no": 43, "internship": 24, "interpret": [10, 11, 21, 22, 23, 27, 28, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 51, 54], "interv": [42, 43, 46, 50, 54], "intrins": 42, "intro": [10, 19, 20, 40, 41], "introduc": [29, 32, 43], "introduct": [9, 10, 11, 13, 16, 42, 43, 48, 54], "intslid": [27, 48], "intuit": [27, 28, 29, 31, 33, 35, 37, 38, 43, 44, 54], "invalid": 31, "inventori": 46, "invers": [30, 33], "inverse_func": 33, "investig": [27, 35, 48], "involv": [2, 4, 31, 33, 34, 38, 40, 41], "io": [9, 28, 41, 43, 44], "io_loop": 44, "ipkernel": 44, "ipykernel": 44, "ipykernel_19402": 35, "ipykernel_32469": 28, "ipykernel_79734": 26, "ipykernel_86208": 44, "ipykernel_launch": 44, "ipynb": [7, 8], "ipython": [24, 25, 26, 27, 28, 29, 30, 32, 40, 44, 47, 49, 51], "ipywidget": [27, 48], "ir1": [33, 35], "ir2": [33, 35], "iri": [27, 48], "iris_df": [27, 48], "irregular": 54, "irregularli": 46, "irrelev": [27, 36, 40], "irrelevant_po": 40, "irrespect": [26, 30, 54], "is_avail": 41, "is_leap_year": [42, 53], "is_stop": 40, "is_year_end": [42, 53], "isinst": 43, "island": [28, 29], "isn": [26, 27, 32, 33, 34, 40], "isnul": 28, "isol": [11, 32, 33, 35], "issu": [4, 6, 7, 34, 39, 43, 46, 50, 54], "issubclass": 43, "isupp": 44, "itali": 40, "item": [24, 34, 35, 37, 39, 40, 41, 43, 46, 52], "item_inverse_mapp": 39, "item_kei": 39, "item_mapp": 39, "iter": [31, 36, 37, 38, 41], "iterable_with_config": 29, "iterrow": 39, "its": [8, 24, 26, 27, 29, 30, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 48, 50, 53, 54], "itself": [7, 32, 34, 38, 40], "j": [8, 30, 35, 36, 37, 39, 41], "j6": 44, "jackin": 31, "jackpot": 29, "jaguar": [24, 41], "jalebi": 40, "jam": 31, "jame": [40, 43, 44], "jan": 1, "januari": 42, "japan": 40, "jargon": 25, "jason": [10, 36], "javascript": 35, "jazz_musician": 40, "jellyfish": 41, "jennif": 44, "jerri": 39, "jet": 28, "jetti": 41, "jieba": 40, "jim": 39, "jmlr": 31, "joan_baez": 40, "job": [29, 42, 43, 53], "joblib": 29, "john": 34, "johnny_cash": 40, "join": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54], "jointli": 42, "joke": [24, 39], "jolen": 44, "joni_mitchel": 40, "joseph": 54, "journal": 40, "journei": [10, 38, 54], "jpg": 41, "ju": 24, "jubatu": [24, 41], "judg": 36, "juic": 40, "juli": 42, "jun": 54, "june": [10, 42], "junh": 54, "jupyt": [1, 7, 8, 9, 11, 24, 28, 29, 31, 32, 33, 34, 35, 36, 41, 44], "jupyter_notebook": 43, "jupyterlab": 35, "jurafski": 40, "jurisdict": 40, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 48, 52, 53, 54], "justic": [35, 40, 54], "justif": 52, "k": [7, 10, 15, 26, 30, 32, 33, 34, 36, 40, 41, 43, 44, 45, 48, 54], "k_neighbor": 32, "k_valu": 27, "kaggl": [25, 28, 32, 33, 34, 35, 36, 41, 51, 52], "kaggler": 36, "kangaroo": 41, "kaplan": 54, "kaplanmeierfitt": 43, "kb": [29, 33, 43], "kbinsdiscret": 36, "kbinsdiscretizer__latitude_0": 36, "kbinsdiscretizer__latitude_1": 36, "kbinsdiscretizer__latitude_2": 36, "kbinsdiscretizer__latitude_3": 36, "kbinsdiscretizer__latitude_4": 36, "kbinsdiscretizer__latitude_5": 36, "kbinsdiscretizer__latitude_6": 36, "kbinsdiscretizer__latitude_7": 36, "kbinsdiscretizer__latitude_8": 36, "kbinsdiscretizer__latitude_9": 36, "kbinsdiscretizer__longitude_11": 36, "kbinsdiscretizer__longitude_12": 36, "kbinsdiscretizer__longitude_13": 36, "kbinsdiscretizer__longitude_14": 36, "kbinsdiscretizer__longitude_15": 36, "kbinsdiscretizer__longitude_16": 36, "kbinsdiscretizer__longitude_17": 36, "kbinsdiscretizer__longitude_18": 36, "kbinsdiscretizer__longitude_19": 36, "kbinsdiscretizerkbinsdiscret": 36, "kc_house_data": [24, 25, 48], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 32, 34, 35, 36, 37, 39, 40, 43, 48, 49, 54], "keep_empty_featur": 39, "kei": [9, 25, 26, 27, 28, 31, 32, 33, 34, 39, 40, 43, 50, 52, 54], "kelbowvisu": 37, "kellei": 30, "kelli": 54, "kept": 26, "kera": 35, "kernel": [7, 10, 15, 28, 30, 31, 35, 36, 48], "kernelapp": 44, "kernelbas": 44, "kernelexplain": 35, "keyword": [4, 31, 44], "kfold": 32, "kick": 40, "kilian": 35, "kill": 43, "kimia": 54, "kind": [0, 24, 25, 26, 28, 29, 30, 32, 33, 35, 37, 38, 39, 41, 42, 43, 45, 53], "king": [39, 40, 48], "kitchenabvgr": [33, 35], "kitchenqu": [33, 35], "kiwi": 40, "kk": 37, "km": [43, 46], "km_label": 37, "kmean": [37, 38, 46], "kmf": 43, "kmqfw": 43, "kneighborregressor": 28, "kneighborsclassifi": [28, 29, 30, 36, 48, 49], "kneighborsregressor": [28, 29, 30, 49], "kneighborsregressorkneighborsregressor": [28, 29], "knew": 37, "knn": [2, 15, 26, 27, 28, 29, 30, 35, 36, 39, 41, 45, 46, 52], "knn1": 27, "knn100": 27, "knn_pipe": 29, "knn_scale": 28, "knn_unscal": 28, "knn_valid_accuraci": 27, "knnimput": 39, "knob": 25, "know": [8, 10, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54], "knowledg": [8, 25, 29, 31, 36, 37, 40, 46], "knowleg": 46, "known": [39, 40, 43], "koala": 41, "kolhatkar": [0, 1, 40], "kr9rkqfj4w78h49djkz8yy9r0000gp": 26, "ksatr": 43, "kvarada": [11, 25, 26, 29, 31, 35, 40, 41, 43, 45], "kvarada01": 11, "kwantlen": 40, "kwarg": [26, 28, 29, 43, 44], "l": 11, "l1": [10, 43], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 32, "l2": [10, 32, 40, 43], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "lab": [11, 25, 26, 37, 39], "lab1": [25, 26, 29, 46], "lab2": [25, 26, 29, 46], "lab3": [25, 26, 29, 46], "lab4": [25, 26, 29, 46], "label": [7, 8, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 49], "label_": [40, 44], "label_encod": [34, 35], "label_n_clust": 38, "labelencod": [34, 35], "labels": [32, 37], "labels_": [37, 38], "lack": [26, 39], "lag": [43, 46], "lag_df": 42, "lakehead_univers": 40, "lakeshor": 41, "lakesid": 41, "lambda": [8, 25, 30, 38, 41, 42, 43, 44], "land": 43, "landcontour": [33, 35], "landcontour_bnk": 33, "landcontour_hl": 33, "landcontour_low": 33, "landcontour_lvl": 33, "landmark": 46, "landown": 44, "landscap": [37, 40], "landslop": [33, 35], "landslope_gtl": [33, 35], "landslope_mod": [33, 35], "landslope_sev": [33, 35], "langara_colleg": 40, "languag": [2, 9, 28, 29, 39, 41, 44], "language_enc": 28, "language_english": 28, "language_french": 28, "language_hindi": 28, "language_mandarin": 28, "language_spanish": 28, "language_vietnames": 28, "laptop": 24, "lar": 24, "larg": [24, 26, 27, 28, 30, 32, 33, 37, 38, 40, 41, 46, 48, 51], "larger": [25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 43], "largest": 33, "larvatu": [24, 41], "last": [8, 25, 26, 27, 28, 29, 32, 35, 39, 41, 42, 43, 44, 48, 50, 52, 53, 54], "last_row": 8, "lastp": 38, "lat": [24, 25], "late": [32, 54], "latent": [39, 40, 41], "latentdirichletalloc": 40, "later": [11, 25, 29, 32, 41, 42, 48], "latest": [29, 35, 43], "latex": [4, 7], "latin": [24, 32, 51], "latitud": [26, 27, 28, 29, 30, 36, 49], "latitude_0": 36, "latitude_1": 36, "latitude_10": 36, "latitude_11": 36, "latitude_12": 36, "latitude_13": 36, "latitude_14": 36, "latitude_15": 36, "latitude_16": 36, "latitude_17": 36, "latitude_18": 36, "latitude_19": 36, "latitude_2": 36, "latitude_3": 36, "latitude_4": 36, "latitude_5": 36, "latitude_6": 36, "latitude_7": 36, "latitude_8": 36, "latitude_9": 36, "latter": 33, "launch_inst": 44, "launch_new_inst": 44, "lauvagrand": 44, "law": 40, "lawsuit": 40, "layer": 41, "layout": [27, 48], "lazi": 27, "lbfg": 32, "lda": 41, "ldot": 31, "lead": [8, 10, 26, 30, 33, 38, 39, 40, 43], "leaf": [25, 38, 40], "leagu": 40, "leak": [28, 43, 46], "leakag": 46, "leaner": 26, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "learner": [26, 27, 34], "learning_method": 40, "learning_r": 34, "learnxinyminut": 9, "least": [4, 10, 26, 27, 32, 33, 35, 36, 37, 38, 52, 53, 54], "least_confident_i": 30, "least_confident_x": 30, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 38, 41, 43, 45], "lec11": 19, "lectur": [5, 7, 8, 11, 19, 46, 51], "lecun": 35, "lee": 35, "left": [7, 24, 31, 32, 33, 37, 38, 40, 42, 43, 54], "legal": [0, 40], "legend": [7, 8, 27, 30, 32, 33, 36, 37, 41, 42, 43, 45], "legendari": 44, "leisur": 32, "lemma": 40, "lemma_": 40, "lemmat": 40, "lemon": 37, "len": [26, 28, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44], "length": [25, 26, 27, 30, 33, 35, 37, 38, 40, 42, 43, 44, 48, 53], "leo": 34, "leopard": [24, 41], "leq": [36, 37], "less": [5, 6, 10, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 43, 46, 48, 51], "lesson": [9, 28, 44], "lesssim": 26, "let": [24, 25, 26, 30, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "letter": [30, 44], "lev": 33, "level": [27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 51, 54], "leverag": [35, 39], "lewi": 44, "lexic": 40, "lexicon": 44, "lg": [19, 23], "lgbm": [34, 35, 46, 54], "lgbmclassifi": [24, 34, 35, 52], "lgbmclassifierifittedlgbmclassifi": [24, 35], "lgbmclassifierlgbmclassifi": 34, "lgbmregressor": [24, 34], "li": 30, "liabil": 0, "liabl": 0, "liao": 24, "lib": [25, 26, 29, 31, 35, 43, 44, 45], "librari": [4, 8, 11, 26, 32, 35, 36, 40, 41, 42, 44, 48], "licensor": 0, "life": [25, 30, 37, 39, 47, 54], "lifelin": [43, 54], "lifetim": 43, "lighter": 31, "lightgbm": [24, 35, 52], "lightweight": 40, "like": [2, 4, 7, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54], "likelihood": 43, "likewis": 7, "lime": 35, "limit": [0, 24, 25, 26, 29, 34, 35, 44, 46, 47, 50, 54], "linalg": 40, "line": [4, 8, 11, 25, 29, 30, 31, 32, 33, 37, 40, 41, 42, 43, 44, 48, 50], "line2d": 8, "linear": [10, 17, 21, 22, 23, 31, 32, 34, 36, 38, 39, 41, 42, 43, 45, 46], "linear_model": [24, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 51, 52, 53], "linear_svc": 30, "linearli": [30, 36, 42], "linearregress": [30, 33, 36, 43, 44], "linestyl": [37, 42, 53], "linewidth": 42, "linger": 27, "lingual": 40, "linguist": 29, "link": [0, 4, 5, 7, 10, 24, 25, 29, 30, 33, 34, 38, 43], "linkag": 38, "linkage_arrai": 38, "linkage_typ": 38, "linkedin": 39, "linspac": [30, 31, 33, 36, 50], "lion": 39, "list": [4, 7, 8, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 43, 52, 54], "listedcolormap": 30, "liter": 44, "literatur": 34, "littl": [8, 32, 41], "live": [10, 11, 27, 28, 29, 31, 37, 43, 50], "liver": 25, "livestream": 54, "ll": [6, 7, 10, 11, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 48, 53, 54], "llazx": 43, "llm": 10, "lo": 44, "load": [8, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 44, 48, 49, 51], "load_breast_canc": 36, "load_citibik": 42, "load_iri": [27, 48], "loan": [32, 51], "loc": [8, 27, 30, 32, 35, 39, 42, 43, 53], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 32, 34, 35, 36, 41, 44], "locat": [8, 29, 37, 39, 40, 42, 44, 52, 53, 54], "location_katherin": 42, "location_mountginini": 42, "location_townsvil": 42, "location_witchcliff": 42, "location_wollongong": 42, "lock": 26, "log": [27, 33, 34, 43, 48, 52, 54], "log10": 33, "log1p": 33, "log2": 43, "log_likelihood_ratio_test": 43, "logarithm": [27, 48], "logic": 36, "logical_xor": 36, "login": 39, "logisit": 41, "logist": [17, 34, 35, 42, 43, 44, 45, 46, 51, 52, 53], "logisticregress": [24, 30, 33, 34, 35, 36, 40, 41, 44, 45, 51, 52, 53], "logisticregressionifittedlogisticregress": 41, "logisticregressionlogisticregress": [32, 34, 41, 44], "logloss": 35, "lognorm": 31, "logspac": [31, 50], "loguniform": [31, 50], "lol": 29, "london": 44, "lone": 38, "long": [0, 24, 25, 30, 32, 34, 38, 39, 43, 46, 54], "longer": [7, 31, 32, 41, 43], "longest": 25, "longitud": [26, 27, 28, 29, 30, 36, 49], "longitude_0": 36, "longitude_1": 36, "longitude_10": 36, "longitude_11": 36, "longitude_12": 36, "longitude_13": 36, "longitude_14": 36, "longitude_15": 36, "longitude_16": 36, "longitude_17": 36, "longitude_18": 36, "longitude_19": 36, "longitude_2": 36, "longitude_3": 36, "longitude_4": 36, "longitude_5": 36, "longitude_6": 36, "longitude_7": 36, "longitude_8": 36, "longitude_9": 36, "look": [1, 11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52], "lookatm": 24, "loop": [31, 34, 42, 45, 46], "loos": 38, "lose": [6, 29], "loss": [2, 32, 33, 34, 35, 40, 43, 51], "lot": [5, 9, 24, 25, 27, 29, 30, 31, 32, 33, 35, 36, 38, 41, 42, 43, 50, 54], "lotarea": [33, 35], "lotconfig": [33, 35], "lotconfig_corn": 33, "lotconfig_culdsac": 33, "lotconfig_fr2": 33, "lotconfig_fr3": 33, "lotconfig_insid": 33, "lotfrontag": [33, 35], "lotshap": [33, 35], "lotshape_ir1": 33, "lotshape_ir2": 33, "lotshape_ir3": 33, "lotshape_reg": 33, "loud": [27, 28, 31, 46, 50], "loui": 42, "lourenzutti": 31, "love": 44, "low": [6, 26, 27, 31, 32, 33, 35, 36, 37, 38, 43], "lower": [26, 27, 32, 33, 35, 37, 39, 40, 43, 50, 54], "lowercas": [28, 29], "lowest": [48, 54], "lowqualfinsf": [33, 35], "lr": [30, 32, 33, 35, 41, 42, 43, 44, 45], "lr_1": 36, "lr_2": 36, "lr_3": 36, "lr_coef": [35, 42, 43, 53], "lr_coefs_landslop": 35, "lr_flatten_pip": 41, "lr_item": 39, "lr_pipe": [33, 35, 42], "lr_pred": [32, 33], "lr_scale": 35, "lr_schedul": 41, "lr_x": 39, "lr_y": 39, "ls15hb": 24, "lstm": 42, "lt": [26, 28, 29, 31, 32, 33, 34, 35, 36, 43], "ltorgo": 30, "lucki": [27, 31], "luckili": [50, 52], "lundberg": 35, "luster": 38, "lvert": 40, "lvl": [33, 35], "lwq": [33, 35], "lynx": [24, 41], "l\u00e9cuyer": 40, "m": [11, 24, 26, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], "m_neighbor": 32, "ma": [31, 40], "macaqu": [24, 41], "macbook": 11, "mach": 40, "machin": [2, 9, 10, 11, 13, 14, 15, 28, 29, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 48, 53, 54], "mackworth": 10, "made": [0, 6, 7, 8, 24, 25, 32, 34, 35, 39, 40, 41, 42, 50], "magazin": 40, "magnitud": [31, 33, 35, 40, 42, 53], "maguir": 39, "mahsa": 54, "mai": [0, 7, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54], "mail": 43, "main": [8, 11, 25, 27, 29, 34, 37, 38, 46, 54], "mainland": 30, "maintain": [34, 39, 46], "mainten": 34, "maj1": [33, 35], "maj2": [33, 35], "major": [2, 26, 27, 28, 29, 40, 46, 47, 52], "major_biologi": 29, "major_comput": 29, "major_econom": 29, "major_linguist": 29, "major_mathemat": 29, "major_mechan": 29, "major_phys": 29, "major_psychologi": 29, "make": [2, 4, 5, 6, 7, 11, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54], "make_blob": [27, 37, 38, 41, 45], "make_circl": 38, "make_classif": [27, 32], "make_column_transform": [31, 32, 33, 34, 35, 36, 42, 43, 44, 49, 50, 51, 52, 53], "make_forg": 27, "make_grid": 41, "make_imb_pipelin": 32, "make_moon": 38, "make_num_tree_plot": 34, "make_pipelin": [24, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 49, 50, 51, 52, 53], "make_scor": [33, 36, 44], "malcolm": [37, 39], "malcom": 37, "male": [32, 34, 35, 43, 51], "male_cm": [32, 51], "male_pr": [32, 51], "mall": 44, "man": [39, 40], "manag": [5, 42, 43, 46, 54], "mandarin": 28, "mango": 40, "mani": [2, 5, 8, 10, 24, 25, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 50, 52, 53, 54], "manner": [0, 34], "manual": [11, 24, 29, 32, 36, 37, 38, 40, 50], "manufactur": 41, "map": [10, 25, 26, 29, 31, 39, 50], "mape": 46, "mape_scor": 33, "maple_leaf": 40, "mapper": 39, "march": 42, "marit": [32, 34, 35, 51], "mark": [6, 7, 31, 32, 38, 54], "marker": [27, 30, 37], "markers": [30, 32], "market": [24, 37, 41, 42], "markov": 40, "marri": [32, 34, 35], "martin": 40, "mask": 31, "massiv": [29, 31], "master": [8, 31, 32, 34, 35, 40, 51], "masvnrarea": [33, 35], "masvnrtyp": [33, 35], "masvnrtype_brkcmn": 33, "masvnrtype_brkfac": 33, "masvnrtype_miss": 33, "masvnrtype_ston": 33, "match": [29, 30, 32, 34, 35, 42, 52, 53], "materi": [8, 11, 19, 24, 25, 26, 27, 37, 40, 43, 46, 54], "matern": 36, "math": [2, 37, 39, 43], "mathcal": 27, "mathemat": [2, 29, 34, 46], "mathematician": 40, "mathia": 44, "matlab": 8, "matplotlib": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "matplotlibdeprecationwarn": 35, "matric": [27, 32, 39, 51], "matrix": [18, 29, 38, 40, 46, 51], "matter": [28, 29, 32, 34, 38, 46], "max": [8, 26, 28, 30, 31, 32, 33, 34, 37, 38, 42, 53], "max_bin": 34, "max_cat_threshold": 34, "max_cat_to_onehot": 34, "max_clust": 38, "max_colwidth": [24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 39, 47, 48, 49, 50, 51], "max_delta_step": 34, "max_depth": [26, 27, 31, 34, 35, 47, 48], "max_depth_widget": [27, 48], "max_df": 29, "max_displai": 35, "max_featur": [24, 29, 31, 34, 50], "max_it": [24, 32, 34, 35, 36, 40, 41, 42, 43, 44, 45, 51], "max_leaf_nod": 25, "max_leav": 34, "max_opt": [27, 32, 37, 38], "max_row": 43, "maxclust": 38, "maxent": 45, "maxhr": 52, "maxim": [24, 32, 33, 37], "maximum": [25, 28, 33, 34, 37, 38, 48, 54], "maxosx": 11, "maxtemp": [42, 53], "may": 10, "mayb": [32, 35, 42, 54], "maybe_coerce_valu": 43, "mb": [28, 29, 32, 36, 42, 43, 53], "md": [11, 25, 40], "me": [8, 24, 31, 40, 44], "mean": [5, 6, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54], "mean_absolute_percentage_error": 33, "mean_cv_error": 26, "mean_cv_scor": [27, 30, 31], "mean_fit_tim": [31, 33], "mean_scor": [26, 28, 31, 44], "mean_score_tim": [31, 33], "mean_squared_error": [33, 36, 44], "mean_std_cross_val_scor": [26, 28, 29, 34, 35, 43, 44], "mean_test_neg_mean_squared_error": 33, "mean_test_scor": [31, 33, 50], "mean_train_error": 26, "mean_train_neg_mean_squared_error": 33, "mean_train_scor": [27, 30, 31, 33], "meaning": [27, 29, 32, 35, 37, 40, 49, 54], "meaningless": 38, "measur": [0, 24, 25, 26, 27, 32, 33, 35, 37, 38, 39, 40, 42, 43, 46, 48, 52, 53], "mechan": [29, 46], "mechanical_engin": 40, "medal": 8, "median": [25, 28, 29, 30, 33, 35, 36, 42, 43, 53], "median_house_valu": [28, 29, 36, 49], "median_incom": [28, 29, 36, 49], "medic": [32, 37, 54], "medinc": 30, "medit": 32, "medium": [0, 27, 43, 46], "meet": 40, "meier": 54, "melbourneairport": [42, 53], "member": [30, 34, 54], "membership": [29, 37, 38], "memori": [8, 28, 29, 32, 33, 34, 36, 41, 42, 43, 46, 53], "mention": [0, 4, 30, 43], "menu": 11, "merchant": 0, "merg": [0, 5, 11, 38], "meshgrid": 36, "mess": [39, 43], "messag": [4, 6, 11, 26, 29], "messi": [36, 40], "met": 54, "meta": 34, "metacademi": 10, "method": [2, 25, 27, 28, 30, 32, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 52, 53, 54], "methodologi": [28, 42], "metric": [10, 27, 29, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 51, 52, 54], "mexico": 32, "mglearn": [25, 26, 27, 28, 29, 30, 31, 32, 37, 40, 41, 42, 45, 47, 48, 50, 51], "mi": [24, 31, 32], "microsoft": 44, "midnight": 42, "midterm": [6, 10], "might": [6, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 48, 54], "mightn": 40, "mike": [0, 1, 9, 25, 50], "mikolov": 40, "milk": 40, "mill": 34, "millennia": 54, "million": 41, "min": [10, 30, 33, 38, 42, 53], "min1": [33, 35], "min2": [33, 35], "min_child_weight": 34, "min_df": 29, "min_sampl": 38, "min_samples_leaf": 25, "min_samples_split": 25, "min_token_len": 40, "min_token_length": 40, "mind": [26, 28, 29, 34, 35, 39, 43, 46, 54], "mine": 10, "minibatchkmean": 38, "miniconda": 11, "miniconda3": [11, 44], "miniforge3": [25, 26, 29, 31, 35, 43, 45], "minim": [5, 25, 33, 37, 38], "minimum": [8, 26, 28, 38, 40], "minmaxscal": [28, 29], "minor": [6, 43], "mintemp": [42, 53], "minut": [4, 25, 36, 43, 46], "miracl": 44, "miscalcul": 10, "miscfeatur": [33, 35], "miscfeature_gar2": 33, "miscfeature_miss": 33, "miscfeature_othr": 33, "miscfeature_sh": 33, "miscfeature_tenc": 33, "misclassifi": 51, "misconduct": 54, "miscval": [33, 35], "mislead": [26, 32], "miss": [11, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 43, 46, 48, 50, 51, 53, 54], "mistak": [28, 34, 43, 48], "mit": [0, 1], "mitig": [39, 54], "mitlp": 43, "mitt": 40, "mitten": 40, "mix": 33, "mixtur": [38, 40, 41], "ml": [2, 9, 10, 14, 15, 25, 28, 34, 38, 40, 41, 54], "ml_experi": [25, 26, 29, 46], "mlpclassifi": 41, "mlpregressor": 41, "mm": [42, 53], "mmsto": 24, "mn": [33, 35], "mnprv": [33, 35], "mnww": [33, 35], "mo": 40, "mobil": [29, 41], "mobilenet": 41, "mod": [33, 35], "mode": [27, 28, 31, 50], "model": [2, 10, 19, 20, 21, 22, 23, 31, 32, 37, 38, 39, 42, 45, 47, 50, 53, 54], "model_nam": 39, "model_select": [24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 53], "modern": [10, 27, 40], "modif": 43, "modifi": [0, 11, 32, 43, 54], "modul": [9, 10, 25, 26, 32, 44], "moe": 31, "mole": 41, "mom": 36, "moment": [32, 50, 52, 54], "mon": [10, 42], "monarch": 40, "monarchi": 40, "mondai": [10, 42, 54], "monei": [8, 43], "monitor": 40, "monkei": [24, 41], "monotone_constraint": 34, "montani": 44, "month": [26, 29, 33, 43, 53], "month_nam": [42, 53], "monthli": 43, "monthlycharg": 43, "montreal": [40, 44], "moon": 38, "moosvi": [0, 1, 40, 54], "moral": [0, 37], "more": [1, 2, 5, 6, 8, 10, 11, 14, 26, 31, 34, 35, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54], "morn": 24, "morpholog": 40, "moskowitz": 37, "mosold": [33, 35], "mosold_1": 33, "mosold_10": 33, "mosold_11": 33, "mosold_12": 33, "mosold_2": 33, "mosold_3": 33, "mosold_4": 33, "mosold_5": 33, "mosold_6": 33, "mosold_7": 33, "mosold_8": 33, "mosold_9": 33, "most": [7, 8, 11, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 52, 54], "most_confident_i": 30, "most_confident_x": 30, "most_frequ": [25, 27, 28, 32, 33, 35, 47], "most_similar": 40, "mostli": [8, 29, 42], "motiv": [19, 20, 21, 22, 23, 24, 29], "mountginini": 42, "move": [7, 12, 30, 35, 36, 47, 52, 54], "movi": [30, 40, 44], "movie_feats_df": 39, "movie_id": 39, "movie_nam": 39, "movies_rated_by_pat": 39, "movies_to_pr": 39, "movieto": 44, "mpimg": 41, "mri": 46, "mrtssm448usn": 42, "mse": [25, 39, 46], "msg": [29, 43], "mssubclass": [33, 35], "mssubclass_120": 33, "mssubclass_160": 33, "mssubclass_180": 33, "mssubclass_190": 33, "mssubclass_20": 33, "mssubclass_30": 33, "mssubclass_40": 33, "mssubclass_45": 33, "mssubclass_50": 33, "mssubclass_60": 33, "mssubclass_70": 33, "mssubclass_75": 33, "mssubclass_80": 33, "mssubclass_85": 33, "mssubclass_90": 33, "mszone": [33, 35], "mszoning_c": [33, 35], "mszoning_fv": 33, "mszoning_rh": 33, "mszoning_rl": 33, "mszoning_rm": 33, "much": [4, 5, 8, 25, 26, 27, 28, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 48, 50, 54], "mueller": 10, "multi": [33, 35, 37, 40, 42], "multi_class": [32, 45], "multi_strategi": 34, "multiclass": [41, 45], "multicoliniar": 35, "multicultur": 40, "multilevel": 33, "multimod": 37, "multinomi": 45, "multipl": [7, 8, 26, 30, 31, 34, 35, 40, 41, 42, 43, 53], "multiplelin": 43, "multiplelines_no": 43, "multiplelines_y": 43, "multipli": [30, 31, 32, 34, 36, 43], "music": [39, 44], "musqueam": 54, "must": [0, 6, 7, 8, 25, 26, 28, 35, 38, 40, 43, 44, 54], "mustn": 40, "mutual": 38, "mwf": 54, "my": [6, 11, 24, 31, 32, 37, 40, 44, 54], "my_heatmap": [31, 50], "my_map": 33, "mypreprocessor": 40, "myself": [25, 40], "m\u00fcller": 9, "n": [10, 25, 27, 30, 31, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 48, 53], "n_bin": 36, "n_class": [27, 32, 51], "n_cluster": [37, 38], "n_clusters_per_class": 32, "n_compon": 40, "n_constitu": 34, "n_estim": [36, 42, 43], "n_exampl": 37, "n_feat": 27, "n_featur": [27, 32, 37, 50], "n_features_to_select": 36, "n_inform": 32, "n_init": 37, "n_iter": 50, "n_job": [29, 32, 33, 34, 50], "n_neighbor": [39, 48], "n_neighbors_selector": 27, "n_neighbors_widget": [27, 48], "n_redund": 32, "n_rental": 42, "n_rentalsin3hour": 42, "n_rentalsin6hour": 42, "n_repeat": 35, "n_resourc": 31, "n_sampl": [27, 32, 37, 38, 41, 45, 51], "n_split": 42, "n_threshold": 32, "n_topic": 40, "n_train": 42, "n_word": [40, 44], "na": [33, 35], "nafter": 40, "nah": 29, "naiv": 38, "name": [4, 5, 6, 7, 8, 11, 25, 27, 28, 29, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 48, 52, 53, 54], "named_estimators_": 34, "named_step": [30, 32, 33, 34, 35, 36, 42, 44, 53], "named_transformers_": [29, 32, 33, 34, 35, 36, 42, 43, 44, 51, 53], "nan": [28, 29, 32, 33, 34, 35, 36, 39, 42, 43, 44, 46, 51, 53], "nanmean": 39, "nanosecond": 42, "narr": 40, "narrow": 39, "nasali": [24, 41], "nation": 54, "nativ": [32, 34, 35, 41, 45, 51], "natur": [2, 24, 29, 32, 34, 36, 41, 45, 54], "navig": [7, 11], "nbsp": [24, 28, 29, 31, 33, 34, 35, 36, 41], "nbviewer": [24, 28, 29, 31, 32, 33, 34, 35, 36, 41, 44], "nc": 1, "ncol": 30, "ndarrai": [8, 29], "ndate": 44, "ndframe": [36, 43], "ndim": 8, "ne": [42, 53], "nearbi": [27, 37], "nearest": [15, 32, 38, 48], "necessari": [0, 7, 25, 31, 46, 49], "necessarili": [26, 33, 34, 39], "necvq": 43, "need": [5, 7, 8, 11, 24, 25, 27, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 52, 53, 54], "needn": 40, "neg": [25, 26, 27, 30, 33, 34, 35, 40, 42, 43, 44, 48, 51], "neg_mean_absolute_percentage_error": 33, "neg_mean_squared_error": 33, "neg_root_mean_square_error": 33, "neg_root_mean_squared_error": 33, "neigh": 27, "neighbor": [27, 28, 29, 30, 32, 36, 38, 48, 49], "neighborhood": [30, 33, 35], "neighborhood_blmngtn": 33, "neighborhood_bluest": 33, "neighborhood_brdal": 33, "neighborhood_brksid": 33, "neighborhood_clearcr": 33, "neighborhood_collgcr": 33, "neighborhood_crawfor": 33, "neighborhood_edward": 33, "neighborhood_gilbert": 33, "neighborhood_idotrr": 33, "neighborhood_meadowv": 33, "neighborhood_mitchel": 33, "neighborhood_nam": 33, "neighborhood_noridg": [33, 35], "neighborhood_npkvil": 33, "neighborhood_nridght": [33, 35], "neighborhood_nwam": 33, "neighborhood_oldtown": [33, 35], "neighborhood_sawy": [33, 35], "neighborhood_sawyerw": [33, 35], "neighborhood_somerst": [33, 35], "neighborhood_stonebr": [33, 35], "neighborhood_swisu": [33, 35], "neighborhood_timb": [33, 35], "neighborhood_veenk": [33, 35], "neighbour": [15, 26, 35, 37, 38, 40, 48], "neighbourhood": [30, 36, 38, 49], "neither": [26, 29, 39], "neq": [35, 39], "ner": 40, "nervou": 25, "nest": [31, 46], "net": [41, 43], "netflix": [39, 44], "network": [10, 24, 29, 34, 36, 37, 39, 40, 42, 54], "neu": 44, "neural": [10, 36, 42, 54], "neutral": 44, "never": [32, 34, 35, 39, 41, 43], "new": [10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 49, 50, 52, 53], "new_cent": 37, "new_column": [33, 35, 42, 43, 53], "new_data": 43, "new_df": [42, 53], "new_exampl": [25, 37], "new_feature_nam": [42, 53], "new_valu": 43, "newaxi": 8, "newcastl": 44, "newer": 33, "newli": [28, 33, 36, 38], "newsgroup": 40, "newswir": 40, "next": [11, 25, 26, 27, 28, 29, 32, 33, 34, 40, 41, 42, 49, 50, 51, 52, 54], "nfeat": 27, "nfeats_accuraci": 27, "ng": [9, 10, 31, 36], "ngram": 36, "ngram_rang": 29, "nhl": 40, "nhqxu": 43, "nice": [4, 31, 32, 34, 35, 38, 41, 43], "nicki": 31, "night": [32, 42], "niki": 54, "nlemma": 40, "nlp": [29, 41, 44], "nltk": [40, 44], "nltk_data": [40, 44], "nn": [10, 28, 41, 44, 48], "nne": [42, 53], "nnw": [42, 53], "nnz": 29, "no_grad": 41, "nobodi": 24, "node": [25, 34, 38, 41, 47], "nois": [38, 46, 48], "non": [1, 8, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 38, 39, 41, 42, 43, 46, 51, 53, 54], "noncommerci": 1, "none": [10, 26, 28, 29, 30, 31, 32, 34, 36, 38, 42, 43, 44, 52], "noninfring": 0, "nonzero": 29, "noqa": [31, 44], "nor": [7, 26, 29, 40], "norg": [40, 44], "norm": [31, 40], "normal": [6, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 51, 52], "north": 40, "norvig": 10, "notat": 27, "note": [0, 3, 7, 9, 10, 11, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 45, 46, 50, 51, 53, 54], "notebook": [5, 7, 9, 11, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 41, 44, 49, 53], "notic": [0, 29, 30, 32, 33, 36], "notion": [27, 31, 37, 39], "notna": [42, 53], "noun": [40, 44], "nov": 42, "novel": 46, "novemb": 42, "novic": 9, "now": [8, 11, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52], "np": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "nperson": 44, "npie": 8, "npo": 40, "npr": [36, 40, 44, 46], "nsubj": 40, "ntest": [27, 31, 48], "ntoken": 40, "ntree": 34, "null": [28, 29, 32, 33, 36, 42, 43, 53], "null_distribut": 43, "num": [32, 34, 35, 51], "num_output_channel": 41, "num_parallel_tre": 34, "num_sent": 32, "num_work": 41, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 43, 46, 48, 50, 53, 54], "number_test": 31, "numberbatch": 40, "numer": [2, 25, 28, 29, 30, 32, 33, 34, 39, 40, 42, 43, 48, 49, 51, 53], "numeric_feat": [29, 31, 36, 46, 50], "numeric_featur": [29, 32, 33, 34, 35, 42, 43, 44, 51, 52, 53], "numeric_looking_column": 33, "numeric_transform": [29, 32, 33, 34, 35, 42, 51, 52, 53], "numpi": [9, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "numpy_dtyp": 43, "nutrit": 40, "nw": [42, 53], "nwith": 27, "ny": 44, "o": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "obelisk": 41, "object": [26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 44, 46, 47, 48, 50, 51, 53], "observ": [24, 25, 26, 27, 34, 35, 37, 38, 42, 43, 48, 51, 52, 53], "obtain": [0, 30, 37, 38, 39, 43, 48, 50], "obviou": [38, 40], "occasion": 32, "occup": [32, 34, 35, 51], "occupation_farm": 35, "occupation_miss": 35, "occupation_priv": 35, "occupi": 54, "occur": [8, 25, 26, 29, 40, 43], "occurr": [40, 43], "ocean": [28, 29, 36, 49], "ocean_proxim": [28, 29, 36, 49], "ocean_proximity_": [28, 29], "ocean_proximity_inland": [28, 29], "ocean_proximity_island": [28, 29], "ocean_proximity_near": [28, 29], "oct": 30, "octob": 42, "oe": [29, 46], "oe_encod": 46, "off": [30, 31, 32, 33, 36, 37, 40, 41, 43, 46, 50, 54], "off_shelf": 52, "offens": 4, "offer": [8, 34, 39, 40, 43, 54], "offic": [4, 11, 46, 54], "offici": [40, 54], "offlin": 39, "offset": 30, "often": [8, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48], "ogunrind": 24, "oh": [35, 36, 41, 42, 43, 46, 50, 53], "ohe_column": [33, 35], "ohe_enc": 29, "ohe_encod": 46, "ohe_feature_nam": [35, 42, 53], "ohehotencod": 29, "ois": 38, "ok": [24, 27, 33, 42, 43, 46, 53], "okai": 37, "ola": 40, "old": [9, 34, 35], "old_cent": 37, "older": 33, "oldpeak": 52, "olymp": 8, "omit": 35, "omw": 40, "onc": [6, 7, 8, 11, 25, 26, 28, 29, 31, 36, 38, 39, 40, 41, 50, 51, 52, 54], "onca": [24, 41], "one": [6, 8, 9, 11, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54], "one_c": 27, "one_ex_preprocess": 35, "one_ex_preprocessed_perturb": 35, "one_exampl": 35, "one_example_perturb": 35, "onehot": [29, 36], "onehotencod": [28, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44, 46, 49, 50, 51, 52, 53], "onehotencoder__major_biologi": 29, "onehotencoder__major_comput": 29, "onehotencoder__major_econom": 29, "onehotencoder__major_linguist": 29, "onehotencoder__major_mathemat": 29, "onehotencoder__major_mechan": 29, "onehotencoder__major_phys": 29, "onehotencoder__major_psychologi": 29, "onehotencoderonehotencod": [29, 31, 33, 34], "ones": [8, 24, 27, 28, 34, 35, 37, 39, 40, 48, 52], "onevsoneclassifi": 45, "onevsrestclassifi": 45, "onli": [2, 4, 8, 11, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 48, 49, 51, 54], "onlin": [3, 5, 7, 11, 25, 40, 54], "onlinebackup": 43, "onlinebackup_no": 43, "onlinebackup_y": 43, "onlinesecur": 43, "onlinesecurity_no": 43, "onlinesecurity_y": 43, "ontario": 40, "ontonot": 40, "op": 32, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 41, 54], "openporchsf": [33, 35], "oper": [4, 8, 11, 29, 36, 40], "operand": 8, "opinion": 34, "opportun": 39, "oppos": [33, 34], "opposit": [8, 33, 34, 35, 53], "opt": [11, 34], "optic": 43, "optim": [2, 10, 25, 26, 27, 29, 32, 34, 35, 36, 37, 38, 41, 43, 50], "optimist": 31, "option": [7, 8, 10, 25, 33, 37, 40, 50, 52, 53], "oracl": 10, "orang": 30, "order": [5, 7, 8, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 46], "ordering_ordinal_oth": [33, 35], "ordering_ordinal_reg": [33, 35], "ordin": [33, 46, 49], "ordinal_feat": 29, "ordinal_featur": [32, 34, 35, 51], "ordinal_features_oth": [33, 35], "ordinal_features_reg": [33, 35], "ordinal_transform": [32, 34, 35, 51], "ordinal_transformer_oth": [33, 35], "ordinal_transformer_reg": [33, 35], "ordinalencod": [28, 29, 32, 33, 34, 35, 36, 42, 43, 44, 46, 49, 51, 52, 53], "ordinalencoderordinalencod": [29, 33, 34], "ordinari": 33, "oreilli": [41, 42], "org": [9, 24, 26, 28, 29, 31, 32, 33, 34, 35, 36, 40, 41, 44], "organ": [24, 25, 28, 40], "orgin": 8, "orig_featur": [42, 53], "orig_pr": 35, "orig_scor": 32, "origin": [28, 29, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 48, 50, 53, 54], "original_hm": 32, "originaltweet": 44, "ornithorhynchu": 41, "oscar": 30, "ostblom": 40, "other": [0, 1, 4, 5, 6, 7, 11, 25, 26, 28, 29, 30, 31, 32, 34, 35, 38, 39, 41, 44, 45, 46, 48, 50, 51, 52, 53, 54], "otherwis": [0, 7, 29], "ounc": [24, 41], "our": [5, 6, 8, 11, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 54], "ourselv": [25, 32, 40, 41, 42], "out": [0, 4, 7, 8, 11, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54], "out_col": [26, 28, 44], "out_step": 32, "outcom": 12, "outer": 44, "outlier": [33, 38, 46], "outlook": 43, "output": [7, 8, 11, 24, 25, 26, 29, 30, 32, 34, 35, 40, 41, 42, 46, 52, 53, 54], "outsid": [7, 32, 34, 35, 39, 40, 42, 43], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 31, 33, 40, 41, 42, 43, 46, 54], "over_confident_i": 30, "over_confident_x": 30, "over_sampl": 32, "overal": [11, 32, 35, 37, 40, 41, 46, 51, 52, 54], "overallcond": [33, 35], "overallqu": [33, 35], "overconfid": [35, 36], "overfit": [10, 27, 30, 33, 34, 36, 41, 48, 50, 52, 54], "overflow": 7, "overhead": 29, "overlap": [2, 26, 37], "overli": [27, 31, 48], "overload": [39, 43], "overpredict": 33, "oversample_pip": 32, "overshadow": 40, "overus": 34, "overview": [37, 38, 39, 40], "overwhelm": 37, "overzeal": 6, "own": [4, 5, 8, 26, 28, 32, 33, 35, 36, 37, 38, 40, 41, 42, 44, 45, 53], "p": [30, 31, 38, 40, 43], "p_i": 37, "p_value_threshold": 43, "pace": [30, 37, 40, 54], "packag": [5, 8, 25, 26, 29, 31, 32, 35, 37, 38, 39, 40, 41, 43, 44, 45, 54], "pad": 41, "page": [1, 4, 10, 24, 28, 29, 31, 32, 33, 34, 35, 36, 40, 41, 44, 52, 54], "pai": 35, "pain": [4, 41, 42, 53], "pair": [38, 40, 45], "pairwis": [27, 38], "panda": [9, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "pane": [27, 48], "panel": [27, 32, 35, 37, 38, 48], "panic": 44, "panther": [24, 41], "panthera": [24, 41], "paper": [7, 35, 36, 40, 41, 43, 44], "paperlessbil": 43, "paperlessbilling_no": 43, "paperlessbilling_y": 43, "paradigm": [24, 25, 37, 40], "paradox": 39, "paragraph": 40, "paraleg": 40, "parallel": [29, 31, 34], "param": [27, 29, 31, 33, 48], "param_columntransformer__countvectorizer__max_featur": 31, "param_dist": [31, 50], "param_distribut": [31, 50], "param_grid": [26, 27, 31, 33, 50], "param_grid1": [31, 50], "param_grid2": [31, 50], "param_grid3": 31, "param_grid4": 31, "param_ridge__alpha": 33, "param_svc__c": 31, "param_svc__gamma": 31, "paramet": [27, 28, 29, 33, 34, 35, 37, 38, 40, 42, 43, 44, 47, 48, 50, 51, 52, 53], "parametr": 38, "params_": 43, "params_str": 31, "paramter": 27, "pardu": [24, 41], "parent": [38, 44], "park": [36, 41, 44], "pars": 40, "parse_d": [8, 42, 53], "parser": 40, "part": [4, 9, 10, 11, 28, 29, 30, 31, 32, 34, 35, 36, 38, 40, 42, 44, 52, 54], "part1": 39, "part2": 39, "parti": 40, "partial": [4, 43], "particip": 54, "particular": [0, 9, 11, 28, 29, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 48, 51], "particularli": [34, 39, 54], "partit": [29, 37, 38], "partner": [43, 54], "partner_no": 43, "partner_y": 43, "parton": 44, "pass": [8, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 48], "passthrough": [29, 31, 43, 44, 50, 52], "passthrough__ml_experi": 29, "passthrough_feat": [29, 31, 46, 50], "passthrough_featur": [43, 44, 52], "passthroughpassthrough": [29, 31, 44], "past": [25, 26, 34, 42, 43, 46], "pat": 39, "pat_i": 39, "pat_model": 39, "pat_x": 39, "pata": [24, 41], "path": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "patial": 38, "patient": [25, 52], "patio": 41, "patric": 35, "patrick": 54, "pattern": [24, 25, 26, 29, 31, 36, 37, 40, 42, 48, 53], "pav_bhaji": 40, "pave": [33, 35], "paveddr": [33, 35], "paveddrive_i": 33, "paveddrive_n": 33, "paveddrive_p": 33, "paymentmethod": 43, "paymentmethod_bank": 43, "paymentmethod_credit": 43, "paymentmethod_electron": 43, "paymentmethod_mail": 43, "pca": [32, 38, 39], "pcarter": 9, "pd": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "pdf": [7, 9, 19], "peac": 40, "pedest": 41, "pedro": [10, 26, 36], "peek": 53, "peer": [46, 54], "pembrok": [24, 41], "penal": [6, 43], "penalti": [32, 40, 54], "peopl": [4, 25, 26, 28, 30, 32, 34, 37, 39, 40, 41, 42, 43, 44, 46, 48, 51, 54], "per": [8, 30, 32, 33, 34, 35, 39, 41, 42, 45, 46, 50, 51, 53], "perceiv": 6, "percent": 33, "percent_error": 33, "percentag": [25, 32, 39], "perfect": [6, 25, 26, 32, 33, 35, 39, 43, 44], "perfectli": [2, 39, 40], "perform": [25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 53, 54], "performac": 26, "perhap": [33, 42, 45], "perimet": 36, "period": [40, 42, 43, 44, 54], "perm_sorted_idx": 35, "perman": 8, "permiss": [0, 54], "permit": [0, 28, 32, 54], "permut": 35, "persist": 39, "person": [0, 4, 6, 10, 24, 32, 37, 40, 41, 42, 43, 44, 54], "perspect": [34, 39], "pertain": 5, "perthairport": [42, 53], "perturb": [35, 38], "perturbed_pr": 35, "pete_seeg": 40, "peter": 10, "ph": 40, "phascolarcto": 41, "phase": 26, "phd": 40, "phdei": 43, "phenomenon": [39, 43, 48], "philippin": 44, "philosoph": 40, "phone": [24, 43, 54], "phoneservic": 43, "phoneservice_no": 43, "phoneservice_y": 43, "photo": [44, 46], "photograph": 54, "phrase": 40, "physic": [29, 42], "pi": 8, "pick": [25, 30, 32, 34, 35, 36, 37, 38, 41, 45, 47, 48, 50, 51, 52], "pictur": [34, 35, 38, 40, 42], "pie": 8, "piec": [30, 43], "pil": [24, 41], "pin": 41, "pineappl": 40, "pip": [11, 35, 40, 41, 44], "pipe": [28, 29, 30, 31, 32, 34, 40, 41, 44, 50, 51], "pipe_bestalpha": 33, "pipe_bigalpha": 33, "pipe_catboost": 34, "pipe_dt": [34, 35, 52], "pipe_forward": 36, "pipe_knn": 52, "pipe_lgbm": [34, 35, 52], "pipe_lr": [32, 34, 35, 51, 52], "pipe_lr_all_feat": 36, "pipe_lr_balanc": [32, 51], "pipe_lr_model_bas": 36, "pipe_lr_weight": [32, 51], "pipe_rf": [34, 35, 52], "pipe_rf_demo": 34, "pipe_ridg": [30, 33], "pipe_sklearn_gb": 34, "pipe_sklearn_histgb": 34, "pipe_smallalpha": 33, "pipe_svc": 32, "pipe_svm": [31, 50], "pipe_xgb": [34, 35], "pipe_xor": 36, "pipelin": [2, 10, 16, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 44, 49, 50, 51, 52, 53, 54], "pipeline__lab1": 29, "pipeline__lab2": 29, "pipeline__lab3": 29, "pipeline__lab4": 29, "pipeline__quiz1": 29, "pipeline__rooms_per_household": 36, "pipeline__university_year": 29, "pipelineifittedpipelin": [28, 29, 31, 32, 36, 41, 44], "pipelineinot": [29, 31, 33], "pipelinepipelin": 31, "pitfal": 42, "pixel": 35, "pizza": 40, "pkg": 11, "pla": 40, "place": [5, 40, 42, 54], "plagiar": 54, "plai": [25, 27, 31, 35, 38, 40, 47, 48], "plain": 37, "plan": [11, 24, 33, 36, 43, 44, 49, 52, 54], "plane": 30, "plant": 46, "plastic": 40, "platform": [4, 44], "platypu": 41, "player": [35, 40, 41], "pleas": [1, 4, 7, 11, 24, 28, 29, 31, 32, 33, 34, 35, 36, 41, 44, 50, 54], "plinth": 41, "plot": [7, 25, 26, 27, 28, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 48, 50, 51, 53], "plot_2d_scor": 30, "plot_2d_separ": [27, 30, 48], "plot_confusion_matrix": 32, "plot_confusion_matrix_exampl": 32, "plot_cross_valid": [26, 42], "plot_dbscan": 38, "plot_dbscan_with_label": 38, "plot_dendrogram_clust": 38, "plot_elbow": 37, "plot_example_dist": 37, "plot_fruit_tre": 25, "plot_grid_search_overview": 31, "plot_k_means_dbscan_comparison": 38, "plot_km_initi": 37, "plot_km_it": 37, "plot_km_iter": 37, "plot_kmean": 38, "plot_knn_clf": 27, "plot_knn_decision_boundari": 27, "plot_knn_regress": 27, "plot_lda_w_vector": 40, "plot_linkage_criteria": 38, "plot_logistic_regress": 30, "plot_logistic_regression_graph": 41, "plot_multiclass_lr_ovr": 45, "plot_original_clust": 38, "plot_partial_effects_on_outcom": 43, "plot_result": [27, 48], "plot_scal": 28, "plot_silhouette_dist": 37, "plot_single_hidden_layer_graph": 41, "plot_support_vector": 27, "plot_survival_funct": 43, "plot_svc_c": 27, "plot_svc_gamma": 27, "plot_time_spacing_distribut": [42, 53], "plot_train_test_point": 27, "plot_tree_decision_boundari": 26, "plot_tree_decision_boundary_and_tre": [25, 26, 47], "plot_two_hidden_layer_graph": 41, "plot_typ": 35, "plot_x_dendrogram": 38, "plotli": [36, 40], "plotting_funct": [25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52], "plotting_functions_unsup": [37, 38, 39, 40], "plt": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "plu": [30, 41], "plural": 29, "pm": [1, 10, 42, 53, 54], "pmltt": 10, "pn": [27, 32, 37, 38, 48], "po": [26, 28, 30, 33, 35, 40, 44], "pobox": 24, "poet": 40, "point": [4, 10, 24, 25, 26, 28, 29, 30, 31, 33, 36, 38, 43, 45, 46, 48, 51, 54], "point_ind": 37, "point_index": 37, "pointless": 50, "polarity_scor": 44, "pole": 41, "polici": [3, 4, 7, 54], "polit": [39, 40, 41], "poly_transform": 42, "polynomialfeatur": [36, 42], "pomegran": 41, "pool": 10, "poolarea": [33, 35], "poolqc": [33, 35], "poor": [29, 33, 36, 46, 49], "poorli": [27, 33, 38, 42], "pope": 40, "popul": [28, 29, 30, 36, 42, 49], "popular": [8, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 54], "population_per_household": [28, 29, 49], "porter": 40, "porterstemm": 40, "portion": [0, 26, 28, 31, 33, 35, 52, 53, 54], "portug": [32, 35], "pos_": [40, 44], "pos_label": 33, "posit": [25, 26, 27, 28, 30, 33, 34, 35, 40, 42, 43, 44, 51], "posix": 43, "possibl": [4, 5, 6, 8, 24, 25, 26, 28, 31, 32, 34, 35, 36, 38, 39, 40, 41, 43, 46, 48, 49, 50, 51, 54], "possibli": [7, 40], "post": [4, 6, 8, 10, 40, 42, 54], "postprocess": 41, "potenti": [27, 28, 37, 40, 54], "powder": 40, "power": [8, 26, 34, 39, 40, 41], "pplicat": 38, "pr": 46, "practic": [0, 6, 9, 10, 26, 28, 36, 41, 46, 49, 50, 54], "prairielearn": [10, 54], "pre": [10, 11, 19, 23, 24, 34, 36, 40, 44, 46], "precis": [18, 33, 46, 51, 54], "precision_lr": 32, "precision_recall_curv": 32, "precision_scor": 32, "precision_svc": 32, "precisionrecallcurvedisplai": 32, "precisionrecalldisplai": 32, "pred": [32, 33, 39, 42, 43], "pred_df": [24, 39], "pred_dict": 24, "pred_g": 39, "pred_lin_reg": 39, "pred_train": 33, "pred_x": 39, "prediciton": 43, "predict": [2, 17, 26, 27, 28, 31, 32, 33, 36, 37, 38, 40, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54], "predict_expect": 43, "predict_for_usr": 39, "predict_proba": [32, 34, 35, 41, 45, 52], "predict_survival_funct": 43, "predicted_categori": 32, "predicted_n_rent": 42, "predicted_quiz2": 25, "predicted_sal": 42, "predicted_target": 24, "predictor": [25, 46], "prefer": [24, 34, 37, 39, 50], "prefix": 8, "preliminari": [28, 36], "prepar": [28, 36, 41], "prepend": 11, "preprocess": [10, 16, 18, 26, 27, 30, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 48, 49, 50, 52, 54], "preprocess_featur": [42, 53], "preprocessing_fin": 43, "preprocessing_notenur": 43, "preprocessor": [29, 31, 32, 33, 34, 35, 42, 43, 44, 49, 50, 51, 52, 53], "preprocessor1": 36, "preprocessor2": 36, "preprocessor3": 36, "prerequisit": [2, 43, 54], "preschool": [32, 34, 35, 51], "presenc": [29, 35, 43], "present": [7, 26, 32, 39, 40, 41, 42, 43, 46, 48, 53], "preserv": [32, 37], "pressure3pm": [42, 53], "pressure9am": [42, 53], "pretend": [25, 26, 42], "pretrain": [40, 41, 44], "pretti": [25, 29, 30, 32, 34, 37, 40, 42, 43, 53], "prevent": [31, 40, 43, 54], "previou": [25, 33, 34, 37, 38, 42, 43, 46, 50, 51, 53], "previous": [39, 41, 42], "price": [8, 18, 28, 30, 33, 35, 36, 43, 48], "primari": [8, 19, 23, 27], "primarili": [25, 35, 41], "prime": 24, "princ": 40, "princess": 40, "principl": [9, 25, 46, 54], "print": [7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 51, 53], "print_top": 40, "prior": [37, 42, 46], "priorit": [36, 46], "privaci": [0, 37, 54], "privat": [7, 32, 34, 35], "privileg": 6, "prize": 29, "pro": [37, 41], "prob": [30, 34], "proba": 41, "probabilist": [2, 40], "probabl": [17, 24, 27, 28, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 46, 51, 52, 53], "problem": [4, 6, 10, 24, 29, 30, 32, 33, 34, 35, 37, 38, 40, 41, 43, 45, 46, 48, 50, 51, 52, 53, 54], "problemat": [32, 35, 43], "probosci": [24, 41], "proce": 54, "procedur": 34, "proceed": [26, 53], "process": [2, 5, 7, 25, 27, 28, 29, 31, 36, 37, 38, 41, 44, 48, 50, 54], "process_on": 44, "prod": [29, 31], "produc": [2, 7, 33, 35, 38, 43, 46, 48], "product": [5, 31, 39, 40], "prof": [32, 34, 35, 51], "profession": 39, "profil": 33, "profile_df": 39, "profilereport": 33, "program": [0, 4, 9, 11, 24, 40, 54], "programm": 40, "progress": 37, "project": [11, 28, 34, 36, 41, 46, 54], "promin": 40, "promis": [24, 40, 42], "promot": 43, "prompt": [11, 54], "pron": [40, 44], "prone": 31, "proper": [41, 47], "properli": [7, 43], "properti": [25, 33, 35, 36], "prophet": 42, "propn": [40, 44], "proport": [25, 26, 29, 30, 32, 33, 34, 35, 51, 54], "proportional_hazard_test": 43, "prostitut": 40, "prototyp": 46, "prove": 32, "provid": [0, 5, 7, 11, 25, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 46, 50, 51, 52, 53, 54], "provinc": [29, 40], "provinci": 40, "proxi": 26, "proxim": [30, 40, 54], "prune": 36, "psychologi": [29, 46], "pt": [30, 31, 41], "public": [0, 4, 7, 40, 44], "publish": [0, 10, 30, 40], "puck": 40, "pud": 33, "pull": [11, 30, 40], "punct": [40, 44], "punctuat": [29, 40], "punkt": 44, "punkt_tab": 44, "purchas": [24, 39], "pure": [25, 42], "purpos": [0, 25, 26, 28, 39, 40, 42, 46, 47, 48, 52, 54], "push": [7, 35], "put": [7, 8, 11, 25, 26, 28, 29, 36, 37, 38, 39, 50], "px": [36, 40], "py": [25, 26, 28, 29, 31, 34, 35, 37, 38, 43, 44, 45], "pybind11": 44, "pybo": 31, "pydata": 36, "pyplot": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "pysurviv": 43, "python": [3, 4, 10, 24, 31, 33, 39, 40, 41, 42, 43, 44, 54], "python3": [9, 25, 26, 29, 31, 35, 43, 44, 45], "pythonwarn": 33, "pytorch": [24, 41], "pytorch_1711403226120": 44, "pyviz": 32, "q": 10, "qualiti": [32, 35, 37, 38], "quantifi": [32, 51], "queen": 40, "queen_consort": 40, "queri": [28, 32, 34, 37, 39, 40, 42, 43, 51, 53, 54], "query_point": 27, "quest": 36, "question": [6, 7, 54], "quick": [4, 40, 54], "quickli": [25, 27, 28, 31, 38, 43, 46, 54], "quickstart": 9, "quirk": 26, "quit": [6, 24, 25, 28, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44], "quiz": [1, 10, 40], "quiz1": [25, 26, 29, 46], "quiz2": [26, 29, 46], "quizz": 25, "r": [25, 29, 30, 32, 42, 52, 54], "r1": 34, "r2": [33, 34, 46, 48], "r2_score": [33, 36, 44], "r4": 34, "race": [29, 32, 34, 35, 51, 54], "radial": 27, "radiu": [36, 38], "rail": 41, "rain": [42, 53], "rain_df": [42, 53], "rain_df_modifi": [42, 53], "rainfal": [42, 53], "rainfall_lag1": [42, 53], "rainfall_lag2": [42, 53], "rainfall_lag3": [42, 53], "raintodai": [42, 53], "raintoday_miss": [42, 53], "raintoday_no": [42, 53], "raintoday_y": [42, 53], "raintomorrow": [42, 53], "rais": [6, 29, 32, 42, 43, 53], "rand": [8, 34], "randint": [31, 50], "randn": [30, 36], "random": [6, 8, 26, 27, 30, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 52, 54], "random_forest_data": 34, "random_search": [31, 50], "random_st": [24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52], "randomforestclassifi": [35, 36, 42, 52, 53], "randomforestclassifierrandomforestclassifi": 34, "randomforestregressor": [33, 34, 35, 36, 42, 43, 44, 52], "randomhorizontalflip": 41, "randomizedsearchcv": [27, 34, 35, 50, 52], "randomizedsearchcvifittedrandomizedsearchcv": 31, "randomli": [26, 30, 31, 32, 34, 43, 51], "randomoversampl": 32, "randomresizedcrop": 41, "randomst": [36, 38], "randomundersampl": 32, "rang": [4, 8, 26, 27, 28, 29, 30, 34, 37, 39, 40, 41, 42, 43, 44, 50, 54], "rangeindex": [29, 36, 42, 43, 53], "rank": [32, 36, 39, 40, 43, 51], "rank_test_mape_scor": 33, "rank_test_neg_mean_squared_error": 33, "rank_test_scor": [31, 33], "ranking_": 36, "rare": [29, 32, 33, 37, 40, 46], "rate": [24, 30, 32, 34, 37, 43, 46, 51], "rated_item": 39, "rather": [24, 29, 31, 32, 33, 34, 35, 37, 40, 41], "ratings_df": 39, "ratio": [32, 34, 40, 43], "ravel": [32, 46], "raw": [8, 29, 32, 35, 36, 40, 41, 45, 51], "raw_model_output": 30, "raw_scor": 35, "rbf": [10, 15, 26, 28, 30, 31, 34, 35, 36, 46, 48, 50], "rcparam": [24, 25, 26, 32, 37, 38, 39, 41, 42, 43, 47, 53], "re": [4, 7, 8, 11, 24, 25, 26, 29, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 47, 53], "reach": [6, 37, 54], "read": [1, 4, 7, 10, 27, 28, 29, 32, 33, 34, 35, 40, 42, 52, 53], "read_csv": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 54, "readi": [7, 26, 27, 28, 30], "readlin": 41, "readm": 43, "readthedoc": 43, "real": [26, 27, 28, 29, 30, 32, 35, 37, 38, 39, 40, 41, 44, 46], "realdonaldtrump": 44, "realist": [28, 42, 53], "realiti": [26, 33, 43], "realli": [8, 26, 30, 31, 34, 36, 38, 39, 41, 42, 43], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 31, 32, 33, 35, 37, 39, 40, 42, 43, 46, 54], "rebuild": 44, "rec": [33, 35], "recal": [18, 25, 26, 27, 28, 29, 30, 33, 37, 42, 46, 51, 54], "recall_lr": 32, "recall_scor": 32, "recall_svc": 32, "receiv": [6, 7, 29, 38, 41, 42], "recent": [8, 11, 24, 29, 36, 39, 40, 42, 43, 44], "recip": 26, "recogn": [26, 38, 42, 54], "recognit": [24, 25, 27, 32, 40, 54], "recommend": [2, 4, 8, 10, 11, 24, 26, 27, 31, 32, 37, 40, 41, 52, 54], "record": [25, 43], "recreat": 53, "rectangular": 37, "recurr": 42, "recurs": 54, "red": [25, 27, 32, 35, 36, 37, 42], "redbon": 31, "redefin": 43, "redistribut": 0, "reduc": [7, 8, 24, 27, 31, 32, 33, 34, 35, 36, 39, 40, 41, 45, 48, 51, 54], "reduct": [2, 32, 34, 36, 37], "redund": [30, 35], "ref": [32, 43, 51], "refer": [8, 25, 26, 27, 28, 29, 30, 32, 35, 37, 39, 40, 41, 48, 54], "referenc": 54, "referenti": 40, "refin": [27, 48], "refit": 33, "reflect": [27, 33, 35, 40, 48, 50, 54], "reflection_period": 32, "reg": [25, 34, 52], "reg_model": 25, "regard": 54, "regardless": 7, "regex": 40, "region": [25, 32, 38, 42, 45, 50, 53], "region_data": [42, 53], "regist": 54, "registered_nurs": 40, "registri": 44, "regrad": 6, "regress": [2, 10, 17, 24, 28, 29, 35, 36, 39, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54], "regression_df": 25, "regressor": [25, 28, 29, 33, 42, 52], "regular": [27, 29, 30, 34, 40, 42, 43, 46], "regulatori": 35, "reinforc": [24, 37], "reject": [32, 51], "rel": [30, 35, 38, 40, 44, 45, 51], "rel_char_len": 44, "relabel": 37, "relat": [2, 6, 11, 24, 30, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 52, 54], "relationship": [32, 34, 35, 36, 40, 42, 44, 46, 47, 48, 51, 53, 54], "relationship_husband": 35, "relationship_own": 35, "releas": [7, 10], "relev": [4, 8, 10, 25, 27, 28, 31, 35, 42, 54], "reli": [26, 27, 36, 38, 39, 42, 48], "reliabl": [24, 37], "religi": 40, "remain": [5, 33, 36, 39, 42], "remaind": 6, "rememb": [7, 27, 29, 31, 32, 35, 36, 38, 41, 42, 43, 47, 48, 50, 53], "remind": 47, "remix": 0, "remov": [7, 28, 32, 34, 35, 36, 40, 41, 43, 45, 50, 51, 53], "renam": [24, 32, 35, 42], "render": [4, 7, 24, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 44], "rent": 42, "rental": 42, "rentals_df": 42, "rentals_lag5": 42, "rentals_lag5_i": 42, "rentals_lag5_x": 42, "rentals_model": 42, "repair": [32, 34, 35], "repeat": [8, 36, 37, 38, 41, 50, 51, 52], "repeatedli": 6, "replac": [24, 28, 32, 34, 35, 39, 43, 51], "reply_cont": 44, "repo": [10, 32], "report": [6, 25, 31, 33, 36, 42, 44, 51], "repositori": [0, 5, 10, 11, 30, 32, 54], "repres": [25, 26, 27, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 52], "represent": [24, 25, 28, 31, 32, 33, 34, 35, 36, 37, 38, 40, 44, 46], "reproduc": [4, 26, 31, 34, 54], "republ": 35, "request": [6, 40, 54], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 46, 48, 53], "rerun": [24, 28, 29, 31, 32, 33, 34, 35, 36, 41, 44], "res_mean": 26, "resampl": 32, "research": [24, 26, 31, 39, 40], "reserv": [42, 54], "reset_index": 24, "reshap": [8, 30, 31, 41, 42, 50], "resid": 30, "residu": 34, "resiz": 41, "resnet": 41, "resolut": 40, "resolv": 54, "resort": 30, "resourc": [3, 5, 10, 25, 34, 35, 40, 41, 46], "respect": [30, 31, 32, 34, 35, 50], "respons": [4, 7, 25, 37, 40, 54], "rest": [30, 31, 41, 43, 46, 53], "restart": [7, 11], "restaur": 39, "restingbp": 52, "restingecg": 52, "restrict": [0, 33, 34, 40], "result": [2, 7, 8, 10, 11, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 48, 50, 51, 52, 53, 54], "result_block": 43, "result_img": 41, "results_df": [26, 27, 30, 48], "results_dict": [26, 27, 28, 29, 31], "results_single_valid_df": 48, "retail": [44, 46], "retail_df": 42, "retail_df_test": 42, "retail_df_train": 42, "retail_lag_5": 42, "retail_model": 42, "retail_test_5": 42, "retail_test_5_pr": 42, "retail_train_5": 42, "retail_train_5_d": 42, "retail_train_5_i": 42, "retail_train_5_x": 42, "retent": 43, "retrain": [31, 50], "return": [5, 8, 11, 25, 26, 27, 28, 29, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 50, 53], "return_gener": 29, "return_train_scor": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44, 48, 50, 52], "reus": [32, 54], "revenu": 39, "revers": [29, 33], "review": [4, 10, 30, 37, 44, 46, 50, 51, 52, 54], "revisit": [32, 46], "revok": 0, "reward": [24, 29, 37], "rf": [42, 43], "rf_imp_df": 35, "rfe_cv": 36, "rfe_pip": 36, "rfecv": 36, "rgb": 24, "rhode_island": 40, "rich": [35, 40, 43, 46], "rico": 35, "rid": [11, 29, 34, 35, 40, 43], "ridg": [35, 36, 39, 42, 43, 44], "ridge__alpha": 33, "ridge_pr": 33, "ridge_tun": 33, "ridgecv": [36, 44], "ridgecv_pip": 33, "ridgeridg": [33, 36], "right": [0, 10, 24, 30, 31, 32, 33, 36, 37, 38, 39, 40, 46, 50, 51, 54], "rightarrow": [25, 27, 30, 32, 33, 34, 37, 38, 39, 40, 46], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 40, "rise": [36, 40], "risk": [10, 32, 36, 48, 52], "river": 30, "rl": [33, 35], "rmse": [39, 46], "rng": [36, 38], "rnn": 42, "ro": 32, "roast": 37, "robot": [39, 40], "robust": [24, 26, 27, 28, 31, 34, 38, 48, 50], "roc": [46, 54], "roc_auc": 32, "roc_auc_scor": 32, "roc_curv": 32, "roc_lr": 32, "roc_svc": 32, "roccurvedisplai": 32, "rodolfo": 31, "rodr\u00edguez": 40, "roger": 36, "role": [30, 31, 35, 41], "roman": 39, "romanc": 39, "romant": 39, "ronald": 30, "roof": 35, "roofmatl": [33, 35], "roofmatl_clytil": [33, 35], "roofmatl_compshg": [33, 35], "roofmatl_membran": 33, "roofmatl_met": 33, "roofmatl_rol": 33, "roofmatl_tar": 33, "roofmatl_wdshak": 33, "roofmatl_wdshngl": [33, 35], "roofstyl": [33, 35], "roofstyle_flat": 33, "roofstyle_g": 33, "roofstyle_gambrel": 33, "roofstyle_hip": 33, "roofstyle_mansard": 33, "roofstyle_sh": 33, "room": [24, 25, 30, 33, 36, 44, 54], "rooms_per_household": [28, 29, 36, 49], "rooms_per_household_0": 36, "rooms_per_household_1": 36, "rooms_per_household_10": 36, "rooms_per_household_11": 36, "rooms_per_household_12": 36, "rooms_per_household_13": 36, "rooms_per_household_14": 36, "rooms_per_household_15": 36, "rooms_per_household_16": 36, "rooms_per_household_17": 36, "rooms_per_household_18": 36, "rooms_per_household_19": 36, "rooms_per_household_2": 36, "rooms_per_household_3": 36, "rooms_per_household_4": 36, "rooms_per_household_5": 36, "rooms_per_household_6": 36, "rooms_per_household_7": 36, "rooms_per_household_8": 36, "rooms_per_household_9": 36, "root": [11, 25, 27, 39, 41, 46], "rose": 40, "rostin": 54, "rotat": [42, 53], "rough": 4, "roughli": [5, 26, 40, 46], "round": [8, 27, 28, 31, 32, 34, 38, 41, 48], "rout": [5, 25, 42], "row": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 52, 53, 54], "rry": 40, "rsh": 31, "ru": [8, 32], "rubric": 30, "rule": [1, 8, 24, 25, 27, 30, 32, 34, 40, 46, 48, 51], "run": [4, 5, 7, 10, 11, 24, 26, 27, 29, 31, 32, 33, 35, 37, 38, 40, 41, 44, 45, 47, 48, 50, 52], "run_ast_nod": 44, "run_cel": 44, "run_cell_async": 44, "run_cod": 44, "run_forev": 44, "runner": 44, "runpi": 44, "runtimewarn": 31, "ruscorpora": 40, "rush": 36, "russel": 10, "rv": 31, "rv_continuous_frozen": 31, "rv_discrete_frozen": 31, "rvert_2": 40, "s1": [8, 40], "s19": 28, "s2": [8, 40], "s_lag": [42, 53], "sa": 1, "sabr": 40, "sabrina": 10, "sadli": 40, "safe": 28, "safeti": 41, "sai": [8, 25, 27, 28, 29, 32, 33, 34, 35, 40, 42, 46, 51], "said": [26, 28, 30, 35, 38, 39, 40], "sal": [33, 35], "sale": [8, 32, 33, 42, 48], "salecondit": [33, 35], "salecondition_abnorml": 33, "salecondition_adjland": 33, "salecondition_alloca": 33, "salecondition_famili": 33, "salecondition_norm": 33, "salecondition_parti": 33, "salepric": [33, 35], "sales_data": 42, "salesforc": 44, "saleswoman": 40, "saletyp": [33, 35], "saletype_cod": 33, "saletype_con": 33, "saletype_conld": 33, "saletype_conli": 33, "saletype_conlw": 33, "saletype_cwd": 33, "saletype_new": 33, "saletype_oth": 33, "saletype_wd": 33, "salt": [30, 35], "sam": 39, "same": [6, 7, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 51, 53], "samosa": 40, "sampl": [25, 27, 28, 30, 31, 35, 38, 41, 42, 43, 47, 48, 51, 52, 53], "sample_df": 32, "sample_text": 44, "sampling_strategi": 32, "samuel": 24, "sand": 41, "sandbar": 41, "saniti": [25, 43], "sarah": 10, "sat": 42, "satisfactori": 37, "satisfi": [37, 54], "saturdai": 42, "save": [7, 8, 29, 31, 35, 40, 41, 42, 44, 49, 50, 53], "saw": [28, 30, 31, 32, 38, 46], "sb": 36, "scalabl": [24, 38], "scalar": 8, "scale": [16, 26, 27, 29, 31, 32, 33, 34, 36, 38, 41, 43, 46, 48, 49, 50], "scale_pos_weight": 34, "scaler": [28, 35, 36], "scan": 46, "scatter": [28, 33, 35, 36], "scatter_3d": 36, "scatterplot": 36, "scc": 40, "scenario": [26, 29, 34, 35, 36, 38, 42, 43, 46, 54], "schedul": [43, 46], "schmidt": 31, "school": [24, 32, 34, 35, 39, 51], "schoolteach": 40, "scienc": [2, 9, 10, 11, 29, 37, 42, 46, 48, 54], "scientif": [39, 40], "scientist": [9, 10, 38], "scikit": [9, 11, 16, 17, 25, 27, 30, 31, 32, 34, 37, 38, 41, 42, 44, 45, 50, 51, 54], "scipi": [11, 31, 38, 40, 50], "scm": 5, "scope": [40, 42], "score": [17, 18, 24, 27, 28, 29, 34, 35, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54], "score_func": 33, "score_lr_print_coeff": [42, 53], "score_param": 29, "score_tim": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44], "scorer": [29, 33], "scores_averag": 52, "scores_dict": 30, "scores_imag": 30, "scores_stack": 52, "scoring_method": 43, "scoring_metr": [34, 35, 44], "scotland": 40, "scratch": [2, 41], "screen": 7, "screennam": 44, "screenplai": 40, "screenporch": [33, 35], "script": 11, "scroog": 44, "sd": [19, 23], "sdng": 33, "se": [42, 43, 53], "sea": 41, "seaborn": [35, 36, 37, 38, 39], "seacoast": 41, "search": [4, 5, 11, 33, 40, 46, 50], "search_multi": 33, "seashor": 41, "season": 53, "season_autumn": 42, "season_fal": 42, "season_summ": 42, "season_wint": 42, "seat": [41, 54], "seattl": 44, "seawal": 41, "second": [4, 6, 25, 30, 34, 35, 38, 41, 42], "secondari": 24, "secpompeo": 44, "section": [7, 11, 25, 26, 36, 52, 54], "secur": [35, 54], "see": [1, 4, 6, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 54], "seed": [30, 31, 37, 38], "seem": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 42, 43, 44, 45, 48, 50, 51], "seemingli": [32, 51], "seen": [8, 24, 26, 27, 28, 29, 30, 36, 38, 39, 43, 46, 48, 50, 52], "sefa": 54, "segment": [32, 40, 41, 43, 46, 54], "select": [5, 6, 10, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 54], "select_dtyp": 33, "select_knn": 36, "select_rf": 36, "select_svc": 36, "selectfrommodel": 36, "self": [24, 29, 43, 44, 54], "sell": [0, 8, 25], "semant": [37, 38, 40, 54], "semest": 54, "semi": [10, 40], "semicolon": 8, "semilogx": 33, "send": [4, 24, 44], "senior": 43, "seniorcitizen": 43, "sens": [6, 26, 29, 30, 32, 33, 35, 36, 37, 39, 40, 42, 43, 45], "sensibl": 7, "sensit": [26, 28, 31, 32, 33, 37, 43], "sent": [24, 40], "sent_token": 40, "sentenc": 40, "sentiment": [25, 30, 40, 44], "sentimentintensityanalyz": 44, "sepal": [27, 48], "separ": [25, 26, 28, 29, 30, 32, 36, 37, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51], "septemb": 42, "sequenc": [26, 29, 41, 42], "sequenti": [25, 34, 42, 43, 46], "sequentialfeatureselector": 36, "ser": [26, 28, 43], "seri": [2, 10, 26, 28, 29, 32, 36, 41, 43, 44, 54], "serial": 34, "seriou": [6, 32, 39, 40, 43, 54], "serv": [5, 25, 35, 54], "server": 5, "servic": [34, 35, 39, 43, 44], "session": [37, 46, 54], "set": [7, 8, 9, 10, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53], "set_config": [31, 34], "set_index": [26, 27, 31, 32, 33], "set_opt": [24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 39, 47, 48, 49, 50, 51], "set_properti": 24, "set_titl": [27, 30, 32, 41, 48, 51], "set_xlabel": [27, 30, 37, 48], "set_ylabel": [27, 30, 37, 48], "settl": [50, 51], "setup": [3, 7, 11, 47], "setup_default_warn": 44, "sev": [33, 35], "sever": [11, 28, 30, 37, 38, 40, 41, 42, 45, 53, 54], "sex": [32, 34, 35, 36, 51, 52], "sexual": 54, "sfu": 40, "shadab": 54, "shadow": [19, 23], "shaikh": 54, "shall": [0, 40], "shallow": 34, "shan": 40, "shape": [25, 26, 27, 28, 29, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53], "shape_df": 26, "shape_dict": 26, "share": [0, 36, 54], "sharealik": 1, "sharex": 28, "shashwat": 54, "she": [24, 39, 40, 44], "shed": [33, 35], "sheet": [9, 46], "shelf": [34, 40, 50], "shell": [5, 9, 44], "shelv": 44, "shift": [42, 53], "shit": 44, "shng": 33, "shop": 39, "short": [10, 11, 26, 31, 34, 40, 54], "shorter": 43, "shorthand": 28, "shot": 36, "should": [5, 7, 8, 11, 25, 26, 27, 28, 29, 30, 32, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54], "shouldn": [32, 34, 40, 48], "show": [4, 7, 11, 24, 26, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 46, 48, 50, 52, 53], "show_plot": 43, "showcas": 40, "shown": [7, 11, 24, 25, 27, 32, 34, 37, 38, 42], "shrink": [31, 36], "shuffl": [26, 41, 42, 53], "si": 24, "sibl": 36, "sick": [37, 44], "sid": 44, "side": [6, 41], "sift": 39, "sigma": 41, "sign": [4, 33, 35, 41, 48, 50, 52, 54], "signal": [26, 40], "signific": [28, 41, 54], "significantli": [29, 32, 39], "sigoptsearchcv": 31, "silhouett": 38, "silhouettevisu": [37, 38], "sim": 35, "sim_word": 40, "simard": 35, "similar": [10, 11, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 45], "similarity_": 40, "similarli": [35, 37, 43], "simon_fras": 40, "simp": 42, "simpl": [10, 25, 27, 28, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 46, 47, 51], "simplefilt": [34, 35], "simpleimput": [28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44, 46, 49, 50, 51, 52, 53], "simpleimputersimpleimput": [28, 29, 33, 34, 36], "simpler": [30, 31, 48], "simplest": 29, "simpli": [28, 36, 37, 40], "simplic": [25, 29, 39], "simplist": [27, 35, 48], "simul": 36, "sin": 8, "sinc": [5, 30, 33, 35, 36, 37, 39, 41, 42, 43, 45, 46, 47, 53], "singer_songwriter_bob_dylan": 40, "singl": [8, 27, 28, 30, 31, 32, 34, 35, 38, 42, 43, 46, 47, 48, 50, 51], "sit": 54, "sitarist_ravi_shankar": 40, "site": [5, 25, 26, 29, 31, 35, 43, 44, 45, 54], "situat": [6, 24, 32, 34, 37, 41, 43, 54], "six": [26, 34, 42], "size": [24, 25, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 52, 53, 54], "skew": 33, "skill": [34, 54], "skin": 44, "skip": 51, "skipna": 43, "sklearn": [10, 24, 26, 27, 30, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "sklearn_gb": 34, "sklearn_histgb": 34, "sktime": 42, "skyblu": [42, 53], "skyscrap": 42, "sl": 40, "slate": 53, "slice": 8, "slide": [9, 10, 19, 28, 41, 54], "slightli": [29, 30, 32, 34, 43], "slope": 30, "sloppi": 28, "slot": 54, "slow": [27, 34, 36, 41], "slower": [34, 37], "slowest": 52, "sm": [24, 29], "smac": 31, "small": [11, 26, 27, 29, 31, 33, 34, 35, 36, 37, 39, 41, 43, 46, 48, 50, 52], "small_citi": 27, "small_train_df": 27, "smallalpha_coeff": 33, "smaller": [27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 42, 43, 48, 50], "smallest": [30, 33, 37, 38], "smart": [37, 44], "smile": 44, "smooth": [27, 48], "smoothli": 11, "smote_pip": 32, "sms_df": 24, "sn": [35, 37, 38], "snake": [30, 41], "snake_length": 30, "snakes_df": 30, "snbf": 34, "snippet": 7, "snow": [24, 41], "snp": 36, "so": [0, 4, 5, 7, 8, 10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54], "social": [37, 38, 39, 42], "societ": 54, "societi": [32, 40, 51], "sofist": 48, "soft": [30, 34, 52], "softmax": 46, "softwar": [1, 5, 11, 43], "solar": 39, "sold": [8, 33], "sole": [32, 38], "solidifi": 46, "solut": [24, 25, 26, 34, 37, 43, 44, 46, 54], "solv": [4, 24, 25, 27, 36, 40, 48, 54], "solver": 32, "some": [4, 6, 7, 8, 11, 24, 26, 27, 28, 29, 30, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54], "someon": [24, 25, 26, 36, 43], "someth": [4, 7, 11, 25, 29, 32, 33, 34, 35, 37, 42, 43, 46, 54], "sometim": [6, 25, 26, 29, 30, 31, 34, 35, 40], "somewhat": 33, "somewher": [24, 33], "song": [27, 28, 39, 44, 50], "song_titl": [27, 28, 31, 50], "soo": 54, "soon": [24, 27, 28, 42], "sopha": 24, "sophist": [31, 35, 40], "sort": [5, 10, 25, 26, 28, 35, 39, 40, 41, 42, 53], "sort_index": [8, 31, 33, 42, 53], "sort_valu": [28, 29, 30, 31, 33, 34, 35, 36, 42, 43, 44, 52, 53], "sound": [35, 36], "soundtrack": 40, "sourc": [11, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 44, 47, 50, 54], "south": 29, "space": [27, 30, 31, 36, 37, 38, 40, 44, 53, 54], "spaci": 36, "spacymoji": 44, "spam": [26, 32, 37], "spam_predict": 24, "span": [40, 42], "spanish": 28, "spars": [27, 30, 34, 39, 40, 46], "sparse_output": [28, 29, 32, 33, 34, 35, 42, 43, 46, 51, 52, 53], "spatial": 30, "speak": 5, "spearmint": 31, "speci": [27, 46, 48], "special": [24, 29, 39, 40, 41, 42, 43, 48, 54], "specialti": [32, 34, 35], "specif": [8, 25, 26, 31, 32, 35, 37, 39, 40, 41, 42, 43, 46, 48, 50, 52, 54], "specifi": [8, 25, 26, 29, 31, 32, 37, 38, 41, 50, 52], "spectrogram": 36, "speech": [36, 40, 44], "speechi": [27, 28, 31, 50], "speed": [8, 25, 34, 41], "spell": 24, "spend": [24, 28, 36, 44, 54], "spent": [6, 28, 36], "spheric": [38, 46], "spici": 37, "spini": 41, "spit": 41, "split": [15, 25, 27, 29, 30, 31, 33, 34, 36, 39, 40, 43, 44, 46, 51, 52, 53, 54], "split0_test_r2": 33, "split0_test_scor": 31, "split0_train_neg_mean_squared_error": 33, "split0_train_scor": 31, "split1_test_r2": 33, "split1_test_scor": 31, "split1_train_neg_mean_squared_error": 33, "split1_train_scor": 31, "split2_test_r2": 33, "split2_test_scor": 31, "split2_train_neg_mean_squared_error": 33, "split2_train_scor": 31, "split3_test_r2": 33, "split3_test_scor": 31, "split3_train_neg_mean_squared_error": 33, "split3_train_scor": 31, "split4_test_scor": 31, "split4_train_neg_mean_squared_error": 33, "split4_train_scor": 31, "spoken": 29, "sport": [40, 41, 42], "spot": [32, 33, 48], "spotifi": [27, 39, 50], "spotify_df": [27, 28, 31, 50], "spotlight": [5, 11], "spous": [32, 34, 35], "spread": 38, "spring_month": 42, "sqft": 35, "sqft_abov": [24, 25], "sqft_basement": [24, 25], "sqft_live": [24, 25], "sqft_living15": [24, 25], "sqft_lot": [24, 25], "sqft_lot15": [24, 25], "sqrt": [27, 33, 35, 39, 40], "squar": [8, 25, 27, 30, 35, 39, 43, 44, 46, 54], "squash": [30, 41], "squeez": [8, 43], "src": [26, 32], "sse": [42, 53], "ssw": 42, "st": [42, 44], "st_slope": 52, "stabil": 11, "stabl": [26, 32, 34, 48], "stack": [7, 46, 54], "stack_method": 52, "stacking_model": [34, 52], "stacking_model_tre": 34, "stackingclassifi": [34, 52], "stackingregressor": 34, "staff": 6, "stai": [32, 43], "stakehold": 54, "stale": 37, "stand": [27, 31, 40], "standard": [4, 6, 26, 28, 31, 34, 35, 36, 40], "standardscal": [29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53], "standardscalerstandardscal": [28, 29, 31, 32, 33, 34, 36, 41, 44], "stanford": 40, "star": [27, 37, 39, 44], "start": [7, 8, 11, 25, 26, 27, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53], "startswith": 35, "starttim": 42, "stat": [31, 43, 50], "state": [6, 8, 26, 32, 34, 35, 39, 40, 44, 51], "statement": [7, 26, 27, 28, 29, 30, 31, 32, 33, 36, 41, 43], "station": 42, "statist": [9, 10, 25, 30, 35, 39, 40, 43, 54], "statistician": 27, "statlib": 30, "statsmodel": [42, 43], "statu": [32, 34, 35, 51], "status_marri": 35, "status_nev": 35, "std": [26, 27, 28, 32, 33, 41, 42, 44, 45, 53], "std_cv_error": 26, "std_cv_score": 27, "std_fit_tim": [31, 33], "std_score": [26, 28, 44], "std_score_tim": [31, 33], "std_test_neg_mean_squared_error": 33, "std_test_scor": [26, 31], "std_train_error": 26, "std_train_neg_mean_squared_error": 33, "std_train_scor": [26, 27, 31], "stdki": 43, "stem": 40, "step": [7, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 52, 54], "stereotyp": 40, "stick": 42, "still": [4, 11, 31, 32, 33, 34, 36, 37, 42, 43, 44, 48, 49, 50, 51], "stochast": [36, 37], "stock": [24, 42], "stop": [8, 37, 40, 41, 43, 48], "stop_word": [31, 32, 40, 44, 50], "stopword": 40, "storag": 27, "store": [7, 8, 27, 28, 29, 31, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44], "stori": [33, 34, 44], "storylin": 40, "str": [31, 35, 40, 42, 43, 44, 53], "straight": 43, "straightforward": 35, "strain": 7, "strang": [35, 43], "strata": 43, "strategi": [25, 27, 28, 29, 32, 33, 35, 37, 39, 42, 43, 46, 47, 51, 53], "stratif": 43, "stratifi": 43, "stratifiedkfold": [26, 32], "stream": [43, 44], "streamingmovi": 43, "streamingmovies_no": 43, "streamingmovies_y": 43, "streamingtv": 43, "streamingtv_no": 43, "streamingtv_y": 43, "street": [33, 35], "street_grvl": 33, "street_pav": 33, "strength": [40, 46], "stress": 37, "strftime": [42, 43], "string": [8, 11, 27, 32, 33, 34, 35, 40, 42, 43, 48, 52], "strip": [35, 41], "strong": [34, 43, 46], "stronger": 34, "strongli": 34, "structur": [8, 37, 40, 41], "struggl": [37, 42], "stuart": [10, 34], "stuck": [4, 8], "student": [4, 5, 6, 7, 24, 25, 30, 32, 33, 35, 36, 37, 38, 39, 41, 44, 54], "studi": [24, 29, 36, 40, 43], "stuff": [27, 41, 43], "stump": [25, 26, 27, 34, 47], "stupid": 44, "style": [24, 33, 36, 37, 39, 40, 41, 44], "sub": [31, 37, 40, 43, 46], "subdirectori": 35, "subgroup": 43, "subject": [0, 43, 54], "sublicens": 0, "submiss": [3, 54], "submit": [8, 10, 54], "subplot": [26, 27, 30, 32, 37, 41, 43, 48, 51], "subplot_kw": 26, "subprocess": 33, "subscrib": 43, "subscript": [42, 43], "subset": [25, 26, 31, 34, 41, 42, 45, 48], "substanti": 0, "substitut": 0, "subtl": 40, "subtleti": [26, 33], "subtract": [27, 32, 35], "suburb": 44, "subword": 40, "succe": [36, 54], "success": [5, 8, 11, 24, 32, 34, 39, 40, 41, 42], "successfulli": [11, 24, 44], "sudo": 5, "suei": 31, "suffer": 31, "suffici": [7, 40], "suggest": [0, 10, 25, 39, 43], "suicid": 40, "suit": 39, "suitabl": [11, 24, 37, 39, 46, 52, 54], "sultan": 40, "sum": [8, 27, 28, 29, 30, 34, 35, 37, 41, 44], "sum_": [27, 33, 37, 40, 41], "sum_i": [35, 40], "sum_prob_ex1_class_0": 34, "sum_prob_ex1_class_1": 34, "summar": [10, 24, 30, 32, 33, 37, 40], "summari": [0, 45, 46, 48], "summary_plot": 35, "summat": 34, "summer": [1, 39, 42], "summer_month": 42, "sun": [40, 42], "sundai": 42, "sundial": 41, "sunshin": [42, 53], "super": [29, 44, 46], "superfici": 27, "superior": 54, "supermarket": 44, "supervis": [28, 29, 31, 32, 33, 36, 38, 40, 42, 43, 46, 53, 54], "suppli": 54, "support": [11, 15, 25, 28, 32, 34, 35, 36, 38, 40, 44, 45, 48, 54], "support_": [27, 36], "suppos": [24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 46, 47], "suppress": 8, "suprem": 40, "supr\u00eam": 40, "sure": [4, 7, 8, 11, 26, 27, 29, 32, 33, 34, 35, 38, 41, 42, 48, 51, 52, 53, 54], "surgeri": 43, "suri": 54, "surpris": [35, 39], "surprisingli": [29, 30], "surround": [4, 54], "survei": 37, "surviv": [2, 10, 54], "survival_function_": 43, "suscept": 38, "suspect": 31, "svc": [27, 28, 29, 30, 31, 34, 35, 36, 41, 44, 48, 49, 50, 52], "svc__c": [31, 50], "svc__gamma": [31, 50], "svc_pipe": 31, "svc_pred": 32, "svcsvc": [29, 31, 32], "svm": [10, 26, 28, 29, 31, 34, 35, 36, 41, 42, 44, 45, 46, 48, 49, 50, 52], "svm_estim": 32, "svr": [27, 29, 35], "svr_c_pipe": 29, "svr_pipe": 29, "sw": [42, 53], "swai": 24, "swamp": 27, "swan": 41, "swcarpentri": 9, "sweep": 32, "sweet": 44, "switch": [35, 37, 42, 43, 53], "sy": [24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52], "sydnei": 42, "syllabu": [3, 7, 10, 12], "symbol": 25, "symmetri": 36, "sync": 5, "synonym": 40, "synopsi": 40, "syntact": 40, "syntax": [4, 8, 24, 36, 43], "synthet": [36, 45], "system": [2, 4, 5, 6, 10, 11, 24, 26, 27, 29, 32, 35, 37, 42, 51, 54], "systemat": [25, 29, 31, 35, 40], "t": [4, 5, 7, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54], "ta": [7, 24, 33, 35, 47, 48, 49, 50, 51, 52, 53], "tabbi": [24, 41], "tabl": [7, 52], "tabular": [8, 24, 41, 42], "tackl": [26, 28, 32, 38, 48], "taco": 36, "tag": [4, 40, 44], "tail": [8, 42], "tailor": [37, 54], "take": [2, 4, 5, 6, 11, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54], "taken": [42, 45, 50, 54], "talk": [25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 54], "tall": 40, "target": [26, 27, 28, 30, 31, 32, 34, 35, 36, 39, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53], "target_column": [34, 35, 43, 52], "target_nam": 32, "target_names_toi": 32, "tariff": 40, "task": [28, 29, 30, 31, 35, 36, 37, 39, 41, 42, 43, 44, 46, 50, 53, 54], "tast": [37, 39], "taught": [29, 40, 54], "tba": 10, "tbd": [19, 54], "teach": [4, 24, 28, 40, 46], "team": [4, 8, 24, 34, 35, 40, 52], "tech": [27, 32, 35], "technic": 54, "techniqu": [10, 27, 31, 36, 39, 41, 43, 45, 46, 54], "technolog": 0, "technologi": 40, "techsupport": 43, "techsupport_no": 43, "techsupport_y": 43, "ted": 37, "tediou": 38, "telco": 43, "telecom": 43, "telephon": 40, "tell": [26, 27, 28, 30, 32, 35, 36, 39, 40, 42, 43, 48, 50, 53], "temp3pm": [42, 53], "temp9am": [42, 53], "temperatur": 25, "tempo": [27, 28, 31, 50], "tempor": [43, 46, 53], "tend": [26, 27, 30, 34, 36, 39, 42, 43, 54], "tendenc": 26, "tensor": 41, "tensor_numpi": 44, "tensorflow": [11, 35, 41], "tent": 54, "tenur": [43, 46], "tenure_lm": 43, "tenure_predict": 43, "term": [0, 2, 25, 27, 29, 30, 32, 35, 36, 39, 40, 43, 46], "termin": [5, 11, 25, 37], "terminologi": [14, 26, 32, 46, 47], "terrac": 41, "terribl": [33, 39], "territori": 54, "tesoro": 31, "test": [1, 7, 8, 11, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 38, 43, 45, 46, 48, 50, 51, 52, 53, 54], "test_accuraci": 32, "test_average_precis": 32, "test_df": [24, 28, 29, 30, 32, 33, 34, 35, 36, 42, 43, 44, 49, 51, 52, 53], "test_df_churn": 43, "test_df_nan": [32, 34, 35, 51], "test_df_sort": 42, "test_df_surv": 43, "test_exampl": 34, "test_f1": 32, "test_format": 27, "test_g50k": 34, "test_imag": [24, 41], "test_l50k": 34, "test_mape_scor": 33, "test_nam": 43, "test_neg_mean_squared_error": 33, "test_neg_root_mean_square_error": 33, "test_point": [27, 45], "test_precis": 32, "test_r2": 33, "test_recal": 32, "test_roc_auc": 32, "test_sampl": 52, "test_scor": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44, 48], "test_shap_valu": 35, "test_siz": [24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 44, 45, 48, 49, 50, 51, 52], "test_sklearn": 33, "test_statist": 43, "test_x": 43, "text": [7, 10, 16, 17, 24, 25, 30, 31, 32, 33, 34, 35, 36, 39, 41, 46, 50, 54], "text_feat": [31, 50], "text_featur": 44, "text_pp": 40, "textbook": [3, 9], "textrm": 26, "textual": 54, "textur": 36, "tf": 29, "tfidfvector": 30, "th": [30, 39, 54], "than": [6, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 51, 52, 54], "thank": [24, 40, 48], "thankfulli": [42, 53], "thei": [7, 8, 10, 25, 26, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54], "theirs": 40, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 47, 48, 50, 51, 52, 54], "theme": 40, "themselv": [37, 38, 40], "theoret": [28, 32, 34, 46], "theori": 35, "thepopbreak": 44, "therefor": 48, "thermostat": 25, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "thick": 37, "thinc": 44, "thing": [5, 7, 8, 10, 25, 26, 27, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 52, 53], "think": [4, 24, 25, 26, 27, 29, 30, 32, 33, 35, 36, 37, 39, 41, 42, 43, 46, 47, 48, 50, 51, 53, 54], "third": 38, "thk": 24, "thorough": [11, 52], "thoroughli": 46, "those": [5, 8, 11, 28, 33, 34, 35, 39, 40, 43, 54], "though": [26, 29, 30, 37, 38, 39, 44], "thought": [4, 27, 35, 43, 46], "thousand": [30, 38, 39], "thrasher": 40, "threahold": 36, "threaten": 44, "three": [8, 25, 28, 30, 32, 34, 35, 36, 37, 38, 40, 41, 42, 45, 46, 51, 54], "thresh": 8, "threshold": [25, 30, 34, 36, 38, 40, 43], "thresholds_lr": 32, "thresholds_svc": 32, "through": [7, 11, 25, 32, 33, 36, 38, 39, 40, 41, 54], "throughout": 26, "throw": [29, 41, 43, 46], "thu": [6, 31, 42, 43], "thumb": [25, 44], "thursdai": 54, "ti": 29, "tick": 42, "tick_label": 35, "tick_param": 37, "tiffin": 40, "tiger": [24, 41], "tight": [27, 38, 48], "tight_layout": 41, "tightrop": [27, 48], "tile": 35, "till": [27, 40, 43], "timber": 40, "time": [2, 4, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 47, 48, 50, 51, 52, 54], "time_diff": [42, 53], "time_signatur": [27, 28, 31, 50], "timedelta": [42, 53], "timeit": [8, 45], "timeseri": [41, 42], "timeseriessplit": [42, 43, 46, 53], "timestamp": [42, 53], "timezon": [10, 43], "tinder": 39, "tini": [7, 26, 32, 38], "tip": 40, "tire": 44, "titan": 39, "titi": 24, "titl": [7, 26, 27, 30, 33, 36, 38, 41, 42, 43, 48, 53], "tn": 32, "to_datetim": [42, 53], "to_html": [24, 25, 26], "to_notebook_ifram": 33, "to_numpi": [27, 39, 42], "to_str": [24, 41], "toarrai": [29, 35, 42], "tobago": [34, 35], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 39, 41, 42, 43, 46, 52, 53], "todens": [35, 36], "togeth": [5, 8, 25, 27, 28, 29, 37, 40, 48, 54], "toi": [8, 26, 27, 36, 37, 38, 39, 42, 46], "toilet": [41, 44], "token": [7, 44, 54], "token_pattern": 29, "tol": [32, 36], "told": [5, 54], "tolist": [24, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 43, 44, 53], "tomasbeuzen": 8, "tomorrow": [25, 42, 43, 46, 53], "ton": 31, "tone": 44, "too": [6, 7, 26, 27, 29, 31, 33, 34, 35, 40, 42, 43, 48, 50, 53, 54], "took": 42, "tool": [7, 8, 10, 11, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 46, 54], "toolbox": [27, 34, 40], "toolkit": 40, "top": [25, 29, 31, 32, 38, 42, 53], "topi": 40, "topic": [2, 8, 10, 25, 32, 33, 37, 39, 41, 46, 54], "topic2vec": 40, "topics_per_chunk": 40, "topn": [24, 41], "torch": [41, 44], "torchvis": [24, 41], "tornado": 44, "toronto": [40, 44], "tort": 0, "total": [8, 10, 25, 28, 29, 32, 33, 34, 35, 36, 40, 42, 43, 53], "total_bedroom": [28, 29, 36, 49], "total_bilirubin": 24, "total_protien": 24, "total_room": [28, 29, 36, 49], "total_second": [42, 53], "totalbsmtsf": [33, 35], "totalcharg": 43, "totem": 41, "totensor": 41, "toti": [0, 1, 40], "totrmsabvgrd": [33, 35], "toward": [30, 35, 40, 51, 54], "towardsdatasci": [41, 43], "town": 44, "townsvil": 42, "toy_clust": 40, "toy_clust_df": 37, "toy_df": [29, 40], "toy_lda_data": 40, "toy_movie_feat": 39, "toy_rat": 39, "toy_spam": 29, "toy_x": 40, "tp": 32, "tpot": 31, "tpr": 32, "tpr_lr": 32, "tpr_svc": 32, "tr_score": 48, "traceback": [4, 8, 29, 43, 44], "track": [29, 54], "trade": [30, 32, 36, 37, 46, 54], "tradeoff": [15, 27, 28, 30, 33, 36, 37, 41], "tradit": [24, 39, 41, 43, 54], "tradition": 54, "trail": 8, "train": [7, 27, 28, 31, 33, 34, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53], "train_accuraci": 32, "train_dataload": 41, "train_df": [24, 28, 29, 30, 32, 33, 34, 35, 36, 42, 43, 44, 49, 51, 52, 53], "train_df_churn": 43, "train_df_nan": [32, 34, 35, 51], "train_df_ord": [42, 53], "train_df_sort": 42, "train_df_surv": 43, "train_df_surv_not_churn": 43, "train_f1": 32, "train_flatten": 41, "train_for_usr": 39, "train_load": 41, "train_mape_scor": 33, "train_mat": 39, "train_mat_imp": 39, "train_neg_mean_squared_error": 33, "train_neg_root_mean_square_error": 33, "train_precis": 32, "train_r2": 33, "train_recal": 32, "train_scor": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 44, 48], "train_shap_valu": 35, "train_sklearn": 33, "train_test_split": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53], "train_x": 39, "traitlet": 44, "transact": [25, 32, 42, 51], "transfer": 43, "transfer_learning_tutori": 41, "transform": [0, 27, 31, 32, 34, 35, 38, 40, 41, 42, 43, 44, 46, 48, 49, 53], "transformed_exampl": 34, "transformed_oh": 28, "transformedtargetregressor": [33, 36, 44, 46], "transformedtargetregressortransformedtargetregressor": 33, "transformerdecod": 44, "transformerencod": 44, "translat": [9, 10, 24], "transpar": [32, 46], "transpos": [36, 41], "trasform": 28, "trash": 47, "traumat": 54, "treat": [8, 26, 28, 29, 32, 33, 39, 42, 43, 46, 51, 53], "treati": 54, "treatment": 29, "tree": [2, 10, 14, 19, 20, 26, 27, 28, 29, 30, 31, 33, 36, 38, 41, 42, 43, 45, 46, 47, 49, 50, 52], "tree1": 34, "tree2": 34, "tree3": 34, "tree_numeric_transform": 35, "treeexplain": 35, "trend": [43, 46, 54], "tri": [34, 35, 45, 50, 51, 52], "trial": [31, 43], "triangl": [27, 37], "trick": [5, 33], "tricki": [29, 31, 35, 39], "trigger": [27, 44], "trigram": 40, "trivial": 38, "troubl": 11, "true": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53], "truli": [33, 40], "truncat": 38, "truncate_mod": 38, "truncation_mod": 38, "trust": [24, 28, 29, 31, 32, 33, 34, 35, 36, 39, 41, 44], "trustworthi": [38, 52], "truth": [34, 36, 37, 38, 39, 42], "try": [4, 5, 8, 10, 11, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54], "tsa": 42, "tscv": 42, "tslearn": 42, "tsunami": 24, "ttr": 33, "ttr_pipe": 33, "tue": 42, "tuesdai": [10, 36, 42, 53, 54], "tuggeranong": 42, "tumor": 46, "tune": [26, 31, 34, 38, 39, 41, 50, 52], "turn": [4, 26, 40, 41, 43, 49, 50, 54], "tusker": 41, "tutori": [4, 5, 9, 10, 11, 39, 41, 46, 54], "tweak": [27, 48], "tweet": [40, 44], "tweetat": 44, "twice": [8, 26, 29, 30], "twist": 40, "twitter": 40, "twitter_allowed_char": 44, "two": [4, 6, 7, 8, 9, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 49, 51, 54], "two_citi": 27, "two_song": 28, "two_songs_subset": 28, "tx": [30, 44], "txt": [24, 41], "typ": [33, 35], "type": [4, 8, 11, 25, 27, 28, 29, 31, 34, 36, 38, 39, 40, 41, 44, 46, 48, 49, 50, 53, 54], "typeerror": 43, "typic": [2, 7, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 42, 50], "u": [4, 11, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 52, 53], "u6": 25, "u_1": 27, "u_2": 27, "u_i": 27, "u_n": 27, "ubc": [0, 4, 5, 8, 9, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54], "ubc_img": 41, "ubc_okanagan": 40, "ubco": 40, "ubyssei": 40, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 33, "ufv": 40, "ultim": [4, 26], "ultralyt": 41, "uluru": [42, 53], "umbrella": 39, "un": [33, 43], "unabl": [24, 28, 29, 31, 32, 33, 34, 35, 36, 38, 41, 43, 44, 54], "unambigu": 40, "unassign": [37, 38], "unbalanc": 51, "unbias": [32, 51], "unced": 54, "uncertain": [30, 52], "uncertain_indic": 52, "uncertainti": [30, 32], "unchang": 35, "uncia": [24, 41], "uncomfort": 39, "uncorrel": 35, "under": [0, 1, 7, 25, 26, 33, 40, 41, 43], "under_sampl": 32, "underestim": 43, "underfit": [27, 30, 31, 41, 48, 50], "underli": [2, 35, 36, 37], "underneath": 7, "underpredict": 33, "undersample_pip": 32, "understand": [0, 1, 4, 7, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 51, 54], "understood": 32, "unemploi": 43, "unexpect": [29, 30, 31, 40], "unexplain": 33, "unf": [33, 35], "unfinish": 33, "unfortun": [6, 31, 35, 37, 38, 50], "uniform": [31, 32, 38, 50], "unimport": [31, 35], "uninstal": 11, "uninterpret": 35, "unintuit": 8, "union": 8, "uniqu": [28, 29, 32, 33, 34, 35, 39, 40, 42, 43, 51, 53], "unit": [30, 32, 33, 34, 35, 40, 41, 43, 44], "unitless": 33, "univers": [1, 9, 40], "university_year": [29, 46], "unix": [5, 42], "unknown": [6, 40, 46], "unlabel": [24, 26, 38], "unless": [7, 54], "unlik": [8, 26, 27, 29, 33, 35, 37, 38], "unlimit": 42, "unlucki": 26, "unmarri": [34, 35], "unnam": 24, "unoffici": 54, "unqualifi": [32, 51], "unreason": [6, 33], "unreli": 26, "unscal": 28, "unseen": [25, 36, 37, 41, 48], "unsqueez": 41, "unstructur": 40, "unsupervis": [24, 39, 40, 41, 54], "unsur": 7, "until": [4, 25, 26, 31, 36, 37, 38, 40, 43], "unus": 48, "unwieldi": [25, 28], "unzip": 35, "uoft": 40, "up": [7, 8, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 54], "uparrow": 38, "upcom": 37, "updat": [10, 11, 27, 28, 29, 34, 37, 48], "update_cent": 37, "update_plot": [27, 48], "update_z": 37, "upei": 40, "upgrad": [40, 44], "upload": 7, "upon": [0, 25, 26, 29, 32, 34, 35, 36, 37, 38, 40], "upper": [32, 43], "uppercas": 44, "upto": 42, "ur": 24, "urgent": [29, 40], "url": [4, 26, 32, 43, 51], "us": [0, 2, 4, 5, 10, 11, 30, 31, 35, 38, 39, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53], "usa": [8, 26, 27, 30, 40], "usag": [28, 29, 32, 33, 36, 40, 42, 43, 53], "usec_": 43, "useless": [31, 35, 36], "user": [11, 24, 25, 26, 28, 29, 31, 34, 35, 37, 38, 40, 41, 43, 44, 45, 46, 50], "user_global_n": 44, "user_id": 39, "user_inverse_mapp": 39, "user_kei": 39, "user_mapp": 39, "user_n": 44, "user_nam": 39, "usernam": 44, "userwarn": [25, 26, 29, 34, 35, 44], "usf": 29, "using_copy_on_writ": 43, "using_cow": 43, "usual": [10, 11, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 53, 54], "utc": [42, 43], "utcnow": 43, "util": [5, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 43, 44, 46, 47, 48, 49, 50, 52], "utilities_allpub": 33, "utilities_nosewa": 33, "utility_mat": 39, "uvic": 40, "v": [3, 7, 10, 29, 30, 38, 40, 42, 43, 46], "v1": [24, 32], "v10": 32, "v11": 32, "v12": 32, "v13": 32, "v14": 32, "v15": 32, "v16": 32, "v17": 32, "v18": 32, "v19": 32, "v2": [24, 32], "v20": 32, "v21": 32, "v22": 32, "v23": 32, "v24": 32, "v25": 32, "v26": 32, "v27": 32, "v28": 32, "v3": 32, "v4": 32, "v5": 32, "v6": 32, "v7": 32, "v8": 32, "v9": 32, "v_1": 27, "v_2": 27, "v_i": 27, "v_n": 27, "vacat": 30, "vaccin": 44, "vada_pav": 40, "vader": 44, "vader_lexicon": 44, "vader_senti": 44, "vain": 31, "val": [39, 43], "valenc": [27, 28, 31, 44, 50], "valid": [10, 15, 25, 27, 29, 33, 34, 35, 36, 37, 39, 41, 43, 44, 46, 49, 50, 51, 52, 53], "valid_dataload": 41, "valid_flatten": 41, "valid_load": 41, "valid_mat": 39, "valid_sample_df": 34, "valid_sample_i": 34, "valid_sample_x": 34, "valid_scor": 48, "valid_x": 39, "valu": [7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53], "valuabl": [36, 38, 54], "value_count": [25, 29, 32, 34, 35, 42, 43, 44, 51, 52, 53], "value_throttl": [27, 48], "valueerror": [8, 28, 29, 43], "values_format": [32, 51], "vancouv": 40, "vancouver_canuck": 40, "vanilla": 30, "var": [26, 28, 35, 44, 50], "var_": 35, "varada": [0, 1], "vari": [25, 31, 34, 38, 43, 48, 54], "variabl": [7, 8, 25, 28, 29, 30, 31, 33, 35, 36, 42, 43, 48, 53], "varianc": [33, 35, 38, 42, 48], "variant": [35, 38], "variat": [26, 30, 32, 33, 36], "varieti": [24, 34, 40], "variou": [24, 27, 33, 35, 41, 42, 43, 46, 48, 50, 54], "vault": 26, "ve": [7, 8, 24, 26, 27, 32, 33, 35, 39, 40, 41, 42, 45, 53], "vec": [29, 40, 41], "vec1": 40, "vec1_i": 40, "vec2": 40, "vec2_i": 40, "vec8": 29, "vec8_binari": 29, "vec_binari": 29, "vecom": 31, "vector": [15, 25, 30, 32, 39, 41, 48, 52], "verb": [40, 44], "verbos": [24, 32, 34, 35], "veri": [2, 4, 5, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 53, 54], "verifi": 51, "versa": [33, 48, 51], "version": [4, 5, 7, 8, 11, 26, 28, 30, 31, 33, 35, 38, 40, 42, 43, 44, 45, 51, 53, 54], "versu": 9, "vert": 35, "vertic": [25, 32, 42], "vgg": 41, "vgg16": 41, "vgg16_weight": 41, "via": [1, 4, 7, 11, 32, 36, 54], "vice": [33, 48, 51], "video": [1, 7, 8, 9, 10, 11, 19, 23, 39, 41, 43, 48, 51, 54], "vietnames": 28, "view": [6, 7, 11, 24, 25, 35, 38, 41, 42, 43], "viewpoint": 39, "vif": 35, "vikski": 40, "violat": [28, 29, 43, 54], "virginia": 41, "viridi": [31, 50], "visibl": 50, "vision": [10, 45], "visit": [8, 54], "visual": [10, 25, 26, 27, 29, 30, 32, 33, 34, 35, 37, 38, 41, 42, 43, 44, 46, 49, 50, 54], "viu": 40, "voc": [32, 34, 35, 51], "vocab": 40, "vocabulari": [29, 30, 40], "vocabulary_": 29, "voic": 24, "volcano": 24, "vote": [27, 28, 34, 45, 52], "voting_ndt": 34, "votingclassifi": [34, 52], "votingclassifierinot": 34, "votingregressor": 34, "w": [11, 29, 30, 33, 37, 40, 42, 53, 54], "w_0": 30, "w_1": 30, "w_1x_1": 30, "w_2x_2": 30, "w_3x_3": 30, "w_4x_4": 30, "w_d": 30, "w_dx_d": 30, "w_j": 30, "wa": [4, 5, 11, 25, 26, 28, 30, 32, 34, 35, 39, 40, 41, 43, 44, 45, 47, 48, 50, 53, 54], "wa_fn": 43, "wai": [0, 2, 6, 8, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 50, 51, 53, 54], "wait": [4, 24, 25, 27, 29, 43, 54], "waitlist": 54, "waiv": 54, "walk": [27, 32, 48], "walker": [24, 41], "wallabi": 41, "want": [4, 6, 7, 8, 11, 24, 25, 26, 27, 28, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 46, 49, 50, 51, 53, 54], "war": 39, "ward": 38, "warm": 28, "warm_start": 32, "warn": [6, 26, 27, 29, 33, 34, 35, 43, 45, 52], "warranti": 0, "washington": 44, "washroom": 54, "wasn": 40, "wast": [4, 29], "watch": [10, 11, 27, 30, 39, 40, 46], "waterfal": 35, "waterfront": [24, 25], "wavelet": 36, "wd": [33, 35], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "weak": 46, "weather": [25, 42], "weatherau": [42, 53], "web": [5, 40, 46], "weblog": 40, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "wed": [10, 42], "wednesdai": [10, 42, 54], "week": [6, 13, 14, 26, 27, 28, 29, 32, 33, 34, 35, 39, 40, 42, 51, 54], "weekdai": 42, "weekend": [8, 42], "weekli": 44, "weight": [27, 34, 36, 39, 40, 41, 51, 54], "weighted_averag": 32, "weinberg": 35, "weird": 33, "welcom": [47, 54], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 50, 53, 54], "welsh": [24, 41], "went": [33, 44, 50, 52], "were": [0, 6, 29, 30, 32, 33, 40, 41, 42, 43, 50, 52, 54], "weren": 40, "what": [7, 8, 9, 25, 27, 31, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "whatev": 36, "when": [4, 6, 7, 11, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 51, 52, 53, 54], "wher": 44, "where": [0, 7, 10, 11, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 46, 48, 51, 53], "wherea": [2, 25, 30, 31, 33, 35, 38], "whether": [0, 4, 7, 8, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 42, 43, 44, 47, 52, 53, 54], "which": [4, 6, 8, 11, 26, 27, 28, 29, 30, 31, 33, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54], "whichev": 34, "while": [25, 26, 30, 31, 32, 34, 35, 37, 39, 40, 43, 44, 50], "white": [32, 34, 35, 38, 40], "whitespac": [40, 43], "who": [4, 5, 6, 24, 32, 35, 37, 38, 40, 42, 43, 44, 46, 54], "whole": [26, 31, 33, 35, 39, 50], "whom": [0, 40, 44], "whose": 4, "why": [8, 26, 27, 32, 33, 34, 37, 38, 40, 42, 43, 46, 47, 48, 49, 50], "wid": 32, "wide": [11, 30, 31, 34, 36, 39, 41], "wider": [27, 48], "widespread": 40, "widget": [27, 32, 37, 38, 48], "width": [25, 26, 27, 32, 40, 47, 48], "wife": [24, 32, 34, 35], "wiki": 40, "wiki_df": 40, "wiki_dict": 40, "wikipedia": [40, 41], "wikipedia2vec": 40, "wild": [24, 26, 41], "willing": 32, "win": [27, 29, 34, 35, 36, 39, 45], "wind": 25, "winddir3pm": [42, 53], "winddir3pm_miss": [42, 53], "winddir3pm_ss": [42, 53], "winddir3pm_ssw": [42, 53], "winddir3pm_sw": [42, 53], "winddir3pm_w": [42, 53], "winddir3pm_wnw": [42, 53], "winddir3pm_wsw": [42, 53], "winddir9am": [42, 53], "windgustdir": [42, 53], "windgustspe": [42, 53], "window": [10, 43], "windsor": 44, "windspeed3pm": [42, 53], "windspeed9am": [42, 53], "wine_1": 8, "winter": 42, "winter_month": 42, "wire": 39, "wisdom": 34, "wish": [24, 25, 37, 54], "within": [25, 28, 30, 34, 36, 37, 38, 43, 46, 50], "without": [0, 7, 24, 25, 32, 34, 35, 36, 39, 41, 42, 43, 50, 54], "wnw": [42, 53], "wolv": 38, "woman": 40, "wombat": 41, "won": [5, 11, 25, 26, 27, 29, 30, 36, 39, 40, 41, 42, 43, 44], "wonder": [24, 26], "wooddecksf": [33, 35], "word": [24, 30, 31, 32, 36, 37, 38, 39, 41, 42, 43, 46, 50, 54], "word1": 40, "word2": 40, "word2vec": [40, 41, 54], "word3": 40, "word_pair": 40, "word_token": [40, 44], "wordnet": 40, "wordnetlemmat": 40, "work": [0, 4, 5, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 50, 52, 53, 54], "work_of_art": 44, "workclass": [32, 34, 35, 51], "workclass_feder": [34, 35], "workclass_loc": [34, 35], "workclass_miss": 35, "workclass_nev": [34, 35], "workclass_priv": [34, 35], "workclass_self": 35, "workclass_st": 35, "workclass_without": 35, "workflow": [25, 54], "world": [27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 46], "worm": 41, "worri": [24, 37, 38, 39, 52], "wors": [25, 31, 33, 34, 43, 47, 50, 51], "worst": [32, 36, 37], "worth": [25, 27, 32, 33, 51], "worthi": 30, "would": [4, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54], "wouldn": [29, 31, 40, 43], "wow": 35, "wrap": 29, "wrapper": 36, "write": [4, 7, 24, 31, 35, 36, 37, 40, 44, 48, 52, 54], "written": [7, 29, 35, 42, 53], "wrong": [11, 26, 30, 33, 36, 37, 43, 50], "wrote": [40, 42, 53], "wsw": [42, 53], "www": [9, 30], "x": [4, 8, 11, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51], "x0": 36, "x0_male": 32, "x1": [36, 39], "x139": 54, "x1x2": 36, "x2": [36, 38, 39], "x27": [28, 29, 31, 32, 33, 34, 36, 41, 44], "x_": 30, "x_1": [30, 36, 37], "x_1x_2": 36, "x_2": [30, 36, 37], "x_binari": 25, "x_citi": 27, "x_count": 29, "x_d": 30, "x_femal": [32, 51], "x_hour": 42, "x_hour_week": 42, "x_hour_week_onehot": 42, "x_hour_week_onehot_poli": 42, "x_hour_week_onehot_poly_lag": 42, "x_i": [30, 39], "x_imp_ohe_train": 28, "x_init": 37, "x_int": 29, "x_label": [25, 26, 27, 47], "x_lag_featur": 42, "x_lag_features_imp": 42, "x_male": [32, 51], "x_mask": 29, "x_multi": 45, "x_n": 36, "x_orig": 38, "x_re": 32, "x_small_citi": 27, "x_spotifi": [27, 31, 50], "x_subset": [25, 26], "x_test": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52], "x_test_big": 31, "x_test_enc": [35, 42, 43, 53], "x_test_happi": 32, "x_test_imp": 28, "x_test_multi": 45, "x_test_pr": 42, "x_test_predict": 28, "x_test_scal": 28, "x_test_transform": 28, "x_toi": [27, 28, 29, 42], "x_toy_oh": 28, "x_toy_ord": [28, 29], "x_tr": 48, "x_train": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52], "x_train_big": [32, 51], "x_train_enc": [32, 33, 35, 42, 43, 51, 53], "x_train_happi": 32, "x_train_hous": 36, "x_train_imp": 28, "x_train_imp_sc": 28, "x_train_multi": 45, "x_train_oversampl": 32, "x_train_perm": 35, "x_train_pp": 29, "x_train_predict": 28, "x_train_scal": [28, 36], "x_train_subsampl": 32, "x_train_tini": 31, "x_train_transform": 28, "x_train_usr": 39, "x_transform": 29, "x_valid": [32, 39, 48, 51], "x_vari": 38, "x_xor": 36, "xanni": 31, "xavier": [36, 39], "xcode": 5, "xgbclassifi": [34, 35], "xgbclassifierxgbclassifi": 34, "xgboost": 35, "xgbregressor": [24, 34], "xia": 54, "xlabel": [8, 25, 26, 27, 30, 31, 32, 33, 35, 38, 41, 42, 43, 45, 47, 50, 53], "xlim": 43, "xor": [30, 36], "xt": 29, "xtick": [26, 32, 42, 53], "xticklabel": [31, 50], "xticks_rot": 32, "xwm\u0259\u03b8kw\u0259y": 54, "xx": [36, 37], "y": [8, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53], "y_": 39, "y_citi": 27, "y_femal": [32, 51], "y_hat": [30, 34], "y_i": [33, 34, 36, 39], "y_init": 37, "y_label": [25, 26, 27, 47], "y_male": [32, 51], "y_mat": 39, "y_multi": 45, "y_pred": [32, 42], "y_pred_lower_threshold": 32, "y_pred_toi": 32, "y_pred_train": 42, "y_re": 32, "y_small_citi": 27, "y_spotifi": [31, 50], "y_test": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53], "y_test_big": 31, "y_test_happi": 32, "y_test_multi": 45, "y_test_num": [34, 35], "y_toi": [27, 42], "y_tr": 48, "y_train": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53], "y_train_big": [32, 51], "y_train_happi": 32, "y_train_hous": 36, "y_train_multi": 45, "y_train_num": [34, 35], "y_train_ord": [42, 53], "y_train_oversampl": 32, "y_train_subsampl": 32, "y_train_tini": 31, "y_train_usr": 39, "y_true_toi": 32, "y_valid": [32, 39, 41, 48, 51], "y_vari": 38, "y_xor": 36, "yale": 40, "yann": 35, "ycxmx": 43, "ye": [4, 24, 25, 28, 29, 35, 37, 38, 39, 41, 42, 44, 46, 53], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 39, 40, 41, 42, 43], "yearbuilt": [33, 35], "yearremodadd": [33, 35], "yellow": 31, "yellowbrick": [37, 38], "yesterdai": [42, 53], "yet": [10, 11, 30, 35, 39, 42, 43, 48, 54], "yield": 50, "yifei": 54, "yjh": [24, 25, 29, 30, 33, 34], "ylabel": [8, 25, 26, 27, 30, 31, 32, 33, 38, 41, 42, 43, 45, 47, 48, 50, 53], "ylim": 43, "yml": 11, "yolo": 41, "yolo8": 41, "yolo_input": 41, "yolo_result": 41, "yolo_test": 41, "yolov8n": 41, "york": [42, 44], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 35, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "your": [0, 2, 4, 6, 7, 8, 10, 11, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "your_miniconda_path": 44, "your_nam": 11, "yourself": [4, 29, 32, 39, 40, 54], "yourselv": 40, "youtub": [1, 10, 39, 40, 54], "yr_built": [24, 25], "yr_renov": [24, 25], "yrpxn": 43, "yrsold": [33, 35], "ytick": [26, 32], "yticklabel": [31, 50], "yy": [36, 42, 53], "yyyi": [42, 53], "z": [8, 30, 36, 37, 38, 39, 41, 43], "z_i": 41, "z_j": 41, "z_km": 37, "z_train": 41, "z_valid": 41, "zachari": 43, "zarei": 54, "zero": [8, 26, 29, 31, 39, 40], "zero_divis": 32, "zhu": 54, "zip": [27, 30, 39, 48], "zipcod": [24, 25, 48], "zmqshell": 44, "zone": [42, 53], "zoom": [7, 50, 54], "\u0259m": 54, "\u03bc": 45}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Class Meeting 4B", "Class Meeting 4C", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [24, 26, 27, 28, 29, 32, 33, 35, 42], "0": 34, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 43, 46, 47, 48, 49, 50, 51, 52, 53], "10": [18, 33, 52], "11": [20, 34], "12": [21, 34, 35], "13": [22, 36], "14": [23, 36, 37], "15": [23, 37, 38], "16": [38, 39], "17": [39, 40], "18": 41, "19": [41, 42], "1a": 13, "1b": 14, "1c": 15, "2": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 43, 46, 47, 48, 49, 50, 51, 52, 53], "20": 43, "2025s1": 1, "21": 43, "2a": 16, "2b": 17, "3": [15, 24, 25, 26, 28, 36, 37, 38, 43, 47, 48, 49, 50, 51, 52, 53], "330": [1, 2, 3, 6, 8], "340": 2, "3a": 18, "3b": 19, "3c": 20, "4": [15, 25, 26, 27, 47, 48, 49, 50, 51, 52, 53], "4a": 21, "4b": 22, "4c": 23, "5": [8, 16, 25, 26, 27, 28, 29, 32, 35, 36, 37, 40, 41, 43, 48, 49, 50, 51, 52, 53], "6": [16, 29, 48, 50, 51, 52, 53], "7": [17, 30, 50, 52, 53], "8": [17, 31, 50, 52], "9": [18, 32, 52], "A": [4, 32, 38, 42, 44], "No": 8, "Not": 46, "One": [28, 42, 45], "The": [26, 30, 31, 34, 36, 37, 52], "__": 31, "about": [8, 36, 39], "academ": 54, "access": [7, 30, 54], "accommod": 54, "acknowledg": 54, "activ": [32, 35, 36, 37, 40, 51], "actual": 29, "ad": 8, "addit": [7, 35], "address": 32, "advantag": 31, "advic": 36, "ai": 54, "algorithm": [25, 27, 36, 37], "all": [24, 25, 28, 30, 32, 37, 38, 39], "alpha": [30, 33], "altern": [25, 28], "an": [34, 44], "analogi": 27, "analysi": [42, 43, 46, 48, 53], "announc": [25, 27, 29, 30, 34], "answer": 43, "ap": 32, "api": 28, "appendix": [44, 45], "appli": [1, 8, 28, 29, 33], "applic": 37, "applymap": 8, "approach": [39, 42, 43, 45], "approxim": 26, "ar": [5, 24, 25, 28, 30, 32, 37, 38, 39], "area": 32, "argument": [26, 27], "arrai": 8, "articl": 9, "ask": 4, "assign": [7, 54], "associ": 30, "assum": 43, "attent": [25, 27], "attribut": 35, "auc": 32, "autom": 31, "averag": [32, 34, 39, 52], "avoid": 26, "b": [37, 45], "backward": 36, "bad": 31, "bag": [29, 44], "balanc": 32, "base": [27, 34, 36, 39, 42, 53], "baselin": [25, 28, 32, 34, 35, 39, 48], "basic": 40, "befor": 28, "best": 36, "better": [26, 31, 32, 36], "between": [25, 27, 47], "beyond": [35, 39], "bia": [26, 31], "big": [25, 26, 28], "binari": 32, "book": 10, "boost": 34, "bootstrap": 34, "boundari": [25, 27, 30, 47], "bow": 29, "box": 41, "break": [8, 25, 26, 27, 28, 29, 36, 40, 41, 43], "broadcast": 8, "build": [24, 25, 33, 39], "c": [27, 31], "calcul": 30, "california": [29, 30, 49], "can": [8, 26, 28, 34, 35, 36, 37], "canada": [25, 47], "care": 39, "carri": [28, 36], "case": [29, 30, 38], "catboost": 34, "categor": [28, 29, 35, 42], "categori": 29, "censor": 43, "centr": 54, "certain": 29, "cfa": 54, "chang": 32, "charact": 24, "characterist": 32, "cheatsheet": 8, "choos": [27, 37], "churn": 43, "cite": 7, "citi": 30, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 31, 32, 33, 34, 35, 39, 41, 45, 54], "class_attend": 29, "class_weight": 32, "classif": [25, 32, 41, 46], "classifi": [25, 30, 34, 44], "clearli": 36, "cluster": [37, 38, 46], "co": 54, "code": [11, 54], "coeffici": [30, 35], "color": [47, 48, 49, 50, 51, 52, 53], "column": [8, 28, 29, 42], "columntransform": [29, 49], "combin": 34, "come": [26, 27], "command": 5, "comment": [25, 31, 32, 33, 37, 38, 39], "common": [28, 37], "commonli": 40, "commun": 46, "compact": 28, "companion": 9, "complet": 39, "complex": 26, "complic": [42, 53], "compon": 30, "comprehens": 49, "comput": [41, 46], "con": [27, 38, 46], "concern": 6, "concess": 54, "conda": 11, "conduct": 54, "confid": 30, "confus": 32, "consid": 43, "construct": 34, "content": 39, "context": 40, "continu": 25, "conveni": 29, "correct": 37, "correl": 35, "countri": [25, 47], "countvector": 29, "cours": [9, 10, 24, 54], "cover": [39, 43], "cox": 43, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 25, 26, 29, 39], "credit": [11, 54], "cross": [26, 28, 32, 36, 42, 48], "cross_val_scor": 26, "cross_valid": [26, 33], "csv": 8, "curs": 27, "curv": [32, 43], "custom": [37, 43], "cv": 31, "dai": 42, "data": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 44, 48, 53], "datafram": [8, 29], "dataset": [7, 25, 28, 29, 30, 31, 32, 33, 41, 42, 49, 52, 53], "date": [10, 42], "datetim": [42, 53], "dbscan": 38, "deal": [29, 32], "debug": 11, "decis": [25, 27, 30, 35, 48], "decisiontreeclassifi": [25, 34], "decreas": 32, "deep": [41, 42], "defin": 36, "definit": 24, "deliver": 10, "demo": [36, 42, 44], "demonstr": 32, "dendrogram": 38, "depend": 36, "deploy": [26, 46], "descript": 54, "desktop": 5, "detail": [32, 33, 38], "detect": 41, "df": 8, "did": [26, 28, 29, 32, 33, 39, 43], "differ": [28, 31, 32, 33, 35, 46], "dimens": 27, "dimension": 27, "discuss": [31, 32, 39, 40, 51], "diseas": 24, "distanc": [27, 37], "distribut": 31, "do": [28, 29, 31, 32, 34, 35, 36], "document": [3, 8, 37], "doe": [25, 30, 38], "domain": 36, "drop": 8, "due": 10, "dummi": 44, "dummyclassifi": [25, 34, 42, 43], "dummyregressor": [25, 28, 33], "eda": [28, 32, 33, 48], "effect": 34, "elbow": 37, "element": 8, "elimin": 36, "embed": 40, "encod": [28, 29, 36, 42], "engin": [36, 42, 44, 46], "ensembl": [34, 46], "environ": 11, "error": [26, 31, 32, 33, 39], "estim": [28, 34], "ethic": 46, "euclidean": 27, "eva": [24, 26], "evalu": [32, 38, 39, 43, 46, 51], "evalut": 32, "event": 43, "everyon": 43, "exactli": 30, "exam": [46, 54], "examin": [29, 33, 46], "exampl": [24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 40, 43, 44], "exercis": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 43, 47], "exhaust": 31, "explain": 35, "explan": 35, "explor": [27, 37], "exploratori": [42, 48, 53], "extract": [29, 42], "extractor": 41, "f1": 32, "failur": 38, "fair": [32, 51], "fancier": 31, "faster": 8, "fastest": 8, "featur": [24, 25, 27, 28, 29, 30, 33, 35, 36, 39, 41, 42, 44, 46, 53], "feature_importances_": 35, "few": [32, 38], "fictiti": 24, "figur": 7, "filter": [8, 39], "final": [25, 31, 37, 38, 39, 42, 46, 48, 54], "find": [27, 36], "first": 28, "fit": [25, 28, 34], "flatten": 41, "follow": [24, 25, 26, 37, 38, 39], "font": [47, 48, 49, 50, 51, 52, 53], "forecast": 42, "forest": [34, 35], "format": [7, 8], "formul": 39, "forum": 4, "forward": 36, "from": [8, 44], "function": [8, 30, 33], "fundament": [26, 27, 34, 46], "further": [42, 44], "futur": 42, "gamma": 27, "garbag": 36, "gener": [4, 6, 26, 27, 30, 34, 36], "geometr": 27, "get": 35, "git": [5, 11], "github": 5, "given": [24, 25], "global": 39, "goal": 26, "golden": [26, 28, 29], "good": 32, "grade": [4, 6, 25, 54], "gradescop": 7, "gradient": 34, "grid": 31, "gridsearchcv": [31, 33], "group": [32, 37, 51], "guid": 46, "guidelin": [4, 6, 7], "ha": 24, "halv": 31, "handl": 32, "have": [34, 35], "hazard": 43, "heatmap": 31, "help": [4, 36], "here": 26, "hierarch": 38, "home": 38, "homework": 7, "hot": [28, 36, 42], "hous": [24, 25, 28, 29, 30, 49], "how": [4, 7, 25, 26, 27, 28, 30, 34, 35, 36, 38], "hyper": 31, "hyperparamet": [25, 27, 29, 30, 31, 33, 34, 37, 46, 48], "i": [24, 26, 28, 29, 31, 32, 34, 35, 36, 37, 39, 40, 44], "iclick": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 43, 54], "idea": [27, 32, 34, 36], "identifi": [29, 35], "imag": [24, 41], "imagenet": 41, "imbal": [32, 33, 34, 35], "import": [1, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 53], "improv": 44, "imput": [28, 39], "incorpor": 29, "increas": 32, "index": 8, "inertia": 37, "info": 7, "inform": [35, 42], "initi": 37, "inject": 34, "input": [24, 37], "instal": [5, 11], "instruct": [0, 7], "interact": 36, "intercept": 30, "interim": [32, 35, 36, 42], "interpret": [30, 35], "intra": 37, "intro": 39, "introduct": [8, 24, 35, 36, 37, 38, 40, 41, 46], "intuit": 30, "involv": 42, "jupyterlab": 11, "k": [27, 28, 37, 38, 39], "kaplan": 43, "kei": 35, "kernel": 27, "kind": 34, "kneighborsclassifi": 27, "label": [24, 37], "lag": [42, 53], "land": 54, "languag": 40, "larg": 31, "late": 7, "latitud": [25, 47], "lda": 40, "learn": [1, 5, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 54], "least": 30, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 54], "lecture03": 15, "let": [27, 28, 29, 32, 33, 35], "licens": [0, 1], "lightgbm": 34, "limit": [6, 30, 38], "line": 5, "linear": [30, 33, 35], "link": 1, "list": 9, "liver": 24, "ll": 26, "lo": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 41, 42], "logist": [30, 32, 41], "logisticregress": [32, 42, 43], "longitud": [25, 47], "look": [32, 37], "loop": 8, "lower": 31, "mac": 5, "machin": [1, 24, 25, 26, 27, 32, 37], "maco": 11, "macro": 32, "magnitud": 30, "mai": 36, "main": [30, 39], "make": [8, 30], "make_column_transform": 29, "make_pipelin": 28, "mani": [29, 31], "manual": 31, "mape": 33, "materi": [0, 9, 10], "matplotlib": 8, "matric": 29, "matrix": [32, 39], "max_depth": 25, "mean": [33, 37, 38, 40], "measur": 36, "media": 40, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 54], "meier": 43, "messag": [24, 38], "meta": 45, "method": [8, 31, 36, 37], "metric": [32, 33, 46], "midterm": [37, 54], "might": 43, "min": [8, 25, 26, 27, 28, 29, 32, 35, 36, 37, 40, 41, 43], "minor": 32, "misc": [9, 10], "miscellan": 39, "ml": [24, 26, 27, 32, 35, 46, 51], "model": [24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 40, 41, 43, 44, 46, 48, 51], "model_select": 31, "month": 42, "more": [25, 27, 28, 29, 30, 32, 33, 36, 38, 42, 53], "most": 30, "motiv": [26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42], "movi": 39, "mse": 33, "much": 31, "multi": [32, 41, 45], "multiclass": 46, "multipl": [27, 29, 33], "multipli": 8, "n_estim": 34, "n_iter": 31, "n_job": 31, "n_neighbor": 27, "name": [26, 33, 39], "natur": 40, "nearest": [27, 28, 37, 39], "need": [28, 31], "neg": 32, "neighbour": [27, 28, 39], "nest": 8, "netflix": 34, "network": 41, "neural": 41, "nlp": [40, 46], "nn": 27, "non": [27, 29, 35], "notat": 8, "note": [8, 26, 42, 48], "now": 43, "number": [34, 37, 42], "numer": [35, 36], "numpi": 8, "object": [25, 34, 40, 41, 42, 43, 54], "observ": 32, "occasion": 28, "off": [26, 27, 34], "oh": [28, 29], "ok": [28, 29], "onc": 32, "one": [29, 36], "onehotencod": 29, "onli": [29, 43], "onlin": [9, 10], "oper": 32, "optim": [31, 46], "option": [11, 27, 28, 31, 32, 34, 36, 43], "ordin": [28, 29, 35, 54], "other": [8, 27, 33, 36, 37, 40, 42, 43], "our": [7, 26, 28, 44], "out": [28, 36, 41], "outcom": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39], "outlin": [47, 48, 49, 50, 51, 52, 53], "output": 37, "over": [8, 27, 30, 32], "overfit": [26, 31], "oversampl": 32, "overview": [27, 32], "ovo": 45, "ovr": 45, "packag": [11, 42], "panda": 8, "pandas_profil": 33, "paper": [32, 34], "paradigm": 28, "paramet": [25, 30, 31, 32, 46], "parametr": 27, "pars": [42, 53], "part": 46, "pass": [31, 54], "patient": 24, "perfect": 37, "permutation_import": 35, "persona": 24, "pick": [26, 31], "pictur": [25, 26, 28], "pipelin": [28, 40], "plan": 38, "playground": [27, 48], "plot": [8, 35, 37, 43], "point": [27, 32, 35, 37, 42], "polici": 6, "poll": 37, "popular": 24, "posit": 32, "posix": 42, "possibl": [29, 33, 37, 44], "post": 9, "pr": 32, "practic": [25, 27], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 22, 41], "precis": 32, "predict": [24, 25, 29, 30, 34, 35, 39, 41, 43, 45, 47], "predict_proba": 30, "prepar": [7, 46], "preprocess": [28, 29, 33, 40, 42, 46, 51, 53], "preval": 24, "price": [24, 25], "prize": 34, "pro": [27, 38, 46], "probabl": [30, 31], "problem": [25, 26, 27, 28, 31, 36, 39, 42, 44], "procedur": 32, "process": 40, "product": 24, "profil": 39, "program": 25, "project": 44, "proport": 43, "python": [8, 9, 11], "q": 4, "qualiti": 36, "queri": [8, 27], "question": [4, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53], "quick": 27, "quiz": 25, "quiz2": 25, "quot": 36, "r": 33, "random": [31, 34, 35], "random_st": 26, "randomforestclassifi": [34, 43], "randomizedsearchcv": [31, 33], "rang": 31, "rate": 39, "raw": 30, "rbf": 27, "read": [8, 25, 31, 41], "real": [25, 47], "realist": 29, "reason": 6, "recal": 32, "recap": [25, 27, 38, 43, 47, 49], "receiv": 32, "recommend": [28, 39, 46], "record": 54, "recurs": 36, "red": [47, 48, 49, 50, 51, 52, 53], "refer": [9, 10, 43], "reflect": [25, 26, 37, 38], "registr": 54, "regress": [25, 27, 30, 32, 33, 34, 41], "regressor": 27, "relat": [4, 25, 27], "relev": [9, 32, 34, 36], "remark": 42, "rememb": 37, "remind": [25, 39], "remov": 8, "renam": 8, "report": [7, 32], "repositori": 7, "represent": [29, 41], "requir": 54, "rescu": 26, "resourc": [9, 31, 32, 36, 37, 38, 39], "rest": 45, "result": 31, "retail": 42, "review": 19, "rfe": 36, "ridg": [30, 33], "ridgecv": 33, "right": 43, "rmse": 33, "roc": 32, "root": 33, "row": 8, "rule": [26, 28, 29], "run": 28, "same": 8, "sampl": [32, 34, 37], "sauc": 37, "save": 24, "scale": [24, 28, 30, 35], "schedul": [10, 54], "scheme": 54, "scikit": [26, 28, 29, 33], "score": [25, 26, 30, 31, 32, 33, 36, 37, 44], "search": [27, 31, 36], "season": 42, "segment": 37, "select": [24, 25, 36, 37, 38, 39, 46], "separ": [33, 35], "seri": [8, 42, 46, 53], "set": [5, 11, 26, 31, 32], "set_config": 29, "shap": 35, "shape": [8, 38], "shaplei": 35, "short": 9, "should": [34, 39], "show": 35, "sigmoid": [30, 41], "sign": 30, "silhouett": 37, "similar": 27, "simpl": [26, 44], "simplefeatur": 35, "simul": 52, "singl": 26, "size": 8, "sklearn": [25, 28, 29, 31, 32, 34, 35], "slide": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23], "slowest": 8, "smote": 32, "social": 40, "softmax": 41, "softwar": [0, 41, 42], "solv": 31, "some": [25, 31, 32, 34, 36], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 42, "spaci": [40, 44], "spaghetti": 37, "spam": [24, 29], "spars": 29, "specif": [4, 36], "split": [26, 28, 32, 42, 48], "spotifi": [28, 31], "squar": 33, "stack": [34, 52], "standardscal": 28, "statement": [24, 25, 37, 38, 39], "step": [25, 40, 49], "strategi": [34, 45], "stratifi": 32, "strength": [30, 34], "studi": 46, "submiss": 7, "submit": 7, "success": 31, "summari": [8, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "summer": 10, "supervis": [24, 25, 26, 27, 37, 39], "support": 27, "surviv": [43, 46], "svc": 32, "svm": [27, 30], "syllabu": [1, 54], "syntax": [28, 29, 31], "synthet": 32, "system": [39, 46], "ta": 54, "tabular": [25, 27], "tackl": 33, "take": 38, "target": [24, 25, 29, 33, 37], "task": 40, "teach": [10, 54], "team": 54, "techniqu": [28, 32], "templat": 7, "tempor": 42, "ten": 10, "tent": 10, "terminologi": [25, 41], "test": [5, 26, 31, 42], "test_df": 26, "test_siz": 26, "text": [29, 40, 44], "than": [29, 31, 36], "thei": 34, "them": 8, "thi": [8, 24, 28, 29, 35], "thing": 28, "threshold": 32, "time": [6, 24, 42, 43, 46, 53], "tip": 46, "todai": [26, 28, 29, 32, 33], "toi": [25, 29, 32, 40], "token": 40, "tool": 40, "topic": 40, "trade": [26, 27, 34], "tradeoff": [26, 32, 34], "tradit": [25, 42], "train": [24, 25, 26, 29, 30, 32, 41, 42, 51], "train_df": 26, "train_siz": 26, "transfer": 41, "transform": [28, 29, 33, 36], "transpar": 35, "tree": [25, 34, 35, 48], "trend": 42, "true": [24, 37, 38, 39], "try": [28, 33], "tune": [33, 37, 48], "tutori": [47, 48, 49, 50, 51, 52, 53], "two": 29, "type": [24, 26, 32, 33, 35, 37, 42, 43], "typic": [26, 40], "ubc": 1, "ubuntu": 5, "under": 32, "underfit": 26, "undersampl": 32, "unequ": 42, "unknown": 29, "unlabel": 37, "unseen": [24, 26], "unsupervis": [25, 37], "up": [5, 11, 26, 27], "updat": 7, "url": 8, "us": [7, 8, 24, 25, 26, 27, 28, 29, 32, 33, 34, 36, 37, 40, 41, 45, 47, 54], "usa": [25, 47], "user": [5, 39], "usual": 36, "util": 39, "v": [2, 25, 26, 27, 32, 35, 37, 41, 45], "valid": [26, 28, 31, 32, 42, 48], "varianc": 26, "vector": [8, 27, 40], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 37, 38, 40], "view": [27, 29], "violat": 26, "virtual": 11, "vision": [41, 46], "visual": [9, 31], "wai": [31, 36], "want": [29, 35, 43], "warn": [25, 36], "we": [8, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 43], "weak": 34, "weight": [30, 32], "what": [5, 11, 24, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 43], "when": [8, 28, 31], "where": [29, 43], "whether": 24, "which": [24, 25, 32, 34, 37, 38, 39], "why": [11, 24, 29, 31, 35, 36, 39, 41], "window": [5, 11], "wise": 8, "without": 37, "word": [29, 40, 44], "work": [25, 34, 38], "workflow": [24, 26, 32], "would": 26, "wrapper": 45, "write": 25, "x": [24, 25, 33, 35], "xgboost": 34, "y": [24, 25, 33, 35], "ye": 43, "yield": 31, "you": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43], "your": [5, 25]}})