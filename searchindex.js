Search.setIndex({"alltitles": {"(Optional) Changing the data": [[36, "optional-changing-the-data"]], "(Optional) Evaluation": [[47, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[36, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[35, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[35, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[35, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[38, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[40, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[36, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[31, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[35, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[38, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[40, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[40, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[35, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Some more details": [[36, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[28, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[40, "id1"]], "(iClicker) Exercise 21.1": [[47, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[47, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[31, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[31, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[32, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[32, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[32, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[33, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[33, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[34, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[34, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[35, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[41, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[41, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[41, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[41, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[42, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[42, "id2"]], "16.3 Select all of the following statements which are True": [[42, "select-all-of-the-following-statements-which-are-true"]], "<font color='red'>Question 10</font>": [[57, "question-10"]], "<font color='red'>Question 1</font>": [[52, "question-1"], [53, "question-1"], [55, "question-1"], [56, "question-1"], [57, "question-1"], [58, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[53, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[52, "question-2"], [55, "question-2"], [56, "question-2"], [57, "question-2"], [58, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[53, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[52, "question-3"], [55, "question-3"], [56, "question-3"], [57, "question-3"], [58, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[53, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[52, "question-4"], [55, "question-4"], [56, "question-4"], [57, "question-4"], [58, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[53, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[55, "question-5"], [56, "question-5"], [57, "question-5"], [58, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[53, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[55, "question-6"], [56, "question-6"], [57, "question-6"], [58, "question-6"]], "<font color='red'>Question 7</font>": [[55, "question-7"], [57, "question-7"]], "<font color='red'>Question 8</font>": [[55, "question-8"], [57, "question-8"]], "<font color='red'>Question 9</font>": [[57, "question-9"]], "<font color='red'>Recap Questions</font>": [[52, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[54, "recap-comprehension-questions"]], "A few comments on PR curve": [[36, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[42, "a-few-comments-on-clustering-evaluation"]], "AP score": [[36, "ap-score"]], "AP vs. F1-score": [[36, "ap-vs-f1-score"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[59, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[34, "accessing-learned-parameters"]], "Activity (~5 mins)": [[39, "activity-5-mins"], [39, "id3"]], "Activity: Context and word meaning": [[44, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[40, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[48, "activity-explaining-gridsearchcv-15-min"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[36, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[35, "advantages-of-randomizedsearchcv"], [35, "id1"]], "Alternative and more compact syntax: make_pipeline": [[32, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[29, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[38, "an-effective-strategy"]], "An example from a project": [[49, "an-example-from-a-project"]], "An example of a bootstrap samples": [[38, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[48, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[31, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[31, "analogy-based-models"]], "Announcements": [[34, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[49, null]], "Appendix B: Multi-class, meta-strategies": [[50, null]], "Applying feature transformations": [[37, "applying-feature-transformations"], [48, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[47, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[47, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[47, "approach-3-survival-analysis"]], "Approach from all angles": [[48, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[36, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[36, "area-under-the-curve-auc"]], "Assignments": [[59, "assignments"]], "Attention": [[29, null], [29, null], [29, null], [31, null]], "Attribution": [[48, "attribution"]], "Automated hyperparameter optimization": [[35, "automated-hyperparameter-optimization"], [35, "id3"]], "Averaging": [[38, "averaging"]], "Averaging simulation": [[57, "averaging-simulation"]], "Bad range for hyperparameters": [[35, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[33, "bag-of-words-bow-representation"]], "Bag-of-words model": [[49, "bag-of-words-model"]], "Baseline": [[36, "baseline"], [39, "baseline"]], "Baseline Approaches": [[43, "baseline-approaches"]], "Baselines": [[29, "baselines"], [38, "baselines"]], "Baselines [video]": [[29, "baselines-video"]], "Basic text preprocessing [video]": [[44, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[40, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[43, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[30, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[29, "big-picture-and-datasets"]], "Big picture and motivation": [[30, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Bottom-up explanations": [[48, "bottom-up-explanations"]], "Break (5 min)": [[8, "break-5-min"], [29, "break-5-min"], [30, "break-5-min"], [31, "break-5-min"], [32, "break-5-min"], [33, "break-5-min"], [40, "break-5-min"], [44, "break-5-min"], [45, "break-5-min"], [47, "break-5-min"], [48, "break-5-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a supervise machine learning model": [[28, "building-a-supervise-machine-learning-model"]], "Building decision trees with sklearn": [[29, "building-decision-trees-with-sklearn"]], "Building user profiles": [[43, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[41, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[32, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[33, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[38, "catboost"]], "Categorical features": [[39, "categorical-features"]], "Categorical features [video]": [[32, "categorical-features-video"]], "Categorical features with only two possible categories": [[33, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[47, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[59, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[36, "changing-the-training-procedure"]], "Characters in this course?": [[28, "characters-in-this-course"]], "Choosing K [video]": [[41, "choosing-k-video"]], "Choosing n_neighbors": [[31, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Meeting 4B": [[22, null]], "Class Meeting 4C": [[23, null]], "Class Meeting 5A": [[24, null]], "Class Meeting 5B": [[25, null]], "Class Meeting 5C": [[26, null]], "Class Meeting 6A": [[27, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"], [22, "class-slides"], [23, "class-slides"], [24, "class-slides"], [26, "class-slides"], [27, "class-slides"]], "Class imbalance in training sets": [[36, "class-imbalance-in-training-sets"]], "Class meetings": [[59, "class-meetings"]], "Classification report": [[36, "classification-report"]], "Classification vs. Regression": [[29, "classification-vs-regression"]], "Clustering": [[51, "clustering"]], "Clustering Activity (~5 mins)": [[41, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[41, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[41, "clustering-input-and-possible-output"]], "Code of conduct": [[59, "code-of-conduct"]], "Coefficients and intercept": [[34, "coefficients-and-intercept"]], "ColumnTransformer example": [[33, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[33, "columntransformer-on-the-california-housing-dataset"], [54, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[33, "columntransformer-transformed-data"]], "Coming up \u2026": [[30, "coming-up"]], "Coming up:": [[31, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[41, "common-applications"]], "Common preprocessing techniques": [[32, "common-preprocessing-techniques"]], "Communication": [[51, "communication"]], "Completing the utility matrix with content-based filtering": [[43, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[34, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[48, "concepts-then-labels-not-the-other-way-around"]], "Confidence and predict_proba (20 min)": [[48, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[48, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix (video)": [[36, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[36, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[31, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[43, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[33, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[59, "course-learning-objectives"]], "Course co-ordinator": [[59, "course-co-ordinator"]], "Course description": [[59, "course-description"]], "Cox proportional hazards model": [[47, "cox-proportional-hazards-model"]], "Create X and y": [[29, "create-x-and-y"]], "Create a classifier object": [[29, "create-a-classifier-object"]], "Create a column transformer": [[33, "create-a-column-transformer"]], "Creating train_df and test_df": [[30, "creating-train-df-and-test-df"]], "Creating utility matrix": [[43, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[36, "cross-validation-with-different-metrics"]], "Cross-validation": [[46, "cross-validation"], [46, "id4"]], "Cross-validation [video]": [[30, "cross-validation-video"]], "Cross-validation to the rescue!!": [[30, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[30, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[31, "curse-of-dimensionality"]], "Customer churn": [[47, "customer-churn"]], "Customer segmentation": [[41, "customer-segmentation"]], "DBSCAN [video]": [[42, "dbscan-video"]], "DBSCAN introduction": [[42, "dbscan-introduction"]], "DBSCAN: failure cases": [[42, "dbscan-failure-cases"], [42, "id1"]], "Data": [[33, "data"], [34, "data"], [38, "data"], [39, "data"], [39, "id1"]], "Data Splitting [video]": [[30, "data-splitting-video"]], "Data and main approaches": [[43, "data-and-main-approaches"]], "Data exploration": [[41, "data-exploration"]], "Data splitting": [[53, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[45, "dataset"], [48, "dataset"]], "Dataset [video]": [[37, "dataset-video"]], "Dataset for demonstration": [[36, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[32, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[36, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[33, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[29, "decision-boundary"]], "Decision boundary for max_depth=1": [[29, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[29, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[29, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[31, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[34, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[29, "decision-tree-algorithm"]], "Decision tree feature importances": [[39, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[29, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[29, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[29, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[29, "decision-trees-video"]], "Decision trees with continuous features": [[29, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[38, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[29, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[48, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[36, "decreasing-the-threshold"]], "Deep learning": [[46, "deep-learning"]], "Deep learning software": [[45, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of feature engineering with numeric features": [[40, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[46, "demo-a-more-complicated-dataset"]], "Dendrogram": [[42, "dendrogram"]], "Deployment (Not examinable)": [[51, "deployment-not-examinable"]], "Different models": [[39, "different-models"]], "Different range for hyperparameters yields better results!": [[35, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[37, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[31, "dimensions-in-ml-problems"]], "Discussion question": [[44, "discussion-question"]], "Discussion questions:": [[48, "discussion-questions"]], "Distance between feature vectors": [[31, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[33, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[38, "do-we-have-class-imbalance"], [39, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[39, "do-we-have-correlated-features"]], "Document clustering": [[41, "document-clustering"]], "Domain-specific transformations": [[40, "domain-specific-transformations"]], "Dummy classifier": [[49, "dummy-classifier"]], "DummyClassifier": [[29, "dummyclassifier"], [46, "dummyclassifier"], [47, "dummyclassifier"]], "DummyClassifier baseline": [[38, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[29, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[29, "dummyregressor"], [37, "dummyregressor"]], "EDA": [[32, "eda"], [36, "eda"], [37, "eda"]], "EDA: Exploratory Data Analysis": [[53, "eda-exploratory-data-analysis"]], "Encoding text data": [[33, "encoding-text-data"]], "Encoding time as a number": [[46, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[46, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[51, "ensembles"]], "Equally good": [[48, "equally-good"]], "Ethics": [[51, "ethics"]], "Euclidean distance": [[31, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[42, "evaluating-dbscan-clusters"]], "Evaluation": [[43, "evaluation"], [43, "id3"]], "Evaluation metrics": [[51, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[36, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[36, "evalution-metrics-overview"]], "Examining the preprocessed data": [[37, "examining-the-preprocessed-data"], [48, "examining-the-preprocessed-data"]], "Example": [[34, "example"], [38, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[28, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[41, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[29, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[29, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[28, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[28, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[39, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[40, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[28, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[41, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[29, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[29, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[36, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[32, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[28, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[43, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[43, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[29, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[29, "exercise-2-4"]], "Exercise 8.2": [[35, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[52, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[35, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[39, "explaining-a-prediction"]], "Explanation 1": [[48, "explanation-1"]], "Explanation 2": [[48, "explanation-2"]], "Exploratory data analysis": [[46, "exploratory-data-analysis"], [58, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[33, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[46, "extracting-date-and-time-information"]], "F1-score": [[36, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[40, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[46, "feature-engineering"]], "Feature engineering and selection": [[51, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[46, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[46, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[40, "feature-engineering-motivation"]], "Feature importances": [[39, "feature-importances"], [51, "feature-importances"]], "Feature importances in linear models": [[39, "feature-importances-in-linear-models"], [39, "id2"]], "Feature interactions and feature crosses": [[40, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[37, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[40, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[32, "feature-transformations-and-the-golden-rule"]], "Feature types": [[37, "feature-types"], [37, "id1"], [48, "feature-types"]], "Feature vectors": [[31, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[35, "final-comments-and-summary"], [43, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[29, "final-comments-summary-and-reflection"], [41, "final-comments-summary-and-reflection"], [42, "final-comments-summary-and-reflection"]], "Final exam": [[59, "final-exam"]], "Final exam preparation: guiding questions": [[51, null]], "Final note": [[53, "final-note"]], "Final remarks": [[46, "final-remarks"]], "Finding the distances to a query point": [[31, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[31, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[46, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[46, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[43, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "GB better than RF": [[48, "gb-better-than-rf"]], "Garbage in, garbage out.": [[40, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[40, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[38, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[31, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[40, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[30, "generalization-video"]], "Generalization: Fundamental goal of ML": [[30, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[34, "generalizing-to-more-features"]], "Generalizing to unseen data": [[30, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[31, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[43, "global-average-baseline"]], "Golden rule violation: Example 1": [[30, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[30, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[38, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[38, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[59, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[36, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[30, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[42, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[34, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[30, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[39, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[38, "how-do-they-work"]], "How do we carry out feature selection?": [[40, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[29, "how-does-fit-work"], [29, "id2"]], "How does it work?": [[42, "how-does-it-work"], [48, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[34, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[29, "how-does-predict-work"]], "How to approximate generalization error?": [[30, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[32, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[31, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[30, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[34, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[51, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[35, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[41, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[31, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[35, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[33, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[45, "imagenet"]], "Import": [[49, "import"]], "Importance of scaling": [[34, "importance-of-scaling"]], "Important hyperparameters": [[38, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[33, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[41, "important-points-to-remember"]], "Imports": [[28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [48, "imports"], [51, "imports"], [52, "imports"], [53, "imports"], [58, "imports"]], "Imports and LO": [[35, "imports-and-lo"], [37, "imports-and-lo"], [45, "imports-and-lo"], [46, "imports-and-lo"]], "Imports and LOs": [[36, "imports-and-los"]], "Imports and learning outcomes": [[41, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[29, "imports-announcements-los"]], "Imports, Announcements, and LO": [[33, "imports-announcements-and-lo"], [34, "imports-announcements-and-lo"]], "Imports, LOs": [[30, "imports-los"], [32, "imports-los"], [39, "imports-los"]], "Imports, announcements, LOs": [[38, "imports-announcements-los"]], "Imports, announcements, and LOs": [[31, "imports-announcements-and-los"]], "Imputation": [[32, "imputation"]], "Imputation and scaling [video]": [[32, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[33, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[36, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[41, "inertia"]], "Initialization of K-Means": [[41, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[38, "inject-randomness-in-the-classifier-construction"]], "Input data": [[28, "input-data"]], "Input features X and target y": [[28, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[48, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[36, "interim-summary"], [39, "interim-summary"], [40, "interim-summary"], [46, "interim-summary"]], "Interpretation of coefficients": [[34, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[34, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[39, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[42, "introduction"], [51, "introduction"]], "Introduction to NLP": [[51, "introduction-to-nlp"]], "Introduction to computer vision": [[45, "introduction-to-computer-vision"]], "Introduction to neural networks": [[45, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[41, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[49, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[36, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[33, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[48, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[40, "is-relevance-clearly-defined"], [40, "id2"], [40, "id3"], [40, "id4"], [40, "id5"], [40, "id6"], [40, "id7"]], "K-Means algorithm": [[41, "k-means-algorithm"]], "K-Means clustering [video]": [[41, "k-means-clustering-video"]], "K-Means example": [[41, "k-means-example"]], "K-Means limitations": [[42, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[42, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[42, "k-means-recap"]], "K-Means: failure case 1": [[42, "k-means-failure-case-1"]], "K-Means: failure case 2": [[42, "k-means-failure-case-2"]], "K-Means: failure case 3": [[42, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[47, "kaplan-meier-survival-curve"]], "Key point": [[39, "key-point"]], "LDA topics in social media": [[44, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[41, "labeled-vs-unlabeled-data"]], "Lag-based features": [[46, "lag-based-features"], [46, "id5"], [58, "lag-based-features"]], "Land acknowledgement": [[59, "land-acknowledgement"]], "Large datasets solve many of these problems": [[35, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[34, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[44, "learning-objectives"], [45, "learning-objectives"], [46, "learning-objectives"], [47, "learning-objectives"], [48, "learning-objectives"]], "Learning outcomes": [[28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"], [41, "learning-outcomes"], [42, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[43, "learning-outcomes"]], "Least confident cases": [[34, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[37, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[38, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[39, null]], "Lecture 13": [[22, "lecture-13"]], "Lecture 13: Feature engineering and feature selection": [[40, null]], "Lecture 14": [[23, "lecture-14"]], "Lecture 14: K-Means Clustering": [[41, null]], "Lecture 15": [[23, "lecture-15"]], "Lecture 15: More Clustering": [[42, null]], "Lecture 16": [[24, "lecture-16"]], "Lecture 16: Recommender Systems": [[43, null]], "Lecture 17": [[24, "lecture-17"]], "Lecture 17: Introduction to natural language processing": [[44, null]], "Lecture 18": [[26, "lecture-18"]], "Lecture 18: Multi-class classification and introduction to computer vision": [[45, null]], "Lecture 19": [[26, "lecture-19"]], "Lecture 19: Time series": [[46, null]], "Lecture 1: Course Introduction": [[28, null]], "Lecture 20": [[27, "lecture-20"]], "Lecture 20: Survival analysis": [[47, null]], "Lecture 21": [[27, "lecture-21"]], "Lecture 21: Communication": [[48, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[29, null]], "Lecture 3: Machine Learning Fundamentals": [[30, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[31, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[32, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[33, null]], "Lecture 7: Linear Models": [[34, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[35, null]], "Lecture 9: Classification metrics": [[36, null]], "Lecture learning objectives": [[38, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[42, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[59, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[32, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[33, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[31, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[32, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[39, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[36, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[37, "let-s-separate-x-and-y"], [39, "let-s-separate-x-and-y"], [48, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[37, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[32, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[38, "lightgbm"]], "Limitations of linear models": [[34, "limitations-of-linear-models"]], "Linear SVM": [[34, "linear-svm"]], "Linear models [video]": [[34, "linear-models-video"]], "Linear regression": [[34, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Logistic regression [video]": [[34, "logistic-regression-video"]], "Logistic regression intuition": [[34, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[34, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[45, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[46, "logisticregression"], [47, "logisticregression"]], "MAPE": [[37, "mape"]], "ML and decision-making (5 min)": [[48, "ml-and-decision-making-5-min"]], "ML fairness activity": [[56, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[36, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[51, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[28, "machine-learning-workflow"], [36, "machine-learning-workflow"]], "Magnitude of the coefficients": [[34, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[34, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[34, "main-hyperparameters"]], "Main issues in ML-related communication": [[48, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[35, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[41, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[41, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[37, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[28, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[41, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[41, "method-2-the-silhouette-method"]], "Midterms": [[59, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[43, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[37, "model-building"]], "Model complexity and training error": [[30, "model-complexity-and-training-error"]], "Model interpretability beyond linear models": [[39, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[28, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[56, "model-training-and-evaluation"]], "Model-based selection": [[40, "model-based-selection"]], "More comments on tackling class imbalance": [[37, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[42, "more-details-on-dbscan"]], "More on feature transformations": [[33, "more-on-feature-transformations"]], "More on k-NNs [video]": [[31, "more-on-k-nns-video"]], "More terminology [video]": [[29, "more-terminology-video"]], "More than one ordinal columns?": [[33, "more-than-one-ordinal-columns"]], "Most confident cases": [[34, "most-confident-cases"]], "Motivating example": [[34, "motivating-example"]], "Motivation": [[35, "motivation"], [46, "motivation"], [48, "motivation"]], "Motivation [video]": [[38, "motivation-video"]], "Motivation and big picture [video]": [[32, "motivation-and-big-picture-video"]], "Motivation and context": [[44, "motivation-and-context"]], "Motivation and distances [video]": [[31, "motivation-and-distances-video"]], "Movie features": [[43, "movie-features"]], "Multi-class classification": [[45, "multi-class-classification"]], "Multiclass classification and computer vision": [[51, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[33, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "New ideas in small chunks": [[48, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[30, null], [30, null], [46, null]], "Number of trees and fundamental trade-off": [[38, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[33, "ohe-with-many-categories"]], "Object detection": [[45, "object-detection"]], "Observations": [[36, "observations"]], "One Vs. One approach": [[50, "one-vs-one-approach"]], "One Vs. One prediction": [[50, "one-vs-one-prediction"]], "One vs. Rest": [[50, "one-vs-rest"]], "One-hot encoding (OHE)": [[32, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[46, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[46, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[33, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[36, "operating-point"]], "Optimization bias of hyper-parameter learning": [[35, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[35, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[35, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[35, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[35, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[32, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[39, "ordinal-features"]], "Other applications": [[41, "other-applications"]], "Other approaches / what did we not cover?": [[47, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[44, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[37, "other-possible-preprocessing"]], "Other software package": [[46, "other-software-package"]], "Other tools for preprocessing": [[44, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[44, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[31, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[40, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[30, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[52, "outline"], [53, "outline"], [54, "outline"], [55, "outline"], [56, "outline"], [57, "outline"], [58, "outline"]], "Over confident cases": [[34, "over-confident-cases"]], "Overfitting": [[30, "overfitting"]], "Overfitting of the validation data": [[35, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[35, "overfitting-of-the-validation-error"]], "Oversampling": [[36, "oversampling"]], "Overview": [[31, "overview"]], "POSIX time feature": [[46, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[36, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[29, "parameters"]], "Parameters and hyperparameters: Summary": [[29, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[46, "parsing-datetimes"], [58, "parsing-datetimes"]], "Part 1": [[51, "part-1"]], "Part 2": [[51, "part-2"]], "Passing Requirements": [[59, "passing-requirements"]], "Pipelines": [[32, "pipelines"]], "Playground": [[31, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[29, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 13 Videos": [[22, "pre-lecture-13-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[36, "precision"]], "Precision and recall: toy example": [[36, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[36, "precision-recall-f1-score-video"]], "Precision-recall curve": [[36, "precision-recall-curve"], [36, "id1"]], "Precision/Recall tradeoff": [[36, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[28, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[34, "predicting-probability-scores-video"]], "Predicting with learned weights": [[34, "predicting-with-learned-weights"]], "Prediction": [[47, "prediction"]], "Prediction of linear regression": [[34, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[34, "prediction-with-learned-parameters"]], "Predictions": [[45, "predictions"]], "Preferences in LogisticRegression": [[48, "preferences-in-logisticregression"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[33, "preprocessing"], [46, "preprocessing"], [51, "preprocessing"], [56, "preprocessing"], [58, "preprocessing"]], "Preprocessing the targets?": [[33, "preprocessing-the-targets"]], "Prevalence of ML": [[28, "prevalence-of-ml"]], "Principles of effective communication": [[48, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[48, "principles-of-good-explanations-15-min"]], "Problem formulation": [[43, "problem-formulation"]], "Problem: Different transformations on different columns": [[32, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[35, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[30, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[31, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[51, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[31, "question"]], "Question for you": [[42, "question-for-you"]], "Questions for class discussion": [[43, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[35, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[31, "quick-recap"]], "RF better than GB": [[48, "rf-better-than-gb"]], "RFE algorithm": [[40, "rfe-algorithm"]], "R^2 (not in detail)": [[37, "r-2-not-in-detail"]], "Random forest feature importances": [[39, "random-forest-feature-importances"]], "Random forests": [[38, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[38, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[38, "randomforestclassifier"], [47, "randomforestclassifier"]], "Randomized hyperparameter search": [[35, "randomized-hyperparameter-search"]], "Range of C": [[35, "range-of-c"]], "Raw scores": [[34, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[29, "reading-the-data"], [45, "reading-the-data"]], "Real boundary between Canada and USA": [[29, "real-boundary-between-canada-and-usa"], [52, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[36, "recall"]], "Recap": [[47, "recap"], [48, "recap"]], "Recap and motivation [video]": [[42, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[29, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[36, "receiver-operating-characteristic-roc-curve"]], "Recommender systems": [[51, "recommender-systems"]], "Recommender systems intro and motivation": [[43, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[43, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[40, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[47, "references"]], "Registration": [[59, "registration"]], "Regression scoring functions": [[37, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[31, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[31, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[31, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[38, "relevant-papers"]], "Relevant papers and resources": [[36, "relevant-papers-and-resources"]], "Relevant resources": [[40, "relevant-resources"]], "Reminder": [[43, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Report format": [[7, "report-format"]], "Resources": [[41, "resources"], [42, "resources"], [43, "resources"]], "Reuse your running examples": [[48, "reuse-your-running-examples"]], "Ridge": [[34, "ridge"]], "Ridge on the California housing dataset": [[34, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[37, "ridgecv"]], "Root mean squared error or RMSE": [[37, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[39, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[39, "shap-plots"]], "SMOTE idea": [[36, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[36, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[31, "svm-regressor"]], "Saving time and scaling products": [[28, "saving-time-and-scaling-products"]], "Scaling": [[32, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[32, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[59, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[31, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[46, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[28, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[45, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[34, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[41, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[31, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[49, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[30, "simple-train-test-split"]], "SimpleFeature correlations": [[39, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[38, "some-important-hyperparameters"]], "Some quotes on feature engineering": [[40, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[29, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[35, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[33, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[38, "stacking"], [57, "stacking"]], "Step 1": [[54, "step-1"]], "Step 2": [[54, "step-2"]], "Step 3": [[54, "step-3"]], "Step 4": [[54, "step-4"]], "Step 5": [[54, "step-5"]], "Steps to train a classifier using sklearn": [[29, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[36, "stratified-splits"]], "Strengths and weaknesses": [[38, "strengths-and-weaknesses"]], "Strengths of linear models": [[34, "strengths-of-linear-models"]], "Study tips": [[51, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[28, "summary"], [31, "summary"], [38, "summary"], [44, "summary"], [45, "summary"], [47, "summary"]], "Summary and reflection": [[30, "summary-and-reflection"]], "Summary of linear models": [[34, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[30, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[42, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[43, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[41, "supervised-learning"]], "Supervised learning (Reminder)": [[29, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[29, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[28, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[31, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[31, "support-vectors"]], "Survival analysis": [[51, "survival-analysis"]], "Survival plots": [[47, "survival-plots"]], "Syllabus": [[1, "syllabus"], [59, null]], "TAs": [[59, "tas"]], "Tabular data": [[29, "tabular-data"]], "Take-home message": [[42, "take-home-message"]], "Teaching Team": [[59, "teaching-team"]], "Terminology": [[45, "terminology"]], "Terminology [video]": [[29, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[38, "the-netflix-prize"]], "The __ syntax": [[35, "the-syntax"]], "The best features may be dependent on the model you use.": [[40, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[57, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[30, "the-golden-rule"]], "The random forests classifier": [[38, "the-random-forests-classifier"]], "The sigmoid function": [[34, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[30, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[41, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[48, "things-to-watch-out-for"]], "Time series": [[51, "time-series"]], "Time series analysis on a more complicated dataset": [[58, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[47, "time-to-event-and-censoring"]], "Tokenization": [[44, "tokenization"]], "Topic modeling": [[44, "topic-modeling"]], "Topic modeling motivation": [[44, "topic-modeling-motivation"]], "Topic modeling pipeline": [[44, "topic-modeling-pipeline"]], "Topic modeling toy example": [[44, "topic-modeling-toy-example"]], "Toy datasets": [[29, "toy-datasets"]], "Traditional time series approaches": [[46, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[46, "train-test-split-for-temporal-data"]], "Train/test splits": [[46, "train-test-splits"]], "Train/validation/test split": [[30, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[28, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[34, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[30, "training-error-vs-generalization-error"]], "Training models with transformed data": [[33, "training-models-with-transformed-data"]], "Training random forests and gradient boosted trees": [[48, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[45, "transfer-learning"]], "Transformations on the toy data": [[33, "transformations-on-the-toy-data"]], "Transforming the targets": [[37, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[39, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[38, "tree-based-ensemble-models"]], "Tree-based models": [[38, "tree-based-models"]], "Tuning alpha hyperparameter of Ridge": [[37, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[52, null]], "Tutorial 2": [[53, null]], "Tutorial 3": [[54, null]], "Tutorial 4": [[55, null]], "Tutorial 5": [[56, null]], "Tutorial 6": [[57, null]], "Tutorial 7": [[58, null]], "Types of censoring": [[47, "types-of-censoring"]], "Types of errors": [[30, "types-of-errors"]], "Types of machine learning": [[28, "types-of-machine-learning"], [41, "types-of-machine-learning"]], "Types of problems involving time series": [[46, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[47, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[30, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[30, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[36, "undersampling"]], "Unequally spaced time points": [[46, "unequally-spaced-time-points"]], "Unsupervised learning": [[41, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[59, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[50, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[36, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[41, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[37, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[45, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[45, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[37, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[33, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[35, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[48, "visualizing-your-results"]], "Warning": [[29, null]], "Warnings about feature selection": [[40, "warnings-about-feature-selection"], [40, "id8"]], "Weaknesses": [[38, "weaknesses"]], "What all transformations we need to apply on the dataset?": [[32, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[32, "what-are-the-options"]], "What are we exactly learning?": [[34, "what-are-we-exactly-learning"]], "What did we cover?": [[43, "what-did-we-cover"]], "What did we learn today?": [[30, "what-did-we-learn-today"], [32, "what-did-we-learn-today"], [33, "what-did-we-learn-today"], [36, "what-did-we-learn-today"], [37, "what-did-we-learn-today"], [48, "what-did-we-learn-today"]], "What does this have to do with applied ML?": [[48, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[48, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[33, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[44, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[43, "what-is-a-recommender-system"]], "What is clustering?": [[41, "what-is-clustering"]], "What is feature engineering?": [[40, "what-is-feature-engineering"]], "What is feature selection?": [[40, "what-is-feature-selection"]], "What is grid search?": [[48, "what-is-grid-search"]], "What is model interpretability?": [[39, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[28, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[36, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[38, "what-kind-of-estimators-can-we-combine"]], "What should be the loss? (Activity: 4 mins)": [[48, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[41, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[32, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[48, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[32, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[35, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[38, "which-model-should-i-use"]], "Which type of error is more important?": [[36, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[35, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[39, "why-do-we-want-this-information"]], "Why feature selection?": [[40, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[28, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[39, "why-model-transparency-interpretability"]], "Why neural networks?": [[45, "why-neural-networks"], [45, "id1"]], "Why not neural networks?": [[45, "why-not-neural-networks"], [45, "id2"]], "Why should I use it?": [[48, "why-should-i-use-it"]], "Why should we care about effective communication?": [[48, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[43, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[33, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[44, "word-embeddings"]], "Word vectors with spaCy": [[44, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[29, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[38, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[36, "class-weight-balanced"]], "cross_val_score": [[30, "cross-val-score"]], "cross_validate": [[30, "cross-validate"]], "fit and transform paradigm for transformers": [[32, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[29, "fit-the-classifier"]], "fit, predict , and score summary": [[29, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[59, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[37, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[37, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[38, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[38, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[40, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[45, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[29, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[29, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[29, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[30, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[30, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[36, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[36, "iclicker-exercise-9-2"]], "iClicker question": [[48, "iclicker-question"]], "k-Nearest Neighbours (k-NNs) [video]": [[31, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[43, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[35, "n-iter"]], "n_jobs=-1": [[35, "n-jobs-1"]], "pandas_profiler": [[37, "pandas-profiler"]], "predict the target of given examples": [[29, "predict-the-target-of-given-examples"]], "predict_proba": [[34, "predict-proba"]], "random_state argument": [[30, "random-state-argument"]], "score your model": [[29, "score-your-model"]], "sklearn API summary: estimators": [[32, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[32, "sklearn-api-summary-transformers"]], "sklearn set_config": [[33, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[33, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[39, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[39, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[49, "spacy"]], "test score vs. cross-validation score": [[30, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[30, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[30, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[36, "questions-for-group-discussion"], [56, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[28, "questions-for-you"], [29, "questions-for-you"], [29, "id1"], [29, "id3"], [30, "questions-for-you"], [30, "id1"], [31, "questions-for-you"], [31, "id1"], [32, "questions-for-you"], [32, "id1"], [32, "id2"], [33, "questions-for-you"], [33, "id1"], [34, "questions-for-you"], [34, "id1"], [34, "id2"], [35, "questions-for-you"], [35, "id2"], [36, "questions-for-you"], [36, "id2"], [37, "questions-for-you"], [37, "id2"], [38, "questions-for-you"], [38, "id1"], [38, "id2"], [40, "questions-for-you"], [41, "questions-for-you"], [41, "id2"], [42, "questions-for-you"], [42, "id3"], [43, "questions-for-you"], [43, "id1"], [43, "id2"], [45, "questions-for-you"], [46, "questions-for-you"], [46, "id1"], [46, "id2"], [46, "id3"], [47, "questions-for-you"], [47, "id1"], [47, "id2"], [47, "id3"], [47, "id4"], [48, "questions-for-you"], [48, "id1"]], "\ud83e\udd14 Eva\u2019s questions": [[28, "eva-s-questions"], [30, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/classes/class4B", "lectures/classes/class4C", "lectures/classes/class5A", "lectures/classes/class5B", "lectures/classes/class5C", "lectures/classes/class6A", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/21_communication", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/classes/class4B.md", "lectures/classes/class4C.md", "lectures/classes/class5A.md", "lectures/classes/class5B.md", "lectures/classes/class5C.md", "lectures/classes/class6A.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/21_communication.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 34, 35, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "0": [0, 1, 7, 8, 10, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "00": [10, 28, 29, 31, 33, 34, 35, 36, 39, 42, 43, 46, 47, 48, 58, 59], "000": [28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 44, 45, 47, 49], "0000": [32, 34, 36, 49], "00000": [35, 46, 58], "000000": [29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 58], "00000000e": 39, "000000e": 35, "000001": 37, "00000e": 31, "000010": 37, "000011": 36, "000021": 32, "000036": 36, "000057": 32, "000065": 35, "000067": 35, "000077": 35, "000087": 34, "000089": 34, "0001": [34, 36, 37, 47, 48], "000100": [32, 37], "000108": 34, "000113": 36, "000114": 35, "000117": 37, "000130": 34, "000136": 45, "000137": 35, "000145": 35, "000146": 34, "000147": 35, "000149": 32, "000150": 34, "000151": 35, "000155": [32, 36], "000159": 35, "000163": 35, "000166": [34, 35], "000177": [32, 46], "000180": 32, "000181": 35, "000182": 34, "000183": 34, "000187": 34, "000188": 32, "000190": 46, "000192": 46, "000194": 34, "000195": 32, "000198": 36, "000201": 35, "000206": 35, "000208": 32, "000210": 35, "000212": 40, "000213": 34, "000218": 34, "000221": 37, "000226": 37, "000227": 36, "000231": 32, "000232": 45, "000234": [31, 35], "000235": [32, 36], "000240": 32, "000245": 35, "000247": 45, "000255": 34, "000256": 46, "000259": 32, "000260": 32, "000271": 46, "000273": 45, "000274": 45, "000281": 34, "000283": 34, "000285": 34, "000286": 35, "000289": 32, "000294": 35, "000312": 36, "000332": 37, "000336": 45, "000339": 35, "000348": 35, "000353": 35, "000354": 35, "000363": 45, "000366": 36, "000370": 35, "000371": 34, "000373": 37, "000378": 34, "00038": 35, "000397": 37, "000399": 45, "000433": 37, "000435": 45, "000437": 45, "000452": 32, "000459": 34, "000471": 46, "000472": 45, "000489": 35, "000492": 36, "000498": 46, "0005": 48, "000503": 35, "000508": 35, "000520": 37, "000575": 46, "00058": 35, "000580": 31, "000630": 36, "000633": 31, "000637": 45, "000647": 31, "000650": 31, "000651": 31, "000652": 37, "000655": 31, "000661": 31, "000671": 31, "000678": 35, "000713": 37, "000726": 36, "000737": 46, "000747": 35, "000748": 32, "000752": 31, "000758": 45, "000765": 32, "000774": 32, "000786": 36, "000787": 31, "00079": 35, "000794": 31, "000795": 31, "000797": 31, "000803": 37, "000829": 31, "000831": 31, "000832": 37, "000867": 32, "000869": 46, "000873": 31, "000889": 31, "000891": 36, "000917": 35, "000927": 36, "000936": 31, "000945": 40, "000960": 45, "000964": 40, "000976": 35, "000977": 31, "000982": 35, "001": [28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 45, 47, 48, 49], "0010": 34, "00100": 35, "001000": [35, 37], "001002": 30, "001006": 30, "001010": 30, "001011": [31, 37], "001014": 30, "001016": 30, "001017": 30, "001026": 30, "001027": 30, "001029": 30, "001038": 30, "001040": 36, "001043": 32, "001057": [30, 35], "001060": 32, "001063": 30, "001064": 45, "001068": 39, "001071": 30, "001078": 30, "001086": 30, "001087": 40, "001103": 30, "001111": 30, "001139": 31, "001149": 30, "001155": 40, "001162": [35, 40], "001174": 30, "001205": 36, "001220": 34, "001224": 31, "001226": 45, "001236": 35, "001239": 36, "001266": 37, "001279": 40, "001286": 36, "001294": 30, "001299": 30, "001305": 30, "001307": 30, "001315": 30, "001317": 30, "001322": 30, "001323": 30, "001325": 31, "001329": 30, "001337": 30, "001338": 34, "001347": 35, "001352": 30, "001361": 34, "001362": 34, "001365": 31, "001371": 33, "001390": 30, "001391": 30, "001392": 31, "001400": 33, "001406": 37, "001407": 30, "001412": 35, "001414": 31, "001422": 37, "001423": 35, "001429": 30, "001433": 37, "001441": 30, "001448": 33, "001453": 30, "00146": 35, "001466": 33, "001467": 35, "001492": 35, "001495": 31, "001563": 33, "001566": 37, "001585": 35, "001586": 31, "001591": 33, "001594": 35, "001595": 31, "001600": 31, "001604": 33, "001606": 33, "001608": 35, "001616": 35, "001620": 35, "001629": 35, "001641": 45, "001645": 34, "001647": 33, "001679": 35, "001682": 35, "001693": 40, "001699": 30, "0017": 36, "001700": 36, "001710": 34, "001715": 33, "001740": 37, "001769": 35, "001773": 31, "001776": 30, "001790": 37, "001792": 35, "001847": 40, "001850": 34, "001877": 31, "001894": 37, "001900": 31, "001920": 33, "001922": 33, "001933": 37, "001949": 40, "001952": 31, "001968": 30, "001994": 40, "002": [30, 34, 38, 39, 47], "002003": 35, "002022": 33, "002030": 31, "002045": 35, "002057": [32, 33], "002083": 31, "002096": 45, "002105": 35, "002116": 33, "002118": 31, "002123": 35, "002143": 30, "002146": 35, "002158": 40, "002159": 35, "002197": 35, "002221": 37, "002321": 34, "00234": 35, "002355": 40, "002385": 37, "002441": 40, "002460": 45, "002525": 45, "002561": 35, "002646": 40, "002664": 40, "002675": 35, "002682": 45, "002690": 32, "002692": 35, "002704": 35, "002711": 45, "002746": 37, "002783": 35, "002788": 33, "002789": 33, "002807": 33, "002835": 35, "002858": 33, "002867": 40, "002889": 36, "0029": 47, "002910": 33, "002934": 34, "002940": 45, "002948": 31, "002962": 45, "002986": 45, "002999": 35, "003": [35, 38], "003013": 33, "003014": 35, "003015": 35, "003027": 35, "003038": 35, "003083": 35, "003086": 33, "003115": 33, "003124": 37, "003133": 37, "003146": 33, "003148": 34, "003166": [32, 40], "003181": 32, "003183": 40, "003185": 47, "003186": 33, "003188": [32, 33], "003194": 34, "003212": 32, "003242": 45, "003257": 45, "003273": 30, "003283": 45, "003288": 37, "003300": 32, "00332": 35, "003324": 32, "003365": 33, "003401": 40, "003421": 35, "003423": 40, "003427": 40, "003472": 35, "003477": 45, "003479": 35, "003483": 35, "003493": 40, "003528": 35, "003529": 35, "003547": 37, "003563": 35, "003633": 35, "003647": 45, "00369": 35, "003748": 35, "003757": 35, "003785": 37, "003885": 35, "003919": 35, "003919287722401839": 35, "00392157": 45, "003923": 33, "003924": 40, "003933": 35, "003998": 35, "004": [31, 35, 38, 39, 45], "004057": 35, "004065": 46, "004082": 46, "004121": 37, "004143": 37, "004264": 30, "004293": 35, "004305": 35, "004337": 35, "00435173": 41, "004352": 41, "004398": 39, "004402": 35, "004466": 35, "004496": 35, "004521": 37, "004529": 39, "004556": 35, "004574": 37, "004602": 37, "00461": 35, "004714": 35, "004723": 39, "004761": 39, "004770": 32, "004801": [32, 33], "004807": 33, "004826": 37, "004829": 37, "004854": 37, "004884": 45, "004919": 35, "004934": 36, "004952": 35, "004959": 35, "00496": 35, "005": [28, 38, 39, 47, 48], "005067": 32, "005074": 45, "005093": 32, "005098": 37, "005114": 37, "005126": 35, "005151": 35, "005157": 32, "005167": 37, "005196": 35, "005241": 37, "00525962": 32, "005269": 37, "005288": 33, "005335": 35, "005336": 37, "005387": 36, "005423": 35, "005426": 35, "00543825": 32, "005440": 45, "005478": 39, "00548": 35, "005538": 37, "005579": 37, "005641": 37, "005674": 37, "005699": 30, "005708": 35, "00573": 35, "005734": 35, "005735": 35, "005767": 35, "005809": 46, "005834": 35, "005836": 32, "005888": 32, "006": [38, 39, 47], "006012": 35, "006046": 37, "006055": 35, "006067": 37, "006106": 35, "006110": [31, 35, 37], "006236": 37, "006244": 35, "006435": 35, "006452": 34, "006476": 37, "006505": 45, "006531": 30, "006545": 35, "006546893270012566": 34, "006557": 34, "006578": [32, 33], "006652": 35, "006667": 35, "00667": 35, "006744": 37, "006805": 30, "006861": 35, "006904": 35, "00691": 35, "006973": 32, "007": [32, 38, 39, 47, 49], "007068": 40, "00715": 35, "00720988e": 39, "007228": 37, "007291": 33, "007316": 30, "007361": 36, "007362": 35, "007434": 39, "007458": [32, 33], "007517": 37, "007544": 35, "007563": 35, "007588": 41, "00758803": 41, "00759438": 39, "007655": 35, "007666": 36, "00767": 35, "007737": 37, "007776": 37, "007818": 35, "007938": 30, "007986": 37, "008": [38, 39, 49], "008040": 46, "008120": 37, "008153": 35, "008167": [32, 33], "00830586": 33, "008306": 33, "008322e": 47, "008333": 33, "008346": 37, "008377": 35, "008472": 37, "008577": 45, "008581": 37, "008606": 37, "008617": 37, "008667": 35, "00871": 35, "008735": 31, "008785": 37, "009": [33, 38, 47], "009059": 30, "009063": 35, "009082": 35, "009090": 37, "009132": 35, "009140": 37, "009297": 35, "009305": 35, "009339": 37, "009422": 30, "009512": 35, "009514e": 37, "009664": 37, "009692": 45, "009724": 40, "01": [31, 32, 34, 35, 36, 37, 39, 45, 46, 47, 48, 50, 58], "010": [28, 34, 35, 47, 49], "0100": 34, "01000": 35, "010000": [32, 35, 37], "010027": 34, "010183": [32, 33], "0102": [31, 35], "010208": 40, "010294": 30, "010650": 30, "010679": 30, "010688": 40, "010715": 35, "010750": 40, "011": [28, 33, 45, 47], "011210": 40, "011234": 36, "011248": 37, "011252": 40, "011269e": 37, "011287": 40, "011332": 47, "011336": 31, "011440": 37, "011617": 35, "011678": 36, "011767": 37, "011773": 38, "012": [32, 33, 38, 39, 45, 47, 49], "012019": 30, "012030": 40, "012232": 37, "012240": 40, "012252": 35, "012616": 35, "012624": 37, "012707": 36, "012758": 37, "013031": 37, "01311996071": 37, "013120": 39, "013157": 35, "013161": 35, "013433": 31, "013629": 35, "013706928443177698": 35, "013707": 35, "013863": 35, "013888": 35, "014": [30, 32, 38, 39, 47], "014030": 37, "014081e": 37, "014305": 37, "01432486e": 39, "014481": 35, "014503": 35, "014650": 47, "014730": 33, "01473536": 31, "014758": 47, "015": [28, 32, 33, 38, 47, 49], "015003": 35, "015039": 36, "015056": 35, "015165": 37, "015372": 35, "015724": 40, "015755": 35, "015819": 35, "016263": 35, "016372": 35, "01647": 35, "016525": [37, 39, 48], "016555": 34, "016587": 36, "016598": 35, "016602": 35, "016607": 35, "016676": 41, "016688": [32, 40], "016693": 37, "016807": 34, "016815": 35, "016918": 36, "016944": 31, "017": [33, 45], "017185": 35, "017226": 37, "017308": 35, "017427": 35, "017610": 39, "017696": 39, "017737": 39, "017741": 39, "017829": [46, 58], "017837": 35, "01784": 35, "017927": 35, "017959e": 37, "017972": 32, "018": 38, "018014": 39, "018046": 36, "018077": 35, "018178": 31, "018243": 35, "018310": 31, "018434": [46, 58], "018459e": 37, "018487": 34, "0185": 34, "018505": 35, "018507e": 37, "018558": 35, "018581": 37, "018653": 35, "018745": 28, "018789": 35, "018846": 35, "018854": 36, "019": 38, "019012": 35, "019163": 35, "019381838999846482": 35, "019382": 35, "019396": 35, "019444": 33, "019446": 35, "019531": 36, "019556": 47, "0195598": 34, "019574": 35, "019839": 35, "02": [31, 32, 33, 34, 35, 37, 39, 40, 46, 47, 54, 58], "02000e": 31, "020123": 37, "020403": 35, "020414": 35, "020641": 39, "020648": 37, "020653": 30, "020833": 43, "020862": 37, "020873": 32, "021": [38, 49], "021043": 36, "021100": 32, "021281": 35, "021305": 31, "021345": 35, "021523": 36, "021603": 45, "021721": 35, "021746": 35, "021813": 36, "021862": 35, "021900": [31, 35], "022039": 36, "022331": 39, "022433": 35, "022629": 35, "022686": 35, "022848": 30, "022866": 36, "023": [38, 45], "023086": 47, "023105": [46, 58], "023305": 37, "023366": 40, "023367": 36, "023511": 35, "023554": 37, "023636": 36, "023666": 35, "023810": 49, "024": 38, "024028": 35, "024122": 35, "024291": 46, "024351e": 37, "024390": 40, "02446630e": 39, "024540": 32, "025": [32, 36], "025381": [39, 48], "025391": [32, 33], "025396": 35, "025489": 39, "025689": 35, "025910": 31, "025998": [32, 33], "026": 47, "0261": [31, 35], "026620": 35, "026777": 35, "02677733855112973": 35, "026793": [37, 39, 48], "026972": 37, "027070": 37, "027112": [46, 58], "027321": 40, "027484": 37, "027578": 37, "028023": 36, "028337": 35, "028351": 35, "028420": 37, "028672": 40, "028772": 37, "029137": 36, "029146": 36, "029164": [46, 58], "029198": 35, "029264": 37, "029409": 37, "029475": 37, "029909": 30, "029950e": 37, "02d": 46, "03": [34, 35, 37, 39, 45, 46, 47, 49, 58], "030": 39, "03017665e": 39, "030200": 32, "030343": 37, "030349": 37, "030408": 31, "03049217": 31, "0305": 31, "030739733331869412": 34, "030786": 37, "030805": 37, "031": 33, "031070": 37, "031385": 31, "031483": 37, "031564": 32, "031794": 37, "031863": 37, "031994": 37, "032140": 37, "032280": 36, "032324": 35, "032404": 35, "032566": 33, "03256625": 33, "032656": 31, "032874": 31, "033165": 37, "033222": 47, "033267": 46, "033279": 39, "033305": 45, "033322": 37, "033459": 31, "0335": 35, "033723": 37, "033739": 37, "033780": 47, "033833": 36, "0339": 32, "034071": 36, "03411038e": 39, "034132": 37, "0344": [31, 35], "034894": 39, "034977": 37, "034979e": 37, "035": 45, "0351": 32, "03516073": 39, "035161": 39, "035223": 37, "035230": [46, 58], "035722": 37, "036": [32, 38, 45], "036136": 40, "0362": 32, "036646": 37, "036749": 36, "036764": 36, "036886": 38, "0370": 32, "0373": 32, "037414": [46, 58], "037785": 36, "0378": [32, 47], "038102": 34, "038609": 37, "038707": 39, "038948": 37, "039": 45, "039498": 34, "039741": 31, "0399": 32, "04": [32, 33, 35, 37, 39, 46, 47, 54, 58], "040": 38, "040129": 47, "040497": 36, "040698e": 37, "040954": 47, "040984": 46, "041": [38, 45], "041031": 36, "04108378": 34, "041084": 34, "041129": 31, "041201": 36, "041488": 37, "041704": 39, "041769": 37, "042081": 39, "042382": 40, "042743": 37, "042957": [32, 33], "043": 35, "043257": 33, "043319": 39, "043509": 35, "0437": [29, 30, 31, 52], "043890": 31, "044": [31, 35], "044029": [32, 33], "044166": 34, "044253": 39, "044313": 32, "044409": 37, "044614": 35, "044873": 30, "045": [29, 45], "045267": 46, "045280": 36, "045304": 31, "045415": 32, "045481": [46, 58], "046": 45, "04600e": 31, "046020": 31, "046116": 35, "046193e": 37, "046216": 35, "046638": 33, "0468": 47, "0469": 32, "046945": 35, "04709519e": 39, "0474": 34, "047567": 37, "04774884": 41, "047749": 41, "048": [30, 33], "048378": 30, "04861878": 41, "048630": 46, "048860": 32, "048889": 37, "049": [33, 45], "05": [31, 32, 35, 36, 37, 42, 46, 47, 48, 58], "050": [28, 45], "050110e": 37, "050132": [32, 33], "051": 45, "051269": [32, 33], "05137470e": 39, "051392": 45, "051472": 31, "051620": 32, "051824": 37, "051925": 35, "052": 32, "052349": 32, "052607": 36, "052790": 36, "052819": 36, "05290827e": 39, "053156": 41, "05350962": 50, "0537": 35, "053763": 30, "053918": 35, "054054": 36, "054461": 36, "054653": 33, "05465323": 33, "054669": [37, 39, 48], "054784": 33, "05478443": 33, "055": [30, 32, 33], "055100": 35, "055915e": 37, "05598498": 33, "055985": 33, "056": 45, "056478": [32, 33], "056703": 36, "057": [32, 45], "057003": 31, "057082": 37, "057254": 47, "057296": 36, "057331": 37, "057646": 31, "057729": 36, "057732e": 47, "057793": [32, 33], "057910": [32, 33], "058": 38, "0580": [30, 34], "058176": 48, "058298": 37, "058311": 36, "059": [28, 32], "059077": 36, "0591": 32, "059242": [32, 33], "059360": 45, "059588": 35, "059863": 31, "06": [32, 35, 37, 42, 45, 46, 47, 50, 58], "060": 45, "060477": 37, "060543": 40, "061100": 32, "061206": 36, "061241": 31, "061312": 37, "061313": 45, "061937": 31, "062": [28, 31, 35], "062043": 35, "062449": 47, "062658e": 37, "062723": 30, "062792": 31, "063004": 40, "063110": [32, 33], "063173": 39, "064": [35, 39], "06405": 35, "064050": 35, "064200": 31, "064307": 40, "064452": 31, "065": 45, "065169": 35, "065199": 36, "065449": 37, "065463": 36, "066166": 47, "066251": 30, "066605": 35, "066667": 32, "0667579112160865": 34, "066810": 47, "066944": 35, "067119": 32, "067120": 30, "06797961": 37, "067991": 32, "068": 28, "068214": [34, 35], "068291": 45, "068498": 35, "068775": 35, "068891": 35, "069150": 39, "06915047": 39, "069188": 47, "0694": [31, 35], "069530": 31, "07": [35, 37, 40, 46, 47, 58], "070081": 35, "070195": 35, "070850": 36, "070898": 35, "070907": 30, "070929": 36, "071": 45, "071330": [46, 58], "071541": [32, 33], "071654": 40, "07174469222": 37, "071745": 39, "071975": 40, "072": 38, "072043": 35, "072243": 39, "0723": 32, "072396": 35, "07245741": 37, "072595": 35, "072707": 30, "073016": 48, "073058": 32, "073233": 34, "073366": 32, "074": [32, 38], "0741": 31, "074141": 31, "07418": 35, "074327": 38, "074418": 45, "074475": 32, "074719": 33, "07471942": 33, "074853": 48, "075000": 43, "075170": 46, "075453": 47, "075467": 47, "075747": 35, "076104": 37, "0762": 32, "076284": 41, "07639": 35, "076533": 37, "076798": 31, "077": [38, 45], "077204": 39, "077761": 47, "077803": 35, "078": [34, 38], "0780": [29, 30, 52], "078052": 36, "07808506982896266": 37, "078243": 35, "078387": 47, "078552": 35, "078740": 35, "07877994e": 50, "078880": 33, "079": 35, "079282": 35, "079377": 47, "0794": [31, 35], "079471e": 37, "079852e": 37, "08": [32, 35, 37, 40, 42, 45, 46, 47, 58], "080": 45, "08002986030": 33, "080084": 35, "080165": 35, "080319": 33, "08031924": 33, "080694": 39, "080734": 30, "0808": 35, "081": 28, "08116": 35, "081167": 47, "081292": 46, "08151507e": 39, "081837": 47, "082": 32, "082100": 35, "082251": 34, "082265e": 47, "082749": 31, "082835": 39, "082949": 31, "083": [31, 35, 38], "083123": [32, 33], "083338": 30, "083545": 36, "083615": 35, "083813": [32, 33], "084288": 35, "084490": 48, "084746": [32, 33], "085150": 46, "085415": [39, 48], "085477": 36, "085508": 37, "085546": 37, "085550": 37, "085551": 37, "085693": 35, "085698": 37, "08613": 35, "086461": 40, "086932": 30, "087": 33, "087128": 35, "087668": 35, "087996e": 35, "088": 45, "0880": 32, "088543": 35, "088948": 31, "089294": 35, "089313": 35, "089485": 30, "09": [30, 33, 35, 37, 46, 47, 58], "090000": 36, "09009799": 37, "090231": 39, "090376e": 37, "090453": 36, "090473": 35, "09058097218": 28, "090785": 37, "091": 45, "091243": 35, "091625": 40, "091819": 30, "092": 38, "092072": 35, "092123": 35, "0922": [31, 35], "092204": 30, "09245358900622544": 35, "092454": 35, "092604": 30, "092660": 47, "092670": 35, "092729": 35, "092930": 33, "093051": 35, "0931": 35, "093228": 40, "093350": 48, "093390": 31, "09345386": 33, "093454": 33, "093624": 30, "093787": 35, "093893": 35, "094": 28, "094290": 47, "09430199": 33, "094302": 33, "094581": 33, "094586": 36, "094725": 35, "094863": 35, "095018": 35, "09503409246217484": 37, "095177": 35, "095345": 35, "09573445": 35, "096462": 37, "096692": 32, "096722": 35, "096858": 35, "096927": 36, "096960": 37, "096990": 30, "096997": 45, "097": 45, "09706504": 45, "097088": 47, "097184": 35, "097293": [32, 33], "097516": 32, "097707": 35, "097763": 35, "098": [34, 45], "098152": 35, "098307": 37, "098326": [31, 45], "098559": 35, "098629e": 35, "098663": 35, "0989147678053208": 34, "098915": 34, "098950": 35, "098966": 32, "099": 38, "099230": 39, "099240": [32, 33], "099454": 35, "099558": [32, 33], "099685": 37, "099723": 32, "099729": 35, "099749": [46, 58], "099802": 35, "099869": 35, "0x1227a36e0": 8, "0x1577111f0": 35, "0x16888d4c0": 35, "0x168921100": 35, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 39, 44, 46, 49, 50, 59], "10": [4, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 58, 59], "100": [29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 55, 58], "1000": [30, 31, 33, 34, 35, 36, 37, 39, 40, 45, 46, 47, 48, 49, 50, 55, 56], "10000": [29, 33, 34, 35, 37, 46, 58], "100000": [31, 33, 34, 35, 37, 46, 58], "1000000": 35, "100103": 46, "100105": 35, "100139": 33, "100146": 46, "100248": 31, "100275": 40, "1004": 31, "1005": [46, 58], "1006": [46, 58], "1007": [46, 58], "1008": [46, 58], "100882": 36, "1009": [46, 58], "10092665203438746": 37, "101": [9, 10, 41, 45, 47], "1010": [46, 58], "1012": [46, 58], "101259": 37, "1014": [35, 45], "1015": [45, 46, 58], "1016": [45, 46], "101688": 35, "1017": [45, 46, 58], "101796": 37, "1018": [45, 46, 58], "101810": 30, "101832": 35, "101894": 36, "1019": [45, 46, 58], "102": [36, 37, 57], "1020": [35, 40, 45, 46, 58], "102044": 40, "1021": [45, 46, 58], "102135": 36, "1022": [45, 46, 58], "1023": [45, 46, 58], "1024": [33, 45, 46], "102435": [31, 37], "102474": 33, "10247431": 33, "1025": [46, 58], "10254": 46, "1026": [34, 46], "1027": [46, 58], "10273": 37, "10274": 36, "1028": [46, 58], "1029": [46, 58], "103": 47, "103023": 35, "1031": 46, "103219": 40, "103222": 45, "1034": 40, "103439": 33, "1039": [46, 58], "104": [31, 32, 38, 41, 45], "1040": 32, "104070": 37, "1041": [37, 39, 46, 49, 58], "10416666666666667": 43, "1042": 35, "1044": 28, "104596": 35, "104643": 37, "105": 38, "1050": 29, "105080": 40, "105089": 33, "10513": 46, "1053": 49, "105314": 46, "10556679": 41, "105656": 39, "10584063": 45, "106000": 32, "106023": 37, "106112": 46, "106180": 46, "106319": 46, "106322": 46, "106424": 46, "106452": 31, "10645223": 31, "10653": [46, 58], "106705": 46, "106764": 35, "1068": 49, "106816": 46, "1069": 49, "106996": 35, "107": 38, "1070": 40, "107050": 46, "107292": 46, "1075": 49, "107502": [46, 58], "1076": 33, "107718": 35, "10781": [38, 39], "107917": [46, 58], "10793260e": 45, "107947": 37, "107985": 37, "107991": 36, "108": 28, "1080": 28, "10800": 28, "1085": 34, "10868": 46, "108681": 31, "1089": 37, "10910": 46, "10931": 33, "109526": 36, "1099": 37, "10_000": 47, "10th": [35, 36, 38, 39, 56], "10x": 36, "11": [1, 10, 11, 19, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 47, 49, 51, 53, 58, 59], "110": [34, 45], "110316": [46, 58], "110319": [46, 58], "1104": 31, "11057": 46, "1106": 40, "110645": 37, "110915e": 37, "111": [32, 35, 36, 37, 47, 56], "11121453": 41, "111215": 41, "111220": 46, "111438": 40, "111543": 37, "112": 31, "1122": [37, 39, 49], "1123": [35, 49], "112441": 35, "112490": 35, "112527": 39, "112848": 37, "11331": 49, "11336331e": 39, "113600": [32, 33, 54], "1138": 40, "113837": 37, "1139": [37, 39, 48], "113949e": 47, "114": 32, "1140": [28, 37, 39, 48], "114000": [32, 40], "114079": 35, "114214": 35, "114507": 45, "11457": [37, 39, 48], "114766": 39, "114836": 40, "114966": 39, "115": 33, "1150": 28, "115083": 32, "115089": 46, "11509": 37, "115090": 46, "115091": 46, "115092": 46, "115183": 35, "115276": 47, "115401": 37, "115406": 31, "115428": [46, 58], "115956": 34, "116": 32, "116145": 40, "116167": 34, "116443": 40, "116497": 37, "11664": 49, "11693": 37, "117": [32, 33, 34, 40, 54], "117058": 34, "117379": 35, "117380": 32, "117412": 37, "117528": 40, "11758": [46, 58], "117612": 45, "117712": 46, "117816": 32, "117899e": 37, "1179": 32, "118": [32, 33, 34, 37, 39, 40, 48], "1180": 29, "118182": [32, 33], "118347": 37, "118450": 36, "118563": 40, "11886432": 35, "118874": 37, "118934": 36, "11898": 36, "119": [32, 33, 34, 40, 46, 54, 58], "1190": 32, "119049": [46, 58], "11909976": 41, "119100": 41, "119400": 32, "119570": 40, "119911": [46, 58], "11th": [36, 38, 39, 56], "12": [10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59], "120": [31, 32, 34, 37, 38, 45, 46, 50], "1204": 31, "120769e": 37, "121": [28, 32, 33, 34, 35, 38, 40, 46], "1210": 35, "121056e": 37, "121084e": 37, "121351": 39, "12138": 32, "1214": 37, "121438": 47, "12150684": 34, "121531": 36, "121599": 39, "121628": 31, "1217": 47, "12178": 40, "121846": 39, "121985": 37, "122": [28, 29, 30, 32, 33, 40, 45, 52, 57], "1220": [28, 32, 35], "1222": 35, "122307": [32, 33], "122331": 37, "12266": 44, "122668": 35, "123": [4, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56], "123367": 37, "1235387316046016": 35, "123539": 35, "124": 32, "1240": 28, "1241": [37, 40], "1243": 32, "12436984": 33, "124370": 33, "1247": 35, "12498": 39, "124982": 40, "125": [8, 37], "1250": [32, 33, 54], "12508": [37, 39, 48], "125440e": 37, "125476": 31, "125523": [46, 58], "1256": 50, "125617": [46, 58], "125644": 37, "1258": 47, "126": 40, "126238": 40, "126398": [32, 33], "126488": 41, "12649": 32, "126500": 32, "126563": 35, "126808": [32, 33], "127": [30, 32, 34, 35], "127086": 32, "127087": 47, "1271": 38, "127107": 39, "127226": 33, "127242": 37, "1273": 39, "127326": 37, "1274": 40, "127418": 37, "127439": 37, "127441": 37, "127614": 37, "12761659": 37, "127878": 31, "1279": 37, "128": 49, "1280": [32, 35, 37], "1281": 37, "128188": [32, 33], "128384": 37, "128528": 37, "128820": 46, "128828": 46, "128829": 46, "128830": 46, "128984": 37, "129": [31, 34, 40, 47, 57], "1290": [32, 33], "12906": 28, "129257": 37, "12927": 28, "129300": [32, 33, 54], "129459": 40, "129600": 37, "129900": 36, "129904": 37, "129985": 32, "12th": [36, 38, 39, 56], "13": [8, 10, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 42, 43, 46, 47, 49, 51, 54, 58], "130": [28, 29, 30, 31, 32, 33, 35, 37, 39, 40, 48, 52, 54], "1300": [37, 39, 48], "1302": 36, "130395": [46, 58], "1304": [31, 47, 48], "130432": [46, 58], "130690e": 37, "1307": 37, "131": [32, 38, 46, 47], "131000": 37, "13107": 46, "131275": 36, "1313": 37, "1314": [37, 39, 48], "131607": [37, 39, 48], "131773": 47, "1319796954314723": 38, "132": 47, "1320": 40, "1321": 28, "132158": 37, "132292": 40, "13229595e": 39, "13255": 46, "132875": [32, 33], "132886": 46, "133": [35, 47], "133000": 37, "133210": 35, "133270": 37, "133337": 37, "133562": 47, "13392236": 45, "134": [29, 30, 33, 34, 52], "1340": 29, "134061": 40, "13407": 39, "134287": 36, "1346": [32, 37, 39, 40, 47, 49], "134615": 34, "134658": 32, "1347": 49, "134894": [46, 58], "135": [46, 47, 58], "135134": [46, 58], "135197": [46, 58], "13521135": 39, "135299": 40, "135305": [32, 33], "135384": 37, "135422": 37, "1357": 28, "136": [32, 33], "1360": 29, "13665": [32, 33, 54], "136714": 36, "1370": [28, 31, 35, 47], "13704": [37, 39, 48], "1372": 48, "137410": 41, "137500": [32, 33, 54], "1378": 37, "138": 49, "1380": 28, "138103": 45, "1383": 35, "138503": 40, "138528": 34, "138876": 47, "1389": [32, 37, 39], "139": [32, 49], "1390": 28, "139297": 36, "139317": 36, "139322": 36, "139349": 36, "13941": 36, "139554": 36, "1396": 35, "1397": 35, "14": [10, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 42, 43, 45, 46, 47, 51, 58], "140": 32, "140185": 40, "1404": [31, 47], "1405": 40, "1406": [32, 37, 39], "140641": [46, 58], "140953": [46, 58], "141": [32, 34], "141232": [46, 58], "14159265358979323": 8, "14160": 36, "141851": [46, 58], "142": 38, "142193": [46, 58], "142199": [46, 58], "1423": 36, "142398": [46, 58], "142467": 30, "1427": 48, "142806": [46, 58], "142857": 33, "14289": [32, 33, 54], "143": [35, 36], "143693": [46, 58], "143803": 40, "1438387200": 46, "1438398000": 46, "1438408800": 46, "1438419600": 46, "1438430400": 46, "1438441200": 46, "1438452000": 46, "1438462800": 46, "1438473600": 46, "1438484400": 46, "143975": [46, 58], "144": [28, 35], "144000": [37, 39, 48], "1441": 49, "144199": [46, 58], "144686": 39, "14471": [32, 33, 54], "144729": 46, "144730": 46, "144731": 46, "144732": 46, "144733": [46, 58], "144750": 31, "14485": 37, "145": [46, 58], "1452": 40, "145425": 37, "145454": [46, 58], "145455": [46, 58], "145456": [46, 58], "145457": [46, 58], "145458": [46, 58], "145459": [46, 58], "145460": [46, 58], "1457": [32, 33, 47, 54], "14579": 40, "1458": [32, 33, 54], "145833": 43, "146": [28, 38, 48], "1460": [37, 47], "1465": [32, 33, 54], "146656": [46, 58], "1467": 40, "146767": [36, 39], "146809": 36, "146830": 36, "14690": 33, "147": [39, 48], "147166": [38, 39], "14716638": 39, "147641": 37, "1477": 49, "147737": 45, "147893": 32, "147898": 36, "148": [31, 35, 39, 50], "14813": 46, "148141": 38, "148343": 37, "148349": 47, "14841": 36, "149": 47, "14970": 32, "149788": 39, "149822": [32, 33], "14999": 32, "15": [8, 10, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 46, 47, 49, 51, 52, 56, 58], "150": [31, 35, 37, 45, 48], "150000": [36, 43], "150115": 35, "15026771": 37, "150395": 31, "1504": 31, "1505": 32, "150mb": 36, "150p": 28, "151357": 40, "152": 46, "1520": 35, "152401": 36, "152859": 36, "1530": 28, "1534": 32, "15377": [32, 40], "1540": 28, "154076": [36, 39], "154105": 40, "15429": 46, "154386": [32, 33], "1545": 40, "154795": [37, 39, 48], "154842": 47, "155": [28, 35], "15500": 37, "155178e": 37, "15559528e": 39, "155624": 37, "156": [32, 35, 36], "1562": 35, "156311e": 37, "1564": 35, "15661": 46, "157": [28, 35, 45], "157008": 37, "157157": 49, "157234": 40, "15725": [32, 40], "15775": 46, "1578": 39, "15795": [36, 39], "158": 35, "1580": 28, "1582": 39, "158867": [46, 58], "158982": 37, "159": 35, "1590": [31, 35], "15915": 46, "15992": 39, "16": [10, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 46, 47, 49, 51, 52, 58], "160": [30, 31, 34, 35, 37, 39], "160000": [37, 39, 48], "160258": 30, "160282": 40, "1604": 31, "160506": 36, "160634": 45, "16063983": 33, "160640": 33, "160727": 39, "160729": [46, 58], "161": 32, "1610243052583638": 34, "16111330565237164": 34, "1613": 32, "16153": 46, "16157": 46, "16160": 46, "161606": [32, 33], "161782": 36, "1619": 35, "161931": [37, 39, 48], "162": 28, "162000": 37, "162007": 49, "162214": 48, "162330": 36, "162667": [36, 39], "1627": 40, "162904": 47, "1631": 35, "163195": [32, 33], "163397": [32, 33], "1634": [32, 33, 35, 54], "16358": 46, "164": [40, 45], "1645": 34, "16460": 40, "164679": 36, "165": [34, 37], "1650": [31, 35], "16507": [34, 40], "16508": [34, 40], "16509": [34, 40], "16510": [34, 40], "16511": [34, 40], "16512": [34, 40], "165198e": 37, "1652": [30, 34], "16533": 46, "165485": 39, "165617": 46, "165811": 35, "16630": 40, "166631": [32, 33], "167": 30, "167214": 31, "167241": 49, "16736": 44, "167600": 40, "167620": 45, "168": 37, "1680": 29, "168151": 45, "168196": [32, 33], "168244": 39, "1687": 35, "169": [30, 34, 40], "1690": [28, 29], "169269e": 47, "169421": 35, "169693": 31, "169748": 34, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 25, 29, 31, 32, 33, 34, 35, 36, 37, 40, 46, 47, 51, 54, 58], "170": [32, 42], "170100": [32, 33, 54], "170277": [38, 39], "1704": 31, "17054987": 45, "170670": 37, "170931": 45, "171": [28, 45], "17144": 46, "171468": [37, 39, 48], "1715": 35, "171657": 30, "171899": 47, "1720": 32, "17205": 46, "172792": 36, "173": [31, 35], "173025": 35, "17393037": 8, "1739787032867638": 35, "173979": 35, "174": [28, 31, 35], "174590": 36, "174766": 40, "1750": 32, "175000": [37, 39, 48], "17518": 46, "176": 32, "1766": 37, "176924": 47, "177": 40, "17730": [32, 40], "177709": 47, "178": [28, 37], "178494": 37, "17896": 46, "179": [38, 47], "179080": 36, "179123": 31, "179300": 32, "179730": 35, "17973005068132514": 35, "179802": 37, "18": [10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43, 46, 47, 48, 49, 51, 54, 58], "180": [35, 37, 45], "1800": [28, 29, 31, 35], "18000": 46, "180000": 29, "180279e": 37, "180388": 31, "1804": 31, "180900": 40, "18096": 46, "181": 47, "18113": 46, "18116": 46, "1813": 35, "182": [46, 47], "18201414": 39, "18245": 46, "182639": 37, "182648": 37, "18311": 46, "18313": 46, "18317085": 8, "183179": 47, "183423": 31, "183471e": 37, "18365": 33, "18391": [32, 33], "184": [46, 47], "1840": 28, "184405": 39, "1847": 33, "185": 47, "185155": 39, "185175": 47, "18533": 46, "1854": 35, "185707": [31, 35], "18571": [32, 33], "18572": [32, 33], "18573": [32, 33], "18574": [32, 33], "18575": [32, 33], "18576": [32, 33], "1858": 40, "185868": 40, "185975": 39, "18597545": 39, "186024": 28, "186814": 36, "186899": 36, "187": [30, 34, 38], "1870": 35, "187000": 32, "1872": 37, "1875": 34, "187503": 46, "187663": 31, "187700": 32, "188": [28, 30, 34], "1880": 35, "1886": 34, "1887": [36, 39], "18955": 46, "189981": 37, "19": [8, 10, 28, 29, 30, 31, 33, 35, 36, 37, 40, 43, 47, 49, 51, 58], "190": [30, 37, 40], "19000e": 31, "1901": 28, "190319": 40, "19032": 46, "1904": 31, "190617": [32, 33], "191": [30, 32], "1911": 40, "191169": [37, 39], "191204": 40, "191250": 30, "191396": 31, "191700": 40, "1918": 33, "191k": 39, "1920": 28, "19213263": 33, "192133": 33, "19266": 46, "1927": 49, "1928": 49, "193": 45, "1930": 28, "193021": 36, "193122": 36, "193247": 40, "1933": 29, "193346": 39, "193427": 35, "19365": 46, "193704": [46, 58], "19380": 46, "1940": 33, "194002": 31, "194034": [46, 58], "194040": 32, "19422": 39, "1945": 37, "1946": [28, 37], "194710": 37, "19485": 32, "194985": 37, "195": 32, "1950": 37, "1951": 29, "195228": 33, "1953": [35, 37], "19536": 36, "1954": 44, "1955": 29, "195564": 40, "1957": 44, "1959": 28, "19591": 40, "1960": 29, "1963": 35, "196385": 39, "1965": 29, "196599": 37, "1966": 37, "196717": 45, "196739": 46, "1968": 28, "1970": [34, 37, 46], "1972": 37, "197649": 40, "1977": [28, 47], "19777": [38, 39], "19781": 46, "198": [45, 49], "198127": 37, "1984": 37, "1985": 37, "198629": 45, "198645": 47, "1987": [28, 29], "1989": 28, "198924": [32, 33], "199": [28, 31, 36], "1990": [31, 34, 35], "1991": [29, 38], "1992": [46, 49], "1993": 37, "199364": 36, "1994": 28, "199412": 47, "199413": [31, 35], "19966": [32, 33, 40], "1997": [34, 35], "199771": 39, "1_000_000_000": 35, "1d": 45, "1e": [35, 37, 55], "1e3": [35, 55], "1e4": 35, "1h": [32, 33, 40], "1st": [8, 36, 38, 39, 46, 56], "1stflrsf": [37, 39, 48], "1v": 50, "1v2": 50, "1v3": 50, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 38, 39, 40, 44, 45, 46, 49, 50, 59], "20": [4, 8, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 46, 49, 50, 51, 53, 54, 58, 59], "200": [28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 45, 48, 52, 53, 54, 55, 56], "2000": [31, 35, 36, 37, 38, 39, 40, 45, 50, 55], "200000": [35, 46, 58], "200326e": 37, "2004": 37, "200475": 36, "2006": [37, 39, 48], "2007": [37, 39, 46, 48, 58], "2008": [37, 39, 46, 48, 58], "200876": 33, "20087625": 33, "2009": [37, 39, 46, 48], "200978": 31, "200k": 56, "201": [31, 59], "2010": [37, 39, 46], "20113": [32, 33, 54], "2012": [8, 32, 35], "2013": [44, 46, 58], "201332": 42, "2014": [28, 38, 46], "2015": [45, 46, 58], "20150630": [46, 58], "2016": [8, 45, 46], "20160101": 46, "2017": [39, 46, 58], "201810": 36, "201862": 40, "202": [31, 33], "2020": 49, "2022": 46, "2023": [10, 46], "2024": [0, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58], "20248": 32, "2024w1": 45, "2025": [1, 48], "2025_2026": 48, "2025s1": [0, 11, 48], "20274": 46, "202839": 36, "203": 31, "20310": 46, "20311": 40, "20319": 46, "203265": 39, "20334": 46, "203421": 37, "203500": 32, "20357847293371892": 34, "204": [29, 30, 31, 35, 52], "204167": 30, "2043": 47, "204302": [46, 58], "20433": 40, "204583": 30, "2046": 33, "204600": [31, 35], "204692": 37, "204734": 36, "20485": 46, "205": [29, 30, 31, 49, 52], "205000": [32, 33, 37, 39, 48, 54], "205059": 40, "20509": 46, "20514": 46, "205144": 40, "205323": [46, 58], "205479": 34, "205597": 37, "20564": 46, "206": [29, 30, 31, 35, 36, 52], "206041": 39, "206073": 36, "206099": 35, "20620": 46, "206292": 32, "20639": 40, "2064": 32, "20640": [34, 40], "206724": 47, "20683258": 34, "20694": 46, "207": [29, 30, 31, 32, 35, 45, 52], "207039e": 37, "2071": 40, "207814e": 37, "20794": 46, "208": [29, 30, 31, 34, 35, 52], "209": [28, 29, 30, 31, 35, 52], "209221": 48, "209583": 30, "209746": 36, "209903": 40, "20analysi": 47, "20assumpt": 47, "20hazard": 47, "20intro": 47, "20learn": 45, "20lifelin": 47, "20with": 47, "21": [10, 28, 29, 31, 32, 33, 36, 37, 40, 41, 43, 46, 49, 58], "210": 35, "210001": 36, "210240": 35, "210272": 40, "210591": [32, 33], "210779": 46, "21086181023099526": 34, "211": 35, "2110": 32, "211250": 30, "211343": 40, "211544": 36, "211892": [32, 33], "212": [30, 35], "212385": 39, "212581": 40, "21274": 46, "212870": 37, "212975": 37, "213": [35, 45, 46], "2130": 28, "21353": 46, "21382972": 38, "21389": 46, "2139": [32, 33, 54], "214": [28, 33, 35], "21405": 46, "2144": 35, "214740": 32, "214769": 45, "214821": 46, "214852": 36, "215": 35, "215245": 37, "21530": 46, "215412": 37, "21549": 46, "21571": 46, "21581": 46, "215865": 39, "21596": 46, "216": 35, "21603": 46, "21605": 46, "216123": 47, "21613": 29, "21616484": 50, "21617": 46, "216346": 39, "21634631": 39, "216585": 32, "216596": [46, 58], "21668": 46, "21670": 46, "216718": 36, "216728": 32, "21694": 46, "21697": 46, "2170": 29, "217334": 33, "21733442": 33, "21767954": 39, "21768": [39, 46], "217680": [38, 39], "21774": 46, "218207": [32, 33], "21847": 46, "21872": [37, 39, 48], "218760": 39, "218830": 32, "219": 40, "2190": 32, "2192": 35, "219512": 40, "219700": 40, "219845e": 37, "22": [10, 31, 32, 33, 35, 36, 37, 38, 39, 40, 46, 47, 49, 50, 54, 58, 59], "220": 30, "22001": 39, "220392": 47, "22057": 46, "2206": 47, "22078": 46, "2210": 28, "22114": 46, "221329": 37, "221348": [46, 58], "2214": 49, "22154": 46, "221622": [32, 33], "22168237": 50, "221900": 29, "22219": 46, "22221894": 37, "222222": 32, "22225": 46, "222307": 32, "222500": 30, "22260": 46, "222647": [37, 39, 48], "2229": 34, "222963e": 37, "22305705": 38, "22320": 46, "223333": 30, "223460": 47, "223750": 30, "223804": 39, "224": [35, 45], "22452": 46, "2246468746": 30, "224662": 37, "22471154513694713": 34, "224865": [37, 39], "225": 45, "225301e": 37, "2254": 32, "22550": 46, "226": 35, "226415": 32, "226789": 47, "2268": 38, "22697768": 33, "226978": 33, "2270": 35, "227143": 32, "2272": 36, "227304": 46, "22741": 40, "227559": [37, 39, 48], "227836": 36, "22788": 46, "22811601": 34, "22826": 46, "228329": 36, "2285": 46, "228603": 37, "228750": 30, "229": 45, "229000": 32, "22910": 46, "229102": 39, "2293467570951035": 38, "2295": 46, "229583": 30, "229718": 39, "22974": 44, "23": [10, 31, 32, 33, 34, 35, 36, 37, 40, 46, 47, 54, 58], "230": [31, 35], "2300": 28, "23011": 39, "2305": 39, "2307": [30, 34], "2309": 46, "23091772": 38, "2310": 46, "2311": 46, "2312": 46, "2313": 46, "23175": 46, "231815": 39, "232143": 33, "232751": 47, "23290": 46, "233": 29, "234": 47, "234040": 36, "234436": 47, "235": 40, "235096": [32, 33], "235152": 31, "235417": 30, "235706": 40, "236": [31, 35, 47], "236096": 45, "236174": 40, "236210": 41, "23621041": 41, "23640124": 34, "236456": 32, "23654": [36, 39], "236960": 35, "237": [36, 47], "237895": 36, "237935": 39, "238": [36, 47], "238192": [36, 39], "2389": 33, "239": 47, "23902": 46, "23941": 46, "239944e": 37, "24": [1, 11, 28, 31, 32, 36, 37, 38, 39, 40, 45, 46, 47, 58], "240": 47, "2401": 40, "240893": 40, "241": 47, "241489": 47, "241620": 36, "24182": 46, "242015": [38, 39], "242083": 30, "242169": 36, "242381": 46, "24295676": 33, "242957": 33, "242996": [32, 33], "243": 46, "243243": 37, "2435": 40, "2436": 40, "24395": [38, 39], "24397122221206388": 46, "244": 46, "244592": 31, "2447": 38, "244814": 47, "245": 46, "2451": 35, "245329": 37, "245521": 36, "245686": 36, "246": 46, "246332": 37, "246646": 35, "246646103936": 35, "246653": 35, "247": 46, "247119": 46, "247439": 41, "24743939": 41, "247690828913": 35, "247691": 35, "248": 46, "248328": 38, "248333": 30, "2484": 28, "248457": [37, 39, 48], "248609": 37, "248664": 40, "2488": 31, "248999": 47, "249": 49, "2496": [30, 34], "249601e": 37, "249618e": 37, "249720": 31, "24h": 36, "25": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59], "2500": [8, 49], "250000": [32, 36, 37], "25031": 46, "25037": 46, "2506": [29, 30, 52], "250900": 37, "251093": 35, "251158e": 37, "2516": 38, "25176": 46, "251769": 45, "252042": 40, "25214": 46, "252160": 31, "252859": 39, "2530": 28, "2533": [30, 34], "253312": [32, 33], "253432": 39, "253724": 31, "253914": 37, "254380": 47, "254443": 36, "255": 32, "2551": 49, "255134": 45, "2556": 38, "255751": 40, "255889": [46, 58], "256": [28, 45], "25622": 46, "256263": [38, 39], "256333": 32, "256437": 40, "25658": 40, "256813": 31, "257": 29, "2570": [28, 29], "257024": 35, "257103": 36, "2574": 40, "2580": 28, "258225": 46, "25823": 36, "258387": 39, "258427": 31, "258886": 36, "259": [37, 40], "25904": 46, "2590575478171884": 34, "259286": 31, "259500": 32, "26": [8, 10, 28, 31, 32, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 58], "2600": [32, 33, 54], "260258": 40, "26048": 39, "260572": 37, "26063": 46, "260890": [37, 39, 48], "261035": 37, "261953": [46, 58], "262": [37, 39, 47, 48], "262079e": 37, "262156e": 37, "262269e": 37, "2623": 37, "262361": 40, "262500": 37, "263": 37, "2630": 32, "26307": 44, "263541": 47, "263600": 32, "26370005": 34, "263736": 47, "263742e": 37, "26376": 46, "264195": 47, "264283e": 37, "26447953": 33, "264480": 33, "265": 38, "265273": 34, "266120": [46, 58], "266135": [32, 33], "2670": 35, "267612e": 37, "268": 35, "2683": 36, "26831": 46, "2691": [29, 30, 52], "26919": 40, "269689": 36, "269880": 31, "269972": [37, 39, 48], "27": [8, 31, 33, 35, 36, 37, 46, 47, 58], "270093": 35, "270093376167": 35, "27021": 46, "270270": 43, "27048": 36, "2705": 35, "271037": 40, "271287": 46, "271500": 40, "271738e": 37, "2720": 29, "27206": 46, "27263": 39, "272667": [32, 33], "2730": 32, "273382": [32, 33], "273606": [32, 33], "273890": 45, "273962": 40, "274": [32, 33, 46, 54], "274404": 32, "275008": [46, 58], "27502379069": 37, "275290": 36, "275352": 31, "275410": 34, "2759": 39, "276": 32, "27638": 46, "27652": 36, "276687": 37, "27676": 36, "27678": 36, "276943e": 37, "27697": 36, "2770": 35, "27705": 36, "27715": 36, "277381": 31, "2777": 47, "278441": [46, 58], "278634": 36, "27874871715903093": 34, "278755": 33, "27875502": 33, "2788": [30, 34], "2794": 34, "28": [10, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 47, 58], "280": [32, 40, 49], "2800": 8, "280028": 40, "280310": [32, 33], "2806": 35, "280618": 36, "2807": 47, "280801": 47, "281": 32, "28122025543": 37, "281583": 37, "2817": 39, "2820": 35, "282021e": 37, "2822": 39, "282600": 47, "283119e": 37, "28327": 46, "283421": 37, "2836": 39, "28362": 46, "283857": 31, "283921": 32, "284": [40, 46], "2845": 47, "2846": 49, "2847": 49, "285": [32, 33, 46, 54], "285263": 39, "28526302": 39, "285467": [37, 39, 48], "28571429": 29, "286": [30, 31, 35, 46], "286000": 35, "286200": 40, "286416": 33, "2865025": 50, "286821": 31, "287": 46, "287031": [46, 58], "287079e": 37, "287344": [32, 33], "287500": 40, "288": 46, "288002": [46, 58], "288462": 34, "28854": 46, "28868": 36, "289": 46, "2890": [31, 35], "28953": 46, "289541": [37, 39, 48], "289799": 31, "29": [8, 31, 32, 36, 37, 46, 47, 49, 58], "290": 46, "290002": 36, "290424": 37, "29045704": 37, "290961e": 37, "291": [34, 46], "291667": 43, "292": 46, "292587": 47, "293": 46, "29324459": 45, "293663": 36, "294": [32, 44], "294251": 33, "2948": [32, 33, 54], "294855": 39, "2953863599856862": 34, "295397": 36, "29545": 37, "296": [32, 49], "296601": 40, "29691": 46, "297": 34, "29802": [36, 39], "298561": 47, "298612": [46, 58], "29881": 46, "298813": 36, "299": 45, "299164": 40, "2d": 45, "2d454e5fd9a5": 47, "2e": 10, "2f": [30, 35, 43, 46], "2nd": 34, "2ndflrsf": [37, 39, 48], "2v": 50, "2v3": 50, "3": [7, 8, 10, 11, 14, 16, 17, 18, 31, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 59], "30": [4, 10, 28, 30, 31, 34, 36, 37, 38, 39, 40, 46, 47, 48, 49, 58, 59], "300": [31, 42, 44, 48, 50], "3000": 45, "300000": [32, 33, 46, 58], "300464": 40, "300837": 36, "301": 47, "3010": 40, "301200": 35, "3014": 40, "30146": 46, "301563": 37, "30167": 46, "301784": 47, "301838": 48, "3019": [29, 30, 34, 52], "301952": 40, "302": [37, 39, 48], "302131": 37, "30279": 46, "302801": 47, "302844": 47, "303": [37, 39, 48], "303000": 32, "303004": 40, "303030": 34, "303109": 33, "303790": 35, "3038": 49, "3038344082": 39, "303916": 31, "304": 31, "3040": 46, "3041": 46, "3042": 46, "3043": 46, "3044": 46, "304784": 37, "305": 28, "30504657": 41, "305047": 41, "30530902": 31, "305346": 31, "305674": 40, "3057": [30, 34], "30573": 40, "306": 49, "306500": 31, "306564": 45, "307": 32, "3075": 49, "307516": 45, "307521": 34, "308120": 32, "30815": 37, "308216": 45, "308220": 36, "308448": 31, "3089": 35, "309": 40, "3092": [29, 30, 52], "309249": 45, "309859": 34, "31": [10, 28, 31, 32, 33, 34, 36, 37, 38, 39, 41, 46, 47, 49, 54, 58], "310": 59, "310000": 32, "31000e": 31, "310284": 39, "310405": 36, "311": 32, "3110": 32, "311151": 47, "31127015": 39, "311310": 28, "311769": 40, "31196406381465247": 34, "3120": 32, "3125": 32, "312500": 43, "312501": [37, 39, 48], "312696": 49, "3129": 49, "31297381": 33, "312974": 33, "31298589e": 45, "313": [33, 37], "3130": 49, "31384": 36, "314": 32, "3140": 32, "314000": 35, "31449687e": 39, "31454": 40, "314582": 39, "314840": 40, "314929": [46, 58], "315134": [46, 58], "315630": 36, "316164": 40, "316230": 40, "316363": 31, "316395e": 37, "316426": 40, "316552": 33, "31655231": 33, "316798": 40, "317": [32, 39], "317277": 40, "317761": 36, "318": 32, "3180": 35, "3180174485124284": 32, "318937": [32, 33], "319": [29, 32], "31908384": 45, "319630": 47, "31984311": 37, "31st": 46, "32": [8, 31, 32, 33, 34, 35, 37, 41, 46, 47, 54, 58], "320": 32, "320155": 36, "320430": 37, "32064171": 38, "321": 39, "32127053": 37, "322": 40, "32240": [38, 39], "32247597e": 39, "322755": 31, "323045": [32, 33], "32323": 28, "32397724e": 39, "3245": 28, "3252": 40, "325319": 40, "32561": 36, "326": [32, 40], "326730": 36, "326741e": 47, "326933": [31, 35], "327188": 36, "3272": 47, "327283": 37, "32734": 40, "3274": 47, "327408": 36, "328": 40, "328077e": 37, "328799": 36, "328953": 31, "3298721": 45, "3299": 49, "33": [8, 28, 31, 32, 33, 34, 35, 36, 37, 40, 46, 47, 58], "330": [9, 10, 11, 28, 29, 45, 46, 48, 49, 59], "33000e": 31, "330346": 47, "3310": 32, "332125": 36, "332130": 37, "332671": 39, "3327": 46, "332710": 37, "332746": 47, "332791": 47, "332824": 37, "3330": 32, "33308783": 33, "333088": 33, "333139": 36, "333333": [29, 32, 35, 43], "3333333333333333": [43, 45], "333340": 31, "3334": 49, "334": 40, "334411": 31, "334576": 37, "335": 38, "335309": 37, "3355": [32, 33, 54], "3356700488_183566145b": 45, "33590": 46, "336389": 39, "33641142": 39, "3364114233677307": 39, "336411423367732": 39, "336735": 35, "336826": 33, "33682642": 33, "33683087": 34, "336831": 34, "337034": 40, "33726089": 37, "338": [31, 35], "33888659": 8, "339": 36, "339368": 47, "339889": 47, "34": [28, 31, 32, 33, 34, 36, 37, 40, 46, 47, 54], "340": [3, 10, 29, 38, 40, 45, 46, 47], "34000e": 31, "340988": 36, "341109": 37, "341300": 40, "341571": 47, "34161762": [37, 39], "341712": [46, 58], "34182": 39, "3420": 32, "342200": 40, "342605e": 37, "3436": [46, 58], "3437": 49, "3438": 49, "344": 32, "3442": 47, "34426571": 37, "34441": 37, "345": 39, "345136": 31, "345386e": 37, "3454": [47, 49], "3455": 49, "345831": 28, "346": [32, 33, 54], "346850": 36, "34691": 46, "347523": 35, "348": [32, 40], "34806": 37, "348569": 48, "34900": 37, "35": [31, 32, 34, 36, 37, 38, 39, 46, 47, 49, 53, 57, 58], "350": 28, "3500": 53, "350000": 32, "351351": 43, "351366": 36, "3515": 47, "3517": 49, "351821": 47, "351883": 48, "3520": 47, "3521": 28, "352100": 40, "352930": [32, 33], "353": 45, "35375221": 50, "353961": 35, "354114": [37, 39, 48], "354604": 36, "3547": 40, "354759e": 37, "356689": [38, 39], "35671794": 39, "357": 32, "357500": [32, 33], "3576": 28, "3577": 49, "357823": 28, "358": [28, 35], "358032": 39, "3582": [47, 49], "358264": [37, 39, 48], "3583": 49, "358333": 31, "358500": 40, "358913": 33, "3589134": 33, "359": [31, 35], "3590": 35, "359784": 35, "359887": 41, "359992": 31, "35p": 28, "36": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 58], "360": 33, "360172": 36, "360918": [46, 58], "361": 47, "361718": 36, "362": [47, 49], "362009": 46, "362185e": 37, "362553": 40, "36269995": 33, "362700": 33, "363": 47, "363192": 31, "363913": 36, "364": [46, 47], "364352": 34, "365": 46, "36525": 39, "365420": 49, "365603": 34, "365623": 31, "366": [33, 46, 47], "366005": 36, "3663": 47, "366626": 31, "367": 46, "367329e": 47, "367423": 35, "368": [46, 49], "3681": 39, "368304": 34, "3684": 47, "368922": 42, "369": 37, "369875": 31, "369896": 45, "37": [32, 33, 34, 37, 40, 46, 47, 49, 54, 58], "37050406": 8, "370643": 36, "371": [40, 46, 58], "3717": 39, "371722": 39, "372": 32, "372706": [46, 58], "372763": [37, 39, 48], "373031": 31, "373275": [46, 58], "373656": 46, "374": 32, "374584": 45, "37546": 39, "376": [32, 37], "376089": 37, "37647072": 38, "3768": 49, "3769": 49, "377032": 37, "377619": 35, "377619120792": 35, "37797291": 33, "377973": 33, "378159": 37, "378764": 31, "378971e": 37, "37906": 36, "379416e": 37, "379875e": 37, "38": [8, 31, 32, 34, 36, 37, 40, 46, 47, 58], "3803": 47, "380436": 33, "38043616": 33, "380495": 31, "380504": [32, 33], "380643": 31, "381190": 40, "3814": 33, "381416e": 47, "381428": [37, 39, 48], "381676": 31, "38192364": 41, "381924": 41, "382558": 36, "383": [32, 40], "384111": 49, "384127": 31, "384613e": 35, "3851": 36, "3856": 31, "385639": 41, "386": 35, "386071e": 37, "386530": [39, 48], "387": 35, "388023": 36, "388169": 40, "38853": 37, "3889": 33, "389": [35, 40], "389065": 39, "389349": 40, "389736": [32, 33], "39": [31, 35, 36, 37, 41, 46, 57, 58], "390428669205": 35, "390429": 35, "390725": 37, "39095422e": 39, "391": 32, "3912": 47, "39163": 36, "391996": 45, "392": [28, 47], "392082": 39, "392221": 34, "392385": 47, "392612": 37, "392893": [31, 35], "393": [29, 33], "3932": 47, "39375": 46, "394113e": 37, "394920": 32, "395282e": 37, "395686e": 37, "395688": 47, "395697e": 37, "396": [32, 47], "396266": 45, "396752e": 37, "396991": [32, 33], "397": 47, "398": 40, "398495": [46, 58], "39896994": 33, "398970": 33, "399": 32, "3990": [29, 30, 52], "3991": 37, "39931": 39, "399827": 36, "3blue1brown": 45, "3d": [40, 45], "3f": [29, 30, 31, 32, 36, 37, 43, 44, 49], "3h": 46, "3m": 45, "3rd": 44, "3ssnporch": [37, 39, 48], "3v": 50, "4": [0, 1, 8, 9, 10, 14, 16, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 59], "40": [8, 28, 31, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 48, 53, 58, 59], "400": [29, 32, 35, 48, 55], "40000": [45, 46, 58], "400000": [35, 46, 58], "400047": 47, "400157": 40, "400164": 45, "400649628005": 35, "400650": 35, "401": [31, 35], "401102": 46, "401541": 36, "401623": 37, "401830": 39, "401895": 35, "402": 28, "402808": 39, "404": [31, 40], "405": 38, "405227e": 37, "405415": 31, "405650": 37, "406": 45, "406202": 35, "40689": 40, "407": 36, "407234": 45, "40725012": 45, "407510": 36, "40756124": 38, "407862": 47, "4084": 47, "40_000": 45, "40b5a809b05a": 47, "41": [31, 32, 36, 37, 39, 40, 41, 43, 46, 47, 58], "410": 32, "410240": [36, 39], "410599": 40, "411412": 37, "41150573": 37, "412": [28, 31, 35], "412500": 40, "413050": 45, "413718": 47, "413796": 37, "413958": 36, "414": 49, "4143": 47, "4151": 38, "4153": 40, "4158382658": 32, "416": 39, "4165": 38, "4169": 47, "418031": 31, "418069": 35, "41901484361": 35, "419015": 35, "419355": 34, "4195": 39, "4197": [29, 30, 34, 52], "419973": 36, "42": [28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 52, 53, 56, 57], "420": 35, "420000": 28, "4203": 44, "42060": 40, "421": 45, "42104086": 39, "421215": 41, "42121526": 41, "421875": 34, "422": 37, "4234": 39, "4236": 39, "4238": 36, "423852": 36, "424222": 37, "424337e": 37, "425": 38, "425365": 47, "42541681": 50, "425419": 37, "426067": 32, "426410": 31, "427": 47, "428": 47, "429": [37, 39, 48], "429217": 36, "429634": 47, "43": [31, 34, 35, 36, 37, 46, 47], "430": [35, 37, 39, 47, 48], "430323": 32, "430571": 36, "430704": 41, "4307043": 41, "430868": 34, "431": [30, 47], "4310": [31, 32, 35], "431137": 34, "4314": 36, "432": 47, "433": 47, "433514": [46, 58], "433814": 47, "434": [31, 34, 35, 47], "43445": 40, "435": 47, "435186": 31, "435489": 36, "435792": 35, "436": 47, "436492": 37, "43697758253484614": 34, "437": 49, "4372": 41, "437367": [32, 33], "4375": [40, 43], "437500": 43, "437684": 46, "438": 43, "438231": 45, "438275": 33, "43827545": 33, "43833466": 37, "438592": [39, 48], "438906": 39, "439": 32, "4390": [31, 35], "439209": 36, "439360": 32, "439779": 36, "44": [30, 31, 32, 34, 36, 37, 40, 44, 46, 47, 49, 58], "440": [35, 46], "441": 37, "441404": 45, "441445": 40, "442377e": 37, "442806": 31, "4430": 47, "44311": 40, "4432": 40, "443317": 31, "443419": [37, 39, 48], "444297": 40, "444444": 32, "4448": 40, "445": 35, "445111e": 37, "445124e": 37, "44586935": 38, "44586935141902073": 38, "446216": 40, "446284e": 37, "446869": 40, "447": [32, 39], "447461": [46, 58], "447517": 39, "4482": 28, "4484": 31, "448757": 47, "449": 49, "449666": 31, "44966612": 31, "45": [8, 29, 30, 31, 34, 36, 37, 44, 46, 47, 52, 58, 59], "450000": 43, "450132": [46, 58], "450739": 37, "450822": 40, "451888": 36, "452600": 40, "453367": 40, "4537": 47, "454427": [32, 33], "454677": 41, "45467725": 41, "454788": [39, 48], "454966": 36, "455": 33, "4552": 39, "45555535": 39, "45587": [46, 58], "45588": [46, 58], "45589": [46, 58], "45590": [46, 58], "45591": [46, 58], "456": 45, "456419": 40, "45653693": 33, "456537": 33, "456904786": 49, "457435": [46, 58], "45756": 49, "458": 32, "458333": 43, "458524": 47, "459": 37, "4591": 32, "459214e": 37, "459873": 47, "45a": [46, 58], "45am": [46, 58], "46": [8, 29, 30, 31, 32, 33, 34, 36, 37, 46, 47, 48, 49, 52, 54, 58], "460047": 47, "46019608e": 39, "46021": 49, "46075": 49, "4608": [29, 30, 52], "460950": 41, "461": [32, 35], "462060": 47, "462545": 39, "462963": 34, "46299": 49, "463": 36, "463582": 38, "464104e": 37, "465279e": 37, "46530779": 33, "465308": 33, "466246": 45, "4664": 28, "46729488": 37, "467379": 39, "467628": 40, "468": [31, 35, 39], "468232": [46, 58], "4687": 40, "46880": 49, "469": [32, 36], "469383": 36, "4695": 36, "469571": 40, "47": [10, 28, 29, 30, 31, 32, 34, 35, 37, 40], "470": [32, 49], "4700": 35, "470060": 37, "470666": 37, "471032": 39, "472": 49, "47232": 44, "47242662": 50, "4726": 47, "472603": 37, "472790": 36, "473691": 31, "474": 36, "474552": 31, "47491": 36, "475099": 39, "476": 29, "4760": 35, "47606": 40, "476092": [37, 39, 48], "476406": 39, "476412": 41, "47641249": 41, "477": 35, "477291": 40, "47799": 49, "478060": [46, 58], "479109": 31, "479132": 40, "48": [29, 30, 31, 34, 36, 37, 43, 46, 47, 52, 58], "480": 37, "4800": 28, "480249": 31, "48073598": 41, "4809": 35, "481": 32, "4813": [30, 34], "481514": 37, "481793": 32, "481893": 36, "481960": 36, "4822": 47, "483751": 31, "48390": 49, "48407": 49, "484937": 34, "485": 45, "48535": 49, "4854": 39, "486": 39, "4861": [32, 33, 54], "486266": 32, "487": 32, "48721": 49, "4879": 49, "488": 32, "488753": [46, 58], "489130": 34, "49": [31, 34, 36, 37, 40, 46, 47, 57, 58], "490": [40, 50], "490000": 32, "490033": 37, "490568": 35, "491217": 36, "491366": [39, 48], "491379": [32, 40], "492": [32, 36], "492270": 33, "493": [29, 30, 32], "493544": 32, "493921": 33, "494": [31, 32, 35], "4943": 35, "49575": 36, "496": 40, "496213": 37, "496757": 39, "497386": 31, "497787": 37, "498": 36, "498133e": 37, "498562": 31, "499900": 32, "4f": [31, 33, 36, 44], "4m": 45, "4th": [36, 38, 39, 56], "4x": 59, "5": [4, 10, 28, 34, 35, 37, 38, 42, 43, 46, 49, 50, 51, 52, 59], "50": [10, 28, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 55, 56, 58, 59], "500": [28, 32, 36, 38, 39, 40, 56], "5000": [28, 29], "50000": [46, 58], "500000": [32, 33, 36, 37, 42, 46, 49, 58], "500000e": 35, "500001": 32, "5002": 37, "500625": 31, "50062e": 31, "500924": [32, 33], "501": [32, 49], "501071": 45, "501250": 31, "501304e": 37, "501875": 31, "5024752475247525": 35, "502500": 31, "502985": 36, "503000": 32, "503090": 36, "503125": 31, "503750": 31, "504": [31, 40], "504231": 47, "504375": 31, "504429": 33, "504644": 35, "50475372e": 39, "504fde4fcf8": 47, "505335": 36, "505592e": 37, "505625": 31, "5057": 37, "50596432e": 50, "506023": 38, "506035e": 37, "506079e": 37, "506084e": 37, "506211": [32, 35], "506410": 34, "506875": 31, "507130": 35, "507359": [32, 35], "507500": 31, "50774": 35, "507740": 32, "50775": 35, "507750": 35, "507752": [32, 35], "507995": 34, "508": [32, 37], "508125": 31, "508133": [32, 35], "508371": 35, "50884": 40, "50899": 35, "509000": 28, "509001": 37, "509317": [32, 35], "509930": [46, 58], "50k": [36, 38, 39, 56], "51": [31, 32, 33, 35, 36, 37, 39, 41, 46, 47, 48, 54, 58], "510000": [29, 31, 35], "5106": 49, "510836": 35, "5109": 39, "511": 9, "5112": 29, "51137414e": 39, "51143": 40, "51150": 36, "511620e": 37, "5118": 39, "512": 45, "5120": 28, "512000": [31, 35], "51226051": 41, "512319": 32, "512408": [37, 39, 48], "512897": 31, "512x640": 45, "513": 32, "513678": 47, "514155": [32, 33, 37], "514598e": 37, "5146": 34, "515000": 31, "51503393": 33, "515034": 33, "515351e": 37, "5156": [32, 40], "515848": 40, "516394": 40, "517346": 36, "519029": 36, "52": [31, 32, 34, 36, 37, 40, 46, 47, 49, 58], "52061": 46, "5208": 29, "520857": 36, "5209": 37, "5212": 37, "521284e": 37, "521567e": 37, "521578e": 37, "521743e": 37, "522": 37, "522563e": 37, "5238095238095238": 29, "52398": 40, "524": [29, 43], "524364": 47, "5253": 39, "525554": 40, "525757": 31, "526078": [32, 33], "526214": 39, "526596": 40, "526602": 37, "5274": 47, "527500": 32, "528": 37, "5282": 47, "528403": 31, "52881619": 31, "529210": 36, "529388e": 37, "5294": 38, "529412": 32, "53": [34, 37, 46], "530052": 35, "530978": 36, "531": 48, "531116e": 37, "531353": 45, "5315": 35, "532034": 37, "533454": 45, "533498": 31, "534": 49, "534114": 35, "534342": 40, "535": [32, 40], "535014": 32, "53520104": 31, "535604": 32, "535622": 40, "536362": 41, "53636249": 41, "537267": 32, "538000": 29, "538702": 31, "538816": 36, "5390": [36, 39], "5391": [32, 40], "539116": [46, 58], "539376": 47, "539459": 49, "54": [37, 46, 47, 57, 58], "540": 46, "540000": 32, "540359": 40, "541117": 37, "541488": 40, "54152": 36, "541667": 33, "541795": 36, "542": 48, "54240": 36, "542624": 39, "542873": [32, 33], "543297": 35, "543351": 39, "544": 35, "544462": 39, "545": [37, 49], "546": 32, "5461": 37, "546473": 34, "546610": 31, "54676006e": 39, "547": [35, 37, 39], "547993": 36, "548831": 39, "549": 49, "549682": 36, "5498": 31, "55": [29, 30, 31, 34, 36, 37, 38, 39, 46, 47, 48, 52], "55000": 35, "550000": [32, 33, 35], "550004": 38, "550616": 36, "55101": 46, "5513": 35, "5514": [38, 39], "5515": 47, "551579e": 37, "551862e": 37, "551975": 37, "552": [32, 37], "552721": 38, "553965": 39, "553979": 36, "5540": 47, "5541306485809793": 38, "55413065": 38, "554180": [46, 58], "554621": 40, "5551": 34, "555740": 31, "5566": [32, 33, 54], "557197": 45, "557242": 36, "557739": 37, "558": [37, 39, 40, 48], "558564": 36, "55862988e": 39, "55873324": 45, "5588": 28, "558824": 36, "558889": 37, "559": [35, 37, 39, 48], "56": [31, 33, 36, 37, 46, 47, 57, 58], "560225": 32, "560768": 37, "561": [10, 31, 35, 39, 40], "561467": [32, 33], "561602": 39, "561645e": 37, "562112": 32, "563": 10, "5630224174651539": 34, "563314": [37, 39, 48], "563467": 32, "5644": 37, "564483": 40, "56499": 44, "565": 40, "5650": 29, "565062": 47, "56521734": 8, "565679": 36, "565746": 47, "565888": 32, "566": 32, "566092": 32, "566222": 45, "5667": 36, "567724": 45, "567856e": 37, "568": 45, "568009": 31, "56804591": 37, "568663": 37, "5690201394302518": 39, "56902014": 39, "569375": 31, "5694": 40, "57": [31, 32, 33, 36, 37, 39, 46, 47, 48, 54, 58], "57000": 47, "570015": 37, "570449": 36, "570473": 40, "5707": 47, "570739": 40, "571": [41, 50], "571500": 40, "571901e": 37, "571969": 40, "572": 10, "572105": 31, "572549": 32, "572962": 47, "573": 50, "573050": 36, "573129": [37, 39, 48], "5732": 36, "573542": 40, "573818": 36, "57415": [46, 58], "574260": 40, "575000": 43, "57510": 40, "575907": 40, "576": 32, "57640869": 33, "576409": 33, "578523": 34, "578654": 36, "5789": 37, "579091": 40, "579432": 34, "579559e": 37, "579660": 38, "5798": 38, "57994": 36, "58": [29, 30, 31, 34, 37, 46, 47, 52], "580": 45, "580539e": 37, "581": 39, "58137177": 33, "581372": 33, "5814": 28, "581687": 40, "581787": 47, "582": [28, 38], "582090": 36, "582469": 37, "58387198": 41, "583872": 41, "584": 32, "584615": [32, 40], "585": 32, "585513": 34, "5857": 47, "586095": [32, 33], "587773": 36, "588": [31, 35], "588125": 31, "588235": 34, "588307": 32, "589286": 49, "59": [1, 31, 37, 46, 47], "59049": 36, "59050": 36, "590618": 40, "59082668": 33, "590827": 33, "5915": 33, "592": 49, "592401": 28, "59243876": 38, "59300": 40, "5931": 37, "593370": 37, "593508": 41, "5938": 32, "594": 32, "594595": 31, "594982": 36, "594995": 36, "5950": 32, "595427": 45, "595569e": 37, "596088e": 37, "596151": 40, "596810": 31, "596864": 37, "5970": 38, "59700": 36, "597015": 34, "59708": 36, "597326": 36, "597555": 28, "597924": [37, 39, 48], "598": 32, "59810": 36, "598100": 34, "598149": [37, 39, 48], "598750": 31, "599": 49, "599492": 34, "599860": 31, "599894": [46, 58], "5fin": 37, "5th": [36, 38, 39, 56], "5unf": 37, "6": [8, 10, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 59], "60": [8, 28, 32, 36, 37, 39, 40, 41, 43, 44, 46, 47, 48], "600": [32, 34, 44], "60000": [46, 58], "600000": [30, 31, 35, 46, 58], "600193": 36, "60023631": 37, "600k": 37, "601": 35, "601042": 28, "601504": 34, "601712": 36, "601790": 34, "602": [32, 33, 54], "602000": 32, "602649": 31, "6028": 36, "602941": 36, "602954": 38, "60319915": 50, "603684e": 35, "603970": 47, "604": 31, "6040": [31, 35], "604000": 29, "604032": 36, "60429913": 37, "604320": 34, "60455": [46, 58], "604619": 34, "604797": 34, "6048": 46, "604807": 47, "60495488": 31, "605060": 36, "6051": [32, 33, 54], "605100": 34, "605101": 34, "605102": 34, "605263": 31, "605625": 31, "605696": 34, "606": 32, "606061": 34, "606557": 34, "606567": 34, "606811": 35, "606875": 31, "606902": 34, "607062": [46, 58], "608050": 34, "608125": 31, "6082": 32, "608468": 34, "608532": 45, "608565": 47, "60860": 32, "609": 32, "6092": 28, "609375": 31, "60943": 36, "60k": 37, "61": [31, 33, 34, 36, 37, 41, 46, 47], "61029914": 37, "610407": 36, "610931": 42, "611": 33, "611007": 45, "611178": [46, 58], "612349": 33, "61234944": 33, "6124": 47, "612546": 36, "612621": 34, "612755": 31, "613507": 34, "613738": 35, "613738418384": 35, "614": 32, "61420598": 33, "614206": 33, "614567": 40, "615": 32, "6154": 40, "615730": 38, "616": 35, "616099": 35, "6168": 29, "617342": 47, "617431": 42, "6176": 36, "617647": 36, "618": 32, "618012": 35, "619": 49, "61912405": 39, "62": [31, 35, 36, 37, 46, 47, 58], "622255": 32, "622454": 35, "622500": 31, "6226": 40, "622612": 36, "622709": 34, "623000": 32, "62320": 46, "62352928": 38, "624049": 37, "6241": 28, "624375": 31, "624450e": 37, "624615": 37, "6250": 32, "625387": 35, "6257": 47, "626206": 37, "62657": 46, "626875": 31, "62688064": 39, "627": 47, "6273": 35, "6275": [29, 30, 52], "627722": 39, "627966": 32, "628032": 40, "628139": 36, "62873917": 39, "629792e": 37, "63": [31, 35, 36, 37, 46, 47, 49, 58], "6303": [32, 33, 54], "6306": [32, 40], "631899": 47, "632": 49, "6320": 34, "6322": 40, "632353": 36, "632786": [46, 58], "63316788": 50, "63358": 44, "63362": 37, "634397": 34, "634490": 33, "634686": 36, "635": 32, "635200": 40, "635239": [32, 33], "635648": 34, "636": [28, 32, 33, 47, 54], "636364": 49, "636410": 38, "636849e": 37, "637": 45, "637982": 31, "638169": 39, "6389": [32, 40], "6391518364256": 47, "6392": 40, "639754": 37, "64": [11, 31, 34, 37, 45, 46, 47], "640": [35, 45, 49], "6400": 32, "640000": [36, 49], "640266": [32, 33], "640x480": 31, "641216": 46, "641538": 47, "641873": 37, "642676": 46, "642965": 36, "643": 35, "6431": 40, "643311e": 37, "644106": 36, "64417243": 45, "64454": 36, "644770": 42, "645519": 36, "6458": [29, 30, 52], "645963": 35, "646050": 39, "6464": 47, "646617": 48, "647796": 40, "648": [31, 32, 35], "6480": 38, "648195": 36, "648550": 45, "649658": 39, "64994": [46, 58], "65": [29, 33, 37, 47], "650": 36, "65000": 35, "650000": 35, "65000e": 31, "65013704": 41, "65125032": 50, "6513": 39, "651446": 46, "65243": 37, "652487": 40, "6526853": 37, "652828": 35, "652986": 40, "653": 32, "653205": 35, "653205232272": 35, "654": 32, "65424895": 37, "656297e": 37, "656349": 31, "656827": 36, "657675": 40, "658047": 34, "658645": 34, "659056": 37, "66": [29, 30, 32, 34, 36, 37, 45, 46, 52, 58], "660171": 31, "6604": [32, 33, 54], "660714": 33, "66214339": 31, "66221": 46, "662450": 36, "662541e": 37, "662745": 32, "662879": 38, "66368": 39, "663680": [37, 39, 48], "6637": 47, "6638": 47, "663822": 39, "6639": 47, "6641": 47, "6642": 47, "664207": 36, "6643": 47, "6644": 47, "6645": 47, "664707": 34, "66473": [46, 58], "665": 32, "665351e": 37, "665625": 31, "665882": 38, "666": [32, 33], "666166": [46, 58], "6666666666666666": 45, "666667": [30, 32, 43], "666754": 45, "667450": 46, "668787": 31, "6688": 28, "669614": 36, "669725": 36, "669805e": 37, "67": [29, 30, 33, 34, 36, 37, 46, 47], "670344": 31, "67186503136": 37, "673277": 35, "6744": 39, "674490": 35, "674721": 38, "675000": 28, "67501": 46, "67512181": 37, "67562658": 33, "675627": 33, "675676": 43, "675814": 31, "676": 48, "676250": 31, "676373": 36, "67672595": 37, "677": 32, "6772": 47, "677268": 47, "677579": 31, "677601": 35, "677629": 31, "678": [31, 35], "678689": 34, "679478": 32, "679877": [37, 39, 48], "68": [29, 30, 31, 33, 36, 37, 39, 41, 42, 46, 47, 50, 58], "680000": 28, "680657": 32, "681223": 31, "683015": 38, "683171": 36, "68323": 35, "68339": [46, 58], "684211": 31, "684447": 32, "684960": [32, 33], "685103e": 37, "68523": 46, "685786": 38, "6858": 34, "686": 32, "686348e": 37, "687": 37, "687055": 36, "687307": 35, "687500": 30, "688": 35, "6880359361853475": 34, "688135": 35, "689338": [37, 39, 48], "69": [29, 30, 31, 33, 37, 41, 46, 47, 58], "690": 49, "69027185e": 39, "690402": 35, "690778": 39, "691241": 36, "691640": 31, "691877": 35, "691924": 41, "69192445": 41, "692308": 32, "693": 32, "693498": 35, "693590": 33, "6938": [28, 46], "693890": 46, "693898": 46, "693936": 33, "69393613": 33, "69411": 40, "694155": 31, "694334": 38, "6950": 39, "695532": 32, "696034e": 37, "6962": 32, "6963": 39, "696373": 32, "696429": 36, "696712": 46, "696859": 35, "696875": 31, "696970": 34, "69698010e": 39, "697": [32, 40], "697248": 36, "6973": 32, "698": 32, "698167": [46, 58], "698206": 37, "698384608345687": 35, "698385": 35, "6984": 40, "698857": 35, "699224": 31, "699706": 45, "699901396097971": 42, "6th": [36, 38, 39, 56], "6x6": 55, "7": [10, 11, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 59], "70": [29, 30, 33, 36, 37, 41, 42, 46, 47, 48, 58], "70000": [46, 58], "700000": [46, 58], "700855": 36, "701128": [46, 58], "701173": 35, "701186e": 37, "70162085e": 39, "7017": 47, "701863": 35, "702703": 31, "703406": 47, "704": [31, 32, 37], "704099": 33, "7042": 47, "7043": 47, "7046136400143138": 34, "70472": 40, "704969": 35, "705000": 32, "705511": 35, "70560276": 33, "705603": 33, "70568": 37, "705696": 31, "705882": [30, 35], "70588235": 30, "705898": 40, "706": 33, "706128": 31, "706444": 36, "706783": 33, "70678332": 33, "706966": 46, "707681": 31, "707712": 47, "707899": 41, "70789903": 41, "70799": 35, "708": [32, 33, 35, 38, 54], "708075": 35, "708527": 32, "708978": 35, "709185": 31, "70978": 40, "709874": 35, "709880": 35, "709893": 46, "7099": 40, "71": [28, 29, 30, 33, 34, 36, 37, 41, 46, 47, 58], "710000": 32, "710031": 39, "710526": 31, "710896": 36, "71096": 40, "711": [33, 35], "711077": 32, "711086": 35, "711717": 35, "711754": [32, 33], "711852": 40, "71199006": 37, "712": 32, "712074": 35, "71219761": 33, "712198": 33, "712324": 35, "712402": 38, "7129": 35, "713": 33, "71327467": 37, "714": 45, "714077": [32, 33], "714286": 35, "714402": 36, "715072": 45, "71517": 35, "7153": 47, "715424": 35, "715728": 36, "715992": 45, "716157": 36, "716655": 35, "716657": 35, "716792": 36, "716985": 31, "717289": 35, "717391": 35, "717829": 32, "718242": 35, "718266": 35, "718524": 46, "71866979": 37, "718750": 31, "7188": 33, "719": [28, 32, 40], "719056": 38, "719427e": 37, "719500": 31, "719747": 36, "72": [29, 30, 31, 36, 37, 46, 47, 52, 55], "720357": [46, 58], "72036": 46, "720497": 35, "720859": 32, "720893": 47, "720904": 46, "7210": 29, "721006": 35, "721008": 35, "7212512828409691": 34, "721616": 35, "721705": 32, "7218": [29, 30, 52], "721818": 40, "721921": 32, "722": 32, "722241": 35, "722249": 35, "723": 32, "72338": 44, "72345029": 37, "723602": 35, "723613": 31, "7242": 29, "724458": 35, "724539": [46, 58], "724891": 36, "725": [34, 35], "7250894": 50, "726": [32, 36, 40], "726412": [32, 33], "726474": 45, "726573": 35, "726583": 35, "726634": 36, "7266666666666667": 50, "726788": 37, "727014": 46, "727198": 35, "727273": 31, "727554": 35, "7277854625841886": 47, "727821": 35, "7278214718381631": 35, "727829": 35, "728": [32, 36], "728235": [32, 33], "7283": 36, "728324": 36, "728777": 31, "729": 35, "729109": 49, "729143": 36, "7292": 40, "729814": 35, "73": [29, 30, 33, 34, 35, 36, 37, 42, 46, 47], "730383": 36, "731498": 47, "7315": 34, "7315558717766282": 35, "731572": 34, "731583": 31, "7328": 32, "732919": 35, "733102": [32, 33], "733333": [30, 32, 33], "733746": 35, "734": [35, 37, 47], "734011": 35, "734385": 36, "734816": 46, "735": 37, "735043": 36, "735261": 35, "7352614272253524": 35, "735879": 35, "736285": 36, "736498": 35, "736900": 32, "7379": 29, "738": [32, 37], "738564": 46, "738701": [32, 33], "738715": 47, "738839": 34, "738977": 35, "739": 49, "739264": [32, 40], "7395977155164125": 35, "739598": 35, "739938": 35, "74": [29, 30, 32, 33, 34, 35, 36, 37, 42, 54], "740542": 28, "740844": 35, "741": 47, "741037": [46, 58], "741250": 31, "741463": 35, "7418": 39, "741935": 49, "742084": 35, "742088": 35, "742703": 35, "742981": 36, "743": [31, 32, 35, 47, 49], "743133": 31, "743135": 36, "743321": 35, "743323": 35, "743324": 35, "743391": 31, "743555": 39, "7436": [29, 30, 52], "743917": [32, 33], "7440": 28, "744201": 36, "744565": 35, "745": 38, "745178": 35, "746114": 38, "746328": 31, "747": 28, "74720920774": 37, "74798624e": 39, "748510": 36, "748725": 47, "748749e": 35, "748797": 34, "749118": 39, "75": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 46, 47, 48, 54, 58], "750": 28, "7500": 37, "750000": 37, "7503": 29, "7504": 49, "751": 49, "7524": 46, "753286": [32, 33], "754": 32, "754165": 49, "754386": 36, "754874": 40, "755": 47, "755000": 37, "7551": 35, "755364": 31, "755418": 35, "755477": 31, "756": 47, "7562": 28, "75625": [46, 58], "757": 36, "7574257425742574": 35, "75745416": 41, "757545": 37, "757591": 46, "757932": 47, "757985": [38, 39], "758": [38, 39, 47], "758062e": 37, "75826": [38, 39], "758514": 35, "7588186": 45, "759561": 41, "75956122": 41, "7599": 34, "76": [30, 32, 34, 35, 36, 37, 39, 40, 47], "760": 47, "760262": 35, "760678": 46, "76161": 35, "761945e": 37, "762": [30, 47], "7620": 28, "762093e": 37, "76270194": 39, "763": 32, "7639": 29, "764052": 40, "76470588": 30, "764706": [30, 31, 35], "765": 36, "765591": 36, "765601": 37, "766317e": 37, "766423": 37, "766430": 31, "767": [37, 39, 48], "767742": 34, "767802": 35, "767819": 46, "767852": 31, "768": [32, 33, 37, 39, 48, 54], "768176": 47, "768279": 48, "768512": 36, "76908228": 38, "769231": 32, "77": [29, 30, 33, 34, 36, 37, 42, 46, 47, 51, 57], "770": 29, "7706532429048965": 38, "770833": 43, "770898": 35, "771": 32, "771969": 31, "772532": 36, "773017": [37, 39, 48], "7736": 35, "773851": 46, "774261": 46, "774844": 33, "77484447": 33, "7750553478074826": 46, "775270": 37, "7752884548630529": 34, "775311": 39, "77536150e": 39, "7758": 35, "776": 35, "7763": [32, 40], "776427": 47, "77694295": 38, "77709": 35, "777934": 31, "778": 49, "7781845435415525": 46, "779": [32, 40], "779271": 40, "78": [28, 29, 30, 32, 33, 36, 37, 40, 41, 46, 47, 51], "7800": 35, "780000": 38, "780296": 37, "780298": 37, "780316": 37, "780497": 37, "78058051e": 39, "780864": 36, "781": 32, "781004": 31, "781531": 36, "7816": 37, "782183": 37, "782219": 31, "7827": 36, "783282": 35, "783582": 31, "783784": 43, "783789": 31, "784424": 34, "784573": 40, "785": 33, "785105": 37, "785108": 37, "785134": 37, "785399": 37, "785483": [46, 58], "785714": 32, "786115": 40, "78617028": 38, "786555": 37, "787": 32, "787574": 37, "787879": [31, 34], "787933": 37, "788": 30, "788374": 45, "7887": 39, "7891381897690047": 34, "789436": 32, "789657": [46, 58], "79": [29, 30, 32, 33, 34, 36, 37, 46, 47, 52], "790": 36, "790000": 32, "79041": 37, "790721": 48, "790731": 34, "791017": 47, "791467": 32, "792": 50, "792023": [39, 48], "79250": 32, "792577": 37, "792603": 31, "792828": 37, "793": 40, "793243": 32, "79378": 36, "7938": 33, "794": 47, "794118": 31, "794236": 32, "794820": 32, "795": [31, 35], "79500e": 31, "7951": 35, "7951559890417761": 37, "795902": [46, 58], "796": 32, "7964215270662811": 34, "797": 32, "797355": [32, 33], "7978563117812038": 32, "798": 32, "7982": 31, "7986546": 37, "799983": 31, "79998417": 50, "7f688092391a": 45, "7pm": 40, "7th": [36, 38, 39, 56], "8": [9, 10, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 58], "80": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 46, 47, 48, 51, 58], "800": [28, 30, 35, 44, 55], "800000": [35, 46, 58], "8001": 34, "800190": 31, "80062924": 31, "800k": 48, "801219e": 37, "801666": 36, "801863": 31, "802502": 40, "802902": 37, "802987": 31, "803": [31, 32, 49], "803617": 36, "804": [31, 47, 49], "804818": [32, 33], "80482065": 33, "804821": 33, "805198": 37, "805342": 46, "805970": [31, 34], "806": 33, "8062": 29, "806899": 45, "8076": 37, "807684": 31, "807735": 36, "8078": 28, "808": 47, "8080": 29, "808208": 36, "808958": 31, "809": 32, "8098": 47, "81": [29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 46, 47, 48, 58], "810073": [37, 39], "810098": 40, "810368": 31, "81071706": 35, "810811": 43, "8112": 28, "812272": 37, "812363": 37, "812500": 30, "812593": 45, "812875": 47, "813": 32, "813586": 36, "815669": 36, "816717791411044": 47, "817": 38, "817034": 49, "817558": [32, 33], "8180": 32, "818041": 47, "818868": 32, "819152": 31, "819213": 47, "8195": 34, "819549": 31, "819584": 31, "81970188": 33, "819702": 33, "82": [29, 33, 35, 36, 42, 46, 47, 58], "820": 31, "820033": 37, "820143": 34, "82025568e": 39, "820564": 37, "821040": 39, "821807": 37, "8219": 32, "8221": 33, "8225": 49, "82273995": 33, "822740": 33, "823511": 36, "823529": [30, 31, 34], "82352941": 30, "823543": 40, "824849": 36, "824884": 37, "825": 32, "825123": 40, "8253": 31, "825306": 35, "825470": 47, "825697": 37, "826142": 37, "826203": 34, "826216": 37, "826513": [46, 58], "826553": 37, "82670": [46, 58], "826739": 37, "826758": 37, "826760": 37, "827039": 34, "827068": 34, "827130": 36, "827261": 37, "827842": 34, "827907": 35, "8280229354283182": 37, "82804": 35, "828332": [37, 39, 48], "828358": 31, "828405": 46, "828682": 35, "828891": 35, "828976": 35, "83": [29, 30, 33, 35, 36, 42, 43, 44, 46, 47, 51, 58], "830382": 36, "830712e": 37, "831135": 31, "831611": [37, 39], "831989": 35, "832": 32, "832320": 34, "832370": 36, "832866": 37, "833": [31, 35], "83320": 46, "8334": 39, "8340": 31, "834109": 35, "834356e": 37, "83437": 37, "834455": 31, "8356": 39, "835651": 35, "835749": [37, 39], "83603": [37, 39], "8361313": 37, "836189": 31, "836735": 36, "836878e": 37, "836880e": 37, "837022e": 37, "837838": 31, "837848": 31, "838": [31, 35], "83848729e": 45, "83876": 35, "8388866943476283": 34, "838951": 37, "8389756947416362": 34, "839225": 37, "84": [29, 30, 33, 46, 47, 49, 50, 51], "840": 32, "84002795": 33, "840028": 33, "840074": 30, "840183": 37, "840492": [37, 39, 48], "84062193": 39, "841": 37, "841208": 35, "841886": 35, "841983": 35, "842": 32, "842028": 36, "842064": 47, "842105": 31, "843": 38, "843281": 39, "843284": [31, 34], "843842": [32, 33], "843992": [37, 39], "844409": 33, "84440919": 33, "844921": 41, "845": 35, "846154": [32, 49], "8462": 40, "846260e": 37, "846650": 37, "84679073": 31, "84698489": 45, "847178": 36, "847287": 35, "8475": 46, "84772": 36, "847799": 35, "847808": 36, "8478316682480326": 46, "848": [38, 39], "8481": 49, "84893192": 35, "849": [38, 39], "849102e": 37, "849438e": 37, "849612": 35, "85": [29, 30, 33, 36, 37, 38, 39, 40, 46, 47, 51, 58], "850": [28, 38, 39], "8502": 35, "850283": [46, 58], "850503": 35, "850746": 31, "851460": 37, "851852": 34, "852": [47, 49], "852053": 35, "852104": 37, "852941": 34, "853125": 31, "853399": 36, "854129": 37, "854167": 43, "854500": 47, "8546143543902771": 47, "854744525547446": 47, "854749": 46, "85545875": 31, "85597188": 33, "855972": 33, "856": 35, "856175": 32, "856589": 35, "857": 37, "857874": 35, "858": 34, "8580": [32, 33, 54], "858209": [31, 34], "858915": 35, "859": 38, "859318": 37, "859439": 41, "85943906": 41, "859455": 47, "85969": 35, "859799": 35, "86": [29, 31, 33, 34, 35, 36, 40, 46, 47], "860": [36, 39], "86000e": 31, "8601643854446082": 37, "860677": 36, "861": 32, "86102": [46, 58], "861157": 48, "861348": 35, "862432": 37, "862552": 32, "8625888648969532": 47, "86267067": 33, "862671": 33, "862997": 40, "863014": 34, "863889": 46, "863941": 37, "864": 38, "86400": [46, 58], "8641864337292489": 47, "864205": 39, "865562": 47, "8661": 49, "866110": 34, "866667": [30, 36], "866980": 37, "867434": 45, "867558": 40, "868003": 37, "868281": 37, "868305": 37, "868308": 37, "869077": 33, "86907725": 33, "869094": 35, "8691": 33, "869531": 31, "869964": 35, "87": [29, 32, 33, 36, 46, 47], "870": [38, 39], "870503": 45, "871": [35, 38], "871094": 46, "8711": 36, "872": [38, 39], "872093": 35, "872603": 45, "872722908439952": 39, "8727229084399575": 39, "872961060": 37, "8729610607986": 37, "873": 38, "8731": [37, 39, 48], "873103": 31, "873182": 46, "873356": 31, "873643": 35, "873704": 37, "874062": 33, "87406235": 33, "874305": 46, "874516": 35, "874532": 37, "874767e": 37, "875": 36, "8750": [32, 40], "875000": 30, "876065": 35, "876540": 47, "876574": [32, 33], "877046": 40, "877390": 39, "877519": 35, "877551": 36, "878183": 31, "87844893": 37, "87849316": 34, "879": 32, "87907": 35, "879938": 35, "88": [29, 30, 32, 33, 34, 36, 40, 47, 49, 54], "880": 40, "880348": 35, "880831": [46, 58], "881395": 35, "881720": 36, "883138": 35, "884586": 35, "885": [28, 33], "885044": [37, 39, 48], "885968": 47, "886047": 35, "886759": 34, "887": 38, "887017": 36, "887159": [46, 58], "8873": 36, "887324": 36, "887343": 31, "887597": 35, "887701": 36, "8878117": 33, "887812": 33, "888": [35, 38, 39], "888066": 39, "888372": 35, "888513": 36, "888811": 35, "888889": [32, 34], "888961": 39, "889086": 37, "889147": 35, "889429": 46, "889921": 46, "89": [29, 30, 33, 36, 42, 46, 47, 51, 58], "890": 38, "890457": 37, "890933": 47, "891001": 36, "891557": 35, "892476": 36, "892477": 31, "892491": 32, "89270": 40, "892733": 46, "892961": 40, "893000": 32, "893260": 33, "8937442459553657": 39, "894": 32, "894587": 48, "895": 38, "895349": 35, "895541": 37, "89572": [46, 58], "895833": 36, "895963": 34, "897010": [32, 33], "89706451e": 39, "897674": 35, "898": 39, "898016": 35, "898703e": 37, "899": [32, 33, 35, 38, 54], "8994": 39, "8997": 37, "899969": [46, 58], "8m": 45, "8th": [36, 38, 39, 56], "9": [4, 10, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 58, 59], "90": [8, 28, 29, 30, 31, 33, 36, 37, 42, 43, 46, 47, 51], "900": [33, 35, 36], "90000": [46, 58], "900000": [30, 46, 58], "900662": 30, "901085": 34, "9010852321946792": 34, "901262": 46, "90159483": 41, "901595": 41, "902401": 35, "903101": 35, "904": [31, 35], "90403853": 33, "904039": 33, "904226": 31, "9047619047619048": 29, "904902": 45, "905": [31, 32], "905327": 46, "906667": 30, "90669": 40, "906865": 30, "907": 47, "907143": 49, "907595": 46, "908": 32, "908140": [32, 33], "908215": 37, "909091": 32, "90982": 40, "91": [29, 30, 32, 33, 35, 36, 40, 41, 46, 51, 58], "910": 29, "9100": 46, "910018": 37, "910174": 37, "9103": 46, "910456e": 37, "91063776": 39, "910714": 49, "910843": 37, "911615": 37, "911846": 37, "912": 32, "912395": 39, "913333": 30, "913767": 37, "913849": 37, "914003": 39, "914451894267": 37, "914585": 39, "91515735": 37, "915714e": 37, "915952": 37, "916254": 31, "916722": 39, "917526": 36, "917837": 36, "918": 38, "918124": 36, "918191": 45, "9182": 46, "919198": 39, "9196": 28, "92": [29, 30, 33, 36, 42, 45, 46, 47, 51], "920000": 30, "9203": 35, "920305": 40, "920462": 39, "92120500e": 50, "921422": 47, "921438": 37, "921850": 37, "92195464": 39, "921955": 39, "922": 33, "923077": 36, "923283": [32, 33], "923432": 39, "924485": 40, "9245": [30, 34], "925272e": 37, "925288e": 37, "925593": 31, "925768": 36, "926657": 37, "926733e": 37, "926829": 36, "928": 35, "92809": 40, "92852376": 31, "929": 35, "9295": 35, "93": [29, 30, 33, 34, 35, 41, 46, 47, 51], "930000": 32, "930123": 31, "930561": 31, "931439e": 37, "931786": 34, "932": 32, "932070": 47, "932124": 31, "932143": 49, "93279": 46, "9336": 32, "934205": 31, "934269": [32, 33], "934783": 36, "9351": 40, "935512": 47, "935802": 31, "93665": [46, 58], "937429": 48, "9375": 30, "937500": [30, 33], "93788": 44, "938": 36, "9383": [31, 34], "93869659": 33, "938697": 33, "939006": 36, "9391": 37, "939394": [31, 34], "94": [29, 30, 32, 33, 34, 35, 36, 37, 46, 51, 54], "9401": 46, "9406": [29, 30, 52], "941": 47, "941176": [30, 33], "94117647": 30, "943609": 40, "944": 28, "944092": 36, "944354": 33, "946783": 31, "947": [32, 35, 49], "9471": 35, "948482": 47, "94888": 36, "949": 32, "9490": 32, "9492": 37, "94933723": 37, "94959681": 33, "949597": 33, "95": [29, 30, 33, 36, 42, 46, 47, 48], "950000": 32, "950088": 40, "9505": 39, "950564": 40, "9506": 39, "950696": 47, "950733": 31, "951294": 37, "951574": 40, "951644": 40, "951669": 40, "951696": 31, "953": 38, "95511263": 31, "955113": 31, "9558": 46, "956": 32, "956966": 40, "957075": 40, "9573": 46, "9576": 28, "957886": 45, "957919": 31, "957987": 31, "9583333333333334": 45, "958393": [32, 40], "95886206e": 45, "959": 32, "959139": 39, "959402e": 37, "959870": 36, "959873": 47, "96": [29, 33, 34, 35, 36, 40, 46], "960": 34, "961106": 36, "961109802000133": 42, "961404": [32, 33], "961498": [37, 39, 48], "961771": 34, "961898": 34, "962776": 36, "96319": 46, "96320": 46, "96321": 46, "96322": 46, "96323": 46, "96325": 46, "963689": 40, "96554": 40, "9661": 37, "966131": [32, 33], "9664": [29, 30, 52], "966491": 36, "967102": 36, "967907": 36, "968": 32, "968233": 40, "96834506": 31, "968493": 47, "968514e": 37, "96875": 45, "969048e": 37, "9691": 37, "9692602666681306": 34, "96965253": 39, "969653": 39, "97": [29, 30, 33, 34, 35, 39, 42, 46, 47], "970518": 36, "970683": 40, "971": 33, "97203586": 33, "972036": 33, "97217": 46, "972198": 35, "97223953": 33, "972240": 33, "972440": 36, "97253": 46, "9730": 33, "973225": 36, "973280": 33, "97328024": 33, "973482e": 35, "973750": 31, "974": 32, "974480": 40, "9748": 34, "974801e": 37, "975895": 46, "976": [32, 36, 38], "977": [32, 46, 58], "977278": 40, "9773": [29, 30, 31, 52], "978": 34, "9781449369880": 46, "9781789957211": 45, "97823755": 34, "978738": 40, "979": [38, 39], "979562": 47, "98": [29, 32, 33, 34, 37, 39, 41, 44, 46, 47, 48], "980": [46, 58], "98007": 28, "98028": 29, "98045": 28, "98052": 28, "98055": 28, "980634": 47, "98072": 28, "98074": 29, "98075": 28, "9808": 34, "98107": 28, "98112": 28, "98116": 28, "981195": 46, "98125": 29, "98136": 29, "981735": 34, "98178": 29, "982": 33, "982184": 35, "982570": 47, "983": 45, "9837": [30, 34], "984": 35, "984653": 34, "984664": 37, "985283": 35, "9854": [29, 30, 34, 52], "985457": 47, "985816": 30, "986047": 35, "9862": 49, "986207": 35, "987": [35, 45], "987062": 37, "987597": 35, "9876": [38, 39], "987681": 40, "988": 40, "9881": [29, 30, 52], "988381": 35, "988841": 35, "988901": 37, "989": 29, "989147": 35, "989156": 35, "989443": 47, "989922": 35, "989973": 34, "99": [29, 30, 32, 33, 35, 36, 46, 56, 58], "990631": [46, 58], "990754": 46, "9912": [31, 34], "9915": [46, 58], "991966": 47, "992": [30, 35], "992254": 35, "99240562": 39, "992406": 35, "9926": 33, "992857": 30, "992908": 30, "993023": 35, "993029": 35, "993065": 47, "9931": [29, 30, 52], "9934531067299874": 34, "993666": 39, "993969": [37, 39, 48], "994": 28, "994266": 35, "994574": 35, "994764": 46, "995": [40, 45], "9950": 40, "9951": [29, 30, 52], "99515": 46, "995434": 37, "996588e": 37, "996765": 39, "996788": 47, "996820": 47, "996899": 35, "99744241e": 39, "9977957422135844": 39, "998": [36, 47, 49], "9983": 36, "998302": 36, "99845": 35, "998451": 35, "999": [34, 49], "99907": 35, "999122": 36, "999147": 36, "999172": 36, "999183": 36, "999185": 36, "999192": 36, "999210": 36, "999214": 36, "999221": 36, "999223": 36, "999225": 35, "999254": 36, "999298": 36, "999317": 36, "99931882": 37, "999335": 36, "999535": 35, "999577": 46, "999622": 32, "9am": 40, "9th": [36, 38, 39, 56], "A": [0, 8, 9, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 50, 51, 58, 59], "AND": [0, 37], "AS": 0, "And": [28, 29, 35, 37, 44, 46, 47, 48, 52, 53], "As": [4, 30, 33, 35, 37, 38, 39, 43, 46, 47, 48, 50, 53, 55, 57, 59], "At": [4, 28, 30, 34, 36, 38, 40, 41, 45, 46], "BE": [0, 44], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 31, 39, 48, 51, 53], "Being": 45, "But": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 53, 55, 57, 58, 59], "By": [28, 30, 31, 33, 36, 38, 41, 44, 45, 47, 48, 53, 55, 59], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 55, 56, 57, 58, 59], "IN": [0, 30, 34], "IT": 34, "If": [4, 5, 6, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59], "In": [6, 7, 8, 9, 10, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59], "Ines": 49, "It": [2, 4, 7, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 55, 57, 59], "Its": 47, "NEAR": [32, 33, 40, 54], "NO": 0, "NOT": [0, 8, 33, 34], "No": [0, 28, 29, 37, 38, 39, 40, 42, 46, 47, 48, 51, 58], "Not": [36, 37, 38, 39, 40, 41, 43, 46, 47, 56], "OF": 0, "OR": [0, 8, 37], "Of": [9, 33, 35], "On": [4, 7, 28, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 47, 48, 49], "One": [5, 8, 16, 29, 30, 33, 34, 35, 36, 39, 41, 42, 47, 51, 56, 58], "Or": [31, 33, 35, 48, 53], "Such": [6, 43, 46], "THE": [0, 30], "TO": [0, 44], "That": [29, 30, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 56], "The": [0, 1, 2, 5, 7, 8, 10, 28, 29, 31, 32, 33, 36, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59], "Their": 5, "Then": [29, 34, 38, 41, 46, 56], "There": [2, 5, 8, 9, 10, 11, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 59], "These": [4, 11, 29, 30, 31, 34, 36, 37, 38, 39, 40, 41, 43, 46, 48, 57, 59], "To": [8, 11, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 42, 44, 45, 46, 48, 49, 53, 55, 57, 58, 59], "WITH": 0, "Will": [36, 47, 49, 51, 56], "With": [0, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 45, 47, 50, 53, 59], "_": [38, 45, 47, 49], "__call__": 33, "__class__": [34, 46], "__finalize__": 47, "__getitem__": [30, 32], "__init__": 49, "__name__": [34, 46], "_arg": 49, "_array_api": 49, "_astype_nansaf": 47, "_c": 49, "_california_housing_dataset": 34, "_call_func_on_transform": 33, "_callback": 49, "_column_transform": 33, "_constructor_from_mgr": 47, "_context": 49, "_data": 35, "_distn_infrastructur": 35, "_encod": 33, "_get_default_devic": 49, "_get_sequential_output": 33, "_i": 45, "_logist": 50, "_mgr": 47, "_proba": 38, "_pseudo_sync_runn": 49, "_run": 49, "_run_cel": 49, "_run_cod": 49, "_run_module_as_main": 49, "_run_onc": 49, "_score": 33, "_scorer": 33, "_set_output": 33, "_temp": 49, "_time_fit_was_cal": 47, "_transform": 33, "_transform_on": 33, "_valid": 33, "ab": [34, 36, 37, 39], "abbrevi": 44, "abil": [28, 33, 35, 39, 44, 46, 53], "abl": [8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 53, 55, 59], "about": [2, 4, 7, 10, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 59], "abov": [0, 5, 8, 11, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 53, 55, 58, 59], "absenc": [33, 39, 43], "absolut": [34, 36, 37, 39, 41, 49, 59], "abspath": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58], "academ": [7, 40], "accept": [5, 8, 36, 37, 44], "accept_spars": 33, "access": [10, 11, 30, 32, 35, 38, 41, 43, 44, 46, 48, 55], "accessori": 46, "accident": [31, 32], "accommod": 7, "accompani": [7, 28, 29], "accord": [34, 36, 37, 40, 43, 47, 55, 56, 57, 59], "account": [7, 10, 30, 36, 40, 43, 47, 51, 56], "accur": [28, 30, 38, 39, 40, 43, 47, 48, 51, 52], "accuraci": [29, 30, 31, 32, 35, 36, 38, 39, 40, 42, 45, 47, 48, 49, 51, 52, 56, 57, 59], "accuracy_scor": 36, "acdm": [36, 38, 39, 56], "acf": 46, "achiev": [8, 31, 36, 55, 57, 58], "acinonyx": [28, 45], "acoust": [31, 32, 35, 55], "acquir": 59, "acquisit": 43, "across": [28, 29, 30, 32, 36, 39, 45, 59], "act": [34, 59], "action": [0, 28, 38, 39, 41, 43, 44, 47, 59], "activ": [4, 11, 28, 35, 49, 51, 59], "actor": [43, 44], "actual": [7, 28, 34, 36, 38, 39, 41, 43, 44, 46, 47, 48, 55, 57], "ad": [33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 47, 49, 55, 58], "adapt": [0, 32, 33, 36, 38, 44, 46, 48, 49], "add": [7, 8, 11, 32, 33, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 54, 56, 57, 58], "add_pip": 49, "addit": [0, 4, 37, 43, 48, 56, 59], "addition": [52, 53, 59], "address": [18, 42, 56], "adelaid": [46, 58], "adio": 48, "adj": 49, "adject": 44, "adjust": [31, 35, 42, 46, 53], "adm": [36, 38, 39], "admin": 59, "administr": 1, "admit": 30, "adopt": [6, 43], "adp": [44, 49], "adult": [36, 38, 39, 56], "adult_df_larg": [38, 39], "adv": 44, "advanc": [33, 35, 41, 42, 43, 44, 45, 52, 59], "advantag": [32, 33, 34, 38, 42, 43, 44, 51, 59], "advic": 47, "advis": 28, "advisor": 59, "af": 39, "affect": [11, 31, 32, 34, 35, 36, 41, 46, 47, 49, 53], "affix": 44, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 36, 37, 39, 41, 42, 45, 46, 47, 48, 49, 51, 57, 58, 59], "ag": [28, 34, 36, 37, 38, 39, 40, 43, 56, 57], "again": [11, 29, 30, 32, 42, 43, 44, 45, 47, 53, 56, 57, 58], "against": [43, 46, 55], "agenc": 49, "agent": 10, "agglomerativeclust": 42, "aggress": 44, "agnost": 39, "ago": [45, 46], "agre": 53, "agreement": [47, 59], "ahead": [48, 56], "ai": [7, 9, 36, 40, 45, 56], "aight": 28, "aim": 51, "airplan": 48, "airport": 36, "aka": [34, 47], "al": [38, 44], "alamine_aminotransferas": 28, "alan": 10, "alaska": 34, "album": 35, "albumin": 28, "albumin_and_globulin_ratio": 28, "alburi": [46, 58], "alexand": 48, "alexnet": 45, "algebra": [43, 44], "algorithm": [2, 15, 28, 30, 32, 33, 36, 37, 38, 39, 42, 44, 45, 48, 52, 53, 54, 56, 59], "align": [8, 28, 29, 30], "align_kei": 47, "alkaline_phosphotas": 28, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 30, 31, 33, 35, 37, 38, 39, 40, 44, 45, 46, 47, 49, 50, 53, 54, 55, 56, 57, 58, 59], "all_cap": 49, "all_featur": [46, 58], "allei": [37, 39, 48], "allen": 49, "alley_grvl": 37, "alley_miss": 37, "alley_pav": 37, "alloc": [8, 44, 45], "allow": [5, 7, 11, 30, 32, 35, 36, 40, 44, 46, 47, 52, 53, 55, 58, 59], "allpub": [37, 39, 48], "almost": [34, 35, 37, 40, 42, 43, 44, 56], "along": [7, 29, 33, 36, 45, 46, 48, 52], "alpha": [31, 32, 46, 53, 58], "alpha_": 37, "alphabet": 34, "alphago": [28, 41], "alq": [37, 39, 48], "alreadi": [4, 8, 11, 36, 37, 39, 41, 46, 47, 48, 49, 52, 55, 58, 59], "also": [2, 4, 5, 7, 8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "altar": 45, "altern": [8, 35, 41, 48, 55, 59], "although": [30, 38, 41, 43, 47], "alwai": [28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 49, 51, 52, 53, 55, 59], "am": [32, 41, 48, 49], "amatriain": 43, "amazon": [28, 41, 43, 49], "ambigu": 44, "amer": 36, "america": 33, "american": 41, "aml": 32, "among": [28, 29, 35, 36, 38, 39, 43, 57], "amongst": 49, "amount": [4, 28, 30, 34, 35, 36, 37, 39, 41, 45, 46, 47, 55, 58], "amp": [38, 39], "amplifi": [36, 44, 56], "amuel": 32, "an": [0, 2, 4, 6, 7, 8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 54, 55, 57, 58, 59], "anaconda": [11, 39, 49], "analogi": [15, 42, 44, 48], "analysi": [2, 9, 10, 29, 36, 37, 41, 42, 44, 48, 56, 59], "analyt": 46, "analyz": [36, 40, 46, 47, 48, 58, 59], "anatinu": 45, "anca": 59, "ancestor": 40, "ancestr": 59, "ancuta": 59, "andrea": [9, 10], "andrew": [9, 10, 35, 40], "anemon": 45, "angel": [47, 49], "ani": [0, 11, 29, 30, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 59], "anim": [36, 45], "animal_fac": 45, "anneal": 40, "annot": [39, 41], "announc": 7, "annoyingli": 37, "annual": 49, "anomali": [36, 37, 41], "anonym": 46, "anoth": [8, 11, 29, 31, 34, 35, 36, 38, 39, 41, 42, 43, 45, 46, 47, 48, 51, 52, 54, 57, 58], "answer": [4, 6, 7, 28, 29, 30, 35, 38, 41, 43, 44, 46, 48, 50, 52, 53, 56, 57, 58, 59], "anteat": 45, "anti": 47, "anymor": [37, 41, 43, 53], "anyon": 48, "anyth": [0, 30, 33, 36, 43, 44, 47, 55], "anytim": 59, "anywher": 33, "ap": [51, 59], "ap_lr": 36, "ap_svc": 36, "apart": [31, 42], "apeendixa": 40, "api": [36, 44, 46, 51], "app": [29, 49, 51], "appeal": 44, "appear": [2, 7, 33, 38, 53, 57, 59], "append": [4, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55, 56, 57], "appendix_b": 44, "appendixb": 45, "appli": [0, 2, 6, 9, 10, 28, 29, 30, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 59], "applic": [0, 5, 28, 33, 35, 36, 37, 39, 40, 44, 47, 49, 51, 56, 59], "appreci": [41, 59], "approach": [10, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 44, 45, 51, 53, 58, 59], "appropri": [0, 4, 11, 29, 30, 33, 36, 37, 41, 42, 46, 47, 51, 59], "approv": [36, 56, 59], "approx": [31, 39], "approxim": [29, 35, 40], "april": 46, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 35, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "arang": [8, 30, 31, 34, 35, 36, 37, 53, 55], "arbitrari": [39, 41, 42, 46], "architectur": 45, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "area": [35, 37, 38, 40, 41, 48, 55], "aren": [7, 37, 40, 41, 45, 46, 49, 58], "arena": 40, "arg": [30, 33, 49], "argh": 47, "argmin": [30, 31, 36, 41], "argsort": [39, 44], "argu": [41, 44, 55], "argument": [8, 29, 33, 35, 36, 37, 39, 48, 49, 51, 54], "arima": 46, "arima_model": 46, "aris": [0, 28, 44], "aristotl": 31, "arithmet": 8, "around": [7, 31, 33, 36, 37, 46, 47, 52], "aroundn": 28, "arr": 47, "arr1": 8, "arr2": 8, "arrai": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 55], "array_equ": 8, "arriv": 40, "art": 48, "arthur": 28, "articl": [10, 29, 30, 32, 36, 41, 43, 44, 45, 48], "articul": [48, 51], "artifici": [10, 44], "artist": [31, 32, 35, 55], "as_fram": [31, 53], "ascend": [8, 33, 34, 35, 37, 38, 39, 40, 46, 47, 51, 57], "ased": 42, "asi": 49, "asia": 33, "asid": [4, 30, 38, 53], "ask": [3, 7, 11, 28, 29, 30, 31, 33, 36, 40, 41, 43, 44, 47, 48, 49, 52, 59], "asleep": 34, "aspartate_aminotransferas": 28, "aspect": [34, 39, 40, 42, 43, 47, 48, 51], "assault": 59, "assert": [7, 33, 36, 38, 39, 56], "assess": [6, 10, 28, 29, 30, 32, 36, 39, 41, 48, 59], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 51, 52, 54, 56, 58], "assist": 28, "assoc": [36, 38, 39, 56], "associ": [0, 28, 30, 31, 36, 37, 39, 40, 41, 44, 45, 46, 47, 48, 51, 57, 59], "assum": [28, 29, 33, 34, 36, 37, 42, 43, 44, 46, 48, 51, 56], "assumpt": 47, "asterisk": 35, "astyp": [8, 46, 47, 58], "astype_arrai": 47, "astype_array_saf": 47, "async_": 49, "async_help": 49, "asyncio": 49, "asyncio_loop": 49, "atabak": 59, "atratu": 45, "attack": 29, "attempt": [30, 55, 56], "attend": 59, "attent": [6, 44], "attic": 37, "attract": 44, "attribut": [0, 1, 28, 29, 31, 32, 34, 35, 40, 41, 44, 45, 55, 57], "attrit": 47, "auc": [47, 51, 56, 59], "audienc": [48, 56, 59], "audio": [45, 59], "audit": 59, "auditor": 59, "augment": 36, "august": 46, "australia": [46, 58], "authent": 41, "author": [0, 44, 59], "auto": [28, 35, 36, 40, 41, 48], "autocorrel": 46, "autom": [29, 37, 44, 48], "automat": [32, 33, 37, 40, 44, 46, 47, 48, 58], "autoregress": 34, "autumn": 46, "autumn_month": 46, "aux": 49, "av": [37, 39, 48], "avail": [0, 1, 7, 9, 10, 11, 30, 33, 35, 36, 37, 42, 43, 44, 45, 46, 47, 51, 56, 57, 58, 59], "avebedrm": 34, "aveoccup": 34, "averag": [30, 31, 33, 34, 35, 37, 39, 41, 42, 44, 47, 49, 51, 53, 59], "average_precis": 36, "average_precision_scor": 36, "average_word_length": 49, "averaging_model": [38, 57], "averaging_model_ndt": 38, "averoom": 34, "avg": [36, 43, 46], "avg_sent_emb": 44, "avocado": 48, "avoid": [7, 8, 29, 32, 36, 37, 42, 46, 47, 48, 50, 51, 53, 56, 59], "awai": [4, 6, 29, 34, 41, 43, 45, 47, 48, 51], "await": 49, "awar": [33, 47, 48, 59], "award": 59, "awesom": 9, "ax": [30, 31, 34, 36, 41, 42, 45, 47, 48, 53, 56], "axi": [7, 8, 28, 29, 30, 32, 33, 34, 39, 41, 42, 44, 45, 46, 48, 58], "axvlin": 41, "az": 49, "b": [8, 10, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48], "b3": [32, 39], "babe": 28, "babi": [40, 44], "bachelor": [36, 38, 39, 56], "back": [8, 32, 35, 44, 51], "backdrop": 46, "background": [29, 48, 59], "bad": [8, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 45, 46], "badgeryscreek": 46, "bag": [40, 44, 45, 51, 55], "bai": [32, 33, 40], "baidu": 30, "bal_scor": 36, "balanc": [6, 31, 38, 41, 43, 50, 56, 57], "ballarat": [46, 58], "balust": 45, "balustrad": 45, "bambi": 43, "banist": 45, "bank": [36, 39, 46, 47, 56], "bannist": 45, "bar": [36, 37, 39, 45, 46, 47, 48, 58], "baranski": 49, "barbu": 59, "barri": 34, "base": [5, 8, 11, 15, 29, 30, 32, 33, 34, 35, 36, 37, 39, 41, 42, 44, 47, 48, 49, 51, 52, 55, 56, 57, 59], "base_ev": 49, "base_scor": 38, "base_valu": 39, "baseblockmanag": 47, "baselin": [14, 47, 51, 52, 54, 55, 58], "baseline_hazard_": 47, "bash": 5, "basi": [29, 31], "basic": [2, 8, 29, 35, 40, 43, 45, 47, 49, 57, 58], "batch": [44, 45], "batch_siz": 45, "batch_t": 45, "bath": 28, "bathroom": [28, 29, 34], "bayesian": 35, "bayesopt": 35, "beagl": [28, 45], "bear": 45, "beat": [38, 47], "beauti": [43, 44, 48], "becam": 45, "becaus": [7, 8, 10, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 56, 58, 59], "becom": [4, 30, 31, 34, 35, 36, 39, 40, 41, 44], "bed": 36, "bedroom": [28, 29, 34], "bedroomabvgr": [37, 39, 48], "bedrooms_per_household": [32, 33, 54], "beef": 44, "been": [4, 6, 10, 28, 29, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 59], "befor": [4, 10, 11, 28, 29, 30, 31, 33, 34, 37, 38, 41, 42, 43, 44, 45, 46, 47, 52, 53, 55, 56, 57, 58], "begin": [29, 34, 40, 43, 46, 47, 51], "beginn": 45, "behav": [35, 39], "behavior": [30, 32, 36, 43], "behaviour": [33, 56, 57], "behind": [28, 34, 59], "being": [4, 28, 30, 32, 36, 37, 38, 39, 42, 44, 47, 48, 53, 59], "belief": 48, "believ": [35, 39, 46], "bell": 45, "belong": [29, 34, 42, 52], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59], "bench": 45, "benchmark": 45, "bendigo": [46, 58], "benefici": [33, 48], "benefit": [4, 31, 38, 42, 44, 48, 51], "bengio": 35, "ber": 44, "bergstra": 35, "berri": 44, "bertop": 44, "best": [2, 29, 30, 31, 35, 36, 37, 38, 39, 41, 42, 43, 47, 48, 52, 53, 55, 57], "best_alpha": 37, "best_depth": 30, "best_estimator_": [35, 37], "best_n_neighbour": 31, "best_param": [35, 48], "best_paramet": 35, "best_params_": [35, 37, 48, 55], "best_scor": 35, "best_score_": [35, 37, 55], "best_svr": 48, "bestalpha_coeff": 37, "better": [6, 28, 29, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 59], "between": [2, 8, 11, 28, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 59], "bewar": 44, "beyond": [30, 35, 40, 48], "bia": [34, 36, 39, 47, 51, 56], "bias": [36, 39, 44, 47, 56, 59], "bicycl": [29, 46], "big": [7, 31, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 53], "bigalpha_coeff": 37, "bigger": [31, 33, 34, 37, 39, 42, 44, 45, 46], "biggest": [37, 40, 58], "bike": 46, "bill": 45, "billboard": 46, "billion": 37, "billionth": 46, "bin": [32, 35, 37, 40, 46, 47, 48, 49, 52], "binar": [29, 33], "binari": [29, 32, 33, 34, 45, 47, 48, 50, 51, 56], "binary_feat": 33, "binary_featur": [36, 38, 39, 56, 57], "binary_transform": [36, 38, 39, 56, 57], "bincount": [36, 38, 56], "bind": [31, 53], "binomi": 35, "biolog": 40, "biologi": 33, "bit": [11, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 48, 55, 56, 58], "black": [31, 39, 41, 45, 46, 58], "bld": 49, "bldgtype": [37, 39, 48], "bldgtype_1fam": 37, "bldgtype_2fmcon": 37, "bldgtype_duplex": 37, "bldgtype_twnh": 37, "bldgtype_twnhs": 37, "blei": 44, "blend": 44, "blindli": [36, 37], "blob": 50, "block": [34, 47], "blog": [44, 46], "bloomberg": [9, 10], "blq": [37, 39, 48], "blue": [29, 31, 35, 36, 39, 40, 41, 46], "bmatrix": [40, 43], "board": 4, "boathous": 45, "bob_dylan": 44, "bodi": 49, "boggl": 38, "bold": 48, "bond": 36, "bonu": 38, "book": [1, 9, 36, 37, 43, 44, 46, 48, 59], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "bool": [37, 46], "boom": 49, "boost": [19, 20, 44, 51], "booster": 38, "bootstrap": [11, 48], "border": [29, 34, 42, 44, 50, 52], "bore": 34, "boston": 34, "both": [2, 6, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 59], "bother": 39, "bottom": 42, "bought": 43, "bound": [40, 47], "boundari": [30, 42, 44, 48, 53], "bow_df": 33, "box": [9, 39, 51], "boxplot": 39, "boyc": 29, "br": 44, "bracket": 8, "brain": [40, 45], "branch": [29, 42, 44, 47], "brand": 48, "break": [36, 51, 53], "breakwat": 45, "breath": 51, "breathtak": 44, "breed": 51, "breiman": 38, "brief": [4, 34, 38], "briefli": [28, 36, 38, 40], "bring": [6, 39, 42, 49, 51], "british": [1, 44], "british_columbia": 44, "broad": [31, 53], "broadcast": 44, "broader": [2, 38, 44], "broadli": [29, 31, 34, 36, 38, 41, 42, 44], "broken": 48, "brownle": 40, "browser": 11, "brush": 45, "bsmtcond": [37, 39, 48], "bsmtexposur": [37, 39, 48], "bsmtfinsf1": [37, 39, 48], "bsmtfinsf2": [37, 39, 48], "bsmtfintype1": [37, 39, 48], "bsmtfintype2": [37, 39, 48], "bsmtfullbath": [37, 39, 48], "bsmthalfbath": [37, 39, 48], "bsmtqual": [37, 39, 48], "bsmtunfsf": [37, 39, 48], "btw": 39, "bubbl": [43, 45], "bucket": [40, 49], "budget": [35, 43], "bug": [4, 8], "bui": 43, "build": [0, 2, 11, 30, 32, 33, 38, 40, 41, 44, 46, 48, 50, 53, 58, 59], "built": [8, 28, 29, 30, 34, 35, 39, 46, 48, 58], "bullshit": [10, 47], "bulwark": 45, "bunch": [8, 11, 29, 37, 38, 45, 47, 48, 53], "bundl": [7, 11], "bureau": 34, "busi": [36, 41, 47, 49], "bustl": 46, "butterfli": 42, "buzz": 28, "bypass": 59, "c": [0, 5, 8, 9, 10, 11, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 53, 55, 59], "c1": 42, "c2": 42, "c_1": 41, "c_2": 41, "c_3": 41, "c_log": [31, 53], "c_widget": [31, 53], "ca": [5, 9, 49, 59], "ca_transform": 33, "cache_s": 48, "cal_hous": 34, "calcul": [7, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 46, 49, 50, 51, 53, 56, 58], "california": [32, 40], "california_h": 40, "californian": 32, "call": [8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58], "callback": 38, "calm": 51, "came": 46, "camera": 33, "campu": [40, 59], "can": [4, 6, 7, 10, 11, 28, 29, 31, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "canada": [5, 30, 31, 33, 34, 44, 48, 49, 51], "canada_usa_c": [29, 30, 31, 34, 52], "canadian": 44, "canadien": 44, "canberra": [46, 58], "cancel": 59, "cancer": [28, 40], "candid": [35, 38, 44, 53], "cannot": [0, 8, 30, 31, 35, 36, 38, 39, 40, 42, 46, 47, 48, 49, 59], "canva": [1, 7, 10], "capabl": 9, "capit": [36, 38, 39, 56], "caption": [7, 45], "captiv": 44, "captur": [30, 32, 34, 38, 40, 42, 43, 44, 46, 47, 51, 59], "car": [28, 44, 45], "card": [28, 29, 36, 47, 48, 56], "care": [5, 7, 30, 32, 35, 36, 37, 39, 40, 41, 46, 47, 51, 55, 57, 58], "carefulli": [1, 36, 37, 56, 59], "carpentri": 5, "carri": [29, 30, 31, 33, 35, 36, 37, 38, 41, 43, 44, 46, 49, 53, 55, 58], "caruana": 39, "case": [6, 11, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 58, 59], "cash": 28, "cast": [35, 43, 49], "castl": 45, "cat": [28, 36, 38, 44, 45, 49, 51], "catamount": [28, 45], "catboost": [39, 48, 51, 59], "catboostclassifi": 38, "catboostregressor": 38, "catch": [36, 59], "categor": [29, 35, 36, 37, 38, 40, 41, 43, 44, 47, 48, 51, 53, 54, 56, 58], "categori": [31, 32, 36, 37, 38, 39, 40, 41, 45, 48, 51, 56], "categorical_feat": [33, 35, 51, 55], "categorical_featur": [33, 36, 37, 38, 39, 46, 47, 48, 56, 57, 58], "categorical_transform": [33, 36, 37, 38, 39, 46, 48, 56, 57, 58], "categories_": [32, 33], "cater": 41, "caus": [36, 39, 40, 43, 47, 55], "causal": [39, 40], "caution": 46, "cbar": 34, "cbtf": [10, 59], "cc": [0, 1], "cc_df": [36, 56], "cconj": 44, "ccp_alpha": 48, "cell": [7, 8, 28, 32, 33, 35, 36, 37, 38, 39, 40, 43, 45, 47, 48, 49, 52, 53, 55, 57], "cell_nam": 49, "censor": [10, 48, 51, 59], "censu": [34, 36, 38, 39, 56], "census_df": [36, 56], "cent": 37, "center": [31, 41, 42, 45, 50], "centercrop": 45, "centers_idx": 41, "central": 5, "centralair": [37, 39, 48], "centralair_i": 37, "centralair_n": 37, "centric": [48, 59], "centroid": [41, 42], "centroids_idx": 41, "centroids_idx_init": 41, "centuri": 44, "certain": [11, 31, 34, 35, 36, 39, 40, 41, 44, 47, 48, 56], "certainli": 52, "certainti": 36, "cezannec": 45, "chage": 55, "chain": 33, "challeng": [6, 30, 40, 41, 43, 45, 46, 51, 57, 59], "chanc": [29, 30, 35, 36, 37, 40, 41, 47, 48, 56], "chang": [0, 5, 7, 8, 11, 29, 30, 31, 32, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 52, 53, 55, 56, 57, 58, 59], "channel": [1, 11, 45], "chapter": 10, "charact": [33, 36, 44], "characterist": [29, 30, 34, 55], "charg": [0, 28, 47], "charl": 34, "charm": 44, "chart": [39, 46, 47, 48, 58], "chat": 59, "chatgpt": 44, "che210d": 9, "cheaper": 40, "cheat": 9, "check": [4, 7, 10, 11, 28, 29, 30, 32, 34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 53, 56, 57, 58], "check_assumpt": 47, "check_invers": 33, "checklist": 51, "checkmark": 43, "checkout": 35, "cheetah": [28, 45], "cherri": 48, "chest": 30, "chestpaintyp": 57, "chetah": [28, 45], "chi": 47, "chicago": 49, "chicken": 41, "child": [36, 39], "children": 43, "chines": 44, "chn": 8, "choic": [2, 35, 37, 38, 39, 41, 42, 43, 46, 49, 53, 54, 55], "cholesterol": 57, "choos": [28, 35, 36, 38, 42, 48, 51, 53], "chop": [35, 44, 48], "choreograph": 49, "chose": 48, "chosen": [30, 35, 36, 47, 48, 51, 57], "chrbv": 47, "christin": 49, "christma": 49, "chunki": 41, "churn": [48, 51], "ciml": 10, "cinematographi": 44, "cinereu": 45, "circl": [31, 36], "circumst": 7, "citat": 7, "cite": 47, "citi": [29, 30, 31, 46, 48, 51, 52], "citibik": 46, "cities_df": [31, 34], "citizen": 47, "cityscap": 46, "civ": [36, 38, 39], "clai": 39, "claim": [0, 35, 36], "clarif": 41, "clarifi": 51, "clariti": 59, "class": [4, 5, 11, 28, 29, 30, 31, 32, 33, 34, 40, 41, 46, 47, 48, 52, 53, 56, 57, 58], "class_attend": [29, 30, 51], "class_attendance_enc": 33, "class_attendance_level": 33, "class_label": 36, "class_labels_fil": 28, "class_nam": [29, 31, 38, 45], "class_sep": 36, "class_weight": [38, 48, 56], "classes_": [34, 36, 38, 39, 45, 50], "classic": [31, 45, 50], "classif": [2, 10, 30, 31, 32, 33, 34, 37, 38, 39, 40, 43, 44, 46, 47, 48, 50, 52, 53, 55, 56, 57, 59], "classifi": [30, 31, 32, 33, 35, 36, 39, 45, 48, 50, 52, 54, 56, 57], "classification_df": [29, 30], "classification_report": [36, 45, 56], "classifiers_ndt": 38, "classify_imag": [28, 45], "classmat": [6, 53, 54, 55, 56, 57, 58, 59], "classroom": 10, "clean": [2, 28, 42, 48, 58, 59], "clean_text": 44, "cleaned_hm": 36, "cleaner": [36, 39], "clear": [7, 36, 41, 53, 59], "clearli": [4, 6, 7, 35, 38, 39, 46], "cleric": [36, 38, 39], "clever": 48, "clf": [28, 29, 31, 34, 45], "cli": 44, "click": [5, 7, 10, 36, 43, 48], "client": 43, "clinic": 29, "clip": 28, "clone": [5, 7, 11], "close": [2, 30, 31, 34, 35, 36, 41, 42, 44, 46, 49, 50, 53, 59], "close_default_lr": 36, "close_zero_svm": 36, "closer": [31, 32, 34, 43, 52, 55, 59], "closest": [31, 32, 36, 41, 42, 44, 46], "cloth": 46, "cloud": [28, 29, 33, 34, 35, 37, 38, 49], "cloud3pm": [46, 58], "cloud9am": [46, 58], "clust_label": 41, "cluster": [2, 10, 43, 44, 46, 59], "cluster_cent": 41, "cluster_centers_": 41, "cluster_std": [42, 45], "clutter": 29, "cm": [31, 34, 36, 39, 43, 53, 56], "cmap": [32, 35, 36, 39, 45, 55], "cmn": 37, "cmp": 47, "cnn": [45, 46], "co": [33, 44], "coast": 45, "cockpit": 48, "code": [4, 7, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58], "code_ast": 49, "code_obj": 49, "codecademi": 9, "coef": [46, 47, 49, 58], "coef0": 48, "coef_": [34, 37, 38, 39, 40, 43, 45, 46, 47, 49, 50, 57], "coef_df": [34, 39], "coef_nonzero": 46, "coeff": 34, "coeff_df": 46, "coeffici": [37, 38, 40, 43, 45, 46, 47, 48, 49, 50, 51, 57, 58], "coefs_df": 40, "coher": 41, "col": [29, 33, 34, 43, 46, 51], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 32, "colinear": 39, "collabor": [5, 43, 59], "collaps": 39, "colleagu": [8, 9], "collect": [28, 29, 32, 33, 36, 38, 39, 40, 43, 44, 45, 46, 47, 51, 57, 59], "colleg": [36, 38, 39, 56], "collinear": 40, "color": [19, 23, 24, 25, 26, 27, 34, 39, 40, 41, 42, 46, 48], "color_continuous_scal": 40, "color_threshold": 42, "colorbar": [32, 34], "colour": [33, 34, 35, 39, 41, 42, 45], "colsample_bylevel": 38, "colsample_bynod": 38, "colsample_bytre": 38, "columbia": [1, 9, 44], "column": [7, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "column_nam": 33, "column_stack": 40, "columntranform": 54, "columntransform": [10, 16, 17, 32, 35, 36, 37, 38, 39, 40, 46, 47, 48, 49, 55, 56, 57, 58], "columntransformer__countvectorizer__max_featur": [35, 55], "columntransformercolumntransform": [33, 35, 37, 38, 40, 49], "columntransformerifittedcolumntransform": [33, 37, 48], "columntransformerinot": [33, 38], "com": [0, 5, 8, 9, 11, 28, 29, 33, 34, 36, 37, 38, 45, 46, 47, 49, 56], "comat": 44, "combin": [29, 32, 33, 35, 36, 40, 43, 45, 46, 47, 48, 52, 53, 55, 57], "come": [11, 28, 29, 32, 33, 36, 40, 43, 44, 45, 46, 47, 48, 52], "comedi": 43, "comfort": 5, "command": [4, 11, 36, 44], "comment": [8, 9, 58], "commerci": 0, "commit": [7, 36, 59], "common": [1, 8, 29, 30, 31, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 50, 53, 59], "commonli": [29, 32, 35, 36, 41, 47], "commun": [2, 10, 11, 33, 35, 37, 59], "commut": 8, "comp_dict": 36, "compact": [35, 40], "compani": [36, 41, 43, 44, 47, 49, 56], "compar": [8, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 55, 56, 57, 58, 59], "comparison": [42, 45, 47, 51], "compassion": 59, "compat": [8, 39, 49], "compatibitl": 8, "compel": 46, "compet": 49, "competit": [38, 45, 50], "compil": 49, "complain": [6, 49], "complaint": [6, 59], "complement": 44, "complet": [1, 6, 7, 28, 32, 35, 38, 39, 40, 42, 44, 47, 48, 52, 53, 56, 57, 59], "complex": [29, 31, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 53, 59], "compli": 0, "complic": [4, 29, 30, 35, 37, 40], "compon": [33, 36, 43, 46, 48, 59], "components_": 44, "compos": [31, 33, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58], "composit": 33, "compound": [44, 45, 47, 49], "comprehend": 44, "comprehens": [41, 51, 59], "compress": [33, 41], "compris": [28, 29, 41], "comput": [7, 9, 10, 11, 28, 33, 35, 36, 38, 39, 40, 41, 42, 44, 46, 48, 50, 56, 57, 59], "computation": 40, "compute_class_weight": 36, "computer_programm": 44, "coms4995": 32, "con": [41, 45, 48], "concat": [28, 31, 32, 33, 34, 39], "concaten": [33, 44], "concav": 40, "concensu": 30, "concentr": [35, 51], "concept": [10, 29, 30, 39, 40, 41, 46, 51, 53, 59], "conceptu": [38, 48], "concern": [4, 33, 38, 59], "concess": 7, "concis": 29, "conclus": 48, "concord": 47, "concordance_index": 47, "concordance_index_": 47, "concret": [28, 48], "conda": [28, 36, 37, 38, 39, 41, 44, 47, 49], "condit": [0, 28, 29, 33, 40, 44, 47, 59], "condition1": [37, 39, 48], "condition1_arteri": 37, "condition1_feedr": 37, "condition1_norm": 37, "condition1_posa": 37, "condition1_posn": 37, "condition1_rra": 37, "condition1_rran": 37, "condition1_rrn": 37, "condition1_rrnn": 37, "condition2": [37, 39, 48], "condition2_arteri": 37, "condition2_feedr": 37, "condition2_norm": 37, "condition2_posa": 37, "condition2_posn": [37, 39], "condition2_rra": 37, "condition2_rran": 37, "condition2_rrnn": 37, "conditional_aft": 47, "confid": [28, 30, 39, 47, 51, 53, 56, 57], "confidenti": 36, "config": [11, 49], "configur": [35, 37, 38], "confirm": 11, "conflict": [11, 42, 59], "confound": 40, "confus": [8, 18, 31, 33, 37, 41, 53, 56], "confusion_matrix": [36, 45, 47], "confusionmatrixdisplai": [36, 56], "congrat": 33, "conjunct": 40, "connect": [0, 29, 42, 43], "connot": 44, "conort": 40, "consciou": 59, "consecut": 46, "consequ": [7, 28, 33, 36, 43, 48, 56], "consid": [4, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 51, 53, 59], "consider": [2, 36, 38, 41, 43, 47, 48, 59], "consist": [6, 7, 29, 30, 32, 41], "constant": [29, 36, 37, 38, 39, 46, 47, 48, 56, 58], "constitu": 38, "constitut": [44, 59], "construct": 43, "constructor": [29, 32], "consult": [31, 53, 59], "consum": [28, 40, 41, 43, 51], "consumpt": 46, "contact": [28, 59], "contain": [8, 11, 19, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 37, 43, 44, 45, 49, 50, 59], "content": [1, 4, 11, 41, 44, 45, 51, 59], "contest": 6, "context": [29, 32, 34, 35, 36, 38, 39, 40, 42, 43, 45, 46, 48, 51, 53, 59], "contextu": 59, "contin": 33, "conting": 42, "continu": [15, 33, 35, 37, 38, 40, 44, 46, 48, 58], "contract": [0, 47], "contract_month": 47, "contract_on": 47, "contract_two": 47, "contrast": [51, 59], "contribut": [31, 34, 39, 45, 57, 59], "control": [5, 8, 29, 30, 31, 33, 34, 37, 38, 45, 59], "convei": 59, "conveni": [8, 35, 36, 41, 44, 46, 47, 48], "converg": 41, "convers": [36, 37, 39, 44, 55], "convert": [28, 32, 33, 34, 38, 39, 40, 44, 46, 47, 58], "convinc": [33, 48], "convolut": [40, 45], "convolutional_neural_network": 45, "cooccurrencematrix": 44, "cook": 41, "cool": 45, "coolwarm": 34, "coordin": 59, "copi": [0, 7, 8, 11, 29, 35, 38, 39, 41, 43, 45, 46, 47, 57, 58, 59], "copy_arrai": 49, "copyright": 0, "cor": 39, "coral": 45, "core": [9, 30, 32, 33, 35, 36, 37, 40, 42, 43, 46, 47, 49, 51, 58, 59], "corefer": 44, "corgi": [28, 45], "coro": 49, "corona_nlp_test": 49, "coronapocalyps": 49, "coronaviru": 49, "corpor": [5, 49], "corpora": [33, 44], "corpu": [33, 36, 44], "corr": 39, "corr_df": 39, "correct": [7, 28, 29, 30, 31, 36, 38, 39, 47, 48, 52, 53, 57], "correctli": [10, 11, 29, 30, 36], "correl": [46, 51], "correspond": [10, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 43, 46, 53, 55], "cosin": 44, "cosine_similar": 44, "cost": [8, 28, 45, 48, 59], "cost_rep": 8, "costli": 36, "cot": 45, "cote": 45, "could": [6, 8, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 48, 53, 55, 56, 58, 59], "count": [8, 29, 32, 33, 36, 37, 40, 44, 45, 46, 47, 49, 50, 53, 55, 56, 58, 59], "counter": 36, "counti": 53, "countri": [30, 31, 33, 34, 36, 38, 39, 56, 59], "country_columbia": 39, "country_dominican": 39, "country_guatemala": 39, "country_hondura": 39, "country_hong": 39, "country_hungari": 39, "country_india": 39, "country_iran": 39, "country_miss": [38, 39], "country_puerto": 39, "country_scotland": 39, "country_south": 39, "country_taiwan": 39, "country_thailand": 39, "country_trinadad": [38, 39], "country_unit": [38, 39], "country_vietnam": [38, 39], "country_yugoslavia": [38, 39], "countvector": [28, 34, 35, 36, 44, 49, 51, 55], "countvectorizercountvector": [33, 35, 49], "countvectorizeroriginaltweet": 49, "countvectorizersong_titl": 35, "coupl": [4, 29, 35, 42, 49, 58], "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55], "coursera": [9, 10], "coursework": 59, "court": 44, "covari": [29, 47], "cover": [8, 36, 38, 41, 45, 46, 59], "coverag": 36, "covid": 49, "covid2019": 49, "cow": 48, "cox": 59, "coxph_fitt": 47, "coxphfitt": 47, "cph": [47, 48, 51], "cph_param": 47, "cpp": 49, "cpsc": [9, 10, 11, 28, 29, 38, 40, 44, 45, 46, 48, 49, 59], "cpsc330": [0, 11, 28, 29, 30, 33, 35, 39, 44, 45, 47, 48, 49, 59], "cpsc330env": 11, "cpu": [35, 45, 49], "craft": [31, 36, 38, 39, 41, 53], "crash": [10, 49], "crate": 45, "creat": [8, 9, 11, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "create_lag_df": 46, "create_lag_featur": [46, 58], "create_y_from_r": 43, "creativ": 1, "credenc": 48, "credit": [0, 29, 36, 38, 44, 46, 47, 48, 56], "creditcard": [36, 56], "crime": 34, "crimin": 39, "criteria": [29, 42], "criterion": [42, 48], "critic": [48, 59], "cross": [15, 29, 31, 33, 35, 37, 38, 39, 41, 43, 47, 48, 49, 51, 54, 55, 56, 57, 58], "cross_val": 38, "cross_val_predict": [36, 38, 47], "cross_val_scor": [32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "cross_valid": [31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58], "cross_validate_std": 30, "crowd": [38, 42], "crown": 59, "crucial": [28, 30, 34, 39, 41, 42, 43, 44], "crude": 44, "cs189": 9, "cs189_ch7": 9, "csrc": 49, "csv": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "ct": 33, "cuda": 45, "cui": 59, "cultiv": 59, "cultur": [45, 59], "cupi": 49, "curios": 28, "curiou": [28, 53], "current": [38, 44, 45, 46, 47, 48, 49], "curriculum": 59, "curs": 48, "curv": [7, 8, 41, 48, 51, 53, 59], "custom": [5, 8, 28, 29, 33, 36, 37, 43, 49, 51], "custom_plot_tre": [29, 30, 38, 39], "customerid": 47, "customiz": 49, "cut": 42, "cv": [30, 33, 36, 37, 38, 39, 40, 46, 47, 48, 51, 53, 55], "cv_feat": 49, "cv_results_": [35, 37, 55], "cv_score": [30, 37], "cv_train_scor": 53, "cv_valid_scor": 53, "cycl": 8, "cyclic": 46, "cycling_data": 8, "cygnu": 45, "d": [4, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 56, 57, 58], "d1b": 59, "d1c": 59, "d1e": 59, "d1f": 59, "d3": 41, "da": 28, "dabeaz": 9, "dad": 40, "dai": [4, 8, 10, 40, 45, 47, 48, 51, 58, 59], "daili": [47, 51], "dall": 46, "damag": [0, 36], "dan": 44, "danceabl": [31, 32, 35, 55], "dark": 49, "darker": 35, "dashboard": [31, 53], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 42, 44, 47, 50, 51, 52, 54, 55, 56, 57, 59], "data_dict": 34, "data_dir": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58], "data_to_wrap": 33, "data_transform": 45, "data_transforms_bw": 45, "data_url": [36, 56], "datacamp": 9, "datafram": [28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58], "dataload": 45, "dataloaders_bw": 45, "datapoint": 34, "dataquest": 9, "dataset": [8, 18, 28, 30, 31, 38, 39, 40, 41, 42, 47, 49, 50, 51, 53, 55, 56, 59], "dataset2": 41, "dataset_s": 45, "dataviz": 48, "date": [7, 11, 28, 29, 43, 47, 49, 51, 53, 58, 59], "date_rang": 46, "dates_rain": [46, 58], "datetim": 47, "datetime64": [46, 58], "datetimeindex": 46, "daughter": 36, "daum\u00e9": 10, "daunt": 43, "dave": 44, "david": [10, 44, 48], "day_nam": [46, 58], "daylight": [46, 58], "dayofweek": 46, "days_sinc": 46, "dbscan": 59, "dc": [46, 47, 49], "dcc": 34, "dd": [46, 58], "de": [44, 46], "deactiv": 11, "deadlin": 59, "deal": [0, 30, 31, 32, 37, 44, 47, 48, 51, 54], "death": 59, "debat": [8, 39], "debbi": 49, "debug": [4, 39], "decad": 45, "decemb": [46, 58], "decid": [8, 29, 31, 34, 38, 39, 40, 41, 42, 44, 46, 47, 51], "decis": [2, 6, 10, 14, 30, 32, 35, 36, 38, 40, 45, 50, 51, 52, 54, 57, 59], "decision_boundari": 50, "decision_funct": 36, "decisiontreeclassifi": [30, 31, 32, 33, 34, 35, 39, 52, 53, 54, 55, 57], "decisiontreeclassifierdecisiontreeclassifi": 38, "decisiontreeregressor": [29, 37, 52, 53], "deck": 9, "declar": 59, "decomposit": [42, 43, 44], "decor": 49, "decreas": [30, 34, 35, 38, 39, 41, 53], "deduct": 7, "deem": 6, "deep": [2, 9, 35, 39, 40, 44, 47], "deepen": [51, 59], "deeper": [2, 35, 36, 37, 39], "deepexplain": 39, "def": [30, 31, 32, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 49, 53, 55, 58], "defalut": 55, "default": [5, 11, 29, 30, 33, 34, 35, 36, 37, 38, 41, 42, 45, 46, 47, 48, 50, 55, 56, 59], "default_threshold": 36, "defaultdict": 43, "defin": [29, 31, 32, 33, 36, 38, 39, 41, 42, 43, 46, 58], "definit": [8, 31, 39, 41, 44, 46, 50, 51, 52], "degre": 36, "degrees_freedom": 47, "degrees_of_freedom": 47, "del": 38, "delai": [10, 11, 40], "deleg": 44, "delet": [4, 7, 32, 48], "delgado": 38, "delight": 44, "deliver": 7, "delv": [44, 59], "demo": [10, 38, 48, 59], "demograph": [29, 43], "demonstr": [29, 30, 32, 34, 35, 37, 38, 41, 43, 44, 45], "denomin": [37, 49], "denot": [29, 43], "dens": [42, 44], "densenet": 45, "densenet121": 45, "densenet121_weight": 45, "densiti": [39, 42, 51], "dep": 44, "department": 59, "departur": 40, "depend": [2, 8, 11, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 48, 57], "dependence_plot": 39, "dependents_no": 47, "dependents_y": 47, "deploi": [30, 36, 43, 48, 51], "deploy": [39, 46, 59], "deprec": [30, 32, 36, 37, 47, 50], "deprecationwarn": [38, 47], "depth": [10, 29, 30, 35, 38, 42, 52, 53], "dequ": [38, 39, 57], "deriv": [0, 29, 34, 36, 43, 47, 51, 56], "descend": [8, 42, 45, 51], "descent": 46, "descr": 34, "describ": [8, 28, 29, 30, 31, 32, 34, 36, 37, 43, 44, 46, 53, 56, 58, 59], "descript": [37, 47, 49], "deserv": 6, "design": [29, 39, 42, 45, 48, 55, 59], "desir": [36, 44, 47, 54], "desk": 59, "despit": [40, 44], "det": [44, 49], "detach": 45, "detail": [7, 31, 33, 38, 45, 59], "detect": [28, 29, 36, 37, 41, 42, 46, 56], "determin": [31, 41, 42, 44, 47, 48, 53, 57, 59], "detriment": [36, 43, 56], "dev": [30, 50], "develop": [9, 10, 28, 30, 32, 33, 35, 36, 37, 38, 44, 45, 48, 49, 51, 59], "devianc": 47, "deviat": [6, 30, 32, 38, 39], "devic": [38, 45, 49], "deviceprotect": 47, "deviceprotection_no": 47, "deviceprotection_y": 47, "df": [28, 29, 30, 32, 33, 35, 36, 37, 39, 40, 45, 46, 47, 48, 49, 52, 58], "df_concat": 28, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 46, "df_locat": [46, 58], "di": 47, "diagnos": [30, 39, 51], "diagnosi": 36, "diagnost": 47, "diagon": [31, 36, 39], "diagram": [33, 35, 38, 39], "dialogu": 44, "dict": [36, 43], "dict_kei": 38, "dictionari": [8, 32, 35, 36, 38, 39], "did": [6, 29, 31, 39, 41, 44, 46, 49, 53, 55, 56, 57, 59], "didn": [35, 38, 39, 42, 46, 47], "die": 49, "diet": 29, "diff": [46, 58], "differ": [2, 5, 7, 8, 10, 11, 28, 29, 30, 31, 33, 34, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 55, 56, 57, 58, 59], "differenti": [28, 29, 59], "difficult": [4, 6, 7, 36, 40, 41, 48], "difficulti": [41, 51], "dig": [36, 37], "digit": [46, 48], "dilemma": 43, "dim": 45, "dimens": [8, 34, 40], "dimension": [2, 8, 34, 35, 36, 38, 40, 41, 44], "direct": [34, 39, 40, 42, 44, 49], "direct_bilirubin": 28, "directli": [8, 10, 33, 37, 45, 47, 59], "director": 43, "directori": [11, 29, 30, 32], "dirichlet": [44, 45], "disabl": 44, "disadvantag": [35, 38, 42, 43, 54], "disast": 28, "discard": [40, 44], "disciplin": [36, 40], "disclos": [49, 59], "discourag": 8, "discours": 43, "discov": [40, 41], "discoveri": 28, "discret": [29, 40, 59], "discrete_scatt": [29, 30, 31, 34, 41, 42, 45, 50, 52, 53], "discretization_feat": 40, "discrimin": 38, "discuss": [1, 4, 30, 31, 32, 34, 39, 40, 41, 42, 46, 51, 53, 54, 55, 57, 58, 59], "diseas": [29, 36, 47], "dislik": 48, "dispatch": 49, "dispatch_queu": 49, "dispatch_shel": 49, "displaci": [44, 49], "displai": [7, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 43, 45, 46, 47, 52, 53, 54, 55, 56, 58], "display_heatmap": [35, 55], "display_label": [36, 56], "disput": 44, "disrespect": 4, "dist": [31, 41, 42], "distanc": [8, 32, 40, 42, 43, 44], "distinct": [36, 40, 46, 48], "distinguish": [29, 31, 33, 36, 53], "distract": 59, "distribut": [0, 11, 30, 36, 39, 40, 42, 44, 45, 46, 55, 58, 59], "district": [32, 34], "districtdatalab": 41, "disturb": 28, "dive": 39, "divers": [38, 41, 43, 46, 59], "divid": [34, 36, 38, 39, 46, 53], "divis": 39, "divorc": [38, 39], "dktal": 47, "dlwqn": 47, "dmp": 59, "do": [0, 4, 5, 6, 7, 8, 10, 11, 28, 29, 30, 31, 34, 37, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "do_execut": 49, "doc": [8, 9, 39, 44, 45, 49, 59], "doctor": [36, 38, 39, 56], "document": [0, 1, 7, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 51, 55, 56, 57, 59], "document_top": 44, "documentari": 43, "doe": [5, 8, 11, 28, 30, 31, 32, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 55, 57, 58, 59], "doesn": [7, 8, 30, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 51], "dog": [36, 45], "dollar": [4, 34, 37, 48], "dolli": 49, "domain": [0, 28, 39, 41, 44], "domin": [32, 37, 45], "domingo": [10, 30, 40], "don": [4, 28, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50], "done": [5, 11, 30, 33, 35, 36, 45, 46, 48, 51, 54, 56], "dont": 49, "door": 45, "dot": [31, 34, 36, 38, 39, 40, 42, 44], "dot_product": 44, "doubl": 35, "down": [30, 36, 39, 47, 48, 53, 57, 59], "downfal": 43, "downgrad": 49, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 36, 37, 39, 44, 45, 48, 49, 53, 57], "downright": 48, "dpi": 40, "dr": [44, 59], "draft": 10, "drag": 7, "drama": 43, "drastic": 36, "draw": [34, 35, 44, 48], "drawback": [39, 43, 59], "drawn": 38, "dream": 45, "drink": 48, "drinker": 44, "drive": [28, 39], "driven": [11, 35, 36], "drop": [7, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59], "drop_dupl": [31, 35], "drop_feat": [33, 51], "drop_featur": [36, 37, 38, 39, 46, 47, 48, 49, 56, 58], "dropdown": [19, 23, 24, 25, 26, 27], "dropdrop": [33, 37, 38, 48, 49], "drope": 32, "dropna": [36, 46, 58], "dropoff": 41, "drug": 28, "dsci": [9, 10, 39, 48, 50], "dsl": 47, "dt": 53, "dt88trtd17lf726d55bq16c40000gr": 49, "dt_best": 53, "dt_pipe": 35, "dtype": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 56, 57, 58], "dual": 36, "duan": 59, "duck": [45, 48], "duckbil": 45, "due": [7, 34, 38, 40, 43, 59], "dummi": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 52, 54, 55, 56, 57, 58], "dummy_clf": [29, 52], "dummy_scor": 31, "dummy_valid_accuraci": 31, "dummyclassifi": [30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 45, 48, 49, 52, 53, 54, 55, 56, 57, 58], "dummyregressor": [33, 38, 39, 40, 48, 49, 54, 57], "dun": 28, "dunno": 28, "duplex": 37, "duplic": 8, "durat": [7, 40, 46, 47], "duration_col": 47, "duration_m": [31, 32, 35], "dure": [4, 8, 10, 28, 29, 31, 33, 34, 35, 38, 39, 40, 43, 51, 52, 53, 54, 55, 56, 57, 58, 59], "dwell": 37, "e": [6, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 58, 59], "e737c5242822": 47, "e_": 30, "each": [7, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59], "earli": [39, 47, 48], "earlier": [32, 38, 40, 46, 47], "early_stopping_round": 38, "earn": 59, "earnest": 59, "easi": [7, 31, 32, 34, 38, 39, 40, 41, 42, 44, 48, 49], "easier": [5, 7, 36, 39, 40, 43, 48], "easiest": [39, 47, 49], "easili": [38, 40, 46, 48, 52, 58], "echidna": 45, "econom": [33, 46], "ecosystem": 45, "ed": 1, "eda": [30, 44, 47, 51, 58], "edg": [29, 35], "edgecolor": [35, 46, 58], "edit": [35, 44], "edu": 9, "educ": [36, 38, 39, 43, 56], "education_level": [36, 38, 39, 56], "effect": [31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 51, 53, 56], "effici": 35, "effort": [4, 11, 35, 40, 41, 43, 45, 59], "egg": 41, "eghbal": 59, "either": [4, 29, 30, 31, 33, 36, 39, 41, 42, 44, 45, 46, 53, 55], "elast": 47, "elbow": 42, "elect": 44, "electr": [37, 39, 48], "electrical_fusea": 37, "electrical_fusef": 37, "electrical_fusep": 37, "electrical_miss": 37, "electrical_mix": 37, "electrical_sbrkr": 37, "electron": [47, 59], "eleg": [32, 48], "elegantli": 44, "element": [0, 9, 10, 30, 33, 44, 52], "eli5": 39, "elif": [29, 46, 47], "elimin": 59, "els": [29, 33, 36, 45, 46, 47, 49, 56], "email": [28, 30, 36, 59], "emb": [7, 31, 36, 41, 42], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 45, 51, 59], "emoji": 49, "emoticon": [40, 41], "emp": 39, "empathi": 44, "emphas": 59, "emphasi": 59, "emploi": [46, 47, 51], "employ": 43, "employe": 29, "empti": [34, 44, 45, 46, 58], "en": [46, 47, 48, 49, 58], "en_core_web_lr": 44, "en_core_web_md": [44, 49], "enabl": [11, 43, 44, 46], "enable_categor": 38, "enable_halving_search_cv": 35, "enc": [32, 33, 46], "enclosedporch": [37, 39, 48], "encod": [16, 17, 28, 30, 35, 36, 37, 39, 43, 47, 51, 54, 56, 58], "encompass": [47, 48, 51], "encount": [33, 35], "encourag": [11, 59], "end": [4, 8, 28, 30, 31, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 53, 59], "endors": 0, "endpoint": 47, "energi": [31, 32, 35, 46, 55], "engag": 59, "engin": [9, 10, 33, 36, 37, 41, 43, 44, 47, 58, 59], "england": 49, "english": [28, 32, 35, 36, 44, 45, 49, 55], "enhanc": 59, "enjoi": [10, 34], "enjoy_class": 33, "enjoy_cours": [33, 51], "enjoy_course_enc": 33, "enjoy_the_mo": 36, "enough": [7, 31, 33, 36, 37, 38, 41, 43, 51, 55, 56, 58], "ensembl": [10, 19, 20, 37, 39, 40, 42, 43, 46, 47, 48, 49, 57, 58, 59], "ensiti": 42, "ensur": [7, 32, 38, 46, 58, 59], "ent": [44, 49], "enter": [33, 47, 48, 55], "enterpris": 5, "entertain": 44, "enthusiast": [28, 48], "entir": [4, 8, 30, 37, 45, 46, 48, 49, 57, 59], "entiti": [40, 43, 44, 49], "entitl": 33, "entlebuch": [28, 45], "entri": [31, 32, 33, 34, 36, 37, 40, 43, 46, 47, 58], "entropi": [29, 48], "enumer": 38, "env": [11, 29, 30, 33, 35, 39, 47, 49, 50], "environ": [3, 5, 8, 28, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 47, 48, 49, 59], "environemnt": 11, "environment": 51, "ep": [29, 30, 31, 34, 42, 52], "epoch": 46, "epsilon": [42, 48], "equal": [8, 31, 33, 36, 37, 38, 39, 42, 43, 46, 51, 58, 59], "equat": [4, 34], "equip": [31, 47, 59], "equival": [8, 36, 38, 56], "err": 44, "error": [4, 6, 7, 8, 11, 29, 31, 33, 34, 38, 39, 40, 44, 47, 48, 49, 51, 53, 57, 59], "error_": 30, "erupt": 28, "erythrocebu": [28, 45], "es": [46, 58], "escap": 48, "eskimo": 36, "esl": 10, "especi": [2, 29, 31, 35, 36, 38, 40, 43, 46], "essenti": [47, 51], "estat": 29, "estim": [30, 31, 33, 34, 35, 40, 41, 47, 48, 51, 57], "estimators_": 38, "et": [38, 44], "etc": [2, 7, 8, 29, 40, 45, 46, 47, 48, 49, 59], "ethic": [10, 59], "euclidean": [41, 42, 44], "euclidean_dist": [31, 32, 41, 42, 44], "ev": 49, "eva": 43, "eva_model": 43, "eval": 45, "eval_metr": [38, 39], "eval_on_featur": 46, "evalu": [8, 10, 29, 30, 35, 37, 39, 41, 46, 48, 53, 57, 59], "evapor": [46, 58], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 34, 35, 36, 40, 41, 42, 43, 46, 47, 48, 49, 51, 53, 54, 56, 59], "event": [0, 36, 37, 49, 59], "event_col": 47, "event_observ": 47, "ever": [29, 50], "everi": [8, 29, 30, 38, 42, 46, 53], "everydai": [8, 44], "everyon": [6, 39, 48, 51], "everyth": [33, 36, 43, 46, 57], "everywher": 46, "evict": 49, "evok": 44, "ex": [37, 39, 48], "ex1_idx": 39, "ex2_idx": 39, "exact": [4, 47], "exactli": [7, 28, 30, 39, 53, 55], "exagger": 48, "exam": [6, 10, 48], "examin": [30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 56, 58], "exampl": [0, 4, 5, 6, 7, 8, 11, 37, 42, 43, 45, 46, 50, 51, 52, 53, 55, 56, 58, 59], "example1": 29, "example2": 29, "exceedingli": 53, "excel": [33, 34, 37, 39, 47, 51, 54], "except": [0, 7, 8, 30, 46, 47, 58, 59], "exception": 4, "exchang": [36, 51], "excit": 43, "exec": 49, "execut": [4, 7, 41], "execute_request": 49, "exercis": [7, 9, 10, 44, 49, 53, 54, 55, 56, 57, 58, 59], "exerciseangina": 57, "exhaust": 55, "exist": [8, 36, 40, 47, 56], "exp": [34, 47, 48], "expand": [10, 29, 59], "expect": [1, 4, 7, 8, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 56, 58, 59], "expected_valu": 39, "expenditur": 46, "expens": [28, 36, 37, 40, 41, 43], "experi": [28, 35, 43, 44, 59], "experienc": 59, "experiment": 35, "expert": [28, 29, 30, 35, 39, 40, 56], "explain": [4, 7, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 56, 57, 59], "explan": [4, 30, 31, 51, 56], "explanatori": 29, "explicit": [36, 47], "explicitli": [8, 28], "exploit": 6, "explor": [29, 30, 33, 35, 36, 39, 40, 43, 44, 45, 53, 55], "exploratori": [37, 47, 51], "explos": 49, "expm1": [37, 48], "expon": 35, "exponenti": 35, "export_graphviz": [29, 52], "exposur": 43, "express": [0, 8, 33, 34, 40, 44, 48], "extend": [44, 45, 50, 59], "extend_block": 47, "extens": [31, 36, 39, 41, 42, 44, 46, 53, 59], "extent": [41, 44], "extercond": [37, 39, 48], "exterior": 39, "exterior1st": [37, 39, 48], "exterior1st_asbshng": 37, "exterior1st_asphshn": 37, "exterior1st_brkcomm": 37, "exterior1st_brkfac": 37, "exterior1st_cblock": 37, "exterior1st_cemntbd": 37, "exterior1st_hdboard": 37, "exterior1st_imstucc": [37, 39], "exterior1st_metalsd": 37, "exterior1st_plywood": 37, "exterior1st_ston": 37, "exterior1st_stucco": 37, "exterior1st_vinylsd": 37, "exterior1st_wd": 37, "exterior1st_wdsh": 37, "exterior2nd": [37, 39, 48], "exterior2nd_asbshng": 37, "exterior2nd_asphshn": 37, "exterior2nd_brk": 37, "exterior2nd_brkfac": 37, "exterior2nd_cblock": 37, "exterior2nd_cmentbd": 37, "exterior2nd_hdboard": 37, "exterior2nd_imstucc": 37, "exterior2nd_metalsd": 37, "exterior2nd_oth": 37, "exterior2nd_plywood": 37, "exterior2nd_ston": 37, "exterior2nd_stucco": 37, "exterior2nd_vinylsd": 37, "exterior2nd_wd": 37, "exterqu": [37, 39, 48], "extra": [4, 41, 46, 58, 59], "extract": [40, 41, 43, 44, 45, 49, 58, 59], "extractor": 51, "extrapol": [46, 47], "extratreesclassifi": 38, "extrem": [6, 33, 36, 38, 39, 43, 47, 49], "ey": 49, "f": [8, 11, 28, 29, 30, 31, 32, 33, 36, 39, 40, 41, 42, 44, 45, 46, 47, 49, 53, 57, 58, 59], "f1": [18, 37, 51, 59], "f1_score": 36, "f403": 49, "fa": [37, 39, 48], "face": [28, 29, 31, 43, 45], "facebook": [43, 44, 59], "facial": 31, "facil": 59, "facilit": [8, 59], "fact": [28, 35, 36, 38, 45, 46, 47, 48, 58], "factor": [29, 35, 39, 40, 42, 43, 47], "fail": [7, 8, 10, 11, 30, 32, 33, 40, 42, 44, 47, 48, 49], "failur": [7, 28, 47, 57, 59], "fair": [6, 30, 32, 37, 39, 41, 51, 59], "fairli": [30, 35, 36, 39, 56], "fake": 31, "fall": [31, 41, 44, 46], "fals": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 51, 56, 57, 58], "famili": [28, 35, 36, 37, 38, 39, 41, 59], "familiar": [8, 11, 29, 32, 48, 53, 58, 59], "famou": [9, 10, 45], "fanci": [4, 28, 35], "fancier": 40, "far": [29, 31, 32, 33, 34, 36, 39, 40, 41, 42, 44, 45, 46, 47, 50, 51, 53, 55, 57], "farm": 36, "farthest": 29, "fashion": [38, 44], "fast": [30, 31, 34, 38, 39, 44, 47, 59], "faster": [28, 35, 38, 40, 45], "fastest": 38, "fastingb": 57, "fasttext": 44, "favourit": 44, "fc": 34, "fcluster": 42, "feat": [35, 46, 49], "feat1": 41, "feat2": 41, "feat_nam": [46, 49], "feat_vec": 43, "featur": [10, 16, 17, 21, 22, 23, 24, 25, 26, 27, 30, 36, 38, 41, 42, 44, 47, 50, 53, 54, 55, 56, 57, 59], "feature_extract": [28, 33, 34, 35, 36, 44, 49, 55], "feature_importances_": 40, "feature_nam": [29, 30, 34, 38, 39, 40, 44], "feature_names_out": 33, "feature_select": 40, "feature_typ": 38, "features_lag": 46, "features_nonzero": 46, "features_poli": 46, "februari": 46, "feder": [36, 39, 46], "feedback": [29, 51], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 41, 51], "feli": [28, 45], "fell": 34, "femal": [36, 38, 39, 47, 56], "female_cm": [36, 56], "female_pr": [36, 56], "fenc": [37, 39, 45, 48], "fernandez": 38, "fetch_california_h": 34, "few": [8, 10, 28, 34, 37, 38, 40, 43, 45, 46, 47, 52, 57], "fewer": [11, 38, 40, 42], "fewest": 57, "feynman": 48, "fiber": 47, "fiction": 49, "field": [2, 4, 28, 33, 44, 45, 46, 59], "fig": [30, 31, 34, 36, 40, 41, 42, 45, 53, 56], "figsiz": [29, 30, 31, 32, 34, 36, 39, 40, 41, 42, 45, 46, 47, 48, 53, 56], "figur": [4, 8, 11, 28, 29, 31, 35, 37, 39, 40, 41, 42, 45, 46, 47, 48, 53], "file": [0, 1, 4, 5, 7, 8, 11, 19, 25, 29, 33, 36, 39, 45, 47, 49, 56, 58], "filenam": 45, "fill": [31, 34, 35, 43, 53, 57, 59], "fill_diagon": 31, "fill_valu": [36, 37, 38, 39, 46, 48, 56, 58], "film": [44, 49], "filter": [4, 28, 30, 41, 46, 51, 58, 59], "filterwarn": [31, 47, 57], "final": [6, 7, 10, 30, 32, 38, 40, 48, 52, 54, 57], "final_estim": 38, "final_estimator_": [38, 57], "financ": [45, 46], "find": [7, 8, 10, 28, 29, 32, 35, 37, 38, 39, 41, 42, 43, 44, 48, 49, 50, 55, 56, 59], "fine": [7, 32, 33, 36, 43, 45, 46, 57], "finish": [25, 28, 37], "fira": [0, 1, 59], "firasm": [36, 48, 56], "fireplac": [37, 39, 48], "fireplacequ": [37, 39, 48], "first": [4, 8, 10, 29, 31, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 55, 56, 57, 59], "first_dai": 46, "first_day_retail": 46, "firth": 44, "fish": [36, 39], "fist": 46, "fit": [0, 28, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58], "fit_intercept": 36, "fit_predict": 42, "fit_resampl": 36, "fit_tim": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 49], "fit_transform": [32, 33, 36, 38, 39, 40, 42, 43, 44, 46, 51, 56], "fittedcolumntransform": [33, 38], "fittedpipelin": [33, 35, 37], "fittedvotingclassifi": 38, "fitter": 47, "five": 35, "fix": [32, 33, 38, 47, 50, 53, 59], "flag": 47, "flagstaff": 49, "flaki": 36, "flashcard": 51, "flat": 42, "flatten": [38, 39, 42, 46, 57], "flatten_train": 45, "flatten_transform": 45, "flatten_valid": 45, "flaw": [30, 32], "flawless": 34, "flexibl": [7, 28, 40, 45, 51, 59], "flibbertigibbet": 44, "flickr_cat_000002": 45, "flight": 40, "flip": [10, 30, 36, 37], "flip_i": 36, "float": [8, 37, 40, 47, 49], "float32": [44, 45], "float64": [29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 46, 47, 58], "floatlogslid": [31, 53], "floatslid": [31, 36, 41, 42, 53], "floor": [28, 29], "flower": [31, 36, 53], "fmt": 35, "fn": 36, "fnlwgt": [36, 38, 39, 56], "focu": [10, 28, 32, 33, 34, 39, 42, 43, 44, 46, 51, 53, 54, 55, 56, 57, 59], "focus": [28, 34, 41, 44, 51, 58], "fold": [30, 32, 33, 35, 36, 37, 38, 53], "folder": [5, 6, 30, 32, 39, 49], "folk": [47, 59], "follow": [0, 5, 6, 7, 8, 11, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 53, 59], "font": [28, 29, 30, 41, 42, 43, 46, 47, 48], "font_scal": 39, "fontsiz": [29, 30, 31, 36, 38, 39, 41, 45, 48, 52, 53], "food": [41, 44, 45, 59], "foot": [37, 39], "footag": 34, "footstal": 45, "forc": [36, 39, 53], "force_plot": 39, "forecast": [29, 47, 48, 51, 58, 59], "forest": [36, 37, 45, 46, 47, 51, 57, 59], "forev": 46, "forg": [11, 36, 37, 38, 39, 44, 47, 49], "forget": [29, 33, 38, 57], "form": [10, 33, 36, 40, 42, 43, 44, 47, 48, 51], "formal": 59, "format": [0, 10, 29, 36, 42, 44, 46, 47, 58], "former": 47, "formul": [4, 35], "formula": [34, 37, 45, 50], "forum": [6, 7], "forward": 47, "found": [7, 10, 30, 33, 35, 37, 41, 43, 44, 49, 51, 55, 57, 59], "foundat": [9, 10, 36, 37, 39, 48, 59], "foundation_brktil": 37, "foundation_cblock": 37, "foundation_pconc": 37, "foundation_slab": 37, "foundation_ston": 37, "foundation_wood": 37, "fountain": 45, "four": [29, 30, 40, 42, 51], "fourth": 42, "foxhound": [28, 45], "foyer": 37, "fp": 36, "fpr": 36, "fpr_lr": 36, "fpr_svc": 36, "frac": [29, 34, 36, 37, 41, 44, 45], "fractal": 40, "fraction": [33, 36, 43], "fragment": 53, "frame": [32, 33, 36, 37, 40, 46, 47, 48, 58], "framework": [29, 35], "fraud": [29, 36, 37, 41, 46, 56], "fraudul": [29, 36, 48, 56], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 37, 44, 47], "freedom": [0, 49], "french": 32, "freq": [46, 58], "frequenc": [33, 44, 46, 47, 51, 58], "frequent": [29, 32, 43, 44, 47], "fresh": 43, "fri": [10, 46], "fridai": [10, 59], "friend": [29, 30, 36, 39, 42, 43, 51, 59], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "from_block": 47, "from_estim": [36, 56], "front": 59, "frozen": 49, "fruit": 44, "frustrat": [4, 6, 35], "full": [35, 38, 45, 46, 47, 59], "fullbath": [37, 39, 48], "fulli": 42, "fun": [36, 44, 45], "func": [8, 33, 34, 37, 48], "function": [2, 28, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 58], "functiontransform": [33, 47], "fund": 49, "fundament": [2, 9, 10, 15, 32, 34, 35, 37, 40, 45, 47, 59], "funni": [28, 38, 49], "furnish": 0, "furnitur": 51, "further": [36, 38, 40, 41, 45, 47, 53, 55, 56], "furthermor": 48, "futur": [30, 32, 35, 37, 47, 51, 55, 58, 59], "futurewarn": [30, 32, 37, 39, 50], "fyi": 47, "g": [6, 7, 8, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 58, 59], "g26r0dcx4b35vf3nk31216hc0000gr": [32, 39], "gain": [6, 29, 36, 38, 39, 56, 59], "game": [29, 39], "gamma": [34, 35, 38, 48, 53, 55], "gamma_log": [31, 53], "gamma_widget": [31, 53], "gap": [30, 46, 47, 48, 51, 53], "garagearea": [37, 39, 48], "garagecar": [37, 39, 48], "garagecond": [37, 39, 48], "garagefinish": [37, 39, 48], "garagefinish_fin": 37, "garagefinish_miss": 37, "garagefinish_rfn": 37, "garagefinish_unf": 37, "garagequ": [37, 39, 48], "garagetyp": [37, 39, 48], "garagetype_2typ": 37, "garagetype_attchd": 37, "garagetype_bas": 37, "garagetype_builtin": 37, "garagetype_carport": 37, "garagetype_detchd": 37, "garagetype_miss": 37, "garageyrblt": [37, 39, 48], "garlic": 41, "gauss": 44, "gaussian": 42, "gaussianmixtur": 42, "gave": [43, 46], "gbr": 8, "gca": [41, 42, 47], "gd": [28, 37, 39, 48], "gdprv": [37, 39, 48], "gdwo": [37, 39, 48], "gelbart": [0, 1, 29, 44, 55], "gender": [28, 33, 36, 44, 46, 47, 56], "gender_femal": 47, "gender_mal": 47, "gener": [7, 9, 15, 29, 32, 33, 35, 36, 37, 39, 42, 44, 45, 46, 47, 48, 50, 51, 53, 55, 56, 58, 59], "genet": 40, "genom": 40, "genr": 43, "gensim": 44, "gentl": 59, "geograph": 34, "geometr": 29, "georg": 44, "geq": 34, "ger": 8, "german": 44, "get": [4, 5, 6, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59], "get_avg_word_length": 49, "get_cmap": 32, "get_depth": 53, "get_dummi": 32, "get_featur": 45, "get_feature_names_out": [32, 33, 36, 37, 38, 39, 40, 44, 46, 47, 48, 49, 56, 58], "get_length_in_word": 49, "get_lr_data_per_us": 43, "get_permutation_import": 39, "get_relative_length": 49, "get_season": 46, "get_senti": 49, "get_stat": 43, "get_text": 48, "get_user_profil": 43, "getattr": 47, "gif": [41, 42], "gift": 49, "gini": [29, 39, 48], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49, 55, 56], "githubusercont": 8, "gitlf": 36, "giulia": [0, 1], "give": [0, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 56], "given": [0, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 58], "gladwel": 41, "glass": 48, "glob": [28, 45], "global": [32, 36, 38, 41, 44, 51], "glove": [44, 59], "glq": [37, 39, 48], "gmail": [28, 41], "go": [5, 7, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58], "goal": [2, 31, 32, 35, 36, 41, 42, 43, 44, 49, 55, 57, 58, 59], "goe": [2, 30, 31, 33, 36, 38, 39, 42, 43, 45, 48], "gold": 8, "goldcoast": 46, "golden": [31, 51, 53], "good": [9, 11, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58], "googl": [4, 10, 28, 29, 38, 39, 40, 41, 44, 48, 49], "google_news_vector": 44, "got": [31, 34, 35, 36, 37, 45], "gotten": [47, 57], "gov": [36, 38, 39], "govern": [44, 59], "gpe": 44, "gpt": [43, 44], "gpu": [38, 44, 45], "grad": [36, 38, 39, 56], "grade": [3, 7, 10, 28, 30, 33, 35, 48, 51, 53, 54, 55, 56, 57, 58], "grader": 6, "grades_df": 51, "gradescop": [1, 6, 10, 59], "gradient": [19, 20, 51], "gradientboostingclassifi": 38, "gradientboostingregressor": [38, 48], "gradientexplain": 39, "grading_concern": 6, "graduat": 45, "grai": 45, "grain": [34, 39], "gram": 44, "grammat": 44, "grandma": 40, "grandmoth": 36, "grant": 0, "granular": 42, "graph": [10, 45, 46], "graphic": 45, "graphviz": [29, 52], "grasp": [51, 59], "grayscal": 45, "great": [28, 29, 31, 33, 34, 39, 40, 44, 45, 46, 48, 49], "greater": [11, 40, 41], "greater_is_bett": 37, "greedili": 42, "green": [31, 35, 41, 48, 50], "grei": 59, "grid": [34, 37, 46, 47, 51, 55, 58], "grid_result": 48, "grid_search": [35, 48, 55], "gridsearchcv": [31, 38, 39, 55, 57], "gridsearchcvifittedgridsearchcv": 35, "grip": 44, "grlivarea": [37, 39, 48], "groak": 44, "groceri": [45, 49], "groin": 45, "ground": [30, 40, 42, 43, 59], "ground_truth_categori": 36, "group": [7, 29, 31, 33, 34, 38, 40, 51, 53, 54, 57, 59], "groupbi": [46, 58], "grow": [35, 38, 40], "grow_polici": 38, "growth": [46, 47], "groyn": 45, "grv": 37, "gsc": 48, "gt": [33, 34, 35, 36, 37, 38], "gtl": 39, "guarante": [35, 36, 38, 41, 45], "guenon": 45, "guess": [31, 32, 44, 49], "guid": [7, 9, 10, 40, 45, 59], "guidanc": 39, "guidelin": [39, 40], "guido": 10, "h": [36, 38, 39, 41, 44, 45, 47, 49, 56], "ha": [2, 5, 6, 10, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 56, 57, 58, 59], "habit": [33, 48], "hacki": [45, 50], "had": [28, 32, 33, 34, 36, 43, 45, 46, 47], "hadn": 47, "hal": 10, "half": [6, 10, 29, 34, 40, 42], "halfbath": [37, 39, 48], "halvingrandomsearchcv": 35, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 35, "ham": 28, "hand": [4, 9, 36, 43, 56, 59], "handi": 36, "handl": [38, 39, 42, 47, 49, 50, 51, 53, 59], "handle_unknow": 33, "handle_unknown": [32, 33, 35, 36, 37, 38, 39, 46, 47, 48, 51, 55, 56, 57, 58], "handler": [36, 39], "handrail": 45, "handwritten": [36, 48], "hang": 36, "happen": [4, 6, 28, 31, 33, 35, 38, 39, 40, 43, 46, 47, 48, 51, 58, 59], "happi": [36, 41, 47], "happier": 59, "happydb": 36, "hard": [8, 28, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 57], "hardli": 43, "hardwar": 45, "harmon": 36, "harri": 44, "has_cupi": 49, "has_emoji": 49, "has_rais": 49, "hasn": [4, 43, 47], "hassl": [8, 39, 46], "hat": [34, 37, 38], "have": [0, 4, 6, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59], "haven": [30, 47, 48, 51], "haylei": 29, "hazard": 59, "hc_truncation_toy_demo": 42, "hdbscan": 42, "he": [30, 33, 59], "head": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "headlin": [44, 48], "health": 44, "healthcar": 39, "healthi": [44, 48], "heard": 30, "heart": [29, 49, 57], "heart_df": 57, "heartdiseas": 57, "heat": [35, 37, 39, 48, 55], "heating_floor": 37, "heating_gasa": 37, "heating_gasw": 37, "heating_grav": 37, "heating_othw": [37, 39], "heating_wal": 37, "heatingqc": [37, 39, 48], "heatmap": 39, "heavi": [38, 49], "heavili": [43, 45, 46, 56], "heeren": 44, "height": [29, 30, 36, 44, 49, 52], "hell": 49, "help": [3, 7, 11, 28, 30, 32, 33, 35, 36, 39, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 58, 59], "henc": [5, 36, 37, 39, 41], "her": [28, 43, 44], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59], "herebi": 0, "herself": 49, "herta": 31, "hesist": 48, "hesit": 48, "heurist": [29, 35], "hi": [44, 53], "hidden": [40, 45, 48], "hide": [8, 45, 48], "hier_label": 42, "hier_labels1": 42, "hier_labels2": 42, "hierarch": [51, 59], "hierarchi": [29, 42], "high": [6, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 59], "high_corr": 39, "higher": [29, 30, 31, 34, 36, 37, 38, 39, 40, 41, 43, 47, 48, 53, 55, 56], "highest": [38, 39, 43, 44, 45, 48, 50, 53, 56], "highland": 49, "highli": [10, 11, 32, 39, 43], "highlight": [4, 45, 48, 51], "highwai": 34, "hinder": 59, "hindi": 32, "hint": [39, 53], "hist": [32, 35, 37, 40, 47], "histgradientboostingclassifi": 38, "histgradientboostingregressor": 38, "histogram": 47, "histor": 51, "histori": [34, 43, 46, 59], "hit": [28, 35], "hitter": 49, "hl": [37, 39, 48], "hmid": 36, "hmmm": 47, "hockei": 44, "hold": [48, 55], "holder": 0, "holdout": 36, "holi": 48, "holidai": [10, 43, 59], "home": [29, 34, 36, 45], "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 31, 34, 35, 44, 51, 59], "honest": 48, "honour": 59, "hood": 30, "hope": [30, 48], "hopefulli": 55, "hopeless": 40, "hopelessli": 31, "horizont": [29, 33], "host": [5, 47], "hot": [16, 30, 33, 39, 51, 58], "hound": [28, 45], "hour": [4, 11, 36, 38, 39, 40, 43, 46, 51, 56, 59], "hourli": [47, 51], "hous": [18, 37, 39, 40, 47, 48, 53], "houseag": 34, "household": [32, 33, 34, 40, 54], "housestyl": [37, 39, 48], "housestyle_1": 37, "housestyle_1stori": 37, "housestyle_2": 37, "housestyle_2stori": 37, "housestyle_sfoy": 37, "housestyle_slvl": 37, "housing_df": [29, 32, 33, 40, 53, 54], "housing_median_ag": [32, 33, 40, 54], "houston": 49, "how": [0, 3, 8, 11, 28, 33, 35, 36, 37, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59], "howard": 41, "howev": [2, 8, 32, 33, 36, 37, 39, 41, 43, 46, 47, 50, 53, 56], "hsjcy": 47, "hstack": 46, "html": [7, 9, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 47, 48, 49, 52, 54, 56], "http": [0, 5, 8, 9, 11, 28, 29, 30, 32, 33, 34, 36, 37, 38, 45, 46, 47, 48, 49, 56, 59], "hug": 43, "huge": [33, 37, 44, 45, 46, 47, 58], "human": [0, 28, 31, 32, 33, 34, 35, 36, 39, 40, 41, 44, 45, 56], "humidity3pm": [46, 58], "humidity3pm_lag1": [46, 58], "humidity9am": [46, 58], "hummu": [41, 44], "humour": [10, 44], "hundr": 34, "hurrai": 57, "hurrican": 28, "husband": [36, 38, 39], "hussar": [28, 45], "hw": 28, "hw1": [4, 10, 52], "hw2": [10, 31, 32, 55], "hw3": 10, "hw4": 10, "hw5": [10, 59], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 43, "hyper": 48, "hyperband": 35, "hyperopt": 35, "hyperparamet": [10, 30, 36, 42, 43, 44, 45, 48, 55], "hyperparameter_": 48, "hyperparamt": [30, 35, 47], "hyperparlan": 34, "hyperplan": 34, "hypothesi": [44, 47], "hypothet": [34, 41], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 34, 37, 42, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "i1": 38, "i2": 38, "ia": 49, "ibm": 49, "ic": 44, "icc": 59, "iclick": 10, "id": [28, 29, 37, 39, 43, 48, 53], "idea": [8, 29, 30, 32, 35, 39, 41, 42, 43, 44, 45, 46, 47, 51, 53, 58], "ideal": [4, 36, 38, 40, 43, 47], "ident": [44, 45, 49], "identif": [28, 49], "identifi": [29, 30, 31, 32, 35, 36, 37, 41, 42, 44, 45, 46, 48, 51, 56, 58, 59], "idf": 33, "idx": 45, "idxmax": 31, "if_binari": [33, 36, 38, 39, 51, 54, 56, 57], "ifram": [30, 36], "igloo": 44, "ignor": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 46, 47, 48, 51, 55, 56, 57, 58], "ignore_index": 8, "ii": 36, "iii": 10, "ij": [34, 43], "ik": 38, "ill": 59, "illus": [36, 56], "illustr": [42, 46], "iloc": [8, 29, 30, 31, 32, 33, 38, 39, 44, 46, 49, 52, 57, 58], "im": 49, "imag": [7, 30, 36, 39, 40, 41, 42, 46, 48, 51, 56, 59], "image_dataset": 45, "image_datasets_bw": 45, "image_s": 45, "imagefold": 45, "imagenet": 50, "imagenet1k_v1": 45, "imagenet_class": [28, 45], "imagin": [28, 29, 30, 32, 34, 36, 39, 40, 41, 44, 47, 48, 51, 52, 56], "imaginari": [30, 44], "imbal": [18, 41, 47, 56], "imbalanc": [36, 37, 50], "imblearn": 36, "img": [28, 45], "img_classifi": 28, "img_path": 28, "img_t": 45, "immedi": [39, 43, 59], "imp": [32, 33, 46], "impact": [7, 33, 34, 38, 39, 42, 46, 48, 53, 58, 59], "implement": [2, 4, 28, 32, 36, 37, 38, 40, 42, 43, 44, 47, 48, 50], "impli": [0, 47], "implic": [32, 51, 59], "implicit": 44, "import": [8, 10, 21, 22, 23, 24, 25, 26, 27, 50, 54, 55, 56, 57, 59], "importance_typ": 38, "importances_mean": 39, "impos": 32, "imposs": 41, "impress": 39, "improv": [35, 36, 37, 38, 40, 41, 42, 43, 46, 47, 48, 51, 55, 59], "impur": [29, 38], "imput": [16, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "imread": 45, "imshow": [28, 45], "inbox": 30, "inc": [39, 44], "incept": [43, 45], "inception": 45, "incl": 37, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 29, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59], "include_bia": [40, 46], "incom": [30, 34, 36, 38, 39, 56], "incomplet": 47, "inconsist": 33, "incorpor": [35, 37, 40, 47, 51], "incorrect": [47, 48], "incorrectli": [28, 36], "increas": [8, 30, 31, 33, 34, 38, 39, 40, 41, 42, 45, 53, 55], "increasingli": 28, "incred": 45, "inde": 39, "independ": [8, 9, 29, 35, 37, 38, 40, 46, 59], "index": [28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 53, 56, 57, 58], "index_col": [8, 31, 32, 35, 36, 43, 55], "india": 44, "indian": 36, "indian_liver_pati": 28, "indic": [0, 33, 41, 43, 44, 45, 46, 47], "indirectli": 48, "individu": [38, 39, 41, 43, 44, 47, 57, 59], "industri": [38, 40, 44, 45], "inequ": [36, 56], "inertia_": 41, "inertia_valu": 41, "inf": [31, 47], "infeas": 35, "infer": [29, 44, 45, 46, 52], "infin": [31, 48], "infinit": 35, "inflamm": 9, "inflat": 39, "inflect": [41, 44], "influenc": [29, 30, 35, 39, 41, 43, 47, 53], "info": [1, 3, 8, 32, 33, 36, 37, 40, 44, 46, 47, 53, 57, 58], "inform": [1, 4, 7, 11, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 53, 56, 57, 58, 59], "inhabit": 59, "inher": [36, 46, 47, 56], "initi": [42, 45, 49], "initj": 39, "inject": [40, 43, 51], "ink": 48, "inland": [32, 33, 40, 54], "inlin": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 48, 52, 53, 55, 56, 57], "inner": [33, 35, 44], "inplac": [8, 28, 29, 35], "input": [8, 29, 32, 34, 38, 39, 42, 44, 45, 46, 49, 51, 58], "input_img": 45, "inputs_bw": 45, "insid": [9, 33, 36], "insight": [2, 31, 36, 39, 41, 59], "inspct": 36, "inspect": [39, 42], "inspir": [29, 36, 38], "instal": [28, 31, 36, 37, 38, 39, 41, 44, 45, 47, 49], "instanc": [28, 29, 30, 33, 34, 36, 41, 42, 43, 44, 45, 46, 50], "instanti": [35, 53], "instead": [5, 8, 11, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53, 55, 56, 57], "institut": 49, "instruct": [3, 4, 5, 11, 31, 48, 59], "instructor": [4, 6, 28, 48, 59], "instrument": [31, 32, 35, 55], "int": [32, 33, 36, 38, 39, 44, 46, 49, 56, 57, 58], "int32": [31, 41, 42, 46], "int64": [29, 31, 33, 36, 37, 43, 46, 47, 49], "integ": [8, 30, 32, 35, 38, 39, 46], "integr": 59, "intellig": [10, 44], "intend": [0, 48], "intens": 44, "inter": 49, "interact": [9, 31, 35, 36, 39, 41, 42, 43, 46, 49, 53], "interaction_constraint": 38, "interaction_onli": [40, 46], "interactive_plot": [31, 53], "interactiveshel": 49, "intercept": [39, 45, 50], "intercept_": [34, 38, 45, 50], "intercept_sc": 36, "interest": [2, 28, 30, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 53, 55, 57, 58], "interfac": 38, "intermedi": [42, 45], "intern": [0, 1, 29, 45, 46, 47, 49], "internet": [47, 48], "internetservic": 47, "internetservice_dsl": 47, "internetservice_fib": 47, "internetservice_no": 47, "internship": 28, "interpret": [10, 11, 21, 22, 23, 24, 25, 26, 27, 31, 32, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 56, 59], "interv": [46, 47, 51, 55, 59], "intrins": 46, "intro": [10, 19, 20, 44, 45], "introduc": [33, 36, 47], "introduct": [9, 10, 11, 13, 16, 46, 47, 53, 59], "intslid": [31, 53], "intuit": [31, 32, 33, 35, 37, 39, 41, 42, 47, 49, 59], "invalid": [35, 48], "inventori": 51, "invers": [34, 37], "inverse_func": [37, 48], "investig": [31, 39, 53], "involv": [2, 4, 35, 37, 38, 42, 44, 45], "io": [9, 32, 45, 47, 49], "io_loop": 49, "ipkernel": 49, "ipykernel": 49, "ipykernel_19402": 39, "ipykernel_32469": 32, "ipykernel_79734": 30, "ipykernel_86208": 49, "ipykernel_launch": 49, "ipynb": [7, 8], "ipython": [28, 29, 30, 31, 32, 33, 34, 36, 44, 49, 52, 54, 56], "ipywidget": [31, 53], "ir1": [37, 39, 48], "ir2": [37, 39, 48], "iri": [31, 53], "iris_df": [31, 53], "irregular": 59, "irregularli": 51, "irrelev": [31, 40, 44], "irrelevant_po": 44, "irrespect": [30, 34, 59], "is_avail": 45, "is_leap_year": [46, 58], "is_stop": 44, "is_year_end": [46, 58], "isinst": 47, "island": [32, 33], "isn": [30, 31, 36, 37, 38, 48], "isnul": 32, "isol": [11, 36, 37, 39, 48], "issu": [4, 6, 7, 38, 43, 47, 51, 55, 59], "issubclass": 47, "isupp": 49, "itali": 44, "item": [28, 38, 39, 41, 43, 44, 45, 47, 51, 57], "item_inverse_mapp": 43, "item_kei": 43, "item_mapp": 43, "iter": [35, 40, 41, 42, 45], "iterable_with_config": 33, "iterrow": 43, "its": [8, 28, 30, 31, 33, 34, 36, 39, 41, 42, 44, 45, 46, 47, 49, 50, 53, 55, 58, 59], "itself": [7, 36, 38, 42], "j": [8, 34, 39, 40, 41, 43, 45], "j6": 49, "jackin": 35, "jackpot": 33, "jaguar": [28, 45], "jam": 35, "jame": [44, 47, 49], "jan": 1, "januari": 46, "japan": 44, "jargon": 29, "jason": [10, 40], "javascript": 39, "jellyfish": 45, "jennif": 49, "jerri": 43, "jet": 32, "jetti": 45, "jieba": 44, "jim": 43, "jmlr": 35, "job": [33, 46, 47, 58], "joblib": 33, "john": 38, "join": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59], "jointli": 46, "joke": [28, 43], "jolen": 49, "joseph": 59, "journal": 44, "journei": [10, 42, 59], "jpg": 45, "ju": 28, "jubatu": [28, 45], "judg": 40, "judgment": 48, "juic": 44, "juli": 46, "jun": 59, "june": [10, 46], "junh": 59, "jupyt": [1, 7, 8, 9, 11, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49], "jupyter_notebook": 47, "jupyterlab": 39, "jurafski": 44, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 51, 53, 57, 58, 59], "justic": [39, 59], "justif": 57, "k": [7, 10, 15, 30, 34, 36, 37, 38, 40, 44, 45, 47, 49, 50, 53, 59], "k_neighbor": 36, "k_valu": 31, "kaggl": [29, 32, 36, 37, 38, 39, 40, 45, 48, 56, 57], "kaggler": 40, "kangaroo": 45, "kaplan": 59, "kaplanmeierfitt": 47, "kb": [33, 37, 47], "kbinsdiscret": 40, "kbinsdiscretizer__latitude_0": 40, "kbinsdiscretizer__latitude_1": 40, "kbinsdiscretizer__latitude_2": 40, "kbinsdiscretizer__latitude_3": 40, "kbinsdiscretizer__latitude_4": 40, "kbinsdiscretizer__latitude_5": 40, "kbinsdiscretizer__latitude_6": 40, "kbinsdiscretizer__latitude_7": 40, "kbinsdiscretizer__latitude_8": 40, "kbinsdiscretizer__latitude_9": 40, "kbinsdiscretizer__longitude_11": 40, "kbinsdiscretizer__longitude_12": 40, "kbinsdiscretizer__longitude_13": 40, "kbinsdiscretizer__longitude_14": 40, "kbinsdiscretizer__longitude_15": 40, "kbinsdiscretizer__longitude_16": 40, "kbinsdiscretizer__longitude_17": 40, "kbinsdiscretizer__longitude_18": 40, "kbinsdiscretizer__longitude_19": 40, "kbinsdiscretizerkbinsdiscret": 40, "kc_house_data": [28, 29, 53], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 36, 38, 39, 40, 41, 43, 44, 47, 53, 54, 59], "keep_empty_featur": 43, "kei": [9, 29, 30, 31, 32, 35, 36, 37, 38, 43, 44, 47, 55, 57, 59], "kelbowvisu": 41, "kellei": 34, "kelli": 59, "kept": 30, "kera": 39, "kernel": [7, 10, 15, 32, 34, 35, 39, 40, 48, 53], "kernelapp": 49, "kernelbas": 49, "kernelexplain": 39, "keyword": [4, 35, 49], "kfold": 36, "kick": 44, "kilian": 39, "kill": 47, "kimia": 59, "kind": [0, 28, 29, 30, 32, 33, 34, 36, 37, 39, 41, 42, 43, 45, 46, 47, 50, 58], "king": [43, 44, 53], "kitchenabvgr": [37, 39, 48], "kitchenqu": [37, 39, 48], "kk": 41, "km": [47, 48, 51], "km_label": 41, "kmean": [41, 42, 51], "kmf": 47, "kmqfw": 47, "kneighborregressor": 32, "kneighborsclassifi": [32, 33, 34, 40, 53, 54], "kneighborsregressor": [32, 33, 34, 54], "kneighborsregressorkneighborsregressor": [32, 33], "knew": 41, "knn": [2, 15, 30, 31, 32, 33, 34, 39, 40, 43, 45, 50, 51, 57], "knn1": 31, "knn100": 31, "knn_pipe": 33, "knn_scale": 32, "knn_unscal": 32, "knn_valid_accuraci": 31, "knnimput": 43, "knob": [29, 48], "know": [8, 10, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59], "knowledg": [8, 29, 33, 35, 40, 41, 44, 48, 51], "knowleg": 51, "known": [43, 44, 47], "koala": 45, "kolhatkar": [0, 1, 44], "kr9rkqfj4w78h49djkz8yy9r0000gp": 30, "ksatr": 47, "kvarada": [11, 29, 30, 33, 35, 39, 45, 47, 50], "kvarada01": 11, "kwarg": [30, 32, 33, 47, 49], "l": 11, "l1": [10, 47], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 36, "l2": [10, 36, 44, 47], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "la": 48, "lab": [11, 29, 30, 41, 43], "lab1": [29, 30, 33, 51], "lab2": [29, 30, 33, 51], "lab3": [29, 30, 33, 51], "lab4": [29, 30, 33, 51], "label": [7, 8, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 54], "label_": [44, 49], "label_encod": [38, 39], "label_n_clust": 42, "labelencod": [38, 39], "labels": [36, 41], "labels_": [41, 42], "lack": [30, 43, 48], "lag": [47, 51], "lag_df": 46, "lakeshor": 45, "lakesid": 45, "lambda": [8, 29, 34, 42, 45, 46, 47, 49], "land": 47, "landcontour": [37, 39, 48], "landcontour_bnk": [37, 48], "landcontour_hl": [37, 48], "landcontour_low": [37, 48], "landcontour_lvl": [37, 48], "landmark": 51, "landown": 49, "landscap": [41, 44], "landslop": [37, 39, 48], "landslope_gtl": [37, 39, 48], "landslope_mod": [37, 39, 48], "landslope_sev": [37, 39, 48], "languag": [2, 9, 32, 33, 43, 45, 49], "language_enc": 32, "language_english": 32, "language_french": 32, "language_hindi": 32, "language_mandarin": 32, "language_spanish": 32, "language_vietnames": 32, "laptop": 28, "lar": 28, "larg": [28, 30, 31, 32, 34, 36, 37, 41, 42, 44, 45, 51, 53, 56], "larger": [29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 47], "largest": 37, "larvatu": [28, 45], "last": [8, 25, 29, 30, 31, 32, 33, 36, 39, 43, 45, 46, 47, 49, 53, 55, 57, 58, 59], "last_row": 8, "lastp": 42, "lat": [28, 29], "late": [36, 59], "latent": [43, 44, 45], "latentdirichletalloc": 44, "later": [11, 29, 33, 36, 45, 46, 53], "latest": [33, 39, 47], "latex": [4, 7], "latin": [28, 36, 56], "latitud": [30, 31, 32, 33, 34, 40, 54], "latitude_0": 40, "latitude_1": 40, "latitude_10": 40, "latitude_11": 40, "latitude_12": 40, "latitude_13": 40, "latitude_14": 40, "latitude_15": 40, "latitude_16": 40, "latitude_17": 40, "latitude_18": 40, "latitude_19": 40, "latitude_2": 40, "latitude_3": 40, "latitude_4": 40, "latitude_5": 40, "latitude_6": 40, "latitude_7": 40, "latitude_8": 40, "latitude_9": 40, "latter": 37, "launch_inst": 49, "launch_new_inst": 49, "lauvagrand": 49, "law": 44, "lawsuit": 44, "layer": 45, "layout": [31, 53], "lazi": 31, "lbfg": 36, "lda": 45, "ldot": 35, "lead": [8, 10, 30, 34, 37, 42, 43, 44, 47, 48], "leaf": [29, 42], "leak": [32, 47, 51], "leakag": 51, "leaner": 30, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "learner": [30, 31, 38], "learning_method": 44, "learning_r": 38, "learnxinyminut": 9, "least": [4, 10, 30, 31, 36, 37, 39, 40, 41, 42, 48, 57, 58, 59], "least_confident_i": 34, "least_confident_x": 34, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 42, 45, 47, 48, 50], "lec11": 19, "lec16": 25, "lec17": 25, "lectur": [5, 7, 8, 11, 19, 25, 51, 56], "lecun": 39, "lee": 39, "left": [7, 28, 35, 36, 37, 41, 42, 44, 46, 47, 48, 59], "legal": [0, 44], "legend": [7, 8, 31, 34, 36, 37, 40, 41, 45, 46, 47, 48, 50], "legendari": 49, "leisur": 36, "lemma": 44, "lemma_": 44, "lemmat": 44, "lemon": 41, "len": [30, 32, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 48, 49], "length": [29, 30, 31, 34, 37, 39, 41, 42, 44, 46, 47, 49, 53, 58], "leo": 38, "leopard": [28, 45], "leq": [40, 41], "less": [5, 6, 10, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 51, 53, 56], "lesson": [9, 32, 49], "lesssim": 30, "let": [28, 29, 30, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "letter": [34, 49], "lev": 37, "level": [31, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 48, 56, 59], "leverag": [39, 43], "lewi": 49, "lexic": 44, "lexicon": 49, "lg": [19, 23, 24, 25, 26, 27], "lgbm": [38, 39, 51, 59], "lgbmclassifi": [28, 38, 39, 57], "lgbmclassifierifittedlgbmclassifi": [28, 39], "lgbmclassifierlgbmclassifi": 38, "lgbmregressor": [28, 38], "li": 34, "liabil": 0, "liabl": 0, "liao": 28, "lib": [29, 30, 33, 35, 39, 47, 49, 50], "librari": [4, 8, 11, 30, 36, 39, 40, 44, 45, 46, 48, 49, 53], "licensor": 0, "life": [29, 34, 41, 43, 48, 52, 59], "lifelin": [47, 59], "lifetim": 47, "lighter": 35, "lightgbm": [28, 39, 57], "lightweight": 44, "like": [2, 4, 7, 8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 59], "likelihood": 47, "likewis": 7, "lime": 39, "limit": [0, 28, 29, 30, 33, 38, 39, 48, 49, 51, 52, 55, 59], "linalg": 44, "line": [4, 8, 11, 29, 33, 34, 35, 36, 37, 41, 44, 45, 46, 47, 48, 49, 53, 55], "line2d": 8, "linear": [10, 17, 21, 22, 23, 24, 25, 26, 27, 35, 36, 38, 40, 42, 43, 45, 46, 47, 48, 50, 51], "linear_model": [28, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 56, 57, 58], "linear_svc": 34, "linearli": [34, 40, 46], "linearregress": [34, 37, 40, 47, 49], "linestyl": [41, 46, 58], "linewidth": [46, 48], "linger": 31, "lingual": 44, "linguist": 33, "link": [0, 4, 5, 7, 10, 28, 29, 33, 34, 37, 38, 42, 47, 48], "linkag": 42, "linkage_arrai": 42, "linkage_typ": 42, "linkedin": 43, "linspac": [34, 35, 37, 40, 48, 55], "lion": 43, "list": [4, 7, 8, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 57, 59], "listedcolormap": 34, "liter": 49, "literatur": 38, "littl": [8, 36, 45, 48], "live": [10, 11, 31, 32, 33, 35, 41, 47, 48, 55], "liver": 29, "livestream": 59, "ll": [6, 7, 10, 11, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 53, 58, 59], "llazx": 47, "llm": 10, "lo": 49, "load": [8, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 48, 49, 53, 54, 56], "load_breast_canc": 40, "load_citibik": 46, "load_digit": 48, "load_iri": [31, 53], "loan": [36, 56], "loc": [8, 31, 34, 36, 39, 43, 46, 47, 48, 58], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 36, 38, 39, 40, 45, 49], "locat": [8, 33, 41, 43, 44, 46, 49, 57, 58, 59], "location_katherin": 46, "location_mountginini": 46, "location_townsvil": 46, "location_witchcliff": 46, "location_wollongong": 46, "lock": 30, "log": [31, 37, 38, 47, 48, 53, 57, 59], "log10": 37, "log1p": [37, 48], "log2": 47, "log_likelihood_ratio_test": 47, "log_loss": 48, "logarithm": [31, 53], "logic": 40, "logical_xor": 40, "login": 43, "logisit": 45, "logist": [17, 38, 39, 46, 47, 48, 49, 50, 51, 56, 57, 58], "logisticregress": [28, 34, 37, 38, 39, 40, 44, 45, 49, 50, 56, 57, 58], "logisticregressionifittedlogisticregress": 45, "logisticregressionlogisticregress": [36, 38, 45, 49], "logloss": 39, "lognorm": 35, "logspac": [35, 55], "loguniform": [35, 55], "lol": 33, "london": 49, "lone": 42, "long": [0, 28, 29, 34, 36, 38, 42, 43, 47, 51, 59], "longer": [7, 35, 36, 45, 47, 48], "longest": 29, "longitud": [30, 31, 32, 33, 34, 40, 54], "longitude_0": 40, "longitude_1": 40, "longitude_10": 40, "longitude_11": 40, "longitude_12": 40, "longitude_13": 40, "longitude_14": 40, "longitude_15": 40, "longitude_16": 40, "longitude_17": 40, "longitude_18": 40, "longitude_19": 40, "longitude_2": 40, "longitude_3": 40, "longitude_4": 40, "longitude_5": 40, "longitude_6": 40, "longitude_7": 40, "longitude_8": 40, "longitude_9": 40, "look": [1, 11, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57], "lookatm": 28, "loop": [35, 38, 46, 50, 51], "loos": 42, "lose": [6, 33], "loss": [2, 36, 37, 38, 39, 44, 47, 56], "lot": [5, 9, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 42, 45, 46, 47, 48, 55, 59], "lotarea": [37, 39, 48], "lotconfig": [37, 39, 48], "lotconfig_corn": 37, "lotconfig_culdsac": 37, "lotconfig_fr2": 37, "lotconfig_fr3": 37, "lotconfig_insid": 37, "lotfrontag": [37, 39, 48], "lotshap": [37, 39, 48], "lotshape_ir1": 37, "lotshape_ir2": 37, "lotshape_ir3": 37, "lotshape_reg": 37, "loud": [31, 32, 35, 51, 55], "loui": 46, "lourenzutti": 35, "love": 49, "low": [6, 30, 31, 35, 36, 37, 39, 40, 41, 42, 47, 48], "lower": [30, 31, 36, 37, 39, 41, 43, 44, 47, 48, 55, 59], "lowercas": [32, 33], "lowest": [53, 59], "lowqualfinsf": [37, 39, 48], "lr": [34, 36, 37, 39, 45, 46, 47, 49, 50], "lr_1": 40, "lr_2": 40, "lr_3": 40, "lr_coef": [39, 46, 47, 58], "lr_coefs_landslop": 39, "lr_flatten_pip": 45, "lr_item": 43, "lr_pipe": [37, 39, 46], "lr_pred": [36, 37], "lr_scale": 39, "lr_schedul": 45, "lr_x": 43, "lr_y": 43, "ls15hb": 28, "lstm": 46, "lt": [30, 32, 33, 35, 36, 37, 38, 39, 40, 47], "ltorgo": 34, "lucki": [31, 35], "luckili": [55, 57], "lundberg": 39, "luster": 42, "lvert": 44, "lvl": [37, 39, 48], "lwq": [37, 39, 48], "lynx": [28, 45], "l\u00e9cuyer": 44, "m": [11, 28, 30, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], "m_neighbor": 36, "ma": 35, "macaqu": [28, 45], "macbook": 11, "machin": [2, 9, 10, 11, 13, 14, 15, 32, 33, 35, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 53, 58, 59], "machine_learn": 48, "mackworth": 10, "made": [0, 6, 7, 8, 28, 29, 36, 38, 39, 43, 44, 45, 46, 48, 55], "magazin": 44, "magnitud": [35, 37, 39, 44, 46, 58], "maguir": 43, "mahsa": 59, "mai": [0, 7, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59], "mail": 47, "main": [8, 11, 29, 31, 33, 38, 41, 42, 51, 59], "mainland": 34, "maintain": [38, 43, 48, 51], "mainten": 38, "maj1": [37, 39, 48], "maj2": [37, 39, 48], "major": [2, 30, 31, 32, 33, 44, 51, 52, 57], "major_biologi": 33, "major_comput": 33, "major_econom": 33, "major_linguist": 33, "major_mathemat": 33, "major_mechan": 33, "major_phys": 33, "major_psychologi": 33, "make": [2, 4, 5, 6, 7, 11, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 56, 57, 58, 59], "make_blob": [31, 41, 42, 45, 50], "make_circl": 42, "make_classif": [31, 36], "make_column_transform": [35, 36, 37, 38, 39, 40, 46, 47, 48, 49, 54, 55, 56, 57, 58], "make_forg": 31, "make_grid": 45, "make_imb_pipelin": 36, "make_moon": 42, "make_num_tree_plot": 38, "make_pipelin": [28, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58], "make_scor": [37, 40, 49], "maker": 48, "malcolm": [41, 43], "malcom": 41, "male": [36, 38, 39, 47, 56], "male_cm": [36, 56], "male_pr": [36, 56], "mall": 49, "man": [43, 44], "manag": [5, 46, 47, 48, 51, 59], "mandarin": 32, "mango": 44, "mani": [2, 5, 8, 10, 28, 29, 30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 55, 57, 58, 59], "manipul": 48, "manner": [0, 38], "manual": [11, 28, 33, 36, 40, 41, 42, 44, 55], "manufactur": 45, "map": [10, 29, 30, 33, 35, 43, 55], "mape": 51, "mape_scor": 37, "mapper": 43, "march": 46, "marit": [36, 38, 39, 56], "mark": [6, 7, 35, 36, 42, 59], "marker": [31, 34, 41], "markers": [34, 36], "market": [28, 41, 45, 46, 48], "marri": [36, 38, 39], "martin": 44, "mask": 35, "massiv": [33, 35], "master": [8, 35, 36, 38, 39, 44, 56], "masvnrarea": [37, 39, 48], "masvnrtyp": [37, 39, 48], "masvnrtype_brkcmn": 37, "masvnrtype_brkfac": [37, 48], "masvnrtype_miss": [37, 48], "masvnrtype_ston": [37, 48], "match": [33, 34, 36, 38, 39, 46, 57, 58], "materi": [8, 11, 19, 28, 29, 30, 31, 41, 44, 47, 51, 59], "matern": 40, "math": [2, 41, 43, 47], "mathcal": 31, "mathemat": [2, 33, 38, 51], "mathematician": 44, "mathia": 49, "matlab": 8, "matplotlib": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "matplotlibdeprecationwarn": 39, "matric": [31, 36, 43, 56], "matrix": [18, 33, 42, 44, 51, 56], "matter": [32, 33, 36, 38, 42, 48, 51], "max": [8, 30, 32, 34, 35, 36, 37, 38, 41, 42, 46, 58], "max_bin": 38, "max_cat_threshold": 38, "max_cat_to_onehot": 38, "max_clust": 42, "max_colwidth": [28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 52, 53, 54, 55, 56], "max_delta_step": 38, "max_depth": [30, 31, 35, 38, 39, 48, 52, 53], "max_depth_widget": [31, 53], "max_df": 33, "max_displai": 39, "max_featur": [28, 33, 35, 38, 48, 55], "max_it": [28, 36, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 56], "max_leaf_nod": [29, 48], "max_leav": 38, "max_opt": [31, 36, 41, 42], "max_row": 47, "max_sampl": 48, "maxclust": 42, "maxent": 50, "maxhr": 57, "maxim": [28, 36, 37, 41], "maximum": [29, 32, 37, 38, 41, 42, 53, 59], "maxosx": 11, "maxtemp": [46, 58], "may": 10, "mayb": [36, 39, 46, 48, 59], "maybe_coerce_valu": 47, "mb": [32, 33, 36, 40, 46, 47, 58], "md": [11, 29, 44], "me": [8, 28, 35, 48, 49], "mean": [5, 6, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 45, 46, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59], "mean_absolute_percentage_error": 37, "mean_cv_error": 30, "mean_cv_scor": [31, 34, 35], "mean_fit_tim": [35, 37], "mean_scor": [30, 32, 35, 49], "mean_score_tim": [35, 37], "mean_squared_error": [37, 40, 49], "mean_std_cross_val_scor": [30, 32, 33, 38, 39, 47, 49], "mean_test_neg_mean_squared_error": 37, "mean_test_scor": [35, 37, 55], "mean_train_error": 30, "mean_train_neg_mean_squared_error": 37, "mean_train_scor": [31, 34, 35, 37], "meaning": [31, 33, 36, 39, 41, 44, 54, 59], "meaningless": 42, "measur": [0, 28, 29, 30, 31, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 51, 53, 57, 58], "mechan": [33, 51], "medal": 8, "media": 48, "median": [29, 32, 33, 34, 37, 39, 40, 46, 47, 48, 58], "median_house_valu": [32, 33, 40, 54], "median_incom": [32, 33, 40, 54], "mediat": 48, "medic": [36, 41, 59], "medinc": 34, "medit": 36, "medium": [0, 31, 47, 51], "meet": 44, "meier": 59, "melbourneairport": [46, 58], "member": [34, 38, 59], "membership": [33, 41, 42], "memori": [8, 32, 33, 36, 37, 38, 40, 45, 46, 47, 51, 58], "mental": 48, "mention": [0, 4, 34, 47, 48], "menu": 11, "merchant": 0, "merg": [0, 5, 11, 42], "meshgrid": 40, "mess": [43, 47], "messag": [4, 6, 11, 30, 33], "messi": [40, 44], "met": 59, "meta": 38, "metacademi": 10, "method": [2, 29, 31, 32, 34, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 51, 57, 58, 59], "methodologi": [32, 46], "metric": [10, 31, 33, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 56, 57, 59], "mexico": 36, "mglearn": [29, 30, 31, 32, 33, 34, 35, 36, 41, 44, 45, 46, 50, 52, 53, 55, 56], "mi": [28, 35, 36, 48], "microsoft": 49, "midnight": 46, "midterm": [6, 10], "might": [6, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 51, 53, 59], "mike": [0, 1, 9, 29, 55], "mikolov": 44, "milk": 44, "mill": 38, "millennia": 59, "million": 45, "min": [10, 34, 37, 42, 46, 58], "min1": [37, 39, 48], "min2": [37, 39, 48], "min_child_weight": 38, "min_df": 33, "min_impurity_decreas": 48, "min_impurity_split": 48, "min_sampl": 42, "min_samples_leaf": [29, 48], "min_samples_split": [29, 48], "min_token_len": 44, "min_token_length": 44, "min_weight_fraction_leaf": 48, "mind": [30, 32, 33, 38, 39, 43, 47, 48, 51, 59], "mine": 10, "minibatchkmean": 42, "miniconda": 11, "miniconda3": [11, 49], "miniforge3": [29, 30, 33, 35, 39, 47, 50], "minim": [5, 29, 37, 41, 42, 48], "minimum": [8, 30, 32, 42, 44], "minmaxscal": [32, 33, 48], "minor": [6, 47], "mintemp": [46, 58], "minut": [4, 29, 40, 47, 51], "miracl": 49, "miscalcul": 10, "miscfeatur": [37, 39, 48], "miscfeature_gar2": 37, "miscfeature_miss": 37, "miscfeature_othr": 37, "miscfeature_sh": 37, "miscfeature_tenc": 37, "misclassifi": 56, "misconduct": 59, "miscval": [37, 39, 48], "mislead": [30, 36], "miss": [11, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 47, 48, 51, 53, 55, 56, 58, 59], "mistak": [32, 38, 47, 48, 53], "mit": [0, 1], "mitig": [43, 59], "mitlp": 47, "mitt": 44, "mitten": 44, "mix": [37, 48], "mixtur": [42, 44, 45], "ml": [2, 9, 10, 14, 15, 29, 32, 38, 42, 44, 45, 59], "ml_experi": [29, 30, 33, 51], "mlpclassifi": 45, "mlpregressor": 45, "mm": [46, 58], "mmsto": 28, "mn": [37, 39, 48], "mnprv": [37, 39, 48], "mnww": [37, 39, 48], "mobil": [33, 45], "mobilenet": 45, "mod": [37, 39, 48], "mode": [31, 32, 35, 55], "model": [2, 10, 19, 20, 21, 22, 23, 24, 25, 26, 27, 35, 36, 41, 42, 43, 46, 48, 50, 52, 55, 58, 59], "model_nam": 43, "model_select": [28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58], "modern": [10, 31, 44, 48], "modif": 47, "modifi": [0, 11, 36, 47, 59], "modul": [9, 10, 29, 30, 36, 49], "moe": 35, "mole": 45, "mom": 40, "moment": [36, 55, 57, 59], "mon": [10, 46], "mondai": [10, 46, 59], "monei": [8, 47], "monitor": 44, "monkei": [28, 45], "monotone_constraint": 38, "montani": 49, "month": [30, 33, 37, 47, 58], "month_nam": [46, 58], "monthli": 47, "monthlycharg": 47, "montreal": [44, 49], "moon": 42, "moosvi": [0, 1, 44, 59], "moral": [0, 41], "more": [1, 2, 5, 6, 8, 10, 11, 14, 30, 35, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 59], "morn": 28, "morpholog": 44, "moskowitz": 41, "mosold": [37, 39, 48], "mosold_1": 37, "mosold_10": 37, "mosold_11": 37, "mosold_12": 37, "mosold_2": 37, "mosold_3": 37, "mosold_4": 37, "mosold_5": 37, "mosold_6": 37, "mosold_7": 37, "mosold_8": 37, "mosold_9": 37, "most": [7, 8, 11, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 57, 59], "most_confident_i": 34, "most_confident_x": 34, "most_frequ": [29, 31, 32, 36, 37, 39, 48, 52], "most_similar": 44, "mostli": [8, 33, 46], "motiv": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33], "mountginini": 46, "move": [7, 12, 34, 39, 40, 52, 57, 59], "movi": [34, 44, 49], "movie_feats_df": 43, "movie_id": 43, "movie_nam": 43, "movies_rated_by_pat": 43, "movies_to_pr": 43, "movieto": 49, "mpimg": 45, "mri": 51, "mrtssm448usn": 46, "mse": [29, 43, 51], "msg": [33, 47], "mssubclass": [37, 39, 48], "mssubclass_120": 37, "mssubclass_160": 37, "mssubclass_180": 37, "mssubclass_190": 37, "mssubclass_20": 37, "mssubclass_30": 37, "mssubclass_40": 37, "mssubclass_45": 37, "mssubclass_50": 37, "mssubclass_60": 37, "mssubclass_70": 37, "mssubclass_75": 37, "mssubclass_80": 37, "mssubclass_85": 37, "mssubclass_90": 37, "mszone": [37, 39, 48], "mszoning_c": [37, 39], "mszoning_fv": 37, "mszoning_rh": 37, "mszoning_rl": 37, "mszoning_rm": 37, "much": [4, 5, 8, 29, 30, 31, 32, 33, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 55, 59], "mueller": 10, "multi": [37, 39, 41, 44, 46], "multi_class": [36, 50], "multi_strategi": 38, "multiclass": [45, 50], "multicoliniar": 39, "multicultur": 44, "multilevel": 37, "multimod": 41, "multinomi": 50, "multipl": [7, 8, 30, 34, 35, 38, 39, 44, 45, 46, 47, 58], "multiplelin": 47, "multiplelines_no": 47, "multiplelines_y": 47, "multipli": [34, 35, 36, 38, 40, 47], "music": [43, 49], "musqueam": 59, "must": [0, 6, 7, 8, 29, 30, 32, 39, 42, 44, 47, 49, 59], "mutual": 42, "mwf": 59, "my": [6, 11, 28, 35, 36, 41, 44, 48, 49, 59], "my_heatmap": [35, 55], "my_map": 37, "mypreprocessor": 44, "myself": [29, 48], "m\u00fcller": 9, "n": [10, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 53, 58], "n_bin": 40, "n_class": [31, 36, 56], "n_cluster": [41, 42], "n_clusters_per_class": 36, "n_compon": 44, "n_constitu": 38, "n_estim": [40, 46, 47, 48], "n_estimators_valu": 48, "n_exampl": 41, "n_feat": 31, "n_featur": [31, 36, 41, 55], "n_features_to_select": 40, "n_inform": 36, "n_init": 41, "n_iter": 55, "n_job": [33, 36, 37, 38, 48, 55], "n_neighbor": [43, 53], "n_neighbors_selector": 31, "n_neighbors_widget": [31, 53], "n_redund": 36, "n_rental": 46, "n_rentalsin3hour": 46, "n_rentalsin6hour": 46, "n_repeat": 39, "n_resourc": 35, "n_sampl": [31, 36, 41, 42, 45, 50, 56], "n_split": 46, "n_threshold": 36, "n_topic": 44, "n_train": 46, "n_word": [44, 49], "na": [37, 39, 48], "nafter": 44, "nah": 33, "naiv": 42, "name": [4, 5, 6, 7, 8, 11, 29, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 53, 57, 58, 59], "named_estimators_": 38, "named_step": [34, 36, 37, 38, 39, 40, 46, 48, 49, 58], "named_transformers_": [33, 36, 37, 38, 39, 40, 46, 47, 48, 49, 56, 58], "nan": [32, 33, 36, 37, 38, 39, 40, 43, 46, 47, 48, 49, 51, 56, 58], "nanmean": 43, "nanosecond": 46, "narr": 44, "narrow": [43, 48], "nasali": [28, 45], "nation": 59, "nativ": [36, 38, 39, 45, 50, 56], "natur": [2, 28, 33, 36, 38, 40, 45, 50, 59], "navig": [7, 11], "nbsp": [28, 32, 33, 35, 37, 38, 39, 40, 45], "nbviewer": [28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49], "nc": 1, "ncol": 34, "ndarrai": [8, 33], "ndate": 49, "ndframe": [40, 47], "ndim": 8, "ne": [46, 58], "nearbi": [31, 41], "nearest": [15, 36, 42, 53], "necessari": [0, 7, 29, 35, 51, 54], "necessarili": [30, 37, 38, 43], "necvq": 47, "need": [5, 7, 8, 11, 28, 29, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59], "neg": [29, 30, 31, 34, 37, 38, 39, 44, 46, 47, 49, 53, 56], "neg_mean_absolute_percentage_error": 37, "neg_mean_squared_error": [37, 48], "neg_root_mean_square_error": 37, "neg_root_mean_squared_error": 37, "neigh": 31, "neighbor": [31, 32, 33, 34, 36, 40, 42, 53, 54], "neighborhood": [34, 37, 39, 48], "neighborhood_blmngtn": 37, "neighborhood_bluest": 37, "neighborhood_brdal": 37, "neighborhood_brksid": 37, "neighborhood_clearcr": 37, "neighborhood_collgcr": 37, "neighborhood_crawfor": 37, "neighborhood_edward": 37, "neighborhood_gilbert": 37, "neighborhood_idotrr": 37, "neighborhood_meadowv": 37, "neighborhood_mitchel": 37, "neighborhood_nam": 37, "neighborhood_noridg": [37, 39], "neighborhood_npkvil": 37, "neighborhood_nridght": [37, 39], "neighborhood_nwam": 37, "neighborhood_oldtown": [37, 39], "neighborhood_sawy": [37, 39], "neighborhood_sawyerw": [37, 39], "neighborhood_somerst": [37, 39], "neighborhood_stonebr": [37, 39], "neighborhood_swisu": [37, 39], "neighborhood_timb": [37, 39], "neighborhood_veenk": [37, 39], "neighbour": [15, 30, 39, 41, 42, 44, 53], "neighbourhood": [34, 40, 42, 54], "neither": [30, 33, 43], "neq": [39, 43], "ner": 44, "nervou": 29, "nest": [35, 51], "net": [45, 47], "netflix": [43, 49], "network": [10, 28, 33, 38, 40, 41, 43, 46, 59], "neu": 49, "neural": [10, 40, 46, 59], "neutral": 49, "never": [36, 38, 39, 43, 45, 47], "new": [10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 54, 55, 57, 58], "new_cent": 41, "new_column": [37, 39, 46, 47, 48, 58], "new_data": 47, "new_df": [46, 58], "new_exampl": [29, 41], "new_feature_nam": [46, 58], "new_text": 48, "new_valu": 47, "newaxi": 8, "newcastl": 49, "newer": 37, "newli": [32, 37, 40, 42], "newsgroup": 44, "newswir": 44, "next": [11, 29, 30, 31, 32, 33, 36, 37, 38, 44, 45, 46, 48, 54, 55, 56, 57, 59], "nfeat": 31, "nfeats_accuraci": 31, "ng": [9, 10, 35, 40], "ngram": 40, "ngram_rang": 33, "nhqxu": 47, "nice": [4, 35, 36, 38, 39, 42, 45, 47, 48], "nicki": 35, "night": [36, 46], "nightmar": 48, "niki": 59, "nlemma": 44, "nlp": [33, 45, 49], "nltk": [44, 49], "nltk_data": 49, "nmax": 48, "nn": [10, 32, 45, 49, 53], "nne": [46, 58], "nnw": [46, 58], "nnz": 33, "no_grad": 45, "nobodi": 28, "node": [29, 38, 42, 45, 52], "nois": [42, 51, 53], "non": [1, 8, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 40, 42, 43, 45, 46, 47, 51, 56, 58, 59], "noncommerci": 1, "none": [10, 26, 27, 30, 32, 33, 34, 35, 36, 38, 40, 42, 46, 47, 48, 49, 57], "noninfring": 0, "nonzero": 33, "noqa": [35, 49], "nor": [7, 30, 33], "norg": [44, 49], "norm": [35, 44], "normal": [6, 36, 37, 38, 39, 41, 42, 44, 45, 46, 48, 49, 56, 57], "norvig": 10, "notat": 31, "note": [0, 3, 7, 9, 10, 11, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 50, 51, 55, 56, 58, 59], "notebook": [5, 7, 9, 11, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49, 54, 58], "notic": [0, 33, 34, 36, 37, 40], "notion": [31, 35, 41, 43], "notna": [46, 58], "noun": [44, 49], "nov": 46, "novel": 51, "novemb": 46, "novic": 9, "now": [8, 11, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 52, 53, 54, 55, 56, 57], "np": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "nperson": 49, "npie": 8, "npo": 44, "npr": [40, 44, 49, 51], "ntest": [31, 35, 53], "ntoken": 44, "ntree": 38, "null": [32, 33, 36, 37, 40, 46, 47, 58], "null_distribut": 47, "num": [36, 38, 39, 56], "num_output_channel": 45, "num_parallel_tre": 38, "num_sent": 36, "num_work": 45, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 51, 53, 55, 58, 59], "number_test": 35, "numer": [2, 29, 32, 33, 34, 36, 37, 38, 43, 44, 46, 47, 48, 53, 54, 56, 58], "numeric_feat": [33, 35, 40, 51, 55], "numeric_featur": [33, 36, 37, 38, 39, 46, 47, 48, 49, 56, 57, 58], "numeric_looking_column": 37, "numeric_transform": [33, 36, 37, 38, 39, 46, 48, 56, 57, 58], "numpi": [9, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "numpy_dtyp": 47, "nutrit": 44, "nw": [46, 58], "nwith": 31, "ny": 49, "nyt": 48, "o": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "obelisk": 45, "object": [30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 49, 51, 52, 53, 55, 56, 58], "observ": [28, 29, 30, 31, 38, 39, 41, 42, 46, 47, 53, 56, 57, 58], "obtain": [0, 34, 41, 42, 43, 47, 53, 55], "obviou": [42, 44], "occasion": 36, "occup": [36, 38, 39, 56], "occupation_farm": 39, "occupation_miss": 39, "occupation_priv": 39, "occupi": 59, "occur": [8, 29, 30, 33, 44, 47], "occurr": [44, 47], "ocean": [32, 33, 40, 54], "ocean_proxim": [32, 33, 40, 54], "ocean_proximity_": [32, 33], "ocean_proximity_inland": [32, 33], "ocean_proximity_island": [32, 33], "ocean_proximity_near": [32, 33], "oct": 34, "octob": 46, "oe": [33, 51], "oe_encod": 51, "off": [25, 34, 35, 36, 37, 40, 41, 44, 45, 47, 48, 51, 55, 59], "off_shelf": 57, "offens": 4, "offer": [8, 38, 43, 44, 47, 59], "offic": [4, 11, 51, 59], "offici": [44, 59], "offlin": 43, "offset": 34, "often": [8, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53], "ogunrind": 28, "oh": [39, 40, 45, 46, 47, 51, 55, 58], "ohe_column": [37, 39, 48], "ohe_enc": 33, "ohe_encod": 51, "ohe_feature_nam": [39, 46, 58], "ohehotencod": 33, "ois": 42, "ok": [28, 31, 37, 46, 47, 51, 58], "okai": 41, "ola": 44, "old": [9, 38, 39], "old_cent": 41, "older": 37, "oldpeak": 57, "olymp": 8, "omit": 39, "omw": 44, "onc": [6, 7, 8, 11, 29, 30, 32, 33, 35, 40, 42, 43, 44, 45, 55, 56, 57, 59], "onca": [28, 45], "one": [6, 8, 9, 11, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59], "one_c": 31, "one_ex_preprocess": 39, "one_ex_preprocessed_perturb": 39, "one_exampl": 39, "one_example_perturb": 39, "onehot": [33, 40], "onehotencod": [32, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "onehotencoder__major_biologi": 33, "onehotencoder__major_comput": 33, "onehotencoder__major_econom": 33, "onehotencoder__major_linguist": 33, "onehotencoder__major_mathemat": 33, "onehotencoder__major_mechan": 33, "onehotencoder__major_phys": 33, "onehotencoder__major_psychologi": 33, "onehotencoderonehotencod": [33, 35, 37, 38, 48], "ones": [8, 28, 31, 32, 38, 39, 41, 43, 44, 53, 57], "onevsoneclassifi": 50, "onevsrestclassifi": 50, "onli": [2, 4, 8, 11, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 53, 54, 56, 59], "onlin": [3, 5, 7, 11, 29, 44, 59], "onlinebackup": 47, "onlinebackup_no": 47, "onlinebackup_y": 47, "onlinesecur": 47, "onlinesecurity_no": 47, "onlinesecurity_y": 47, "ontonot": 44, "oob_scor": 48, "op": 36, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 45, 59], "openporchsf": [37, 39, 48], "oper": [4, 8, 11, 33, 40, 44], "operand": 8, "opinion": 38, "opportun": 43, "oppos": [37, 38], "opposit": [8, 37, 38, 39, 58], "opt": [11, 38], "optic": 47, "optim": [2, 10, 29, 30, 31, 33, 36, 38, 39, 40, 41, 42, 45, 47, 48, 55], "optimist": 35, "option": [7, 8, 10, 29, 37, 41, 44, 48, 55, 57, 58], "oracl": 10, "orang": 34, "order": [5, 7, 8, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 48, 51], "ordering_ordinal_oth": [37, 39, 48], "ordering_ordinal_reg": [37, 39, 48], "ordin": [37, 51, 54], "ordinal_feat": 33, "ordinal_featur": [36, 38, 39, 56], "ordinal_features_oth": [37, 39, 48], "ordinal_features_reg": [37, 39, 48], "ordinal_transform": [36, 38, 39, 56], "ordinal_transformer_oth": [37, 39, 48], "ordinal_transformer_reg": [37, 39, 48], "ordinalencod": [32, 33, 36, 37, 38, 39, 40, 46, 47, 48, 49, 51, 54, 56, 57, 58], "ordinalencoderordinalencod": [33, 37, 38, 48], "ordinari": 37, "oreilli": [45, 46], "org": [9, 28, 30, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 48, 49], "organ": [28, 29, 32, 44, 48], "orgin": 8, "orig_featur": [46, 58], "orig_pr": 39, "orig_scor": 36, "origin": [32, 33, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 53, 55, 58, 59], "original_hm": 36, "originaltweet": 49, "ornithorhynchu": 45, "oscar": 34, "ostblom": 44, "other": [0, 1, 4, 5, 6, 7, 11, 29, 30, 32, 33, 34, 35, 36, 38, 39, 42, 43, 45, 49, 50, 51, 53, 55, 56, 57, 58, 59], "otherwis": [0, 7, 33], "ounc": [28, 45], "our": [5, 6, 8, 11, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 55, 56, 57, 58, 59], "ourselv": [29, 36, 45, 46], "out": [0, 4, 7, 8, 11, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 49, 51, 53, 55, 57, 58, 59], "out_col": [30, 32, 49], "out_step": 36, "outcom": 12, "outer": 49, "outlier": [37, 42, 51], "outlook": 47, "output": [7, 8, 11, 28, 29, 30, 33, 34, 36, 38, 39, 44, 45, 46, 48, 51, 57, 58, 59], "outsid": [7, 36, 38, 39, 43, 44, 46, 47], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 35, 37, 45, 46, 47, 48, 51, 59], "over_confident_i": 34, "over_confident_x": 34, "over_sampl": 36, "overal": [11, 36, 39, 41, 44, 45, 48, 51, 56, 57, 59], "overallcond": [37, 39, 48], "overallqu": [37, 39, 48], "overconfid": [39, 40], "overfit": [10, 31, 34, 37, 38, 40, 45, 53, 55, 57, 59], "overflow": 7, "overhead": 33, "overlap": [2, 30, 41], "overli": [31, 35, 53], "overload": [43, 47], "overpredict": 37, "oversample_pip": 36, "overshadow": 44, "overst": 48, "overus": 38, "overview": [41, 42, 43, 44], "overwhelm": 41, "overzeal": 6, "own": [4, 5, 8, 30, 32, 36, 37, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 58], "p": [34, 35, 42, 44, 47], "p_i": 41, "p_value_threshold": 47, "pace": [34, 41, 44, 59], "packag": [5, 8, 29, 30, 33, 35, 36, 39, 41, 42, 43, 44, 45, 47, 49, 50, 59], "pad": 45, "page": [1, 4, 10, 28, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 48, 49, 57, 59], "pai": 39, "pain": [4, 45, 46, 48, 58], "pair": [42, 44, 50], "pairwis": [31, 42], "panda": [9, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "pane": [31, 53], "panel": [31, 36, 39, 41, 42, 53], "panic": 49, "panther": [28, 45], "panthera": [28, 45], "paper": [7, 39, 40, 44, 45, 47, 49], "paperlessbil": 47, "paperlessbilling_no": 47, "paperlessbilling_y": 47, "paradigm": [28, 29, 41], "paradox": 43, "paragraph": 44, "parallel": [33, 35, 38], "param": [31, 33, 35, 37, 53], "param_columntransformer__countvectorizer__max_featur": 35, "param_dist": [35, 55], "param_distribut": [35, 55], "param_grid": [30, 31, 35, 37, 48, 55], "param_grid1": [35, 55], "param_grid2": [35, 55], "param_grid3": 35, "param_grid4": 35, "param_ridge__alpha": 37, "param_svc__c": 35, "param_svc__gamma": 35, "paramet": [31, 32, 33, 37, 38, 39, 41, 42, 44, 46, 47, 48, 49, 52, 53, 55, 56, 57, 58], "parametr": 42, "params_": 47, "params_str": 35, "paramter": 31, "pardu": [28, 45], "parent": [42, 49], "park": [40, 45, 49], "pars": 44, "parse_d": [8, 46, 58], "parser": 44, "part": [4, 9, 10, 11, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 46, 48, 49, 57, 59], "part1": 43, "part2": 43, "parti": 44, "partial": [4, 47, 48], "particip": 59, "particular": [0, 9, 11, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 53, 56], "particularli": [38, 43, 59], "partit": [33, 41, 42], "partner": [47, 59], "partner_no": 47, "partner_y": 47, "parton": 49, "pass": [8, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 45, 53], "passthrough": [33, 35, 47, 49, 55, 57], "passthrough__ml_experi": 33, "passthrough_feat": [33, 35, 51, 55], "passthrough_featur": [47, 49, 57], "passthroughpassthrough": [33, 35, 49], "past": [29, 30, 38, 46, 47, 48, 51], "pat": 43, "pat_i": 43, "pat_model": 43, "pat_x": 43, "pata": [28, 45], "path": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "patial": 42, "patient": [29, 57], "patio": 45, "patric": 39, "patrick": 59, "pattern": [28, 29, 30, 33, 35, 40, 41, 46, 48, 53, 58], "pave": [37, 39, 48], "paveddr": [37, 39, 48], "paveddrive_i": 37, "paveddrive_n": 37, "paveddrive_p": 37, "paymentmethod": 47, "paymentmethod_bank": 47, "paymentmethod_credit": 47, "paymentmethod_electron": 47, "paymentmethod_mail": 47, "pca": [36, 42, 43], "pcarter": 9, "pd": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "pdf": [7, 9, 19, 25], "peac": 44, "pedest": 45, "pedro": [10, 30, 40], "peek": 58, "peer": [51, 59], "pembrok": [28, 45], "penal": [6, 47], "penalti": [36, 59], "peopl": [4, 29, 30, 32, 34, 36, 38, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 59], "per": [8, 34, 36, 37, 38, 39, 43, 45, 46, 48, 50, 51, 55, 56, 58], "perceiv": 6, "percent": 37, "percent_error": 37, "percentag": [29, 36, 43, 48], "perfect": [6, 29, 30, 36, 37, 39, 43, 47, 49], "perfectli": [2, 43, 44], "perform": [29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59], "performac": 30, "perhap": [37, 46, 50], "perimet": 40, "period": [44, 46, 47, 49, 59], "perm_sorted_idx": 39, "perman": 8, "permiss": [0, 59], "permit": [0, 32, 36, 59], "permut": 39, "persist": 43, "person": [0, 4, 6, 10, 28, 36, 41, 44, 45, 46, 47, 49, 59], "perspect": [38, 43], "pertain": 5, "perthairport": [46, 58], "perturb": [39, 42], "perturbed_pr": 39, "peter": 10, "ph": 44, "phascolarcto": 45, "phase": 30, "phd": 44, "phdei": 47, "phenomenon": [43, 47, 53], "philippin": 49, "philosoph": 44, "phone": [28, 47, 59], "phoneservic": 47, "phoneservice_no": 47, "phoneservice_y": 47, "photo": [49, 51], "photograph": 59, "phrase": 44, "physic": [33, 46], "pi": 8, "pick": [29, 34, 36, 38, 39, 40, 41, 42, 45, 48, 50, 52, 53, 55, 56, 57], "pictur": [38, 39, 42, 44, 46, 48], "pie": 8, "piec": [34, 47], "pil": [28, 45], "pin": 45, "pineappl": 44, "pip": [11, 39, 44, 45, 49], "pipe": [32, 33, 34, 35, 36, 38, 44, 45, 49, 55, 56], "pipe_bestalpha": 37, "pipe_bigalpha": 37, "pipe_catboost": 38, "pipe_dt": [38, 39, 57], "pipe_forward": 40, "pipe_knn": 57, "pipe_lgbm": [38, 39, 57], "pipe_lr": [36, 38, 39, 56, 57], "pipe_lr_all_feat": 40, "pipe_lr_balanc": [36, 56], "pipe_lr_model_bas": 40, "pipe_lr_weight": [36, 56], "pipe_rf": [38, 39, 57], "pipe_rf_demo": 38, "pipe_ridg": [34, 37], "pipe_sklearn_gb": 38, "pipe_sklearn_histgb": 38, "pipe_smallalpha": 37, "pipe_svc": 36, "pipe_svm": [35, 55], "pipe_xgb": [38, 39], "pipe_xor": 40, "pipelin": [2, 10, 16, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59], "pipeline__lab1": 33, "pipeline__lab2": 33, "pipeline__lab3": 33, "pipeline__lab4": 33, "pipeline__quiz1": 33, "pipeline__rooms_per_household": 40, "pipeline__university_year": 33, "pipelineifittedpipelin": [32, 33, 35, 36, 40, 45, 49], "pipelineinot": [33, 35, 37], "pipelinepipelin": 35, "pitch": 48, "pitfal": [46, 48], "pixel": 39, "pizza": 44, "pkg": 11, "place": [5, 44, 46, 59], "plagiar": 59, "plai": [29, 31, 35, 39, 42, 52, 53], "plain": 41, "plan": [11, 28, 37, 40, 47, 49, 54, 57, 59], "plane": 34, "plant": 51, "plastic": 44, "platform": [4, 49], "platypu": 45, "player": [39, 45], "pleas": [1, 4, 7, 11, 28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49, 55, 59], "plinth": 45, "plot": [7, 29, 30, 31, 32, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 48, 53, 55, 56, 58], "plot_2d_scor": 34, "plot_2d_separ": [31, 34, 53], "plot_confusion_matrix": 36, "plot_confusion_matrix_exampl": 36, "plot_cross_valid": [30, 46], "plot_dbscan": 42, "plot_dbscan_with_label": 42, "plot_dendrogram_clust": 42, "plot_elbow": 41, "plot_example_dist": 41, "plot_fruit_tre": 29, "plot_grid_search_overview": 35, "plot_k_means_dbscan_comparison": 42, "plot_km_initi": 41, "plot_km_it": 41, "plot_km_iter": 41, "plot_kmean": 42, "plot_knn_clf": 31, "plot_knn_decision_boundari": 31, "plot_knn_regress": 31, "plot_lda_w_vector": 44, "plot_linkage_criteria": 42, "plot_logistic_regress": 34, "plot_logistic_regression_graph": 45, "plot_loss_diagram": 48, "plot_multiclass_lr_ovr": 50, "plot_original_clust": 42, "plot_partial_effects_on_outcom": 47, "plot_result": [31, 53], "plot_scal": 32, "plot_silhouette_dist": 41, "plot_single_hidden_layer_graph": 45, "plot_support_vector": 31, "plot_survival_funct": 47, "plot_svc_c": 31, "plot_svc_gamma": 31, "plot_time_spacing_distribut": [46, 58], "plot_train_test_point": 31, "plot_tree_decision_boundari": 30, "plot_tree_decision_boundary_and_tre": [29, 30, 52], "plot_two_hidden_layer_graph": 45, "plot_typ": 39, "plot_x_dendrogram": 42, "plotli": [40, 44], "plotting_funct": [29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 48, 50, 52, 53, 54, 55, 56, 57], "plotting_functions_unsup": [41, 42, 43, 44], "plt": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "plu": [34, 45], "plural": 33, "pm": [1, 10, 46, 58, 59], "pmltt": 10, "pn": [31, 36, 41, 42, 53], "po": [30, 32, 34, 37, 39, 44, 48, 49], "pobox": 28, "point": [4, 10, 28, 29, 30, 32, 33, 34, 35, 37, 40, 42, 47, 48, 50, 51, 53, 56, 59], "point_ind": 41, "point_index": 41, "pointless": 55, "polarity_scor": 49, "pole": 45, "polici": [3, 4, 7, 59], "polit": [43, 44, 45], "poly_transform": 46, "polynomialfeatur": [40, 46], "pomegran": 45, "pool": 10, "poolarea": [37, 39, 48], "poolqc": [37, 39, 48], "poor": [33, 37, 40, 51, 54], "poorli": [31, 37, 42, 46], "pope": 44, "popul": [32, 33, 34, 40, 46, 54], "popular": [8, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 49, 59], "population_per_household": [32, 33, 54], "porter": 44, "porterstemm": 44, "portion": [0, 30, 32, 35, 37, 39, 48, 57, 58, 59], "portug": [36, 39], "pos_": [44, 49], "pos_label": 37, "posit": [29, 30, 31, 32, 34, 37, 38, 39, 44, 46, 47, 49, 56], "posix": 47, "possess": 48, "possibl": [4, 5, 6, 8, 28, 29, 30, 32, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 51, 53, 54, 55, 56, 59], "possibli": [7, 44], "post": [4, 6, 8, 10, 44, 46, 59], "postprocess": 45, "potenti": [31, 32, 41, 44, 48, 59], "potteri": 44, "powder": 44, "power": [8, 30, 38, 43, 44, 45, 48], "pplicat": 42, "pr": 51, "practic": [0, 6, 9, 10, 30, 32, 40, 45, 48, 51, 54, 55, 59], "practition": 48, "prairielearn": [10, 59], "pre": [10, 11, 19, 23, 24, 25, 26, 27, 28, 38, 40, 44, 48, 49, 51], "precis": [18, 37, 48, 51, 56, 59], "precision_lr": 36, "precision_recall_curv": 36, "precision_scor": 36, "precision_svc": 36, "precisionrecallcurvedisplai": 36, "precisionrecalldisplai": 36, "pred": [36, 37, 43, 46, 47], "pred_df": [28, 43], "pred_dict": 28, "pred_g": 43, "pred_lin_reg": 43, "pred_train": 37, "pred_x": 43, "prediciton": 47, "predict": [2, 17, 30, 31, 32, 35, 36, 37, 40, 41, 42, 44, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59], "predict_expect": 47, "predict_for_usr": 43, "predict_proba": [36, 38, 39, 45, 50, 57], "predict_survival_funct": 47, "predicted_categori": 36, "predicted_n_rent": 46, "predicted_quiz2": 29, "predicted_sal": 46, "predicted_target": 28, "predictor": [29, 51], "prefer": [28, 38, 41, 43, 55], "prefix": 8, "preliminari": [32, 40], "prepar": [32, 40, 45], "prepend": 11, "preprocess": [10, 16, 18, 30, 31, 34, 35, 36, 38, 39, 40, 42, 43, 45, 47, 49, 53, 54, 55, 57, 59], "preprocess_featur": [46, 58], "preprocessing_fin": 47, "preprocessing_notenur": 47, "preprocessor": [33, 35, 36, 37, 38, 39, 46, 47, 48, 49, 54, 55, 56, 57, 58], "preprocessor1": 40, "preprocessor2": 40, "preprocessor3": 40, "prerequisit": [2, 47, 59], "preschool": [36, 38, 39, 56], "presenc": [33, 39, 47], "present": [7, 30, 36, 43, 44, 45, 46, 47, 48, 51, 53, 58], "preserv": [36, 41], "pressure3pm": [46, 58], "pressure9am": [46, 58], "pretend": [29, 30, 46], "pretrain": [44, 45, 49], "pretti": [29, 33, 34, 36, 38, 41, 44, 46, 47, 58], "prevent": [35, 44, 47, 59], "previou": [29, 37, 38, 41, 42, 46, 47, 48, 51, 55, 56, 58], "previous": [43, 45, 46], "price": [8, 18, 32, 34, 37, 39, 40, 47, 48, 53], "primari": [8, 19, 23, 24, 25, 26, 27, 31], "primarili": [29, 39, 45], "prime": 28, "principl": [9, 29, 51, 59], "print": [7, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 56, 58], "print_top": 44, "prior": [41, 46, 51], "priorit": [40, 51], "privaci": [0, 41, 59], "privat": [7, 36, 38, 39], "privileg": 6, "prize": 33, "pro": [41, 45, 48], "prob": [34, 38], "proba": 45, "probabilist": 2, "probabl": [17, 28, 31, 32, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 51, 56, 57, 58], "problem": [4, 6, 10, 28, 33, 34, 36, 37, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59], "problemat": [36, 39, 47], "probosci": [28, 45], "proce": 59, "procedur": 38, "proceed": [30, 58], "process": [2, 5, 7, 29, 31, 32, 33, 35, 40, 41, 42, 45, 48, 49, 53, 55, 59], "process_on": 49, "prod": [33, 35], "produc": [2, 7, 37, 39, 42, 47, 48, 51, 53], "product": [5, 35, 43, 44, 48], "prof": [36, 38, 39, 56], "profession": 43, "profil": 37, "profile_df": 43, "profilereport": 37, "profit": 48, "program": [0, 4, 9, 11, 28, 44, 59], "programm": 44, "progress": 41, "project": [11, 32, 38, 40, 45, 48, 51, 59], "promin": 44, "promis": [28, 44, 46], "promot": 47, "prompt": [11, 59], "pron": [44, 49], "prone": 35, "proper": [45, 52], "properli": [7, 47, 48], "properti": [29, 37, 39, 40], "prophet": 46, "propn": 49, "proport": [29, 30, 33, 34, 36, 37, 38, 39, 48, 56, 59], "proportional_hazard_test": 47, "prostitut": 44, "prototyp": 51, "prove": 36, "provid": [0, 5, 7, 11, 29, 30, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 48, 51, 55, 56, 57, 58, 59], "provinc": [33, 44], "proxi": 30, "proxim": [34, 44, 59], "prune": 40, "psychologi": [33, 51], "pt": [34, 35, 45], "public": [0, 4, 7, 44, 49], "publish": [0, 10, 34, 44], "pud": 37, "pull": [11, 34, 44], "punct": [44, 49], "punctuat": [33, 44], "punish": 48, "punkt": 49, "punkt_tab": 49, "purchas": [28, 43], "pure": [29, 46], "purpos": [0, 29, 30, 32, 43, 44, 46, 51, 52, 53, 57, 59], "pursuit": 48, "push": [7, 39], "put": [7, 8, 11, 29, 30, 32, 33, 40, 41, 42, 43, 48, 55], "px": [40, 44], "py": [29, 30, 32, 33, 35, 38, 39, 41, 42, 47, 48, 49, 50], "pybind11": 49, "pybo": 35, "pydata": 40, "pyplot": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "pysurviv": 47, "python": [3, 4, 10, 28, 35, 37, 43, 44, 45, 46, 47, 48, 49, 59], "python3": [9, 29, 30, 33, 35, 39, 47, 49, 50], "pythonwarn": 37, "pytorch": [28, 45], "pytorch_1711403226120": 49, "pyviz": 36, "q": 10, "qualiti": [36, 39, 41, 42, 48], "quantifi": [36, 56], "queri": [32, 36, 38, 41, 43, 44, 46, 47, 56, 58, 59], "query_point": 31, "quest": 40, "question": [6, 7, 59], "quick": [4, 44, 59], "quickli": [29, 31, 32, 35, 42, 47, 51, 59], "quickstart": 9, "quirk": 30, "quit": [6, 28, 29, 32, 35, 36, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49], "quiz": [1, 10, 44], "quiz1": [29, 30, 33, 51], "quiz2": [30, 33, 51], "quizz": 29, "r": [29, 33, 34, 36, 46, 48, 57, 59], "r1": 38, "r2": [37, 38, 51, 53], "r2_score": [37, 40, 49], "r4": 38, "race": [33, 36, 38, 39, 56, 59], "radial": 31, "radiu": [40, 42], "rail": 45, "rain": [46, 58], "rain_df": [46, 58], "rain_df_modifi": [46, 58], "rainfal": [46, 58], "rainfall_lag1": [46, 58], "rainfall_lag2": [46, 58], "rainfall_lag3": [46, 58], "raintodai": [46, 58], "raintoday_miss": [46, 58], "raintoday_no": [46, 58], "raintoday_y": [46, 58], "raintomorrow": [46, 58], "rais": [6, 33, 36, 46, 47, 58], "rand": [8, 38], "randint": [35, 55], "randn": [34, 40], "random": [6, 8, 30, 31, 34, 36, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 55, 57, 59], "random_forest_data": 38, "random_search": [35, 55], "random_st": [28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57], "randomforestclassifi": [39, 40, 46, 48, 57, 58], "randomforestclassifierrandomforestclassifi": 38, "randomforestregressor": [37, 38, 39, 40, 46, 47, 48, 49, 57], "randomhorizontalflip": 45, "randomizedsearchcv": [31, 38, 39, 48, 55, 57], "randomizedsearchcvifittedrandomizedsearchcv": 35, "randomli": [30, 34, 35, 36, 38, 47, 56], "randomoversampl": 36, "randomresizedcrop": 45, "randomst": [40, 42], "randomundersampl": 36, "rang": [4, 8, 30, 31, 32, 33, 34, 38, 41, 43, 44, 45, 46, 47, 48, 49, 55, 59], "rangeindex": [33, 40, 46, 47, 58], "rank": [36, 40, 43, 44, 47, 56], "rank_test_mape_scor": 37, "rank_test_neg_mean_squared_error": 37, "rank_test_scor": [35, 37], "ranking_": 40, "rare": [33, 36, 37, 41, 44, 51], "rate": [28, 34, 36, 38, 41, 47, 48, 51, 56], "rated_item": 43, "rather": [28, 33, 35, 36, 37, 38, 39, 41, 44, 45], "ratings_df": 43, "ratio": [36, 38, 44, 47], "ravel": [36, 51], "raw": [8, 33, 36, 39, 40, 44, 45, 48, 50, 56], "raw_model_output": 34, "raw_scor": 39, "rbf": [10, 15, 30, 32, 34, 35, 38, 39, 40, 48, 51, 53, 55], "rcparam": [28, 29, 30, 36, 41, 42, 43, 45, 46, 47, 48, 52, 58], "re": [4, 7, 8, 11, 28, 29, 30, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 49, 51, 52, 58], "reach": [6, 41, 59], "read": [1, 4, 7, 10, 31, 32, 33, 36, 37, 38, 39, 44, 46, 48, 57, 58], "read_csv": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 59, "readi": [7, 30, 31, 32, 34], "readlin": 45, "readm": 47, "readthedoc": 47, "real": [30, 31, 32, 33, 34, 36, 39, 41, 42, 43, 44, 45, 48, 49, 51], "realdonaldtrump": 49, "realist": [32, 46, 58], "realiti": [30, 37, 47], "realiz": 48, "realli": [8, 30, 34, 35, 38, 40, 42, 43, 45, 46, 47], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 35, 36, 37, 39, 41, 43, 44, 46, 47, 48, 51, 59], "rebuild": 49, "rec": [37, 39, 48], "recal": [18, 29, 30, 31, 32, 33, 34, 37, 41, 46, 51, 56, 59], "recall_lr": 36, "recall_scor": 36, "recall_svc": 36, "receiv": [6, 7, 33, 42, 45, 46], "recent": [8, 11, 28, 33, 40, 43, 44, 46, 47, 49], "recip": 30, "recogn": [30, 42, 46, 48, 59], "recognit": [28, 29, 31, 36, 44, 59], "recommend": [2, 4, 8, 10, 11, 28, 30, 31, 35, 36, 41, 44, 45, 48, 57, 59], "record": [29, 47], "recreat": 58, "rectangular": 41, "recurr": 46, "recurs": 59, "red": [29, 31, 36, 39, 40, 41, 46], "redbon": 35, "redefin": 47, "redistribut": 0, "reduc": [7, 8, 28, 31, 35, 36, 37, 38, 39, 40, 43, 44, 45, 50, 53, 56, 59], "reduct": [2, 36, 38, 40, 41], "redund": [34, 39], "ref": [36, 47, 56], "refer": [8, 29, 30, 31, 32, 33, 34, 36, 39, 41, 43, 44, 45, 53, 59], "referenc": 59, "referenti": 44, "refin": [31, 53], "refit": 37, "reflect": [31, 37, 39, 44, 53, 55, 59], "reflection_period": 36, "reg": [29, 38, 57], "reg_model": 29, "regard": 59, "regardless": 7, "regex": 44, "region": [29, 36, 42, 46, 50, 55, 58], "region_data": [46, 58], "regist": 59, "registri": 49, "regrad": 6, "regress": [2, 10, 17, 28, 32, 33, 39, 40, 43, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59], "regression_df": 29, "regressor": [29, 32, 33, 37, 46, 57], "regular": [31, 33, 34, 38, 44, 46, 47, 48, 51], "regulatori": 39, "reinforc": [28, 41], "reject": [36, 56], "rel": [34, 39, 42, 44, 49, 50, 56], "rel_char_len": 49, "relabel": 41, "relat": [2, 6, 11, 28, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 57, 59], "relationship": [36, 38, 39, 40, 44, 46, 48, 49, 51, 52, 53, 56, 58, 59], "relationship_husband": 39, "relationship_own": 39, "releas": [7, 10], "relev": [4, 8, 10, 29, 31, 32, 35, 39, 46, 59], "reli": [30, 31, 40, 42, 43, 46, 53], "reliabl": [28, 41], "religi": 44, "remain": [5, 37, 40, 43, 46, 48], "remaind": 6, "rememb": [7, 31, 33, 35, 36, 39, 40, 42, 45, 46, 47, 52, 53, 55, 58], "remind": 52, "remix": 0, "remov": [7, 32, 36, 38, 39, 40, 44, 45, 47, 50, 55, 56, 58], "renam": [28, 36, 39, 46], "render": [4, 7, 28, 32, 33, 35, 36, 37, 38, 39, 40, 41, 44, 45, 48, 49], "rent": 46, "rental": 46, "rentals_df": 46, "rentals_lag5": 46, "rentals_lag5_i": 46, "rentals_lag5_x": 46, "rentals_model": 46, "repair": [36, 38, 39], "repeat": [8, 40, 41, 42, 45, 55, 56, 57], "repeatedli": 6, "rephras": 48, "replac": [28, 32, 36, 38, 39, 43, 47, 56], "reply_cont": 49, "repo": [10, 36], "report": [6, 29, 35, 37, 40, 46, 49, 56], "repositori": [0, 5, 10, 11, 34, 36, 59], "repres": [29, 30, 31, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 57], "represent": [28, 29, 32, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 51], "reproduc": [4, 30, 35, 38, 59], "republ": 39, "request": [6, 44, 59], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 51, 53, 58], "rerun": [28, 32, 33, 35, 36, 37, 38, 39, 40, 45, 48, 49], "res_mean": 30, "resampl": 36, "research": [28, 30, 35, 43, 44], "reserv": [46, 59], "reset_index": 28, "reshap": [8, 34, 35, 45, 46, 55], "resid": 34, "residu": 38, "resiz": 45, "resnet": 45, "resolut": 44, "resolv": 59, "resort": 34, "resourc": [3, 5, 10, 29, 38, 39, 44, 45, 51], "respect": [34, 35, 36, 38, 39, 55], "respons": [4, 7, 29, 41, 44, 48, 59], "rest": [34, 35, 45, 47, 51, 58], "restart": [7, 11], "restaur": 43, "restingbp": 57, "restingecg": 57, "restrict": [0, 37, 38, 44], "result": [2, 7, 8, 10, 11, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 53, 55, 56, 57, 58, 59], "result_block": 47, "result_img": 45, "results_df": [30, 31, 34, 53], "results_dict": [30, 31, 32, 33, 35], "results_single_valid_df": 53, "retail": [49, 51], "retail_df": 46, "retail_df_test": 46, "retail_df_train": 46, "retail_lag_5": 46, "retail_model": 46, "retail_test_5": 46, "retail_test_5_pr": 46, "retail_train_5": 46, "retail_train_5_d": 46, "retail_train_5_i": 46, "retail_train_5_x": 46, "retent": 47, "retrain": [35, 55], "return": [5, 8, 11, 29, 30, 31, 32, 33, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 53, 55, 58], "return_gener": 33, "return_train_scor": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 49, 53, 55, 57], "reus": [36, 59], "revenu": 43, "revers": [33, 37], "review": [4, 10, 25, 34, 41, 48, 49, 51, 55, 56, 57, 59], "revisit": [36, 51], "revok": 0, "reward": [28, 33, 41], "rf": [46, 47], "rf_imp_df": 39, "rfe_cv": 40, "rfe_pip": 40, "rfecv": 40, "rgb": 28, "rich": [39, 44, 47, 48, 51], "richard": 48, "rico": 39, "rid": [11, 33, 38, 39, 44, 47], "ridg": [39, 40, 43, 46, 47, 48, 49], "ridge__alpha": 37, "ridge_pr": 37, "ridge_tun": 37, "ridgecv": [40, 49], "ridgecv_pip": 37, "ridgeridg": [37, 40], "right": [0, 10, 28, 34, 35, 36, 37, 40, 41, 42, 43, 44, 48, 51, 55, 56, 59], "rightarrow": [29, 31, 34, 36, 37, 38, 41, 42, 43, 44, 48, 51], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 44, "rise": [40, 44], "risk": [10, 36, 40, 48, 53, 57], "river": 34, "rl": [37, 39, 48], "rmse": [43, 51], "rng": [40, 42], "rnn": 46, "ro": 36, "roast": 41, "robot": [43, 44], "robust": [28, 30, 31, 32, 35, 38, 42, 53, 55], "roc": [51, 59], "roc_auc": 36, "roc_auc_scor": 36, "roc_curv": 36, "roc_lr": 36, "roc_svc": 36, "roccurvedisplai": 36, "rodolfo": 35, "rodr\u00edguez": 44, "roger": 40, "role": [34, 35, 39, 45], "roman": 43, "romanc": 43, "romant": 43, "ronald": 34, "roof": 39, "roofmatl": [37, 39, 48], "roofmatl_clytil": [37, 39], "roofmatl_compshg": [37, 39], "roofmatl_membran": 37, "roofmatl_met": 37, "roofmatl_rol": 37, "roofmatl_tar": 37, "roofmatl_wdshak": 37, "roofmatl_wdshngl": [37, 39], "roofstyl": [37, 39, 48], "roofstyle_flat": 37, "roofstyle_g": 37, "roofstyle_gambrel": 37, "roofstyle_hip": 37, "roofstyle_mansard": 37, "roofstyle_sh": 37, "room": [28, 29, 34, 37, 40, 49, 59], "rooms_per_household": [32, 33, 40, 54], "rooms_per_household_0": 40, "rooms_per_household_1": 40, "rooms_per_household_10": 40, "rooms_per_household_11": 40, "rooms_per_household_12": 40, "rooms_per_household_13": 40, "rooms_per_household_14": 40, "rooms_per_household_15": 40, "rooms_per_household_16": 40, "rooms_per_household_17": 40, "rooms_per_household_18": 40, "rooms_per_household_19": 40, "rooms_per_household_2": 40, "rooms_per_household_3": 40, "rooms_per_household_4": 40, "rooms_per_household_5": 40, "rooms_per_household_6": 40, "rooms_per_household_7": 40, "rooms_per_household_8": 40, "rooms_per_household_9": 40, "root": [11, 29, 31, 43, 45, 51], "rose": 44, "rostin": 59, "rotat": [46, 58], "rough": 4, "roughli": [5, 30, 44, 51], "round": [8, 31, 32, 35, 36, 38, 42, 45, 53], "rout": [5, 29, 46], "row": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 52, 53, 57, 58, 59], "rry": 44, "rsh": 35, "ru": [8, 36], "rubric": 34, "rule": [1, 8, 28, 29, 31, 34, 36, 38, 44, 51, 53, 56], "run": [4, 5, 7, 10, 11, 28, 30, 31, 33, 35, 36, 37, 39, 41, 42, 44, 45, 49, 50, 52, 53, 55, 57], "run_ast_nod": 49, "run_cel": 49, "run_cell_async": 49, "run_cod": 49, "run_forev": 49, "runner": 49, "runpi": 49, "runtimewarn": 35, "rush": 40, "russel": 10, "rv": 35, "rv_continuous_frozen": 35, "rv_discrete_frozen": 35, "rvert_2": 44, "s1": [8, 44], "s19": 32, "s2": [8, 44], "s_lag": [46, 58], "sa": 1, "sabrina": 10, "sadli": 44, "safe": 32, "safeti": 45, "sai": [8, 29, 31, 32, 33, 36, 37, 38, 39, 44, 46, 48, 51, 56], "said": [30, 32, 34, 39, 42, 43, 44, 48], "sal": [37, 39, 48], "sale": [8, 36, 37, 46, 48, 53], "salecondit": [37, 39, 48], "salecondition_abnorml": 37, "salecondition_adjland": 37, "salecondition_alloca": 37, "salecondition_famili": 37, "salecondition_norm": 37, "salecondition_parti": 37, "salepric": [37, 39, 48], "sales_data": 46, "salesforc": 49, "saletyp": [37, 39, 48], "saletype_cod": 37, "saletype_con": 37, "saletype_conld": 37, "saletype_conli": 37, "saletype_conlw": 37, "saletype_cwd": 37, "saletype_new": 37, "saletype_oth": 37, "saletype_wd": 37, "salt": [34, 39], "sam": 43, "same": [6, 7, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 56, 58], "sampl": [29, 31, 32, 34, 35, 39, 42, 45, 46, 47, 48, 52, 53, 56, 57, 58], "sample_df": 36, "sample_text": 49, "sampling_strategi": 36, "samuel": 28, "sand": 45, "sandbar": 45, "saniti": [29, 47], "sarah": 10, "sat": 46, "satisfactori": 41, "satisfi": [41, 59], "satur": 48, "saturdai": [10, 46], "save": [7, 8, 33, 35, 39, 44, 45, 46, 48, 49, 54, 55, 58], "saw": [32, 34, 35, 36, 42, 51], "sb": 40, "scalabl": [28, 42], "scalar": 8, "scale": [16, 30, 31, 33, 35, 36, 37, 38, 40, 42, 45, 47, 48, 51, 53, 54, 55], "scale_pos_weight": 38, "scaler": [32, 39, 40], "scan": 51, "scatter": [32, 37, 39, 40], "scatter_3d": 40, "scatterplot": 40, "scc": 44, "scenario": [30, 33, 38, 39, 40, 42, 46, 47, 51, 59], "schedul": [47, 51], "schmidt": 35, "school": [28, 36, 38, 39, 43, 56], "scienc": [2, 9, 10, 11, 33, 41, 46, 48, 51, 53, 59], "scientif": [43, 44], "scientist": [9, 10, 42], "scikit": [9, 11, 16, 17, 29, 31, 34, 35, 36, 38, 41, 42, 45, 46, 48, 49, 50, 55, 56, 59], "scipi": [11, 35, 42, 44, 55], "scm": 5, "scope": [44, 46], "score": [17, 18, 28, 31, 32, 33, 38, 39, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59], "score_func": 37, "score_gb_test": 48, "score_gb_train": 48, "score_lr_print_coeff": [46, 58], "score_param": 33, "score_rf_test": 48, "score_rf_train": 48, "score_tim": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 49], "scorer": [33, 37], "scores_averag": 57, "scores_dict": 34, "scores_imag": 34, "scores_stack": 57, "scoring_method": 47, "scoring_metr": [38, 39, 49], "scotland": 44, "scott": 48, "scratch": [2, 45], "screen": 7, "screennam": 49, "screenplai": 44, "screenporch": [37, 39, 48], "script": 11, "scroog": 49, "sd": [19, 23, 24, 25, 26, 27], "sdng": 37, "se": [46, 47, 58], "sea": 45, "seaborn": [39, 40, 41, 42, 43], "seacoast": 45, "search": [4, 5, 11, 37, 44, 51, 55], "search_multi": 37, "seashor": 45, "season": 58, "season_autumn": 46, "season_fal": 46, "season_summ": 46, "season_wint": 46, "seat": [45, 59], "seattl": 49, "seawal": 45, "second": [4, 6, 29, 34, 38, 39, 42, 45, 46, 48], "secondari": 28, "secpompeo": 49, "section": [7, 11, 29, 30, 40, 57, 59], "secur": [39, 59], "see": [1, 4, 6, 7, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 57, 58, 59], "seed": [34, 35, 41, 42], "seem": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 46, 47, 49, 50, 53, 55, 56], "seemingli": [36, 56], "seen": [8, 28, 30, 31, 32, 33, 34, 40, 42, 43, 47, 51, 53, 55, 57], "sefa": 59, "segment": [36, 44, 45, 47, 51, 59], "select": [5, 6, 10, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 45, 46, 47, 48, 59], "select_dtyp": 37, "select_knn": 40, "select_rf": 40, "select_svc": 40, "selectfrommodel": 40, "self": [28, 33, 47, 49, 59], "sell": [0, 8, 29, 48], "semant": [41, 42, 44, 59], "semest": 59, "semi": [10, 44], "semicolon": 8, "semilogx": 37, "send": [4, 28, 49], "senior": 47, "seniorcitizen": 47, "sens": [6, 30, 33, 34, 36, 37, 39, 40, 41, 43, 44, 46, 47, 50], "sensibl": 7, "sensit": [30, 32, 35, 36, 37, 41, 47], "sent": [28, 44], "sent_token": 44, "sentenc": [44, 48], "sentiment": [29, 34, 44, 49], "sentimentintensityanalyz": 49, "sepal": [31, 53], "separ": [29, 30, 32, 33, 34, 36, 40, 41, 43, 44, 46, 50, 51, 52, 53, 54, 55, 56], "septemb": 46, "sequenc": [30, 33, 45, 46, 48], "sequenti": [29, 38, 46, 47, 51], "sequentialfeatureselector": 40, "ser": [30, 32, 47], "seri": [2, 10, 30, 32, 33, 36, 40, 45, 47, 49, 59], "serial": 38, "seriou": [6, 36, 43, 44, 47, 59], "serv": [5, 29, 39, 59], "server": 5, "servic": [38, 39, 43, 47, 49], "session": [41, 51, 59], "set": [7, 8, 9, 10, 28, 29, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56, 57, 58], "set_config": [35, 38], "set_index": [30, 31, 35, 36, 37], "set_opt": [28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 43, 52, 53, 54, 55, 56], "set_properti": 28, "set_titl": [31, 34, 36, 45, 53, 56], "set_xlabel": [31, 34, 41, 53], "set_ylabel": [31, 34, 41, 53], "settl": [55, 56], "setup": [3, 7, 11, 52], "setup_default_warn": 49, "sev": [37, 39, 48], "sever": [11, 32, 34, 41, 42, 44, 45, 46, 50, 58, 59], "sex": [36, 38, 39, 40, 56, 57], "sexual": 59, "shadab": 59, "shadow": [19, 23, 24, 25, 26, 27], "shaikh": 59, "shall": [0, 44], "shallow": 38, "shape": [29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58], "shape_df": 30, "shape_dict": 30, "share": [0, 40, 59], "sharealik": 1, "sharex": 32, "shashwat": 59, "she": [28, 43, 49], "shed": [37, 39, 48], "sheet": [9, 51], "shelf": [38, 44, 55], "shell": [5, 9, 49], "shelv": 49, "shift": [46, 58], "shit": 49, "shng": 37, "shop": 43, "short": [10, 11, 30, 35, 38, 44, 59], "shorter": 47, "shorthand": 32, "shot": 40, "should": [5, 7, 8, 11, 29, 30, 31, 32, 33, 34, 36, 39, 40, 41, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 59], "shouldn": [36, 38, 53], "show": [4, 7, 11, 28, 30, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53, 55, 57, 58], "show_plot": 47, "showcas": 44, "shown": [7, 11, 28, 29, 31, 36, 38, 41, 42, 46, 48], "shrink": [35, 40, 48], "shuffl": [30, 45, 46, 58], "si": 28, "sibl": 40, "sick": [41, 49], "sid": 49, "side": [6, 45, 48], "sift": 43, "sigma": 45, "sign": [4, 37, 39, 45, 53, 55, 57, 59], "signal": [30, 44], "signific": [32, 45, 48, 59], "significantli": [33, 36, 43], "sigoptsearchcv": 35, "silhouett": 42, "silhouettevisu": [41, 42], "sim": 39, "sim_word": 44, "simard": 39, "similar": [10, 11, 29, 30, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 50], "similarity_": 44, "similarli": [39, 41, 47], "simp": 46, "simpl": [10, 29, 31, 32, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 51, 52, 56], "simplefilt": [38, 39], "simpleimput": [32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "simpleimputersimpleimput": [32, 33, 37, 38, 40, 48], "simpler": [34, 35, 53], "simplest": 33, "simpli": [32, 40, 41], "simplic": [29, 33, 43], "simplist": [31, 39, 53], "simul": 40, "sin": 8, "sinc": [5, 34, 37, 39, 40, 41, 43, 45, 46, 47, 48, 50, 51, 52, 58], "singl": [8, 31, 32, 34, 35, 36, 38, 39, 42, 46, 47, 51, 52, 53, 55, 56], "sit": 59, "site": [5, 29, 30, 33, 35, 39, 47, 49, 50, 59], "situat": [6, 28, 36, 38, 41, 45, 47, 59], "six": [30, 38, 46], "size": [28, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 57, 58, 59], "skeleton": 48, "skeptic": 48, "skew": 37, "skill": [38, 59], "skin": 49, "skip": 56, "skipna": 47, "sklearn": [10, 28, 30, 31, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "sklearn_gb": 38, "sklearn_histgb": 38, "sktime": 46, "skyblu": [46, 58], "skyscrap": 46, "slate": 58, "slice": 8, "slide": [9, 10, 19, 25, 32, 45, 59], "slightli": [33, 34, 36, 38, 47], "slipper": 48, "slope": 34, "sloppi": 32, "slot": 59, "slow": [31, 38, 40, 45], "slower": [38, 41], "slowest": 57, "sm": [28, 33], "smac": 35, "small": [11, 30, 31, 33, 35, 37, 38, 39, 40, 41, 43, 45, 47, 51, 53, 55, 57], "small_citi": 31, "small_train_df": 31, "smallalpha_coeff": 37, "smaller": [31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 53, 55], "smallest": [34, 37, 41, 42], "smart": [41, 48, 49], "smile": 49, "smooth": [31, 53], "smoothli": 11, "smote_pip": 36, "sms_df": 28, "sn": [39, 41, 42], "snake": [34, 45], "snake_length": 34, "snakes_df": 34, "snbf": 38, "snippet": 7, "snow": [28, 45], "snp": 40, "so": [0, 4, 5, 7, 8, 10, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59], "social": [41, 42, 43, 46], "societ": 59, "societi": [36, 44, 56], "sofist": 53, "soft": [34, 38, 57], "softmax": 51, "softwar": [1, 5, 11, 47], "solar": 43, "sold": [8, 37], "sole": [36, 42], "solidifi": 51, "solut": [28, 29, 30, 38, 41, 47, 48, 49, 51, 59], "solv": [4, 28, 29, 31, 40, 44, 48, 53, 59], "solver": 36, "some": [4, 6, 7, 8, 11, 28, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59], "someon": [28, 29, 30, 40, 47, 48], "someth": [4, 7, 11, 29, 33, 36, 37, 38, 39, 41, 46, 47, 48, 51, 59], "sometim": [6, 29, 30, 33, 34, 35, 38, 39, 44, 48], "somewhat": 37, "somewher": [28, 37], "song": [31, 32, 43, 49, 55], "song_titl": [31, 32, 35, 55], "soo": 59, "soon": [28, 31, 32, 46], "sopha": 28, "sophist": [35, 39, 44], "sort": [5, 10, 29, 30, 32, 39, 43, 44, 45, 46, 58], "sort_index": [8, 35, 37, 46, 58], "sort_valu": [32, 33, 34, 35, 37, 38, 39, 40, 46, 47, 49, 57, 58], "sound": [39, 40], "soundtrack": 44, "sourc": [11, 28, 29, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 49, 52, 55, 59], "south": 33, "space": [31, 34, 35, 40, 41, 42, 44, 49, 58, 59], "spaci": 40, "spacy_download": 44, "spacymoji": 49, "spam": [30, 36, 41], "spam_predict": 28, "span": [44, 46], "spanish": 32, "spars": [31, 34, 38, 43, 44, 51], "sparse_output": [32, 33, 36, 37, 38, 39, 46, 47, 48, 51, 56, 57, 58], "spatial": 34, "speak": 5, "spearmint": 35, "speci": [31, 51, 53], "special": [28, 33, 43, 44, 45, 46, 47, 53, 59], "specialti": [36, 38, 39], "specif": [8, 29, 30, 35, 36, 39, 41, 43, 44, 45, 46, 47, 48, 51, 53, 55, 57, 59], "specifi": [8, 29, 30, 33, 35, 36, 41, 42, 45, 48, 55, 57], "spectrogram": 40, "speech": [40, 44, 49], "speechi": [31, 32, 35, 55], "speed": [8, 29, 38, 45], "spell": 28, "spend": [28, 32, 40, 48, 49, 59], "spent": [6, 32, 40], "spheric": [42, 51], "spici": 41, "spini": 45, "spit": 45, "split": [15, 29, 31, 33, 34, 35, 37, 38, 40, 43, 44, 47, 49, 51, 56, 57, 58, 59], "split0_test_r2": 37, "split0_test_scor": 35, "split0_train_neg_mean_squared_error": 37, "split0_train_scor": 35, "split1_test_r2": 37, "split1_test_scor": 35, "split1_train_neg_mean_squared_error": 37, "split1_train_scor": 35, "split2_test_r2": 37, "split2_test_scor": 35, "split2_train_neg_mean_squared_error": 37, "split2_train_scor": 35, "split3_test_r2": 37, "split3_test_scor": 35, "split3_train_neg_mean_squared_error": 37, "split3_train_scor": 35, "split4_test_scor": 35, "split4_train_neg_mean_squared_error": 37, "split4_train_scor": 35, "spoken": 33, "sport": [44, 45, 46], "spot": [36, 37, 53], "spotifi": [31, 43, 55], "spotify_df": [31, 32, 35, 55], "spotlight": [5, 11], "spous": [36, 38, 39], "spread": 42, "spring_month": 46, "sqft": 39, "sqft_abov": [28, 29], "sqft_basement": [28, 29], "sqft_live": [28, 29], "sqft_living15": [28, 29], "sqft_lot": [28, 29], "sqft_lot15": [28, 29], "sqrt": [31, 37, 39, 43, 44], "squar": [8, 29, 31, 34, 39, 43, 47, 48, 49, 51, 59], "squash": [34, 45], "squeez": [8, 47], "src": [30, 36], "sse": [46, 58], "ssw": 46, "st": [46, 49], "st_slope": 57, "stabil": 11, "stabl": [30, 36, 38, 53], "stack": [7, 51, 59], "stack_method": 57, "stacking_model": [38, 57], "stacking_model_tre": 38, "stackingclassifi": [38, 57], "stackingregressor": 38, "staff": 6, "stai": [36, 47], "stakehold": [48, 59], "stale": 41, "stand": [31, 35, 44], "standard": [4, 6, 30, 32, 35, 38, 39, 40, 44], "standardscal": [33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58], "standardscalerstandardscal": [32, 33, 35, 36, 37, 38, 40, 45, 48, 49], "stanford": 44, "star": [31, 41, 43, 49], "start": [7, 8, 11, 29, 30, 31, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58], "startswith": 39, "starttim": 46, "stat": [35, 47, 55], "state": [6, 8, 30, 36, 38, 39, 43, 49, 56], "statement": [7, 30, 31, 32, 33, 34, 35, 36, 37, 40, 45, 47, 48], "station": 46, "statist": [9, 10, 29, 34, 39, 43, 44, 47, 59], "statistician": 31, "statlib": 34, "statsmodel": [46, 47], "statu": [36, 38, 39, 56], "status_marri": 39, "status_nev": 39, "std": [30, 31, 32, 36, 37, 45, 46, 49, 50, 58], "std_cv_error": 30, "std_cv_score": 31, "std_fit_tim": [35, 37], "std_score": [30, 32, 49], "std_score_tim": [35, 37], "std_test_neg_mean_squared_error": 37, "std_test_scor": [30, 35], "std_train_error": 30, "std_train_neg_mean_squared_error": 37, "std_train_scor": [30, 31, 35], "stdki": 47, "stem": 44, "step": [7, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 57, 59], "stereotyp": 44, "stick": 46, "still": [4, 11, 35, 36, 37, 38, 40, 41, 46, 47, 49, 53, 54, 55, 56], "stipul": 48, "stochast": [40, 41], "stock": [28, 46], "stop": [8, 41, 44, 45, 47, 53], "stop_word": [35, 36, 44, 49, 55], "stopword": 44, "storag": 31, "store": [7, 8, 31, 32, 33, 35, 36, 38, 39, 42, 43, 45, 46, 47, 49], "stori": [37, 38, 49], "storylin": 44, "str": [35, 39, 44, 46, 47, 49, 58], "straight": 47, "straightforward": 39, "strain": 7, "strang": [39, 47], "strata": 47, "strategi": [29, 31, 32, 33, 36, 37, 39, 41, 43, 46, 47, 48, 51, 52, 56, 58], "stratif": 47, "stratifi": 47, "stratifiedkfold": [30, 36], "stream": [47, 49], "streamingmovi": 47, "streamingmovies_no": 47, "streamingmovies_y": 47, "streamingtv": 47, "streamingtv_no": 47, "streamingtv_y": 47, "street": [37, 39, 48], "street_grvl": 37, "street_pav": 37, "strength": [44, 51], "stress": 41, "strftime": [46, 47], "string": [8, 11, 31, 36, 37, 38, 39, 44, 46, 47, 53, 57], "strip": [39, 45], "strong": [38, 47, 51], "stronger": 38, "strongli": 38, "structur": [8, 41, 44, 45], "struggl": [41, 46], "stuart": [10, 38], "stuck": [4, 8], "student": [4, 5, 6, 7, 28, 29, 34, 36, 37, 39, 40, 41, 42, 43, 45, 49, 59], "studi": [28, 33, 40, 44, 47], "stuff": [31, 45, 47], "stump": [29, 30, 31, 38, 52], "stupid": 49, "style": [28, 37, 40, 41, 43, 44, 45, 48, 49], "sub": [35, 41, 44, 47, 48, 51], "subdirectori": 39, "subgroup": 47, "subject": [0, 47, 59], "sublicens": 0, "submiss": [3, 59], "submit": [8, 10, 59], "subplot": [30, 31, 34, 36, 41, 45, 47, 48, 53, 56], "subplot_kw": 30, "subprocess": 37, "subscrib": 47, "subscript": [46, 47], "subset": [29, 30, 35, 38, 45, 46, 50, 53], "substanc": 48, "substanti": 0, "substitut": 0, "subtl": 44, "subtleti": [30, 37], "subtract": [31, 36, 39], "suburb": 49, "subword": 44, "succe": [40, 59], "success": [5, 8, 11, 28, 36, 38, 43, 44, 45, 46], "successfulli": [11, 28, 49], "sudo": 5, "suei": 35, "suffer": 35, "suffici": [7, 44], "suggest": [0, 10, 29, 43, 47], "suicid": 44, "suit": 43, "suitabl": [11, 28, 41, 43, 51, 57, 59], "sum": [8, 31, 32, 33, 34, 38, 39, 41, 45, 49], "sum_": [31, 37, 41, 44, 45], "sum_i": [39, 44], "sum_prob_ex1_class_0": 38, "sum_prob_ex1_class_1": 38, "summar": [10, 28, 34, 36, 37, 41, 44], "summari": [0, 50, 51, 53], "summary_plot": 39, "summat": [38, 48], "summer": [1, 43, 46], "summer_month": 46, "sun": [44, 46], "sundai": 46, "sundial": 45, "sunshin": [46, 58], "super": [33, 49, 51], "superfici": 31, "superior": 59, "supermarket": 49, "supervis": [32, 33, 35, 36, 37, 40, 42, 44, 46, 47, 51, 58, 59], "suppli": 59, "support": [11, 15, 29, 32, 36, 38, 39, 40, 42, 44, 48, 49, 50, 53, 59], "support_": [31, 40], "suppos": [28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 48, 51, 52], "suppress": 8, "suprem": 44, "sure": [4, 7, 8, 11, 30, 31, 33, 36, 37, 38, 39, 42, 45, 46, 48, 53, 56, 57, 58, 59], "surgeri": 47, "suri": 59, "surpris": [39, 43], "surprisingli": [33, 34], "surround": [4, 48, 59], "survei": 41, "surviv": [2, 10, 48, 59], "survival_function_": 47, "suscept": 42, "suspect": 35, "svc": [31, 32, 33, 34, 35, 38, 39, 40, 45, 49, 53, 54, 55, 57], "svc__c": [35, 55], "svc__gamma": [35, 55], "svc_pipe": 35, "svc_pred": 36, "svcsvc": [33, 35, 36], "svm": [10, 30, 32, 33, 35, 38, 39, 40, 45, 46, 48, 49, 50, 51, 53, 54, 55, 57], "svm_estim": 36, "svr": [31, 33, 39, 48], "svr_c_pipe": 33, "svr_pipe": 33, "sw": [46, 58], "swai": 28, "swamp": 31, "swan": 45, "swcarpentri": 9, "sweep": 36, "sweet": 49, "switch": [39, 41, 46, 47, 48, 58], "sy": [28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57], "sydnei": 46, "syllabu": [3, 7, 10, 12], "symbol": 29, "symmetri": 40, "sync": [5, 48], "synonym": 44, "syntact": 44, "syntax": [4, 8, 28, 40, 47], "syntaxwarn": 48, "synthet": [40, 50], "system": [2, 4, 5, 6, 10, 11, 28, 30, 31, 33, 36, 39, 41, 46, 48, 56, 59], "systemat": [29, 33, 35, 39, 44], "t": [4, 5, 7, 8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 57, 58, 59], "ta": [7, 28, 37, 39, 48, 52, 53, 54, 55, 56, 57, 58], "tabbi": [28, 45], "tabl": [7, 57], "tabular": [8, 28, 45, 46], "tackl": [30, 32, 36, 42, 53], "taco": 40, "tag": [4, 44, 49], "tail": [8, 46], "tailor": [41, 48, 59], "take": [2, 4, 5, 6, 11, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59], "taken": [46, 50, 55, 59], "talk": [29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 59], "tall": 44, "target": [30, 31, 32, 34, 35, 36, 38, 39, 40, 43, 45, 46, 47, 48, 51, 53, 54, 55, 56, 57, 58], "target_column": [38, 39, 47, 57], "target_nam": 36, "target_names_toi": 36, "tariff": 44, "task": [32, 33, 34, 35, 39, 40, 41, 43, 45, 46, 47, 48, 49, 51, 55, 58, 59], "tast": [41, 43], "taught": [33, 44, 59], "tax": 48, "tba": 10, "tbd": [19, 59], "teach": [4, 28, 32, 44, 48, 51], "team": [4, 8, 28, 38, 39, 44, 57], "tech": [31, 36, 39], "technic": [48, 59], "techniqu": [10, 31, 35, 40, 43, 45, 47, 50, 51, 59], "technolog": 0, "technologi": 44, "techsupport": 47, "techsupport_no": 47, "techsupport_y": 47, "ted": 41, "tediou": 42, "telco": 47, "telecom": 47, "telephon": 44, "tell": [30, 31, 32, 34, 36, 39, 40, 43, 44, 46, 47, 48, 53, 55, 58], "temp3pm": [46, 58], "temp9am": [46, 58], "temperatur": 29, "tempo": [31, 32, 35, 55], "tempor": [47, 51, 58], "tend": [30, 31, 34, 38, 40, 43, 46, 47, 59], "tendenc": 30, "tensor": 45, "tensor_numpi": 49, "tensorflow": [11, 39, 45], "tent": 59, "tenur": [47, 48, 51], "tenure_lm": 47, "tenure_predict": 47, "term": [0, 2, 29, 31, 33, 34, 36, 39, 40, 43, 44, 47, 48, 51], "termin": [5, 11, 29, 41], "terminologi": [14, 30, 36, 51, 52], "terrac": 45, "terribl": [37, 43], "territori": 59, "tesoro": 35, "test": [1, 7, 8, 11, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 42, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59], "test_accuraci": 36, "test_average_precis": 36, "test_df": [28, 32, 33, 34, 36, 37, 38, 39, 40, 46, 47, 48, 49, 54, 56, 57, 58], "test_df_churn": 47, "test_df_nan": [36, 38, 39, 56], "test_df_sort": 46, "test_df_surv": 47, "test_exampl": 38, "test_f1": 36, "test_format": 31, "test_g50k": 38, "test_imag": [28, 45], "test_l50k": 38, "test_mape_scor": 37, "test_nam": 47, "test_neg_mean_squared_error": 37, "test_neg_root_mean_square_error": 37, "test_point": [31, 50], "test_precis": 36, "test_r2": 37, "test_recal": 36, "test_roc_auc": 36, "test_sampl": 57, "test_scor": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 49, 53], "test_shap_valu": 39, "test_siz": [28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 48, 49, 50, 53, 54, 55, 56, 57], "test_sklearn": 37, "test_statist": 47, "test_x": 47, "text": [7, 10, 16, 17, 28, 29, 34, 35, 36, 37, 38, 39, 40, 43, 45, 48, 51, 55, 59], "text_feat": [35, 55], "text_featur": 49, "text_pp": 44, "textbook": [3, 9, 48], "textrm": 30, "textual": 59, "textur": 40, "tf": 33, "tfidfvector": 34, "th": [34, 43, 59], "than": [6, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 50, 52, 53, 56, 57, 59], "thank": [28, 44, 53], "thankfulli": [46, 58], "thei": [7, 8, 10, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 55, 56, 57, 58, 59], "theirs": 44, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 57, 59], "theme": 44, "themselv": [41, 42, 44], "theoret": [32, 36, 38, 51], "theori": 39, "thepopbreak": 49, "therefor": 53, "thermostat": 29, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 25, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "thick": 41, "thinc": 49, "thing": [5, 7, 8, 10, 29, 30, 31, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 53, 57, 58], "think": [4, 28, 29, 30, 31, 33, 34, 36, 37, 39, 40, 41, 43, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 59], "third": 42, "thk": 28, "thorough": [11, 57], "thoroughli": 51, "those": [5, 8, 11, 32, 37, 38, 39, 43, 47, 48, 59], "though": [30, 33, 34, 41, 42, 43, 49], "thought": [4, 31, 39, 47, 51], "thousand": [34, 42, 43], "threahold": 40, "threaten": 49, "three": [8, 29, 32, 34, 36, 38, 39, 40, 41, 42, 44, 45, 46, 50, 51, 56, 59], "thresh": 8, "threshold": [29, 34, 38, 40, 42, 44, 47], "thresholds_lr": 36, "thresholds_svc": 36, "through": [7, 11, 29, 36, 37, 40, 42, 43, 45, 48, 59], "throughout": [30, 48], "throw": [33, 45, 47, 48, 51], "thu": [6, 35, 46, 47], "thumb": [29, 49], "thursdai": 59, "ti": 33, "tick": 46, "tick_label": 39, "tick_param": 41, "tiger": [28, 45], "tight": [31, 42, 53], "tight_layout": [45, 48], "tightrop": [31, 53], "tile": 39, "till": [31, 44, 47], "timber": 44, "time": [2, 4, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 55, 56, 57, 59], "time_diff": [46, 58], "time_signatur": [31, 32, 35, 55], "timedelta": [46, 58], "timeit": [8, 50], "timelin": 48, "timeseri": [45, 46], "timeseriessplit": [46, 47, 51, 58], "timestamp": [46, 58], "timezon": [10, 47], "tinder": 43, "tini": [7, 30, 36, 42], "tip": 44, "tire": 49, "titan": 43, "titi": 28, "titl": [7, 30, 31, 34, 37, 40, 42, 45, 46, 47, 48, 53, 58], "tn": 36, "to_datetim": [46, 58], "to_html": [28, 29, 30], "to_notebook_ifram": 37, "to_numpi": [31, 43, 46], "to_str": [28, 45], "toarrai": [33, 39, 46], "tobago": [38, 39], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 43, 45, 46, 47, 51, 57, 58], "todens": [39, 40], "togeth": [5, 8, 29, 31, 32, 33, 41, 44, 53, 59], "toi": [8, 30, 31, 40, 41, 42, 43, 46, 51], "toilet": [45, 49], "token": [7, 49, 59], "token_pattern": 33, "tol": [36, 40, 48], "told": [5, 59], "tolist": [28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 47, 49, 58], "tomasbeuzen": 8, "tomorrow": [29, 46, 47, 51, 58], "ton": 35, "tone": 49, "too": [6, 7, 30, 31, 33, 35, 37, 38, 39, 46, 47, 48, 53, 55, 58, 59], "took": 46, "tool": [7, 8, 10, 11, 33, 34, 36, 37, 39, 42, 43, 45, 46, 47, 51, 59], "toolbox": [31, 38, 44], "toolkit": 44, "top": [29, 33, 35, 36, 42, 46, 48, 58], "topic": [2, 8, 10, 29, 36, 37, 41, 43, 45, 51, 59], "topic2vec": 44, "topics_per_chunk": 44, "topn": [28, 45], "torch": [45, 49], "torchvis": [28, 45], "tornado": 49, "toronto": [44, 48, 49], "tort": 0, "total": [8, 10, 29, 32, 33, 36, 37, 38, 39, 40, 44, 46, 47, 48, 58], "total_bedroom": [32, 33, 40, 54], "total_bilirubin": 28, "total_protien": 28, "total_room": [32, 33, 40, 54], "total_second": [46, 58], "totalbsmtsf": [37, 39, 48], "totalcharg": 47, "totem": 45, "totensor": 45, "toti": [0, 1, 44], "totrmsabvgrd": [37, 39, 48], "toward": [34, 39, 44, 56, 59], "towardsdatasci": [45, 47], "town": 49, "townsvil": 46, "toy_clust": 44, "toy_clust_df": 41, "toy_df": [33, 44], "toy_lda_data": 44, "toy_movie_feat": 43, "toy_rat": 43, "toy_spam": 33, "toy_x": 44, "tp": 36, "tpot": 35, "tpr": 36, "tpr_lr": 36, "tpr_svc": 36, "tr_score": 53, "traceback": [4, 8, 33, 47, 49], "track": [33, 59], "trade": [34, 36, 40, 41, 51, 59], "tradeoff": [15, 31, 32, 34, 37, 40, 41, 45], "tradit": [28, 43, 45, 47, 59], "tradition": 59, "trail": 8, "train": [7, 31, 32, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58], "train_accuraci": 36, "train_dataload": 45, "train_df": [28, 32, 33, 34, 36, 37, 38, 39, 40, 46, 47, 48, 49, 54, 56, 57, 58], "train_df_churn": 47, "train_df_nan": [36, 38, 39, 56], "train_df_ord": [46, 58], "train_df_sort": 46, "train_df_surv": 47, "train_df_surv_not_churn": 47, "train_f1": 36, "train_flatten": 45, "train_for_usr": 43, "train_load": 45, "train_mape_scor": 37, "train_mat": 43, "train_mat_imp": 43, "train_neg_mean_squared_error": 37, "train_neg_root_mean_square_error": 37, "train_precis": 36, "train_r2": 37, "train_recal": 36, "train_scor": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 47, 49, 53], "train_shap_valu": 39, "train_sklearn": 37, "train_test_split": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58], "train_x": 43, "traitlet": 49, "transact": [29, 36, 46, 48, 56], "transfer": 47, "transfer_learning_tutori": 45, "transform": [0, 31, 35, 36, 38, 39, 42, 44, 45, 46, 47, 49, 51, 53, 54, 58], "transformed_exampl": 38, "transformed_oh": 32, "transformedtargetregressor": [37, 40, 48, 49, 51], "transformedtargetregressortransformedtargetregressor": 37, "transformerdecod": 49, "transformerencod": 49, "translat": [9, 10, 28], "transpar": [36, 51], "transpos": [40, 45], "trasform": 32, "trash": 52, "traumat": 59, "treat": [8, 30, 32, 33, 36, 37, 43, 46, 47, 48, 51, 56, 58], "treati": 59, "treatment": 33, "tree": [2, 10, 14, 19, 20, 30, 31, 32, 33, 34, 35, 37, 40, 42, 45, 46, 47, 50, 51, 52, 54, 55, 57], "tree1": 38, "tree2": 38, "tree3": 38, "tree_numeric_transform": 39, "treeexplain": 39, "trend": [47, 51, 59], "tri": [38, 39, 48, 50, 55, 56, 57], "trial": [35, 47], "triangl": [31, 41], "trick": [5, 37], "tricki": [33, 35, 39, 43], "trigger": [31, 49], "trigram": 44, "trivial": 42, "troubl": 11, "true": [8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 58], "truli": [37, 44], "truncat": 42, "truncate_mod": 42, "truncation_mod": 42, "trust": [28, 32, 33, 35, 36, 37, 38, 39, 40, 43, 45, 48, 49], "trustworthi": [42, 57], "truth": [38, 40, 41, 42, 43, 46], "try": [4, 5, 8, 10, 11, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 59], "tsa": 46, "tscv": 46, "tslearn": 46, "tsunami": 28, "ttr": 37, "ttr_pipe": 37, "tue": 46, "tuesdai": [10, 40, 46, 58, 59], "tuggeranong": 46, "tumor": 51, "tune": [30, 35, 38, 42, 43, 45, 48, 55, 57], "turn": [4, 30, 44, 45, 47, 54, 55, 59], "tusker": 45, "tutori": [4, 5, 9, 10, 11, 43, 45, 51, 59], "tweak": [31, 53], "tweet": [44, 49], "tweetat": 49, "twice": [8, 30, 33, 34], "twinx": 48, "twist": 44, "twitter_allowed_char": 49, "two": [4, 6, 7, 8, 9, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 56, 59], "two_citi": 31, "two_song": 32, "two_songs_subset": 32, "tx": [34, 49], "tx_i": 48, "txt": [28, 45], "typ": [37, 39, 48], "type": [4, 8, 11, 29, 31, 32, 33, 35, 38, 40, 42, 43, 44, 45, 49, 51, 53, 54, 55, 58, 59], "typeerror": 47, "typic": [2, 7, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 46, 48, 55], "u": [4, 11, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 54, 55, 57, 58], "u6": 29, "u_1": 31, "u_2": 31, "u_i": 31, "u_n": 31, "ubc": [0, 4, 5, 8, 9, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 59], "ubc_img": 45, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 37, "ultim": [4, 30, 48], "ultralyt": 45, "uluru": [46, 58], "umbrella": 43, "un": [37, 47], "unabl": [28, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 47, 48, 49, 59], "unambigu": 44, "unassign": [41, 42], "unbalanc": 56, "unbias": [36, 56], "unced": 59, "uncertain": [34, 57], "uncertain_indic": 57, "uncertainti": [34, 36, 48], "unchang": 39, "uncia": [28, 45], "uncomfort": 43, "uncorrel": 39, "under": [0, 1, 7, 29, 30, 37, 45, 47], "under_sampl": 36, "underestim": 47, "underfit": [31, 34, 35, 45, 53, 55], "underli": [2, 39, 40, 41], "underneath": 7, "underpredict": 37, "undersample_pip": 36, "understand": [0, 1, 4, 7, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 56, 59], "understood": 36, "unemploi": 47, "unexpect": [33, 34, 35, 44], "unexplain": 37, "unf": [37, 39, 48], "unfinish": 37, "unfortun": [6, 35, 39, 41, 42, 55], "uniform": [35, 36, 42, 55], "unimport": [35, 39], "uninstal": 11, "uninterpret": 39, "unintuit": 8, "union": 8, "uniqu": [32, 33, 36, 37, 38, 39, 43, 44, 46, 47, 56, 58], "unit": [34, 36, 37, 38, 39, 44, 45, 47, 49], "unitless": 37, "univers": [1, 9, 44], "university_year": [33, 51], "unix": [5, 46], "unknown": [6, 44, 51], "unlabel": [28, 30, 42], "unless": [7, 59], "unlik": [8, 30, 31, 33, 37, 39, 41, 42], "unlimit": 46, "unlucki": 30, "unmarri": [38, 39], "unnam": 28, "unoffici": 59, "unqualifi": [36, 56], "unreason": [6, 37], "unreli": 30, "unscal": 32, "unseen": [29, 40, 41, 45, 53], "unsqueez": 45, "unstructur": 44, "unsupervis": [28, 43, 44, 45, 59], "unsur": [7, 48], "until": [4, 29, 30, 35, 40, 41, 42, 47, 48], "unus": 53, "unwieldi": [29, 32], "unzip": 39, "uoft": 44, "up": [7, 8, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 55, 59], "uparrow": 42, "upcom": 41, "updat": [10, 11, 31, 32, 33, 38, 41, 53], "update_cent": 41, "update_plot": [31, 53], "update_z": 41, "upgrad": [44, 49], "upload": 7, "upon": [0, 29, 30, 33, 36, 38, 39, 40, 41, 42, 44], "upper": [36, 47], "uppercas": 49, "upto": 46, "ur": 28, "urgent": [33, 44], "url": [4, 30, 36, 47, 56], "us": [0, 2, 4, 5, 10, 11, 34, 35, 39, 42, 43, 46, 47, 49, 51, 53, 54, 55, 56, 57, 58], "usa": [8, 30, 31, 34, 44], "usag": [32, 33, 36, 37, 40, 44, 46, 47, 58], "usec_": 47, "useless": [35, 39, 40], "user": [11, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 45, 47, 48, 49, 50, 51, 55], "user_global_n": 49, "user_id": 43, "user_inverse_mapp": 43, "user_kei": 43, "user_mapp": 43, "user_n": 49, "user_nam": 43, "usernam": 49, "userwarn": [29, 30, 33, 38, 39, 49], "usf": 33, "using_copy_on_writ": 47, "using_cow": 47, "usual": [10, 11, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 58, 59], "utc": [46, 47], "utcnow": 47, "util": [5, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 47, 48, 49, 51, 52, 53, 54, 55, 57], "utilities_allpub": 37, "utilities_nosewa": 37, "utility_mat": 43, "v": [3, 7, 10, 33, 34, 42, 44, 46, 47, 48, 51], "v1": [28, 36], "v10": 36, "v11": 36, "v12": 36, "v13": 36, "v14": 36, "v15": 36, "v16": 36, "v17": 36, "v18": 36, "v19": 36, "v2": [28, 36], "v20": 36, "v21": 36, "v22": 36, "v23": 36, "v24": 36, "v25": 36, "v26": 36, "v27": 36, "v28": 36, "v3": 36, "v4": 36, "v5": 36, "v6": 36, "v7": 36, "v8": 36, "v9": 36, "v_1": 31, "v_2": 31, "v_i": 31, "v_n": 31, "vacat": 34, "vaccin": [48, 49], "vader": 49, "vader_lexicon": 49, "vader_senti": 49, "vain": 35, "val": [43, 47], "valenc": [31, 32, 35, 49, 55], "valid": [10, 15, 29, 31, 33, 37, 38, 39, 40, 41, 43, 45, 47, 48, 49, 51, 54, 55, 56, 57, 58], "valid_dataload": 45, "valid_flatten": 45, "valid_load": 45, "valid_mat": 43, "valid_sample_df": 38, "valid_sample_i": 38, "valid_sample_x": 38, "valid_scor": 53, "valid_x": 43, "valu": [7, 8, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58], "valuabl": [40, 42, 59], "value_count": [29, 33, 36, 38, 39, 46, 47, 49, 56, 57, 58], "value_throttl": [31, 53], "valueerror": [8, 32, 33, 47], "values_format": [36, 56], "vancouv": [44, 48], "vanilla": 34, "var": [30, 32, 39, 49, 55], "var_": 39, "varada": [0, 1], "vari": [29, 35, 38, 42, 47, 53, 59], "variabl": [7, 8, 29, 32, 33, 34, 35, 37, 39, 40, 46, 47, 48, 53, 58], "varianc": [37, 39, 42, 46, 53], "variant": [39, 42], "variat": [30, 34, 36, 37, 40], "varieti": [28, 38, 44], "variou": [28, 31, 37, 39, 45, 46, 47, 48, 51, 53, 55, 59], "vault": 30, "ve": [7, 8, 28, 30, 31, 36, 37, 39, 43, 45, 46, 48, 50, 58], "vec": [33, 44, 45], "vec1": 44, "vec1_i": 44, "vec2": 44, "vec2_i": 44, "vec8": 33, "vec8_binari": 33, "vec_binari": 33, "vecom": 35, "vector": [15, 29, 34, 36, 43, 45, 48, 53, 57], "verb": [44, 49], "verbos": [28, 36, 38, 39, 48], "veri": [2, 4, 5, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 58, 59], "verifi": 56, "versa": [37, 53, 56], "version": [4, 5, 7, 8, 11, 30, 32, 34, 35, 37, 39, 42, 44, 46, 47, 49, 50, 56, 58, 59], "versu": 9, "vert": 39, "vertic": [29, 36, 46], "vgg": 45, "vgg16": 45, "vgg16_weight": 45, "via": [1, 4, 7, 11, 36, 40, 59], "vice": [37, 53, 56], "video": [1, 7, 8, 9, 10, 11, 19, 23, 24, 25, 26, 27, 43, 45, 47, 48, 53, 56, 59], "vietnames": 32, "view": [6, 7, 11, 28, 29, 39, 42, 45, 46, 47, 48], "viewpoint": 43, "vif": 39, "vikski": 44, "violat": [32, 33, 47, 59], "virginia": 45, "viridi": [35, 55], "visibl": 55, "vision": [10, 50], "visit": [8, 59], "visual": [10, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 45, 46, 47, 49, 51, 54, 55, 59], "viz": 48, "voc": [36, 38, 39, 56], "vocab": 44, "vocabulari": [33, 34, 44], "vocabulary_": 33, "voic": 28, "volcano": 28, "vote": [31, 32, 38, 50, 57], "voting_ndt": 38, "votingclassifi": [38, 57], "votingclassifierinot": 38, "votingregressor": 38, "w": [11, 33, 34, 37, 41, 44, 46, 48, 58, 59], "w_0": 34, "w_1": 34, "w_1x_1": 34, "w_2x_2": 34, "w_3x_3": 34, "w_4x_4": 34, "w_d": 34, "w_dx_d": 34, "w_j": 34, "wa": [4, 5, 11, 25, 29, 30, 32, 34, 36, 38, 39, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 58, 59], "wa_fn": 47, "wai": [0, 2, 6, 8, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 53, 55, 56, 58, 59], "wait": [4, 28, 29, 31, 33, 47, 59], "waitlist": 59, "waiv": 59, "walk": [31, 36, 53], "walker": [28, 45], "wallabi": 45, "want": [4, 6, 7, 8, 11, 28, 29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 54, 55, 56, 58, 59], "war": 43, "ward": 42, "warm": 32, "warm_start": [36, 48], "warn": [6, 30, 31, 33, 37, 38, 39, 47, 50, 57], "warranti": 0, "washington": 49, "washroom": 59, "wast": [4, 33, 48], "watch": [10, 11, 31, 34, 43, 44, 51], "water": 48, "waterfal": 39, "waterfront": [28, 29], "wavelet": 40, "wd": [37, 39, 48], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "weak": 51, "weather": [29, 46], "weatherau": [46, 58], "web": [5, 44, 51], "weblog": 44, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "wed": [10, 46], "wednesdai": [10, 46, 59], "week": [6, 13, 14, 30, 31, 32, 33, 36, 37, 38, 39, 43, 44, 46, 48, 56, 59], "weekdai": 46, "weekend": [8, 46, 48], "weekli": 49, "weight": [31, 38, 40, 43, 44, 45, 56, 59], "weighted_averag": 36, "weinberg": 39, "weird": 37, "welcom": [52, 59], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 51, 55, 58, 59], "welsh": [28, 45], "went": [37, 49, 55, 57], "were": [0, 6, 33, 34, 36, 37, 45, 46, 47, 48, 55, 57, 59], "what": [7, 8, 9, 29, 31, 35, 42, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "whatev": 40, "when": [4, 6, 7, 11, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 56, 57, 58, 59], "wher": 49, "where": [0, 7, 10, 11, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 48, 51, 53, 56, 58], "wherea": [2, 29, 34, 35, 37, 39, 42, 48], "whether": [0, 4, 7, 8, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 52, 57, 58, 59], "which": [4, 6, 8, 11, 30, 31, 32, 33, 34, 35, 37, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59], "whichev": 38, "while": [29, 30, 34, 35, 36, 38, 39, 41, 43, 44, 47, 49, 55], "white": [36, 38, 39, 42, 44], "whitespac": [44, 47], "who": [4, 5, 6, 28, 36, 39, 41, 42, 46, 47, 48, 49, 51, 59], "whole": [30, 35, 37, 39, 43, 55], "whom": [0, 49], "whose": 4, "why": [8, 30, 31, 36, 37, 38, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55], "wid": 36, "wide": [11, 34, 35, 38, 40, 43, 45, 48], "wider": [31, 53], "widespread": 44, "widget": [31, 36, 41, 42, 53], "width": [29, 30, 31, 36, 44, 52, 53], "wife": [28, 36, 38, 39], "wiki": [44, 48], "wiki_df": 44, "wiki_dict": 44, "wikipedia": [44, 45, 48], "wikipedia2vec": 44, "wild": [28, 30, 45], "willing": 36, "win": [31, 33, 38, 39, 40, 43, 50], "wind": 29, "winddir3pm": [46, 58], "winddir3pm_miss": [46, 58], "winddir3pm_ss": [46, 58], "winddir3pm_ssw": [46, 58], "winddir3pm_sw": [46, 58], "winddir3pm_w": [46, 58], "winddir3pm_wnw": [46, 58], "winddir3pm_wsw": [46, 58], "winddir9am": [46, 58], "windgustdir": [46, 58], "windgustspe": [46, 58], "window": [10, 47], "windsor": 49, "windspeed3pm": [46, 58], "windspeed9am": [46, 58], "wine_1": 8, "winter": 46, "winter_month": 46, "wire": 43, "wisdom": 38, "wish": [28, 29, 41, 48, 59], "within": [29, 32, 34, 38, 40, 41, 42, 47, 51, 55], "without": [0, 7, 28, 29, 36, 38, 39, 40, 43, 45, 46, 47, 48, 55, 59], "wnw": [46, 58], "wolv": 42, "woman": 44, "wombat": 45, "won": [5, 11, 29, 30, 31, 33, 34, 40, 43, 44, 45, 46, 47, 49], "wonder": [28, 30], "wooddecksf": [37, 39, 48], "word": [28, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 51, 55, 59], "word1": 44, "word2": 44, "word2vec": [44, 45, 59], "word3": 44, "word_pair": 44, "word_token": [44, 49], "wordnet": 44, "wordnetlemmat": 44, "work": [0, 4, 5, 7, 8, 11, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 55, 57, 58, 59], "work_of_art": 49, "workclass": [36, 38, 39, 56], "workclass_feder": [38, 39], "workclass_loc": [38, 39], "workclass_miss": 39, "workclass_nev": [38, 39], "workclass_priv": [38, 39], "workclass_self": 39, "workclass_st": 39, "workclass_without": 39, "workflow": [29, 59], "world": [31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 51], "worm": 45, "worri": [28, 41, 42, 43, 57], "wors": [29, 35, 37, 38, 47, 52, 55, 56], "worst": [36, 40, 41], "worth": [29, 31, 36, 37, 56], "worthi": 34, "would": [4, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59], "wouldn": [33, 35, 47], "wow": 39, "wrap": 33, "wrapper": 40, "write": [4, 7, 28, 35, 39, 40, 41, 44, 48, 49, 53, 57, 59], "written": [7, 33, 39, 46, 48, 58], "wrong": [11, 30, 34, 37, 40, 41, 47, 48, 55], "wrote": [44, 46, 58], "wsw": [46, 58], "www": [9, 34], "x": [4, 8, 11, 30, 31, 32, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56], "x0": 40, "x0_male": 36, "x1": [40, 43], "x139": 59, "x1x2": 40, "x2": [40, 42, 43], "x27": [32, 33, 35, 36, 37, 38, 40, 45, 48, 49], "x_": 34, "x_1": [34, 40, 41], "x_1x_2": 40, "x_2": [34, 40, 41], "x_binari": 29, "x_citi": 31, "x_count": 33, "x_d": 34, "x_femal": [36, 56], "x_hour": 46, "x_hour_week": 46, "x_hour_week_onehot": 46, "x_hour_week_onehot_poli": 46, "x_hour_week_onehot_poly_lag": 46, "x_i": [34, 43], "x_imp_ohe_train": 32, "x_init": 41, "x_int": 33, "x_label": [29, 30, 31, 52], "x_lag_featur": 46, "x_lag_features_imp": 46, "x_male": [36, 56], "x_mask": 33, "x_multi": 50, "x_n": 40, "x_orig": 42, "x_re": 36, "x_small_citi": 31, "x_spotifi": [31, 35, 55], "x_subset": [29, 30], "x_test": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57], "x_test_big": 35, "x_test_enc": [39, 46, 47, 48, 58], "x_test_happi": 36, "x_test_imp": 32, "x_test_multi": 50, "x_test_pr": 46, "x_test_predict": 32, "x_test_scal": 32, "x_test_transform": 32, "x_toi": [31, 32, 33, 46], "x_toy_oh": 32, "x_toy_ord": [32, 33], "x_tr": 53, "x_train": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57], "x_train_big": [36, 56], "x_train_enc": [36, 37, 39, 46, 47, 48, 56, 58], "x_train_happi": 36, "x_train_hous": 40, "x_train_imp": 32, "x_train_imp_sc": 32, "x_train_multi": 50, "x_train_oversampl": 36, "x_train_perm": 39, "x_train_pp": 33, "x_train_predict": 32, "x_train_scal": [32, 40], "x_train_subsampl": 36, "x_train_tini": 35, "x_train_transform": 32, "x_train_usr": 43, "x_transform": 33, "x_valid": [36, 43, 53, 56], "x_vari": 42, "x_xor": 40, "xanni": 35, "xavier": [40, 43], "xcode": 5, "xgbclassifi": [38, 39], "xgbclassifierxgbclassifi": 38, "xgboost": 39, "xgbregressor": [28, 38], "xia": 59, "xlabel": [8, 29, 30, 31, 34, 35, 36, 37, 39, 42, 45, 46, 47, 48, 50, 52, 55, 58], "xlim": 47, "xor": [34, 40], "xt": 33, "xtick": [30, 36, 46, 58], "xticklabel": [35, 55], "xticks_rot": 36, "xwm\u0259\u03b8kw\u0259y": 59, "xx": [40, 41], "y": [8, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 56, 58], "y_": 43, "y_citi": 31, "y_femal": [36, 56], "y_hat": [34, 38], "y_i": [37, 38, 40, 43], "y_init": 41, "y_label": [29, 30, 31, 52], "y_male": [36, 56], "y_mat": 43, "y_multi": 50, "y_pred": [36, 46], "y_pred_lower_threshold": 36, "y_pred_toi": 36, "y_pred_train": 46, "y_re": 36, "y_small_citi": 31, "y_spotifi": [35, 55], "y_test": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58], "y_test_big": 35, "y_test_happi": 36, "y_test_multi": 50, "y_test_num": [38, 39], "y_toi": [31, 46], "y_tr": 53, "y_train": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58], "y_train_big": [36, 56], "y_train_happi": 36, "y_train_hous": 40, "y_train_multi": 50, "y_train_num": [38, 39], "y_train_ord": [46, 58], "y_train_oversampl": 36, "y_train_subsampl": 36, "y_train_tini": 35, "y_train_usr": 43, "y_true": 48, "y_true_toi": 36, "y_valid": [36, 43, 45, 53, 56], "y_vari": 42, "y_xor": 40, "yale": 44, "yann": 39, "ycxmx": 47, "ye": [4, 28, 29, 32, 33, 39, 41, 42, 43, 45, 46, 48, 49, 51, 58], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 43, 44, 45, 46, 47], "yearbuilt": [37, 39, 48], "yearremodadd": [37, 39, 48], "yellow": 35, "yellowbrick": [41, 42], "yesterdai": [46, 58], "yet": [10, 11, 34, 39, 43, 46, 47, 53, 59], "yield": 55, "yifei": 59, "yjh": [28, 29, 33, 34, 37, 38], "ylabel": [8, 29, 30, 31, 34, 35, 36, 37, 42, 45, 46, 47, 48, 50, 52, 53, 55, 58], "ylim": [47, 48], "yml": 11, "yolo": 45, "yolo8": 45, "yolo_input": 45, "yolo_result": 45, "yolo_test": 45, "yolov8n": 45, "york": [46, 49], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 39, 44, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "your": [0, 2, 4, 6, 7, 8, 10, 11, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "your_miniconda_path": 49, "your_nam": 11, "yourself": [4, 33, 36, 43, 48, 59], "youtub": [1, 10, 43, 44, 48, 59], "yr_built": [28, 29], "yr_renov": [28, 29], "yrpxn": 47, "yrsold": [37, 39, 48], "ytick": [30, 36], "yticklabel": [35, 55], "yy": [40, 46, 58], "yyyi": [46, 58], "z": [8, 34, 40, 41, 42, 43, 45, 47], "z_i": 45, "z_j": 45, "z_km": 41, "z_train": 45, "z_valid": 45, "zachari": 47, "zarei": 59, "zero": [8, 30, 33, 35, 43, 44, 48], "zero_divis": 36, "zhu": 59, "zip": [31, 34, 43, 53], "zipcod": [28, 29, 53], "zmqshell": 49, "zone": [46, 58], "zoom": [7, 55, 59], "\u0259m": 59, "\u03bc": 50}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Class Meeting 4B", "Class Meeting 4C", "Class Meeting 5A", "Class Meeting 5B", "Class Meeting 5C", "Class Meeting 6A", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Lecture 21: Communication", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [28, 30, 31, 32, 33, 36, 37, 39, 46, 48], "0": 38, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58], "10": [18, 37, 57], "11": [20, 38], "12": [21, 38, 39], "13": [22, 40], "14": [23, 40, 41], "15": [23, 41, 42, 48], "16": [24, 42, 43], "17": [24, 43, 44], "18": [26, 45], "19": [26, 45, 46], "1a": 13, "1b": 14, "1c": 15, "2": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58], "20": [27, 47, 48], "2025s1": 1, "21": [27, 47, 48], "2a": 16, "2b": 17, "3": [15, 28, 29, 30, 32, 40, 41, 42, 47, 52, 53, 54, 55, 56, 57, 58], "330": [1, 2, 3, 6, 8], "340": 2, "3a": 18, "3b": 19, "3c": 20, "4": [15, 29, 30, 31, 48, 52, 53, 54, 55, 56, 57, 58], "4a": 21, "4b": 22, "4c": 23, "5": [8, 16, 29, 30, 31, 32, 33, 36, 39, 40, 41, 44, 45, 47, 48, 53, 54, 55, 56, 57, 58], "5a": 24, "5b": 25, "5c": 26, "6": [16, 33, 53, 55, 56, 57, 58], "6a": 27, "7": [17, 34, 55, 57, 58], "8": [17, 35, 55, 57], "9": [18, 36, 57], "A": [4, 36, 42, 46, 49], "No": 8, "Not": 51, "One": [32, 46, 50], "The": [30, 34, 35, 38, 40, 41, 57], "__": 35, "about": [8, 40, 43, 48], "academ": 59, "access": [7, 34, 59], "accommod": 59, "acknowledg": 59, "activ": [36, 39, 40, 41, 44, 48, 56], "actual": 33, "ad": 8, "addit": [7, 39], "address": 36, "advantag": 35, "advic": 40, "ai": 59, "aka": 48, "algorithm": [29, 31, 40, 41], "all": [28, 29, 32, 34, 36, 41, 42, 43, 48], "alpha": [34, 37], "altern": [29, 32], "an": [38, 48, 49], "analogi": 31, "analysi": [46, 47, 51, 53, 58], "angl": 48, "announc": [29, 31, 33, 34, 38], "answer": 47, "ap": 36, "api": 32, "appendix": [49, 50], "appli": [1, 8, 32, 33, 37, 48], "applic": 41, "applymap": 8, "approach": [43, 46, 47, 48, 50], "approxim": 30, "ar": [5, 28, 29, 32, 34, 36, 41, 42, 43], "area": 36, "argument": [30, 31], "around": 48, "arrai": 8, "articl": 9, "asap": 48, "ask": 4, "assign": [7, 59], "associ": 34, "assum": 47, "attent": [29, 31], "attribut": [39, 48], "auc": 36, "autom": 35, "averag": [36, 38, 43, 57], "avoid": 30, "b": [41, 50], "backward": 40, "bad": 35, "bag": [33, 49], "balanc": 36, "base": [31, 38, 40, 43, 46, 58], "baselin": [29, 32, 36, 38, 39, 43, 53], "basic": 44, "befor": 32, "best": 40, "better": [30, 35, 36, 40, 48], "between": [29, 31, 52], "beyond": [39, 43], "bia": [30, 35], "big": [29, 30, 32], "binari": 36, "book": 10, "boost": [38, 48], "bootstrap": 38, "bottom": 48, "boundari": [29, 31, 34, 52], "bow": 33, "box": 45, "break": [8, 29, 30, 31, 32, 33, 40, 44, 45, 47, 48], "broadcast": 8, "build": [28, 29, 37, 43], "c": [31, 35], "calcul": 34, "california": [33, 34, 54], "can": [8, 30, 32, 38, 39, 40, 41], "canada": [29, 52], "care": [43, 48], "carri": [32, 40], "case": [33, 34, 42], "catboost": 38, "categor": [32, 33, 39, 46], "categori": 33, "censor": 47, "centr": 59, "certain": 33, "cfa": 59, "chang": 36, "charact": 28, "characterist": 36, "cheatsheet": 8, "choos": [31, 41], "chunk": 48, "churn": 47, "cite": 7, "citi": 34, "claim": 48, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 35, 36, 37, 38, 39, 43, 45, 50, 59], "class_attend": 33, "class_weight": 36, "classif": [29, 36, 45, 51], "classifi": [29, 34, 38, 49], "clearli": 40, "cluster": [41, 42, 51], "co": 59, "code": [11, 59], "coeffici": [34, 39], "color": [52, 53, 54, 55, 56, 57, 58], "column": [8, 32, 33, 46], "columntransform": [33, 54], "combin": 38, "come": [30, 31], "command": 5, "comment": [29, 35, 36, 37, 41, 42, 43], "common": [32, 41], "commonli": 44, "commun": [48, 51], "compact": 32, "companion": 9, "complet": 43, "complex": 30, "complic": [46, 58], "compon": 34, "comprehens": 54, "comput": [45, 51], "con": [31, 42, 51], "concept": 48, "concern": 6, "concess": 59, "conda": 11, "conduct": 59, "confid": [34, 48], "confus": [36, 48], "consid": 47, "construct": 38, "content": 43, "context": 44, "continu": 29, "conveni": 33, "correct": 41, "correl": 39, "countri": [29, 52], "countvector": 33, "cours": [9, 10, 28, 59], "cover": [43, 47], "cox": 47, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 29, 30, 33, 43], "credit": [11, 59], "cross": [30, 32, 36, 40, 46, 53], "cross_val_scor": 30, "cross_valid": [30, 37], "csv": 8, "curs": 31, "curv": [36, 47], "custom": [41, 47], "cv": 35, "dai": 46, "data": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 53, 58], "datafram": [8, 33], "dataset": [7, 29, 32, 33, 34, 35, 36, 37, 45, 46, 48, 54, 57, 58], "date": [10, 46], "datetim": [46, 58], "dbscan": 42, "deal": [33, 36], "debug": 11, "decis": [29, 31, 34, 39, 48, 53], "decisiontreeclassifi": [29, 38], "decreas": 36, "deep": [45, 46], "defin": 40, "definit": 28, "deliver": 10, "demo": [40, 46, 49], "demonstr": 36, "dendrogram": 42, "depend": 40, "deploy": [30, 51], "descript": 59, "desktop": 5, "detail": [36, 37, 42], "detect": 45, "df": 8, "did": [30, 32, 33, 36, 37, 43, 47, 48], "differ": [32, 35, 36, 37, 39, 51], "dimens": 31, "dimension": 31, "discuss": [35, 36, 43, 44, 48, 56], "diseas": 28, "distanc": [31, 41], "distribut": 35, "do": [32, 33, 35, 36, 38, 39, 40, 48], "document": [3, 8, 41], "doe": [29, 34, 42, 48], "domain": 40, "drop": 8, "due": 10, "dummi": 49, "dummyclassifi": [29, 38, 46, 47], "dummyregressor": [29, 32, 37], "eda": [32, 36, 37, 53], "effect": [38, 48], "elbow": 41, "element": 8, "elimin": 40, "embed": 44, "encod": [32, 33, 40, 46], "engin": [40, 46, 49, 51], "ensembl": [38, 51], "environ": 11, "equal": 48, "error": [30, 35, 36, 37, 43], "estim": [32, 38], "ethic": 51, "euclidean": 31, "eva": [28, 30], "evalu": [36, 42, 43, 47, 51, 56], "evalut": 36, "event": 47, "everyon": 47, "exactli": 34, "exam": [51, 59], "examin": [33, 37, 48, 51], "exampl": [28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 44, 47, 48, 49], "exercis": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 43, 45, 47, 52], "exhaust": 35, "experi": 48, "explain": [39, 48], "explan": [39, 48], "explor": [31, 41], "exploratori": [46, 53, 58], "extract": [33, 46], "extractor": 45, "f1": 36, "failur": 42, "fair": [36, 56], "fancier": 35, "faster": 8, "fastest": 8, "featur": [28, 29, 31, 32, 33, 34, 37, 39, 40, 43, 45, 46, 48, 49, 51, 58], "feature_importances_": 39, "few": [36, 42, 48], "fictiti": 28, "figur": 7, "filter": [8, 43], "final": [29, 35, 41, 42, 43, 46, 51, 53, 59], "find": [31, 40], "first": 32, "fit": [29, 32, 38], "flatten": 45, "follow": [28, 29, 30, 41, 42, 43], "font": [52, 53, 54, 55, 56, 57, 58], "forecast": 46, "forest": [38, 39, 48], "format": [7, 8], "formul": 43, "forum": 4, "forward": 40, "from": [8, 48, 49], "function": [8, 34, 37], "fundament": [30, 31, 38, 51], "further": [46, 49], "futur": 46, "gamma": 31, "garbag": 40, "gb": 48, "gener": [4, 6, 30, 31, 34, 38, 40], "geometr": 31, "get": 39, "git": [5, 11], "github": 5, "given": [28, 29], "global": 43, "goal": 30, "golden": [30, 32, 33], "good": [36, 48], "grade": [4, 6, 29, 59], "gradescop": 7, "gradient": [38, 48], "grid": [35, 48], "gridsearchcv": [35, 37, 48], "group": [36, 41, 56], "guid": 51, "guidelin": [4, 6, 7], "ha": 28, "halv": 35, "handl": 36, "have": [38, 39, 48], "hazard": 47, "heatmap": 35, "help": [4, 40], "here": 30, "hierarch": 42, "home": 42, "homework": 7, "hot": [32, 40, 46], "hous": [28, 29, 32, 33, 34, 54], "how": [4, 7, 29, 30, 31, 32, 34, 38, 39, 40, 42, 48], "hyper": 35, "hyperparamet": [29, 31, 33, 34, 35, 37, 38, 41, 51, 53], "i": [28, 30, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 48, 49], "iclick": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 48, 59], "idea": [31, 36, 38, 40, 48], "identifi": [33, 39], "imag": [28, 45], "imagenet": 45, "imbal": [36, 37, 38, 39], "import": [1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 58], "improv": 49, "imput": [32, 43], "incorpor": 33, "increas": 36, "index": 8, "inertia": 41, "info": 7, "inform": [39, 46], "initi": 41, "inject": 38, "input": [28, 41], "instal": [5, 11], "instruct": [0, 7], "interact": 40, "intercept": 34, "interest": 48, "interim": [36, 39, 40, 46], "interpret": [34, 39], "intra": 41, "intro": 43, "introduct": [8, 28, 39, 40, 41, 42, 44, 45, 48, 51], "intuit": 34, "involv": [46, 48], "issu": 48, "jupyterlab": 11, "k": [31, 32, 41, 42, 43], "kaplan": 47, "kei": [39, 48], "kernel": 31, "kind": 38, "kneighborsclassifi": 31, "label": [28, 41, 48], "lag": [46, 58], "land": 59, "languag": 44, "larg": 35, "late": 7, "latitud": [29, 52], "lda": 44, "learn": [1, 5, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 59], "least": 34, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 59], "lecture03": 15, "let": [31, 32, 33, 36, 37, 39, 48], "licens": [0, 1], "lightgbm": 38, "limit": [6, 34, 42], "line": 5, "linear": [34, 37, 39], "link": 1, "list": 9, "liver": 28, "ll": 30, "lo": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 45, 46], "logist": [34, 36, 45], "logisticregress": [36, 46, 47, 48], "longitud": [29, 52], "look": [36, 41], "loop": 8, "loss": 48, "lower": 35, "mac": 5, "machin": [1, 28, 29, 30, 31, 36, 41], "maco": 11, "macro": 36, "magnitud": 34, "mai": 40, "main": [34, 43, 48], "make": [8, 34, 48], "make_column_transform": 33, "make_pipelin": 32, "mani": [33, 35], "manual": 35, "mape": 37, "materi": [0, 9, 10], "matplotlib": 8, "matric": 33, "matrix": [36, 43], "max_depth": 29, "mean": [37, 41, 42, 44, 48], "measur": 40, "media": 44, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 59], "meier": 47, "messag": [28, 42], "meta": 50, "method": [8, 35, 40, 41], "metric": [36, 37, 51], "midterm": [41, 59], "might": 47, "min": [8, 29, 30, 31, 32, 33, 36, 39, 40, 41, 44, 45, 47, 48], "minor": 36, "misc": [9, 10], "miscellan": 43, "mislead": 48, "ml": [28, 30, 31, 36, 39, 48, 51, 56], "model": [28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 44, 45, 47, 49, 51, 53, 56], "model_select": 35, "month": 46, "more": [29, 31, 32, 33, 34, 36, 37, 40, 42, 46, 58], "most": 34, "motiv": [30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48], "movi": 43, "mse": 37, "much": 35, "multi": [36, 45, 50], "multiclass": 51, "multipl": [31, 33, 37], "multipli": 8, "n_estim": 38, "n_iter": 35, "n_job": 35, "n_neighbor": 31, "name": [30, 37, 43], "natur": 44, "nearest": [31, 32, 41, 43], "need": [32, 35], "neg": 36, "neighbour": [31, 32, 43], "nest": 8, "netflix": 38, "network": 45, "neural": 45, "new": 48, "nlp": [44, 51], "nn": 31, "non": [31, 33, 39], "notat": 8, "note": [8, 30, 46, 53], "now": 47, "number": [38, 41, 46], "numer": [39, 40], "numpi": 8, "object": [29, 38, 44, 45, 46, 47, 48, 59], "observ": 36, "occasion": 32, "off": [30, 31, 38], "oh": [32, 33], "ok": [32, 33], "onc": 36, "one": [33, 40], "onehotencod": 33, "onli": [33, 47], "onlin": [9, 10], "oper": 36, "optim": [35, 51], "option": [11, 31, 32, 35, 36, 38, 40, 47], "ordin": [32, 33, 39, 59], "other": [8, 31, 37, 40, 41, 44, 46, 47, 48], "our": [7, 30, 32, 48, 49], "out": [32, 40, 45, 48], "outcom": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43], "outlin": [52, 53, 54, 55, 56, 57, 58], "output": 41, "over": [8, 31, 34, 36], "overfit": [30, 35], "oversampl": 36, "overview": [31, 36], "ovo": 50, "ovr": 50, "packag": [11, 46], "panda": 8, "pandas_profil": 37, "paper": [36, 38], "paradigm": 32, "paramet": [29, 34, 35, 36, 51], "parametr": 31, "pars": [46, 58], "part": 51, "pass": [35, 59], "patient": 28, "perfect": 41, "perhap": 48, "permutation_import": 39, "persona": 28, "pick": [30, 35], "pictur": [29, 30, 32], "piec": 48, "pipelin": [32, 44], "plan": 42, "playground": [31, 53], "plot": [8, 39, 41, 47], "point": [31, 36, 39, 41, 46], "polici": 6, "poll": 41, "popular": 28, "posit": 36, "posix": 46, "possibl": [33, 37, 41, 49], "post": 9, "pr": 36, "practic": [29, 31], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 22, 45], "precis": 36, "predict": [28, 29, 33, 34, 38, 39, 43, 45, 47, 50, 52], "predict_proba": [34, 48], "prefer": 48, "prepar": [7, 51], "preprocess": [32, 33, 37, 44, 46, 48, 51, 56, 58], "preval": 28, "price": [28, 29], "principl": 48, "prize": 38, "pro": [31, 42, 51], "probabl": [34, 35], "problem": [29, 30, 31, 32, 35, 40, 43, 46, 49], "procedur": 36, "process": 44, "product": 28, "profil": 43, "program": 29, "project": 49, "proport": 47, "python": [8, 9, 11], "q": 4, "qualiti": 40, "queri": [8, 31], "question": [4, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58], "quick": 31, "quiz": 29, "quiz2": 29, "quot": 40, "r": 37, "random": [35, 38, 39, 48], "random_st": 30, "randomforestclassifi": [38, 47], "randomizedsearchcv": [35, 37], "rang": 35, "rate": 43, "raw": 34, "rbf": 31, "re": 48, "read": [8, 29, 35, 45], "reader": 48, "real": [29, 52], "realist": 33, "reason": 6, "recal": 36, "recap": [29, 31, 42, 47, 48, 52, 54], "receiv": 36, "recommend": [32, 43, 51], "record": 59, "recurs": 40, "red": [52, 53, 54, 55, 56, 57, 58], "refer": [9, 10, 47], "reflect": [29, 30, 41, 42], "registr": 59, "regress": [29, 31, 34, 36, 37, 38, 45], "regressor": 31, "relat": [4, 29, 31, 48], "relev": [9, 36, 38, 40], "remark": 46, "rememb": 41, "remind": [29, 43], "remov": 8, "renam": 8, "report": [7, 36], "repositori": 7, "represent": [33, 45], "requir": 59, "rescu": 30, "resourc": [9, 35, 36, 40, 41, 42, 43], "rest": 50, "result": [35, 48], "retail": 46, "reus": 48, "review": 19, "rf": 48, "rfe": 40, "ridg": [34, 37], "ridgecv": 37, "right": 47, "rmse": 37, "roc": 36, "root": 37, "row": 8, "rule": [30, 32, 33], "run": [32, 48], "same": 8, "sampl": [36, 38, 41], "sauc": 41, "save": 28, "scale": [28, 32, 34, 39], "schedul": [10, 59], "scheme": 59, "scikit": [30, 32, 33, 37], "score": [29, 30, 34, 35, 36, 37, 40, 41, 49], "search": [31, 35, 40, 48], "season": 46, "segment": 41, "select": [28, 29, 40, 41, 42, 43, 51], "separ": [37, 39, 48], "seri": [8, 46, 51, 58], "set": [5, 11, 30, 35, 36], "set_config": 33, "shap": 39, "shape": [8, 42], "shaplei": 39, "short": 9, "should": [38, 43, 48], "show": [39, 48], "sigmoid": [34, 45], "sign": 34, "silhouett": 41, "similar": 31, "simpl": [30, 49], "simplefeatur": 39, "simul": 57, "singl": 30, "size": 8, "sklearn": [29, 32, 33, 35, 36, 38, 39], "slide": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27], "slowest": 8, "small": 48, "smote": 36, "social": 44, "softmax": 45, "softwar": [0, 45, 46], "solv": 35, "some": [29, 35, 36, 38, 40], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 46, "spaci": [44, 49], "spaghetti": 41, "spam": [28, 33], "spars": 33, "specif": [4, 40], "split": [30, 32, 36, 46, 53], "spotifi": [32, 35], "squar": 37, "stack": [38, 57], "standardscal": 32, "statement": [28, 29, 41, 42, 43], "step": [29, 44, 54], "strategi": [38, 50], "stratifi": 36, "strength": [34, 38], "studi": 51, "submiss": 7, "submit": 7, "success": 35, "summari": [8, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], "summer": 10, "supervis": [28, 29, 30, 31, 41, 43], "support": 31, "surviv": [47, 51], "svc": 36, "svm": [31, 34], "syllabu": [1, 59], "syntax": [32, 33, 35], "synthet": 36, "system": [43, 51], "ta": 59, "tabular": [29, 31], "tackl": 37, "take": 42, "target": [28, 29, 33, 37, 41], "task": 44, "teach": [10, 59], "team": 59, "techniqu": [32, 36], "templat": 7, "tempor": 46, "ten": 10, "tent": 10, "terminologi": [29, 45], "test": [5, 30, 35, 46], "test_df": 30, "test_siz": 30, "text": [33, 44, 49], "than": [33, 35, 40, 48], "thei": 38, "them": 8, "thi": [8, 28, 32, 33, 39, 48], "thing": [32, 48], "threshold": 36, "time": [6, 28, 46, 47, 51, 58], "tip": 51, "todai": [30, 32, 33, 36, 37, 48], "toi": [29, 33, 36, 44], "token": 44, "tool": 44, "topic": 44, "trade": [30, 31, 38], "tradeoff": [30, 36, 38], "tradit": [29, 46], "train": [28, 29, 30, 33, 34, 36, 45, 46, 48, 56], "train_df": 30, "train_siz": 30, "transfer": 45, "transform": [32, 33, 37, 40, 48], "transpar": 39, "tree": [29, 38, 39, 48, 53], "trend": 46, "true": [28, 41, 42, 43], "try": [32, 37, 48], "tune": [37, 41, 53], "tutori": [52, 53, 54, 55, 56, 57, 58], "two": 33, "type": [28, 30, 36, 37, 39, 41, 46, 47, 48], "typic": [30, 44], "u": 48, "ubc": 1, "ubuntu": 5, "under": 36, "underfit": 30, "undersampl": 36, "unequ": 46, "unknown": 33, "unlabel": 41, "unseen": [28, 30], "unsupervis": [29, 41], "up": [5, 11, 30, 31, 48], "updat": 7, "url": 8, "us": [7, 8, 28, 29, 30, 31, 32, 33, 36, 37, 38, 40, 41, 44, 45, 48, 50, 52, 59], "usa": [29, 52], "user": [5, 43], "usual": 40, "util": 43, "v": [2, 29, 30, 31, 36, 39, 41, 45, 50], "valid": [30, 32, 35, 36, 46, 53], "varianc": 30, "vector": [8, 31, 44], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 28, 29, 30, 31, 32, 34, 36, 37, 38, 41, 42, 44], "view": [31, 33], "violat": 30, "virtual": 11, "vision": [45, 51], "visual": [9, 35, 48], "wai": [35, 40, 48], "want": [33, 39, 47], "warn": [29, 40], "watch": 48, "we": [8, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48], "weak": 38, "weight": [34, 36], "what": [5, 11, 28, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 47, 48], "when": [8, 32, 35, 48], "where": [33, 47], "whether": 28, "which": [28, 29, 36, 38, 41, 42, 43], "why": [11, 28, 33, 35, 39, 40, 43, 45, 48], "window": [5, 11], "wise": 8, "without": 41, "word": [33, 44, 49], "work": [29, 38, 42, 48], "workflow": [28, 30, 36], "would": 30, "wrapper": 50, "write": 29, "x": [28, 29, 37, 39, 48], "xgboost": 38, "y": [28, 29, 37, 39, 48], "ye": 47, "yield": 35, "you": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48], "your": [5, 29, 48]}})