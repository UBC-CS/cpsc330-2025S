Search.setIndex({"alltitles": {"(Optional) Changing the data": [[31, "optional-changing-the-data"]], "(Optional) Evaluation": [[42, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[31, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[30, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[30, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[30, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[33, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[35, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[31, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[26, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[30, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[33, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[35, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[35, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[30, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Some more details": [[31, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[23, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[35, "id1"]], "(iClicker) Exercise 21.1": [[42, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[42, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[26, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[26, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[27, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[27, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[27, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[28, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[28, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[29, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[29, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[30, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[36, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[36, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[36, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[36, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[37, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[37, "id2"]], "16.3 Select all of the following statements which are True": [[37, "select-all-of-the-following-statements-which-are-true"]], "<font color='red'>Question 10</font>": [[51, "question-10"]], "<font color='red'>Question 1</font>": [[46, "question-1"], [47, "question-1"], [49, "question-1"], [50, "question-1"], [51, "question-1"], [52, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[47, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[46, "question-2"], [49, "question-2"], [50, "question-2"], [51, "question-2"], [52, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[47, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[46, "question-3"], [49, "question-3"], [50, "question-3"], [51, "question-3"], [52, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[47, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[46, "question-4"], [49, "question-4"], [50, "question-4"], [51, "question-4"], [52, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[47, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[49, "question-5"], [50, "question-5"], [51, "question-5"], [52, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[47, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[49, "question-6"], [50, "question-6"], [51, "question-6"], [52, "question-6"]], "<font color='red'>Question 7</font>": [[49, "question-7"], [51, "question-7"]], "<font color='red'>Question 8</font>": [[49, "question-8"], [51, "question-8"]], "<font color='red'>Question 9</font>": [[51, "question-9"]], "<font color='red'>Recap Questions</font>": [[46, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[48, "recap-comprehension-questions"]], "A few comments on PR curve": [[31, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[37, "a-few-comments-on-clustering-evaluation"]], "AP score": [[31, "ap-score"]], "AP vs. F1-score": [[31, "ap-vs-f1-score"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[53, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[29, "accessing-learned-parameters"]], "Activity (~5 mins)": [[34, "activity-5-mins"], [34, "id3"]], "Activity: Context and word meaning": [[39, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[35, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[31, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[30, "advantages-of-randomizedsearchcv"], [30, "id1"]], "Alternative and more compact syntax: make_pipeline": [[27, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[24, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[33, "an-effective-strategy"]], "An example from a project": [[43, "an-example-from-a-project"]], "An example of a bootstrap samples": [[33, "an-example-of-a-bootstrap-samples"]], "Analogy-based algorithms in practice": [[26, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[26, "analogy-based-models"]], "Announcements": [[29, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[43, null]], "Appendix B: Multi-class, meta-strategies": [[44, null]], "Applying feature transformations": [[32, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[42, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[42, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[42, "approach-3-survival-analysis"]], "Are we doing better with class_weight=\"balanced\"?": [[31, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[31, "area-under-the-curve-auc"]], "Assignments": [[53, "assignments"]], "Attention": [[24, null], [24, null], [24, null], [26, null]], "Automated hyperparameter optimization": [[30, "automated-hyperparameter-optimization"], [30, "id3"]], "Averaging": [[33, "averaging"]], "Averaging simulation": [[51, "averaging-simulation"]], "Bad range for hyperparameters": [[30, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[28, "bag-of-words-bow-representation"]], "Bag-of-words model": [[43, "bag-of-words-model"]], "Baseline": [[31, "baseline"], [34, "baseline"]], "Baseline Approaches": [[38, "baseline-approaches"]], "Baselines": [[24, "baselines"], [33, "baselines"]], "Baselines [video]": [[24, "baselines-video"]], "Basic text preprocessing [video]": [[39, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[35, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[38, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[25, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[24, "big-picture-and-datasets"]], "Big picture and motivation": [[25, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Break (5 min)": [[8, "break-5-min"], [24, "break-5-min"], [25, "break-5-min"], [26, "break-5-min"], [27, "break-5-min"], [28, "break-5-min"], [35, "break-5-min"], [39, "break-5-min"], [40, "break-5-min"], [42, "break-5-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a supervise machine learning model": [[23, "building-a-supervise-machine-learning-model"]], "Building decision trees with sklearn": [[24, "building-decision-trees-with-sklearn"]], "Building user profiles": [[38, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[36, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[27, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[28, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[33, "catboost"]], "Categorical features": [[34, "categorical-features"]], "Categorical features [video]": [[27, "categorical-features-video"]], "Categorical features with only two possible categories": [[28, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[42, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[53, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[31, "changing-the-training-procedure"]], "Characters in this course?": [[23, "characters-in-this-course"]], "Choosing K [video]": [[36, "choosing-k-video"]], "Choosing n_neighbors": [[26, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Meeting 4B": [[22, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"], [22, "class-slides"]], "Class imbalance in training sets": [[31, "class-imbalance-in-training-sets"]], "Class meetings": [[53, "class-meetings"]], "Classification report": [[31, "classification-report"]], "Classification vs. Regression": [[24, "classification-vs-regression"]], "Clustering": [[45, "clustering"]], "Clustering Activity (~5 mins)": [[36, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[36, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[36, "clustering-input-and-possible-output"]], "Code of conduct": [[53, "code-of-conduct"]], "Coefficients and intercept": [[29, "coefficients-and-intercept"]], "ColumnTransformer example": [[28, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[28, "columntransformer-on-the-california-housing-dataset"], [48, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[28, "columntransformer-transformed-data"]], "Coming up \u2026": [[25, "coming-up"]], "Coming up:": [[26, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[36, "common-applications"]], "Common preprocessing techniques": [[27, "common-preprocessing-techniques"]], "Communication": [[45, "communication"]], "Completing the utility matrix with content-based filtering": [[38, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[29, "components-of-a-linear-classifier"]], "Confusion matrix (video)": [[31, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[31, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[26, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[38, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[28, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[53, "course-learning-objectives"]], "Course co-ordinator": [[53, "course-co-ordinator"]], "Course description": [[53, "course-description"]], "Cox proportional hazards model": [[42, "cox-proportional-hazards-model"]], "Create X and y": [[24, "create-x-and-y"]], "Create a classifier object": [[24, "create-a-classifier-object"]], "Create a column transformer": [[28, "create-a-column-transformer"]], "Creating train_df and test_df": [[25, "creating-train-df-and-test-df"]], "Creating utility matrix": [[38, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[31, "cross-validation-with-different-metrics"]], "Cross-validation": [[41, "cross-validation"], [41, "id4"]], "Cross-validation [video]": [[25, "cross-validation-video"]], "Cross-validation to the rescue!!": [[25, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[25, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[26, "curse-of-dimensionality"]], "Customer churn": [[42, "customer-churn"]], "Customer segmentation": [[36, "customer-segmentation"]], "DBSCAN [video]": [[37, "dbscan-video"]], "DBSCAN introduction": [[37, "dbscan-introduction"]], "DBSCAN: failure cases": [[37, "dbscan-failure-cases"], [37, "id1"]], "Data": [[28, "data"], [29, "data"], [33, "data"], [34, "data"], [34, "id1"]], "Data Splitting [video]": [[25, "data-splitting-video"]], "Data and main approaches": [[38, "data-and-main-approaches"]], "Data exploration": [[36, "data-exploration"]], "Data splitting": [[47, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[40, "dataset"]], "Dataset [video]": [[32, "dataset-video"]], "Dataset for demonstration": [[31, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[27, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[31, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[28, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[24, "decision-boundary"]], "Decision boundary for max_depth=1": [[24, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[24, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[24, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[26, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[29, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[24, "decision-tree-algorithm"]], "Decision tree feature importances": [[34, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[24, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[24, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[24, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[24, "decision-trees-video"]], "Decision trees with continuous features": [[24, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[33, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[24, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decreasing the threshold": [[31, "decreasing-the-threshold"]], "Deep learning": [[41, "deep-learning"]], "Deep learning software": [[40, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of feature engineering with numeric features": [[35, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[41, "demo-a-more-complicated-dataset"]], "Dendrogram": [[37, "dendrogram"]], "Deployment (Not examinable)": [[45, "deployment-not-examinable"]], "Different models": [[34, "different-models"]], "Different range for hyperparameters yields better results!": [[30, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[32, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[26, "dimensions-in-ml-problems"]], "Discussion question": [[39, "discussion-question"]], "Distance between feature vectors": [[26, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[28, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[33, "do-we-have-class-imbalance"], [34, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[34, "do-we-have-correlated-features"]], "Document clustering": [[36, "document-clustering"]], "Domain-specific transformations": [[35, "domain-specific-transformations"]], "Dummy classifier": [[43, "dummy-classifier"]], "DummyClassifier": [[24, "dummyclassifier"], [41, "dummyclassifier"], [42, "dummyclassifier"]], "DummyClassifier baseline": [[33, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[24, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[24, "dummyregressor"], [32, "dummyregressor"]], "EDA": [[27, "eda"], [31, "eda"], [32, "eda"]], "EDA: Exploratory Data Analysis": [[47, "eda-exploratory-data-analysis"]], "Encoding text data": [[28, "encoding-text-data"]], "Encoding time as a number": [[41, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[41, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[45, "ensembles"]], "Ethics": [[45, "ethics"]], "Euclidean distance": [[26, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[37, "evaluating-dbscan-clusters"]], "Evaluation": [[38, "evaluation"], [38, "id3"]], "Evaluation metrics": [[45, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[31, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[31, "evalution-metrics-overview"]], "Examining the preprocessed data": [[32, "examining-the-preprocessed-data"]], "Example": [[29, "example"], [33, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[23, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[36, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[24, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[24, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[23, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[23, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[34, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[35, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[23, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[36, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[24, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[24, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[31, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[27, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[23, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[38, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[38, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[24, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[24, "exercise-2-4"]], "Exercise 8.2": [[30, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[46, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[30, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[34, "explaining-a-prediction"]], "Exploratory data analysis": [[41, "exploratory-data-analysis"], [52, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[28, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[41, "extracting-date-and-time-information"]], "F1-score": [[31, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[35, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[41, "feature-engineering"]], "Feature engineering and selection": [[45, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[41, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[41, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[35, "feature-engineering-motivation"]], "Feature importances": [[34, "feature-importances"], [45, "feature-importances"]], "Feature importances in linear models": [[34, "feature-importances-in-linear-models"], [34, "id2"]], "Feature interactions and feature crosses": [[35, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[32, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[35, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[27, "feature-transformations-and-the-golden-rule"]], "Feature types": [[32, "feature-types"], [32, "id1"]], "Feature vectors": [[26, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[30, "final-comments-and-summary"], [38, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[24, "final-comments-summary-and-reflection"], [36, "final-comments-summary-and-reflection"], [37, "final-comments-summary-and-reflection"]], "Final exam": [[53, "final-exam"]], "Final exam preparation: guiding questions": [[45, null]], "Final note": [[47, "final-note"]], "Final remarks": [[41, "final-remarks"]], "Finding the distances to a query point": [[26, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[26, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[41, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[41, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[38, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "Garbage in, garbage out.": [[35, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[35, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[33, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[26, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[35, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[25, "generalization-video"]], "Generalization: Fundamental goal of ML": [[25, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[29, "generalizing-to-more-features"]], "Generalizing to unseen data": [[25, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[26, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[38, "global-average-baseline"]], "Golden rule violation: Example 1": [[25, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[25, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[33, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[33, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[53, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[31, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[25, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[37, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[29, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[25, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[34, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[33, "how-do-they-work"]], "How do we carry out feature selection?": [[35, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[24, "how-does-fit-work"], [24, "id2"]], "How does it work?": [[37, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[29, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[24, "how-does-predict-work"]], "How to approximate generalization error?": [[25, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[27, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[26, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[25, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[29, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[45, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[30, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[36, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[26, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[30, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[28, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[40, "imagenet"]], "Import": [[43, "import"]], "Importance of scaling": [[29, "importance-of-scaling"]], "Important hyperparameters": [[33, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[28, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[36, "important-points-to-remember"]], "Imports": [[23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [52, "imports"]], "Imports and LO": [[30, "imports-and-lo"], [32, "imports-and-lo"], [40, "imports-and-lo"], [41, "imports-and-lo"]], "Imports and LOs": [[31, "imports-and-los"]], "Imports and learning outcomes": [[36, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[24, "imports-announcements-los"]], "Imports, Announcements, and LO": [[28, "imports-announcements-and-lo"], [29, "imports-announcements-and-lo"]], "Imports, LOs": [[25, "imports-los"], [27, "imports-los"], [34, "imports-los"]], "Imports, announcements, LOs": [[33, "imports-announcements-los"]], "Imports, announcements, and LOs": [[26, "imports-announcements-and-los"]], "Imputation": [[27, "imputation"]], "Imputation and scaling [video]": [[27, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[28, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[31, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[36, "inertia"]], "Initialization of K-Means": [[36, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[33, "inject-randomness-in-the-classifier-construction"]], "Input data": [[23, "input-data"]], "Input features X and target y": [[23, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interim summary": [[31, "interim-summary"], [34, "interim-summary"], [35, "interim-summary"], [41, "interim-summary"]], "Interpretation of coefficients": [[29, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[29, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[34, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[37, "introduction"], [45, "introduction"]], "Introduction to NLP": [[45, "introduction-to-nlp"]], "Introduction to computer vision": [[40, "introduction-to-computer-vision"]], "Introduction to neural networks": [[40, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[36, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[43, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[31, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[28, "is-this-a-realistic-representation-of-text-data"]], "Is \u201cRelevance\u201d clearly defined?": [[35, "is-relevance-clearly-defined"], [35, "id2"], [35, "id3"], [35, "id4"], [35, "id5"], [35, "id6"], [35, "id7"]], "K-Means algorithm": [[36, "k-means-algorithm"]], "K-Means clustering [video]": [[36, "k-means-clustering-video"]], "K-Means example": [[36, "k-means-example"]], "K-Means limitations": [[37, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[37, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[37, "k-means-recap"]], "K-Means: failure case 1": [[37, "k-means-failure-case-1"]], "K-Means: failure case 2": [[37, "k-means-failure-case-2"]], "K-Means: failure case 3": [[37, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[42, "kaplan-meier-survival-curve"]], "Key point": [[34, "key-point"]], "LDA topics in social media": [[39, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[36, "labeled-vs-unlabeled-data"]], "Lag-based features": [[41, "lag-based-features"], [41, "id5"], [52, "lag-based-features"]], "Land acknowledgement": [[53, "land-acknowledgement"]], "Large datasets solve many of these problems": [[30, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[29, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[39, "learning-objectives"], [40, "learning-objectives"], [41, "learning-objectives"], [42, "learning-objectives"]], "Learning outcomes": [[23, "learning-outcomes"], [24, "learning-outcomes"], [25, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[38, "learning-outcomes"]], "Least confident cases": [[29, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[32, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[33, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[34, null]], "Lecture 13": [[22, "lecture-13"]], "Lecture 13: Feature engineering and feature selection": [[35, null]], "Lecture 14: K-Means Clustering": [[36, null]], "Lecture 15: More Clustering": [[37, null]], "Lecture 16: Recommender Systems": [[38, null]], "Lecture 17: Introduction to natural language processing": [[39, null]], "Lecture 18: Multi-class classification and introduction to computer vision": [[40, null]], "Lecture 19: Time series": [[41, null]], "Lecture 1: Course Introduction": [[23, null]], "Lecture 20: Survival analysis": [[42, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[24, null]], "Lecture 3: Machine Learning Fundamentals": [[25, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[26, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[27, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[28, null]], "Lecture 7: Linear Models": [[29, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[30, null]], "Lecture 9: Classification metrics": [[31, null]], "Lecture learning objectives": [[33, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[37, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[53, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[27, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[28, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[26, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[27, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[34, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[31, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[32, "let-s-separate-x-and-y"], [34, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[32, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[27, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[33, "lightgbm"]], "Limitations of linear models": [[29, "limitations-of-linear-models"]], "Linear SVM": [[29, "linear-svm"]], "Linear models [video]": [[29, "linear-models-video"]], "Linear regression": [[29, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Logistic regression [video]": [[29, "logistic-regression-video"]], "Logistic regression intuition": [[29, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[29, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[40, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[41, "logisticregression"], [42, "logisticregression"]], "MAPE": [[32, "mape"]], "ML fairness activity": [[50, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[31, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[45, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[23, "machine-learning-workflow"], [31, "machine-learning-workflow"]], "Magnitude of the coefficients": [[29, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[29, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[29, "main-hyperparameters"]], "Manual hyperparameter optimization": [[30, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[36, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[36, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[32, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[23, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[36, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[36, "method-2-the-silhouette-method"]], "Midterms": [[53, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[38, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[32, "model-building"]], "Model complexity and training error": [[25, "model-complexity-and-training-error"]], "Model interpretability beyond linear models": [[34, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[23, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[50, "model-training-and-evaluation"]], "Model-based selection": [[35, "model-based-selection"]], "More comments on tackling class imbalance": [[32, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[37, "more-details-on-dbscan"]], "More on feature transformations": [[28, "more-on-feature-transformations"]], "More on k-NNs [video]": [[26, "more-on-k-nns-video"]], "More terminology [video]": [[24, "more-terminology-video"]], "More than one ordinal columns?": [[28, "more-than-one-ordinal-columns"]], "Most confident cases": [[29, "most-confident-cases"]], "Motivating example": [[29, "motivating-example"]], "Motivation": [[30, "motivation"], [41, "motivation"]], "Motivation [video]": [[33, "motivation-video"]], "Motivation and big picture [video]": [[27, "motivation-and-big-picture-video"]], "Motivation and context": [[39, "motivation-and-context"]], "Motivation and distances [video]": [[26, "motivation-and-distances-video"]], "Movie features": [[38, "movie-features"]], "Multi-class classification": [[40, "multi-class-classification"]], "Multiclass classification and computer vision": [[45, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[28, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[25, null], [25, null], [41, null]], "Number of trees and fundamental trade-off": [[33, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[28, "ohe-with-many-categories"]], "Object detection": [[40, "object-detection"]], "Observations": [[31, "observations"]], "One Vs. One approach": [[44, "one-vs-one-approach"]], "One Vs. One prediction": [[44, "one-vs-one-prediction"]], "One vs. Rest": [[44, "one-vs-rest"]], "One-hot encoding (OHE)": [[27, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[41, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[41, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[28, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[31, "operating-point"]], "Optimization bias of hyper-parameter learning": [[30, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[30, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[30, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[30, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[30, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[27, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[34, "ordinal-features"]], "Other applications": [[36, "other-applications"]], "Other approaches / what did we not cover?": [[42, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[39, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[32, "other-possible-preprocessing"]], "Other software package": [[41, "other-software-package"]], "Other tools for preprocessing": [[39, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[39, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[26, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[35, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[25, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[46, "outline"], [47, "outline"], [48, "outline"], [49, "outline"], [50, "outline"], [51, "outline"], [52, "outline"]], "Over confident cases": [[29, "over-confident-cases"]], "Overfitting": [[25, "overfitting"]], "Overfitting of the validation data": [[30, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[30, "overfitting-of-the-validation-error"]], "Oversampling": [[31, "oversampling"]], "Overview": [[26, "overview"]], "POSIX time feature": [[41, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[31, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[24, "parameters"]], "Parameters and hyperparameters: Summary": [[24, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[41, "parsing-datetimes"], [52, "parsing-datetimes"]], "Part 1": [[45, "part-1"]], "Part 2": [[45, "part-2"]], "Passing Requirements": [[53, "passing-requirements"]], "Pipelines": [[27, "pipelines"]], "Playground": [[26, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[24, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 13 Videos": [[22, "pre-lecture-13-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[31, "precision"]], "Precision and recall: toy example": [[31, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[31, "precision-recall-f1-score-video"]], "Precision-recall curve": [[31, "precision-recall-curve"], [31, "id1"]], "Precision/Recall tradeoff": [[31, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[23, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[29, "predicting-probability-scores-video"]], "Predicting with learned weights": [[29, "predicting-with-learned-weights"]], "Prediction": [[42, "prediction"]], "Prediction of linear regression": [[29, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[29, "prediction-with-learned-parameters"]], "Predictions": [[40, "predictions"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[28, "preprocessing"], [41, "preprocessing"], [45, "preprocessing"], [50, "preprocessing"], [52, "preprocessing"]], "Preprocessing the targets?": [[28, "preprocessing-the-targets"]], "Prevalence of ML": [[23, "prevalence-of-ml"]], "Problem formulation": [[38, "problem-formulation"]], "Problem: Different transformations on different columns": [[27, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[30, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[25, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[26, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[45, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[26, "question"]], "Question for you": [[37, "question-for-you"]], "Questions for class discussion": [[38, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[30, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[26, "quick-recap"]], "RFE algorithm": [[35, "rfe-algorithm"]], "R^2 (not in detail)": [[32, "r-2-not-in-detail"]], "Random forest feature importances": [[34, "random-forest-feature-importances"]], "Random forests": [[33, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[33, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[33, "randomforestclassifier"], [42, "randomforestclassifier"]], "Randomized hyperparameter search": [[30, "randomized-hyperparameter-search"]], "Range of C": [[30, "range-of-c"]], "Raw scores": [[29, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[24, "reading-the-data"], [40, "reading-the-data"]], "Real boundary between Canada and USA": [[24, "real-boundary-between-canada-and-usa"], [46, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[31, "recall"]], "Recap": [[42, "recap"]], "Recap and motivation [video]": [[37, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[24, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[31, "receiver-operating-characteristic-roc-curve"]], "Recommender systems": [[45, "recommender-systems"]], "Recommender systems intro and motivation": [[38, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[38, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[35, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[42, "references"]], "Registration": [[53, "registration"]], "Regression scoring functions": [[32, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[26, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[26, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[26, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[33, "relevant-papers"]], "Relevant papers and resources": [[31, "relevant-papers-and-resources"]], "Relevant resources": [[35, "relevant-resources"]], "Reminder": [[38, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Report format": [[7, "report-format"]], "Resources": [[36, "resources"], [37, "resources"], [38, "resources"]], "Ridge": [[29, "ridge"]], "Ridge on the California housing dataset": [[29, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[32, "ridgecv"]], "Root mean squared error or RMSE": [[32, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[34, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[34, "shap-plots"]], "SMOTE idea": [[31, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[31, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[26, "svm-regressor"]], "Saving time and scaling products": [[23, "saving-time-and-scaling-products"]], "Scaling": [[27, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[27, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[53, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[26, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[41, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[23, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[40, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[29, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[36, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[26, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[43, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[25, "simple-train-test-split"]], "SimpleFeature correlations": [[34, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[33, "some-important-hyperparameters"]], "Some quotes on feature engineering": [[35, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[24, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[30, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[28, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[33, "stacking"], [51, "stacking"]], "Step 1": [[48, "step-1"]], "Step 2": [[48, "step-2"]], "Step 3": [[48, "step-3"]], "Step 4": [[48, "step-4"]], "Step 5": [[48, "step-5"]], "Steps to train a classifier using sklearn": [[24, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[31, "stratified-splits"]], "Strengths and weaknesses": [[33, "strengths-and-weaknesses"]], "Strengths of linear models": [[29, "strengths-of-linear-models"]], "Study tips": [[45, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[23, "summary"], [26, "summary"], [33, "summary"], [39, "summary"], [40, "summary"], [42, "summary"]], "Summary and reflection": [[25, "summary-and-reflection"]], "Summary of linear models": [[29, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[25, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[37, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[38, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[36, "supervised-learning"]], "Supervised learning (Reminder)": [[24, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[24, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[23, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[26, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[26, "support-vectors"]], "Survival analysis": [[45, "survival-analysis"]], "Survival plots": [[42, "survival-plots"]], "Syllabus": [[1, "syllabus"], [53, null]], "TAs": [[53, "tas"]], "Tabular data": [[24, "tabular-data"]], "Take-home message": [[37, "take-home-message"]], "Teaching Team": [[53, "teaching-team"]], "Terminology": [[40, "terminology"]], "Terminology [video]": [[24, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[33, "the-netflix-prize"]], "The __ syntax": [[30, "the-syntax"]], "The best features may be dependent on the model you use.": [[35, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[51, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[25, "the-golden-rule"]], "The random forests classifier": [[33, "the-random-forests-classifier"]], "The sigmoid function": [[29, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[25, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[36, "the-perfect-spaghetti-sauce"]], "Time series": [[45, "time-series"]], "Time series analysis on a more complicated dataset": [[52, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[42, "time-to-event-and-censoring"]], "Tokenization": [[39, "tokenization"]], "Topic modeling": [[39, "topic-modeling"]], "Topic modeling motivation": [[39, "topic-modeling-motivation"]], "Topic modeling pipeline": [[39, "topic-modeling-pipeline"]], "Topic modeling toy example": [[39, "topic-modeling-toy-example"]], "Toy datasets": [[24, "toy-datasets"]], "Traditional time series approaches": [[41, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[41, "train-test-split-for-temporal-data"]], "Train/test splits": [[41, "train-test-splits"]], "Train/validation/test split": [[25, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[23, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[29, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[25, "training-error-vs-generalization-error"]], "Training models with transformed data": [[28, "training-models-with-transformed-data"]], "Transfer learning": [[40, "transfer-learning"]], "Transformations on the toy data": [[28, "transformations-on-the-toy-data"]], "Transforming the targets": [[32, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[34, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[33, "tree-based-ensemble-models"]], "Tree-based models": [[33, "tree-based-models"]], "Tuning alpha hyperparameter of Ridge": [[32, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[46, null]], "Tutorial 2": [[47, null]], "Tutorial 3": [[48, null]], "Tutorial 4": [[49, null]], "Tutorial 5": [[50, null]], "Tutorial 6": [[51, null]], "Tutorial 7": [[52, null]], "Types of censoring": [[42, "types-of-censoring"]], "Types of errors": [[25, "types-of-errors"]], "Types of machine learning": [[23, "types-of-machine-learning"], [36, "types-of-machine-learning"]], "Types of problems involving time series": [[41, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[42, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[25, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[25, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[31, "undersampling"]], "Unequally spaced time points": [[41, "unequally-spaced-time-points"]], "Unsupervised learning": [[36, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[53, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[44, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[31, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[36, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[32, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[40, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[40, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[32, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[28, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[30, "visualizing-the-parameter-grid-as-a-heatmap"]], "Warning": [[24, null]], "Warnings about feature selection": [[35, "warnings-about-feature-selection"], [35, "id8"]], "Weaknesses": [[33, "weaknesses"]], "What all transformations we need to apply on the dataset?": [[27, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[27, "what-are-the-options"]], "What are we exactly learning?": [[29, "what-are-we-exactly-learning"]], "What did we cover?": [[38, "what-did-we-cover"]], "What did we learn today?": [[25, "what-did-we-learn-today"], [27, "what-did-we-learn-today"], [28, "what-did-we-learn-today"], [31, "what-did-we-learn-today"], [32, "what-did-we-learn-today"]], "What if we apply OHE?": [[28, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[39, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[38, "what-is-a-recommender-system"]], "What is clustering?": [[36, "what-is-clustering"]], "What is feature engineering?": [[35, "what-is-feature-engineering"]], "What is feature selection?": [[35, "what-is-feature-selection"]], "What is model interpretability?": [[34, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[23, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[31, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[33, "what-kind-of-estimators-can-we-combine"]], "What to look for in these plots?": [[36, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[27, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When is it OK to do things before splitting?": [[27, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[30, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[33, "which-model-should-i-use"]], "Which type of error is more important?": [[31, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[30, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[34, "why-do-we-want-this-information"]], "Why feature selection?": [[35, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[23, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[34, "why-model-transparency-interpretability"]], "Why neural networks?": [[40, "why-neural-networks"], [40, "id1"]], "Why not neural networks?": [[40, "why-not-neural-networks"], [40, "id2"]], "Why should we care about recommendation systems?": [[38, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[28, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[39, "word-embeddings"]], "Word vectors with spaCy": [[39, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[24, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[33, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[31, "class-weight-balanced"]], "cross_val_score": [[25, "cross-val-score"]], "cross_validate": [[25, "cross-validate"]], "fit and transform paradigm for transformers": [[27, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[24, "fit-the-classifier"]], "fit, predict , and score summary": [[24, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[53, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[32, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[32, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[33, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[33, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[35, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[40, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[24, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[24, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[24, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[25, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[25, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[31, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[31, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[26, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[38, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[30, "n-iter"]], "n_jobs=-1": [[30, "n-jobs-1"]], "pandas_profiler": [[32, "pandas-profiler"]], "predict the target of given examples": [[24, "predict-the-target-of-given-examples"]], "predict_proba": [[29, "predict-proba"]], "random_state argument": [[25, "random-state-argument"]], "score your model": [[24, "score-your-model"]], "sklearn API summary: estimators": [[27, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[27, "sklearn-api-summary-transformers"]], "sklearn set_config": [[28, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[28, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[34, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[34, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[43, "spacy"]], "test score vs. cross-validation score": [[25, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[25, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[25, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[31, "questions-for-group-discussion"], [50, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[23, "questions-for-you"], [24, "questions-for-you"], [24, "id1"], [24, "id3"], [25, "questions-for-you"], [25, "id1"], [26, "questions-for-you"], [26, "id1"], [27, "questions-for-you"], [27, "id1"], [27, "id2"], [28, "questions-for-you"], [28, "id1"], [29, "questions-for-you"], [29, "id1"], [29, "id2"], [30, "questions-for-you"], [30, "id2"], [31, "questions-for-you"], [31, "id2"], [32, "questions-for-you"], [32, "id2"], [33, "questions-for-you"], [33, "id1"], [33, "id2"], [35, "questions-for-you"], [36, "questions-for-you"], [36, "id2"], [37, "questions-for-you"], [37, "id3"], [38, "questions-for-you"], [38, "id1"], [38, "id2"], [40, "questions-for-you"], [41, "questions-for-you"], [41, "id1"], [41, "id2"], [41, "id3"], [42, "questions-for-you"], [42, "id1"], [42, "id2"], [42, "id3"], [42, "id4"]], "\ud83e\udd14 Eva\u2019s questions": [[23, "eva-s-questions"], [25, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/classes/class4B", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/classes/class4B.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "0": [0, 1, 7, 8, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "00": [10, 23, 24, 26, 28, 29, 30, 31, 34, 37, 38, 41, 42, 52, 53], "000": [23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 39, 40, 42, 43], "0000": [27, 29, 31, 39, 43], "00000": [30, 41, 52], "000000": [24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 52], "00000000e": 34, "000000e": 30, "000001": 32, "00000e": 26, "000010": 32, "000011": 31, "000021": 27, "000036": 31, "000057": 27, "000065": 30, "000067": 30, "000077": 30, "000087": 29, "000089": 29, "0001": [29, 31, 32, 42], "000100": [27, 32], "000108": 29, "000113": 31, "000114": 30, "000117": 32, "000130": 29, "000136": 40, "000137": 30, "000145": 30, "000146": 29, "000147": 30, "000149": 27, "000150": 29, "000151": 30, "000155": [27, 31], "000159": 30, "000163": 30, "000166": [29, 30], "000177": [27, 41], "000180": 27, "000181": 30, "000182": 29, "000183": 29, "000187": 29, "000188": 27, "000190": 41, "000192": 41, "000194": 29, "000195": 27, "000198": 31, "000201": 30, "000206": 30, "000208": 27, "000210": 30, "000212": 35, "000213": 29, "000218": 29, "000221": 32, "000226": 32, "000227": 31, "000231": 27, "000232": 40, "000234": [26, 30], "000235": [27, 31], "000240": 27, "000245": 30, "000247": 40, "000255": 29, "000256": 41, "000259": 27, "000260": 27, "000271": 41, "000273": 40, "000274": 40, "000281": 29, "000283": 29, "000285": 29, "000286": 30, "000289": 27, "000294": 30, "000312": 31, "000332": 32, "000336": 40, "000339": 30, "000348": 30, "000353": 30, "000354": 30, "000363": 40, "000366": 31, "000370": 30, "000371": 29, "000373": 32, "000378": 29, "00038": 30, "000397": 32, "000399": 40, "000433": 32, "000435": 40, "000437": 40, "000452": 27, "000459": 29, "000471": 41, "000472": 40, "000489": 30, "000492": 31, "000498": 41, "000503": 30, "000508": 30, "000520": 32, "000575": 41, "00058": 30, "000580": 26, "000630": 31, "000633": 26, "000637": 40, "000647": 26, "000650": 26, "000651": 26, "000652": 32, "000655": 26, "000661": 26, "000671": 26, "000678": 30, "000713": 32, "000726": 31, "000737": 41, "000747": 30, "000748": 27, "000752": 26, "000758": 40, "000765": 27, "000774": 27, "000786": 31, "000787": 26, "00079": 30, "000794": 26, "000795": 26, "000797": 26, "000803": 32, "000829": 26, "000831": 26, "000832": 32, "000867": 27, "000869": 41, "000873": 26, "000889": 26, "000891": 31, "000917": 30, "000927": 31, "000936": 26, "000945": 35, "000960": 40, "000964": 35, "000976": 30, "000977": 26, "000982": 30, "001": [23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 40, 42, 43], "0010": 29, "00100": 30, "001000": [30, 32], "001002": 25, "001006": 25, "001010": 25, "001011": [26, 32], "001014": 25, "001016": 25, "001017": 25, "001026": 25, "001027": 25, "001029": 25, "001038": 25, "001040": 31, "001043": 27, "001057": [25, 30], "001060": 27, "001063": 25, "001064": 40, "001068": 34, "001071": 25, "001078": 25, "001086": 25, "001087": 35, "001103": 25, "001111": 25, "001139": 26, "001149": 25, "001155": 35, "001162": [30, 35], "001174": 25, "001205": 31, "001220": 29, "001224": 26, "001226": 40, "001236": 30, "001239": 31, "001266": 32, "001279": 35, "001286": 31, "001294": 25, "001299": 25, "001305": 25, "001307": 25, "001315": 25, "001317": 25, "001322": 25, "001323": 25, "001325": 26, "001329": 25, "001337": 25, "001338": 29, "001347": 30, "001352": 25, "001361": 29, "001362": 29, "001365": 26, "001371": 28, "001390": 25, "001391": 25, "001392": 26, "001400": 28, "001406": 32, "001407": 25, "001412": 30, "001414": 26, "001422": 32, "001423": 30, "001429": 25, "001433": 32, "001441": 25, "001448": 28, "001453": 25, "00146": 30, "001466": 28, "001467": 30, "001492": 30, "001495": 26, "001563": 28, "001566": 32, "001585": 30, "001586": 26, "001591": 28, "001594": 30, "001595": 26, "001600": 26, "001604": 28, "001606": 28, "001608": 30, "001616": 30, "001620": 30, "001629": 30, "001641": 40, "001645": 29, "001647": 28, "001679": 30, "001682": 30, "001693": 35, "001699": 25, "0017": 31, "001700": 31, "001710": 29, "001715": 28, "001740": 32, "001769": 30, "001773": 26, "001776": 25, "001790": 32, "001792": 30, "001847": 35, "001850": 29, "001877": 26, "001894": 32, "001900": 26, "001920": 28, "001922": 28, "001933": 32, "001949": 35, "001952": 26, "0019627889": 39, "001968": 25, "001994": 35, "002": [25, 29, 33, 34, 39, 42], "002003": 30, "002022": 28, "002030": 26, "002045": 30, "002057": [27, 28], "002083": 26, "002096": 40, "002105": 30, "002116": 28, "002118": 26, "002123": 30, "002143": 25, "002146": 30, "002158": 35, "002159": 30, "002197": 30, "002221": 32, "002321": 29, "00234": 30, "002355": 35, "002385": 32, "002441": 35, "002460": 40, "002525": 40, "002561": 30, "002646": 35, "002664": 35, "002675": 30, "002682": 40, "002690": 27, "002692": 30, "002704": 30, "002711": 40, "002746": 32, "002783": 30, "002788": 28, "002789": 28, "002807": 28, "002835": 30, "002858": 28, "002867": 35, "002889": 31, "0029": 42, "002910": 28, "002934": 29, "002940": 40, "002948": 26, "002962": 40, "002986": 40, "002999": 30, "003": [30, 33], "003013": 28, "003014": 30, "003015": 30, "003027": 30, "003038": 30, "003083": 30, "003086": 28, "003115": 28, "003124": 32, "003133": 32, "003146": 28, "003148": 29, "003166": [27, 35], "003181": 27, "003183": 35, "003185": 42, "003186": 28, "003188": [27, 28], "003194": 29, "003212": 27, "003242": 40, "003257": 40, "003273": 25, "003283": 40, "003288": 32, "003300": 27, "00332": 30, "003324": 27, "003365": 28, "003401": 35, "003421": 30, "003423": 35, "003427": 35, "003472": 30, "003477": 40, "003479": 30, "003483": 30, "003493": 35, "003528": 30, "003529": 30, "003547": 32, "003563": 30, "003633": 30, "003647": 40, "00369": 30, "003748": 30, "003757": 30, "003785": 32, "003885": 30, "003919": 30, "003919287722401839": 30, "00392157": 40, "003923": 28, "003924": 35, "003933": 30, "003998": 30, "004": [26, 30, 33, 34, 40], "004057": 30, "004065": 41, "004082": 41, "004121": 32, "004143": 32, "004264": 25, "004293": 30, "004305": 30, "004337": 30, "00435173": 36, "004352": 36, "004398": 34, "004402": 30, "004466": 30, "004496": 30, "004521": 32, "004529": 34, "004556": 30, "004574": 32, "004602": 32, "00461": 30, "004714": 30, "004723": 34, "004761": 34, "004770": 27, "004801": [27, 28], "004807": 28, "004826": 32, "004829": 32, "004854": 32, "004884": 40, "004919": 30, "004934": 31, "004952": 30, "004959": 30, "00496": 30, "005": [23, 33, 34, 42], "005067": 27, "005074": 40, "005093": 27, "005098": 32, "005114": 32, "005126": 30, "005151": 30, "005157": 27, "005167": 32, "005196": 30, "005241": 32, "00525962": 27, "005269": 32, "005288": 28, "005335": 30, "005336": 32, "005387": 31, "005423": 30, "005426": 30, "00543825": 27, "005440": 40, "005478": 34, "00548": 30, "005538": 32, "005579": 32, "005641": 32, "005674": 32, "005699": 25, "005708": 30, "00573": 30, "005734": 30, "005735": 30, "005767": 30, "005809": 41, "005834": 30, "005836": 27, "005888": 27, "006": [33, 34, 42], "006012": 30, "006046": 32, "006055": 30, "006067": 32, "006106": 30, "006110": [26, 30, 32], "006236": 32, "006244": 30, "006435": 30, "006452": 29, "006476": 32, "006505": 40, "006531": 25, "006545": 30, "006546893270012566": 29, "006557": 29, "006578": [27, 28], "006652": 30, "006667": 30, "00667": 30, "006744": 32, "006805": 25, "006861": 30, "006904": 30, "00691": 30, "006973": 27, "007": [27, 33, 34, 42, 43], "007068": 35, "00715": 30, "00720988e": 34, "007228": 32, "007291": 28, "007316": 25, "007361": 31, "007362": 30, "007434": 34, "007458": [27, 28], "007517": 32, "007544": 30, "007563": 30, "007588": 36, "00758803": 36, "00759438": 34, "007655": 30, "007666": 31, "00767": 30, "007737": 32, "007776": 32, "007818": 30, "007938": 25, "007986": 32, "008": [33, 34, 43], "008040": 41, "008120": 32, "008153": 30, "008167": [27, 28], "00830586": 28, "008306": 28, "008322e": 42, "008333": 28, "008346": 32, "008377": 30, "008472": 32, "008577": 40, "008581": 32, "008606": 32, "008617": 32, "008667": 30, "00871": 30, "008735": 26, "008785": 32, "009": [28, 33, 42], "009059": 25, "009063": 30, "009082": 30, "009090": 32, "009132": 30, "009140": 32, "009297": 30, "009305": 30, "009339": 32, "009422": 25, "009512": 30, "009514e": 32, "009664": 32, "009692": 40, "009724": 35, "01": [26, 27, 29, 30, 31, 32, 34, 40, 41, 42, 44, 52], "010": [23, 29, 30, 42, 43], "0100": 29, "01000": 30, "010000": [27, 30, 32], "010027": 29, "010183": [27, 28], "0102": [26, 30], "010208": 35, "010294": 25, "010650": 25, "010679": 25, "010688": 35, "010715": 30, "010750": 35, "011": [23, 28, 40, 42], "011210": 35, "011234": 31, "011248": 32, "011252": 35, "011269e": 32, "011287": 35, "011332": 42, "011336": 26, "011440": 32, "011617": 30, "011678": 31, "011767": 32, "011773": 33, "012": [27, 28, 33, 34, 40, 42, 43], "012019": 25, "012030": 35, "012232": 32, "012240": 35, "012252": 30, "012616": 30, "012624": 32, "012707": 31, "012758": 32, "013031": 32, "01311996071": 32, "013120": 34, "013157": 30, "013161": 30, "013433": 26, "013629": 30, "013706928443177698": 30, "013707": 30, "013863": 30, "013888": 30, "014": [25, 27, 33, 34, 42], "014030": 32, "014081e": 32, "01409912": 39, "014305": 32, "01432486e": 34, "014481": 30, "014503": 30, "014650": 42, "014730": 28, "01473536": 26, "014758": 42, "015": [23, 27, 28, 33, 42, 43], "015003": 30, "015039": 31, "015056": 30, "015165": 32, "015372": 30, "015724": 35, "015755": 30, "015819": 30, "016263": 30, "016372": 30, "01647": 30, "016525": [32, 34], "016555": 29, "016587": 31, "016598": 30, "016602": 30, "016607": 30, "016676": 36, "016688": [27, 35], "016693": 32, "016807": 29, "016815": 30, "016918": 31, "016944": 26, "017": [28, 40], "017185": 30, "017226": 32, "017308": 30, "017427": 30, "017610": 34, "017696": 34, "017737": 34, "017741": 34, "017829": [41, 52], "017837": 30, "01784": 30, "017927": 30, "017959e": 32, "017972": 27, "018": 33, "018014": 34, "018046": 31, "018077": 30, "018178": 26, "018243": 30, "018310": 26, "018434": [41, 52], "018459e": 32, "018487": 29, "0185": 29, "018505": 30, "018507e": 32, "018558": 30, "018581": 32, "018653": 30, "018745": 23, "018789": 30, "018846": 30, "018854": 31, "019": 33, "019012": 30, "019163": 30, "019381838999846482": 30, "019382": 30, "019396": 30, "019444": 28, "019446": 30, "019531": 31, "019556": 42, "0195598": 29, "019574": 30, "019839": 30, "02": [26, 27, 28, 29, 30, 32, 34, 35, 41, 42, 48, 52], "02000e": 26, "020123": 32, "020403": 30, "020414": 30, "020641": 34, "020648": 32, "020653": 25, "020833": 38, "020862": 32, "020873": 27, "021": [33, 43], "021043": 31, "021100": 27, "021281": 30, "021305": 26, "021345": 30, "021523": 31, "021603": 40, "021721": 30, "021746": 30, "021813": 31, "021862": 30, "021900": [26, 30], "022039": 31, "022331": 34, "022433": 30, "022629": 30, "022686": 30, "022848": 25, "022866": 31, "023": [33, 40], "023086": 42, "023105": [41, 52], "023305": 32, "023366": 35, "023367": 31, "023511": 30, "023554": 32, "023636": 31, "023666": 30, "023810": 43, "024": 33, "024028": 30, "024122": 30, "024291": 41, "024351e": 32, "024390": 35, "02446630e": 34, "024540": 27, "025": [27, 31], "025381": 34, "025391": [27, 28], "025396": 30, "025489": 34, "025689": 30, "025910": 26, "025998": [27, 28], "026": 42, "0261": [26, 30], "026620": 30, "026777": 30, "02677733855112973": 30, "026793": [32, 34], "026972": 32, "027070": 32, "027112": [41, 52], "027321": 35, "027484": 32, "027578": 32, "028023": 31, "02807617": 39, "028337": 30, "028351": 30, "028420": 32, "028672": 35, "028772": 32, "029": 39, "029137": 31, "029146": 31, "029164": [41, 52], "029198": 30, "029264": 32, "029409": 32, "029475": 32, "029909": 25, "029950e": 32, "02d": 41, "03": [29, 30, 32, 34, 40, 41, 42, 43, 52], "030": 34, "03017665e": 34, "030200": 27, "030343": 32, "030349": 32, "030408": 26, "03049217": 26, "0305": 26, "030739733331869412": 29, "030786": 32, "030805": 32, "031": 28, "031070": 32, "031385": 26, "031483": 32, "031564": 27, "031794": 32, "031863": 32, "0319": 39, "031994": 32, "032140": 32, "032280": 31, "032324": 30, "032404": 30, "032566": 28, "03256625": 28, "032656": 26, "032874": 26, "033165": 32, "033222": 42, "033267": 41, "033279": 34, "033305": 40, "033322": 32, "033459": 26, "0335": 30, "033723": 32, "033739": 32, "033780": 42, "033833": 31, "0339": 27, "034071": 31, "03411038e": 34, "034132": 32, "0344": [26, 30], "034894": 34, "034977": 32, "034979e": 32, "035": 40, "0351": 27, "03516073": 34, "035161": 34, "035223": 32, "035230": [41, 52], "035722": 32, "036": [27, 33, 40], "036136": 35, "0362": 27, "036646": 32, "036749": 31, "036764": 31, "036886": 33, "0370": 27, "0373": 27, "037414": [41, 52], "037785": 31, "0378": [27, 42], "038102": 29, "038609": 32, "038707": 34, "038948": 32, "039": 40, "039498": 29, "039741": 26, "0399": 27, "04": [27, 28, 30, 32, 34, 41, 42, 48, 52], "040": 33, "040129": 42, "040497": 31, "040698e": 32, "040954": 42, "040984": 41, "041": [33, 40], "041031": 31, "04108378": 29, "041084": 29, "041129": 26, "041201": 31, "041488": 32, "041704": 34, "041769": 32, "042081": 34, "042382": 35, "042743": 32, "042957": [27, 28], "043": 30, "043257": 28, "043319": 34, "043509": 30, "0437": [24, 25, 26, 46], "043890": 26, "044": [26, 30], "044029": [27, 28], "044166": 29, "044253": 34, "044313": 27, "044409": 32, "044614": 30, "044873": 25, "045": [24, 40], "045267": 41, "045280": 31, "045304": 26, "045415": 27, "045481": [41, 52], "046": 40, "04600e": 26, "046020": 26, "046116": 30, "046193e": 32, "046216": 30, "046638": 28, "0468": 42, "0469": 27, "046945": 30, "04709519e": 34, "0474": 29, "047567": 32, "04774884": 36, "047749": 36, "048": [25, 28], "048378": 25, "04861878": 36, "048630": 41, "048860": 27, "048889": 32, "049": [28, 40], "05": [26, 27, 30, 31, 32, 37, 41, 42, 52], "050": [23, 40], "050110e": 32, "050132": [27, 28], "051": 40, "051269": [27, 28], "05137470e": 34, "051392": 40, "051472": 26, "051620": 27, "051824": 32, "051925": 30, "052": 27, "052349": 27, "052607": 31, "052790": 31, "052819": 31, "05290827e": 34, "053156": 36, "05350962": 44, "0537": 30, "053763": 25, "053918": 30, "054054": 31, "054461": 31, "054653": 28, "05465323": 28, "054669": [32, 34], "054784": 28, "05478443": 28, "055": [25, 27, 28], "055100": 30, "055915e": 32, "05598498": 28, "055985": 28, "056": 40, "056478": [27, 28], "05656664": 39, "056703": 31, "057": [27, 40], "057003": 26, "057082": 32, "057254": 42, "057296": 31, "057331": 32, "057646": 26, "057729": 31, "057732e": 42, "057793": [27, 28], "057910": [27, 28], "058": 33, "0580": [25, 29], "058298": 32, "058311": 31, "059": [23, 27], "059077": 31, "0591": 27, "059242": [27, 28], "059360": 40, "059588": 30, "059863": 26, "06": [27, 30, 32, 37, 39, 40, 41, 42, 44, 52], "060": 40, "060477": 32, "060543": 35, "061100": 27, "061206": 31, "061241": 26, "061312": 32, "061313": 40, "061937": 26, "062": [23, 26, 30], "062043": 30, "062449": 42, "062658e": 32, "062723": 25, "062792": 26, "062793": 39, "063004": 35, "063110": [27, 28], "063173": 34, "064": [30, 34], "06405": 30, "064050": 30, "064200": 26, "064307": 35, "064452": 26, "065": 40, "065169": 30, "065199": 31, "065449": 32, "065463": 31, "066166": 42, "066251": 25, "066605": 30, "066667": 27, "0667579112160865": 29, "066810": 42, "066944": 30, "067119": 27, "067120": 25, "06797961": 32, "067991": 27, "068": 23, "068214": [29, 30], "068291": 40, "068498": 30, "068775": 30, "068891": 30, "069150": 34, "06915047": 34, "069188": 42, "0694": [26, 30], "069530": 26, "07": [30, 32, 35, 41, 42, 52], "070081": 30, "070195": 30, "070850": 31, "070898": 30, "070907": 25, "070929": 31, "071": 40, "071330": [41, 52], "071541": [27, 28], "071654": 35, "07174469222": 32, "071745": 34, "071975": 35, "072": 33, "072043": 30, "072243": 34, "0723": 27, "072396": 30, "07245741": 32, "072595": 30, "072707": 25, "073058": 27, "073233": 29, "073366": 27, "074": [27, 33], "0741": 26, "074141": 26, "07418": 30, "074327": 33, "074418": 40, "074475": 27, "074719": 28, "07471942": 28, "075000": 38, "075170": 41, "075453": 42, "075467": 42, "075747": 30, "076104": 32, "0762": 27, "076284": 36, "07639": 30, "076533": 32, "076798": 26, "077": [33, 40], "077204": 34, "077749": 39, "077761": 42, "077803": 30, "078": [29, 33], "0780": [24, 25, 46], "078052": 31, "07808506982896266": 32, "078243": 30, "078387": 42, "078552": 30, "078740": 30, "07877994e": 44, "078880": 28, "079": 30, "079282": 30, "079377": 42, "0794": [26, 30], "079471e": 32, "079852e": 32, "08": [27, 30, 32, 35, 37, 40, 41, 42, 52], "080": 40, "08002986030": 28, "080084": 30, "080165": 30, "080319": 28, "08031924": 28, "080694": 34, "080734": 25, "0808": 30, "081": 23, "08116": 30, "081167": 42, "081292": 41, "08151507e": 34, "081837": 42, "082": 27, "082100": 30, "082251": 29, "082265e": 42, "082749": 26, "082835": 34, "082949": 26, "083": [26, 30, 33], "083123": [27, 28], "083338": 25, "08338644": 39, "083545": 31, "083615": 30, "083813": [27, 28], "084288": 30, "084746": [27, 28], "085150": 41, "085415": 34, "085477": 31, "085508": 32, "085546": 32, "085550": 32, "085551": 32, "085693": 30, "085698": 32, "08613": 30, "08642578": 39, "086461": 35, "086932": 25, "087": 28, "087128": 30, "08740234": 39, "087668": 30, "08791477": 39, "087996e": 30, "088": 40, "0880": 27, "088543": 30, "088948": 26, "089294": 30, "089313": 30, "089485": 25, "09": [25, 28, 30, 32, 41, 42, 52], "090000": 31, "09009799": 32, "090231": 34, "090376e": 32, "090453": 31, "090473": 30, "09058097218": 23, "090785": 32, "091": 40, "091243": 30, "091625": 35, "091819": 25, "092": 33, "092072": 30, "092123": 30, "0922": [26, 30], "092204": 25, "09245358900622544": 30, "092454": 30, "092604": 25, "092660": 42, "092670": 30, "092729": 30, "092930": 28, "093051": 30, "0931": 30, "093228": 35, "093390": 26, "09345386": 28, "093454": 28, "093624": 25, "093787": 30, "093893": 30, "094": [23, 39], "094290": 42, "09430199": 28, "094302": 28, "094581": 28, "094586": 31, "094725": 30, "094863": 30, "095018": 30, "09503409246217484": 32, "095177": 30, "095345": 30, "09573445": 30, "09619141": 39, "096462": 32, "096692": 27, "096722": 30, "096858": 30, "096927": 31, "096960": 32, "096990": 25, "096997": 40, "097": 40, "09706504": 40, "097088": 42, "097184": 30, "097293": [27, 28], "097516": 27, "097707": 30, "097763": 30, "098": [29, 40], "098152": 30, "098307": 32, "098326": [26, 40], "098559": 30, "098629e": 30, "098663": 30, "0989147678053208": 29, "098915": 29, "098950": 30, "098966": 27, "099": 33, "099230": 34, "099240": [27, 28], "099454": 30, "099558": [27, 28], "099685": 32, "099723": 27, "099729": 30, "099749": [41, 52], "099802": 30, "099869": 30, "0x1227a36e0": 8, "0x1577111f0": 30, "0x16888d4c0": 30, "0x168921100": 30, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 34, 39, 41, 43, 44, 53], "10": [4, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53], "100": [24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 49, 52], "1000": [25, 26, 28, 29, 30, 31, 32, 34, 35, 40, 41, 42, 43, 44, 49, 50], "10000": [24, 28, 29, 30, 32, 41, 52], "100000": [26, 28, 29, 30, 32, 41, 52], "1000000": 30, "100103": 41, "100105": 30, "100139": 28, "100146": 41, "100248": 26, "100275": 35, "1004": 26, "1005": [41, 52], "1006": [41, 52], "1007": [41, 52], "1008": [41, 52], "100882": 31, "1009": [41, 52], "10092665203438746": 32, "101": [9, 10, 36, 40, 42], "1010": [41, 52], "1012": [41, 52], "101259": 32, "1014": [30, 40], "1015": [40, 41, 52], "1016": [40, 41], "101688": 30, "1017": [40, 41, 52], "101796": 32, "1018": [40, 41, 52], "101810": 25, "101832": 30, "101894": 31, "1019": [40, 41, 52], "102": [31, 32, 51], "1020": [30, 35, 40, 41, 52], "102044": 35, "1021": [40, 41, 52], "102135": 31, "1022": [40, 41, 52], "1023": [40, 41, 52], "1024": [28, 40, 41], "102435": [26, 32], "102474": 28, "10247431": 28, "1025": [41, 52], "10254": 41, "1026": [29, 41], "1027": [41, 52], "10273": 32, "10274": 31, "1028": [41, 52], "1029": [41, 52], "103": 42, "103023": 30, "1031": 41, "103219": 35, "103222": 40, "1034": 35, "103439": 28, "1039": [41, 52], "104": [26, 27, 33, 36, 40], "1040": 27, "104070": 32, "1041": [32, 34, 41, 43, 52], "10416666666666667": 38, "1042": 30, "1044": 23, "104596": 30, "104643": 32, "105": 33, "1050": 24, "105080": 35, "105089": 28, "10513": 41, "1053": 43, "105314": 41, "10556679": 36, "105656": 34, "10584063": 40, "106000": 27, "106023": 32, "106112": 41, "106180": 41, "106319": 41, "106322": 41, "106424": 41, "10644531": 39, "106452": 26, "10645223": 26, "10653": [41, 52], "106705": 41, "106764": 30, "1068": 43, "106816": 41, "1069": 43, "10693359": 39, "106996": 30, "107": 33, "1070": 35, "107050": 41, "107292": 41, "1075": 43, "107502": [41, 52], "1076": 28, "107718": 30, "10781": [33, 34], "107917": [41, 52], "10793260e": 40, "107947": 32, "107985": 32, "107991": 31, "108": 23, "1080": 23, "10800": 23, "1085": 29, "10868": 41, "108681": 26, "1089": 32, "10910": 41, "10931": 28, "109526": 31, "1099": 32, "10_000": 42, "10th": [30, 31, 33, 34, 50], "10x": 31, "11": [1, 10, 11, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 47, 52, 53], "110": [29, 40], "110316": [41, 52], "110319": [41, 52], "1104": 26, "11057": 41, "1106": 35, "110645": 32, "110915e": 32, "111": [27, 30, 31, 32, 42, 50], "11121453": 36, "111215": 36, "111220": 41, "111438": 35, "111543": 32, "112": 26, "1122": [32, 34, 43], "1123": [30, 43], "112441": 30, "112490": 30, "112527": 34, "112848": 32, "11331": 43, "11336331e": 34, "113600": [27, 28, 48], "1138": 35, "113837": 32, "1139": [32, 34], "113949e": 42, "114": 27, "1140": [23, 32, 34], "114000": [27, 35], "114079": 30, "114214": 30, "114507": 40, "11457": [32, 34], "114766": 34, "114836": 35, "114966": 34, "115": 28, "1150": 23, "115083": 27, "115089": 41, "11509": 32, "115090": 41, "115091": 41, "115092": 41, "115183": 30, "115276": 42, "115401": 32, "115406": 26, "115428": [41, 52], "115956": 29, "116": 27, "116145": 35, "116167": 29, "116443": 35, "116497": 32, "11664": 43, "11693": 32, "117": [27, 28, 29, 35, 48], "117058": 29, "117379": 30, "117380": 27, "117412": 32, "117528": 35, "11758": [41, 52], "117612": 40, "117712": 41, "117816": 27, "117899e": 32, "1179": 27, "118": [27, 28, 29, 32, 34, 35], "1180": 24, "118182": [27, 28], "118347": 32, "118450": 31, "118563": 35, "11886432": 30, "118874": 32, "118934": 31, "11898": 31, "119": [27, 28, 29, 35, 41, 48, 52], "1190": 27, "119049": [41, 52], "11909976": 36, "119100": 36, "11914062": 39, "119400": 27, "119570": 35, "119911": [41, 52], "11th": [31, 33, 34, 50], "12": [10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53], "120": [26, 27, 29, 32, 33, 40, 41, 44], "1204": 26, "120769e": 32, "121": [23, 27, 28, 29, 30, 33, 35, 41], "1210": 30, "121056e": 32, "121084e": 32, "121351": 34, "12138": 27, "1214": 32, "121438": 42, "12150684": 29, "121531": 31, "121599": 34, "121628": 26, "1217": 42, "12178": 35, "121846": 34, "121985": 32, "122": [23, 24, 25, 27, 28, 35, 40, 46, 51], "1220": [23, 27, 30], "1222": 30, "122307": [27, 28], "122331": 32, "122668": 30, "123": [4, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50], "123367": 32, "1235387316046016": 30, "123539": 30, "124": [27, 39], "1240": 23, "1241": [32, 35], "1243": 27, "12436984": 28, "124370": 28, "1247": 30, "12498": 34, "124982": 35, "125": [8, 32], "1250": [27, 28, 48], "12508": [32, 34], "125440e": 32, "125476": 26, "125523": [41, 52], "1256": 44, "125617": [41, 52], "125644": 32, "1258": 42, "126": 35, "126238": 35, "126398": [27, 28], "126488": 36, "12649": 27, "126500": 27, "126563": 30, "126808": [27, 28], "127": [25, 27, 29, 30], "127086": 27, "127087": 42, "1271": 33, "127107": 34, "127226": 28, "127242": 32, "1273": 34, "127326": 32, "1274": 35, "127418": 32, "127439": 32, "127441": 32, "127614": 32, "12761659": 32, "127878": 26, "1279": 32, "128": 43, "1280": [27, 30, 32], "1281": 32, "128188": [27, 28], "128384": 32, "128528": 32, "128820": 41, "128828": 41, "128829": 41, "128830": 41, "12890625": 39, "128984": 32, "129": [26, 29, 35, 42, 51], "1290": [27, 28], "12906": 23, "129257": 32, "12927": 23, "129300": [27, 28, 48], "129459": 35, "129600": 32, "129900": 31, "129904": 32, "129985": 27, "12th": [31, 33, 34, 50], "13": [8, 10, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 45, 48, 52], "130": [23, 24, 25, 26, 27, 28, 30, 32, 34, 35, 46, 48], "1300": [32, 34], "1302": 31, "130395": [41, 52], "1304": [26, 42], "130432": [41, 52], "130690e": 32, "1307": 32, "131": [27, 33, 41, 42], "131000": 32, "13107": 41, "131275": 31, "1313": 32, "1314": [32, 34], "131607": [32, 34], "131773": 42, "1319796954314723": 33, "132": 42, "1320": 35, "1321": 23, "132158": 32, "132292": 35, "13229595e": 34, "13255": 41, "132875": [27, 28], "132886": 41, "133": [30, 42], "133000": 32, "133210": 30, "133270": 32, "133337": 32, "133562": 42, "13392236": 40, "134": [24, 25, 28, 29, 46], "1340": 24, "134061": 35, "13407": 34, "134287": 31, "1346": [27, 32, 34, 35, 42, 43], "134615": 29, "134658": 27, "1347": 43, "13476562": 39, "134894": [41, 52], "135": [41, 42, 52], "135134": [41, 52], "135197": [41, 52], "13521135": 34, "135299": 35, "135305": [27, 28], "135384": 32, "135422": 32, "1357": 23, "136": [27, 28], "1360": 24, "13665": [27, 28, 48], "136714": 31, "1370": [23, 26, 30, 42], "13704": [32, 34], "137410": 36, "137500": [27, 28, 48], "1378": 32, "138": 43, "1380": 23, "138103": 40, "1383": 30, "138503": 35, "138528": 29, "138876": 42, "1389": [27, 32, 34], "139": [27, 43], "1390": 23, "139297": 31, "139317": 31, "139322": 31, "139349": 31, "13941": 31, "139554": 31, "1396": 30, "1397": 30, "14": [10, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 45, 52], "140": 27, "140185": 35, "1404": [26, 42], "1405": 35, "1406": [27, 32, 34], "140641": [41, 52], "140953": [41, 52], "141": [27, 29], "141232": [41, 52], "14159265358979323": 8, "14160": 31, "141851": [41, 52], "142": 33, "142193": [41, 52], "142199": [41, 52], "1423": 31, "142398": [41, 52], "142467": 25, "142806": [41, 52], "142857": 28, "14289": [27, 28, 48], "143": [30, 31], "143693": [41, 52], "143803": 35, "1438387200": 41, "1438398000": 41, "1438408800": 41, "1438419600": 41, "1438430400": 41, "1438441200": 41, "1438452000": 41, "1438462800": 41, "1438473600": 41, "1438484400": 41, "143975": [41, 52], "144": [23, 30], "144000": [32, 34], "1441": 43, "144199": [41, 52], "144686": 34, "14471": [27, 28, 48], "144729": 41, "144730": 41, "144731": 41, "144732": 41, "144733": [41, 52], "144750": 26, "14485": 32, "145": [41, 52], "1452": 35, "145425": 32, "145454": [41, 52], "145455": [41, 52], "145456": [41, 52], "145457": [41, 52], "145458": [41, 52], "145459": [41, 52], "145460": [41, 52], "1457": [27, 28, 42, 48], "14579": 35, "1458": [27, 28, 48], "145833": 38, "146": [23, 33], "1460": [32, 42], "14648438": 39, "1465": [27, 28, 48], "146656": [41, 52], "1467": 35, "146767": [31, 34], "146809": 31, "146830": 31, "14690": 28, "147": 34, "147166": [33, 34], "14716638": 34, "147641": 32, "1477": 43, "147737": 40, "147893": 27, "147898": 31, "148": [26, 30, 34, 44], "14813": 41, "148141": 33, "148343": 32, "148349": 42, "14841": 31, "149": 42, "14970": 27, "149788": 34, "149822": [27, 28], "14999": 27, "15": [8, 10, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 43, 45, 46, 50, 52], "150": [26, 30, 32, 40], "150000": [31, 38], "150115": 30, "15026771": 32, "150395": 26, "1504": 26, "1505": 27, "150mb": 31, "150p": 23, "151357": 35, "152": 41, "1520": 30, "152401": 31, "152859": 31, "1530": 23, "1534": 27, "15377": [27, 35], "1540": 23, "154076": [31, 34], "154105": 35, "15429": 41, "154386": [27, 28], "1545": 35, "154795": [32, 34], "154842": 42, "155": [23, 30], "15500": 32, "155178e": 32, "15559528e": 34, "155624": 32, "156": [27, 30, 31], "1562": 30, "156311e": 32, "1564": 30, "15661": 41, "157": [23, 30, 40], "157008": 32, "157157": 43, "157234": 35, "15725": [27, 35], "15775": 41, "1578": 34, "15795": [31, 34], "158": 30, "1580": 23, "1582": 34, "158867": [41, 52], "158982": 32, "159": 30, "1590": [26, 30], "15915": 41, "15992": 34, "16": [10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 39, 41, 42, 43, 45, 46, 52], "160": [25, 26, 29, 30, 32, 34], "160000": [32, 34], "160258": 25, "160282": 35, "1604": 26, "160506": 31, "160634": 40, "16063983": 28, "160640": 28, "160727": 34, "160729": [41, 52], "161": 27, "1610243052583638": 29, "16111330565237164": 29, "1613": 27, "16153": 41, "16157": 41, "16160": 41, "161606": [27, 28], "161782": 31, "1619": 30, "161931": [32, 34], "162": 23, "162000": 32, "162007": 43, "162330": 31, "162667": [31, 34], "1627": 35, "162904": 42, "1631": 30, "163195": [27, 28], "163397": [27, 28], "1634": [27, 28, 30, 48], "16358": 41, "164": [35, 40], "1645": 29, "16460": 35, "164679": 31, "165": [29, 32], "1650": [26, 30], "16507": [29, 35], "16508": [29, 35], "16509": [29, 35], "16510": [29, 35], "16511": [29, 35], "16512": [29, 35], "165198e": 32, "1652": [25, 29], "16533": 41, "165485": 34, "165617": 41, "165811": 30, "16630": 35, "166631": [27, 28], "167": 25, "167214": 26, "167241": 43, "167600": 35, "167620": 40, "168": 32, "1680": 24, "168151": 40, "168196": [27, 28], "168244": 34, "1687": 30, "169": [25, 29, 35], "1690": [23, 24], "169269e": 42, "169421": 30, "169693": 26, "169748": 29, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 24, 26, 27, 28, 29, 30, 31, 32, 35, 41, 42, 45, 48, 52], "170": [27, 37], "170100": [27, 28, 48], "170277": [33, 34], "1704": 26, "17054987": 40, "170670": 32, "170931": 40, "171": [23, 40], "17144": 41, "171468": [32, 34], "1715": 30, "171657": 25, "171899": 42, "1720": 27, "17205": 41, "1724668": 39, "172792": 31, "173": [26, 30], "173025": 30, "17393037": 8, "1739787032867638": 30, "173979": 30, "174": [23, 26, 30], "174590": 31, "174766": 35, "1750": 27, "175000": [32, 34], "17518": 41, "176": 27, "1766": 32, "176924": 42, "177": 35, "17730": [27, 35], "177709": 42, "178": [23, 32], "178494": 32, "17896": 41, "179": [33, 42], "179080": 31, "179123": 26, "179300": 27, "179730": 30, "17973005068132514": 30, "179802": 32, "18": [10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 41, 42, 43, 45, 48, 52], "180": [30, 32, 40], "1800": [23, 24, 26, 30], "18000": 41, "180000": 24, "180279e": 32, "180388": 26, "1804": 26, "18066406": 39, "180900": 35, "18096": 41, "181": 42, "18113": 41, "18116": 41, "1813": 30, "182": [41, 42], "18201414": 34, "18245": 41, "182639": 32, "182648": 32, "18311": 41, "18313": 41, "18317085": 8, "183179": 42, "183423": 26, "183471e": 32, "18365": 28, "18391": [27, 28], "184": [41, 42], "1840": 23, "184405": 34, "1847": 28, "185": 42, "185155": 34, "185175": 42, "18533": 41, "1854": 30, "185707": [26, 30], "18571": [27, 28], "18572": [27, 28], "18573": [27, 28], "18574": [27, 28], "18575": [27, 28], "18576": [27, 28], "1858": 35, "185868": 35, "185975": 34, "18597545": 34, "186024": 23, "186814": 31, "186899": 31, "187": [25, 29, 33], "1870": 30, "187000": 27, "1872": 32, "1875": [29, 39], "187503": 41, "187663": 26, "187700": 27, "188": [23, 25, 29], "1880": 30, "1886": 29, "1887": [31, 34], "18955": 41, "189981": 32, "19": [8, 10, 23, 24, 25, 26, 28, 30, 31, 32, 35, 38, 39, 42, 43, 45, 52], "190": [25, 32, 35], "19000e": 26, "1901": 23, "190319": 35, "19032": 41, "1904": 26, "190617": [27, 28], "191": [25, 27], "1911": 35, "191169": [32, 34], "191204": 35, "191250": 25, "191396": 26, "191700": 35, "1918": 28, "191k": 34, "1920": 23, "19213263": 28, "192133": 28, "19266": 41, "1927": 43, "1928": 43, "193": 40, "1930": 23, "193021": 31, "193122": 31, "193247": 35, "1933": 24, "193346": 34, "193427": 30, "19365": 41, "193704": [41, 52], "19380": 41, "1940": 28, "194002": 26, "194034": [41, 52], "194040": 27, "19422": 34, "19433594": 39, "1945": 32, "1946": [23, 32], "194710": 32, "19485": 27, "194985": 32, "195": 27, "1950": 32, "1951": 24, "195228": 28, "1953": [30, 32], "19536": 31, "1954": 39, "1955": 24, "195564": 35, "1957": 39, "1959": 23, "19591": 35, "1960": 24, "1962": 39, "1963": 30, "196385": 34, "1965": 24, "196599": 32, "1966": 32, "196717": 40, "196739": 41, "1968": 23, "1970": [29, 32, 41], "1972": 32, "197649": 35, "1977": [23, 42], "19777": [33, 34], "19781": 41, "198": [40, 43], "198127": 32, "1984": 32, "1985": 32, "198629": 40, "198645": 42, "1987": [23, 24], "1989": 23, "198924": [27, 28], "199": [23, 26, 31], "1990": [26, 29, 30], "1991": [24, 33], "1992": [41, 43], "1993": 32, "199364": 31, "1994": 23, "199412": 42, "199413": [26, 30], "19966": [27, 28, 35], "1997": [29, 30], "199771": 34, "1_000_000_000": 30, "1d": 40, "1e": [30, 32, 49], "1e3": [30, 49], "1e4": 30, "1h": [27, 28, 35], "1st": [8, 31, 33, 34, 41, 50], "1stflrsf": [32, 34], "1v": 44, "1v2": 44, "1v3": 44, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 33, 34, 35, 39, 40, 41, 43, 44, 53], "20": [4, 8, 10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 43, 44, 45, 47, 48, 52, 53], "200": [23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 46, 47, 48, 49, 50], "2000": [26, 30, 31, 32, 33, 34, 35, 40, 44, 49], "200000": [30, 41, 52], "200326e": 32, "2004": 32, "200475": 31, "2006": [32, 34], "2007": [32, 34, 41, 52], "2008": [32, 34, 41, 52], "200876": 28, "20087625": 28, "2009": [32, 34, 41], "200978": 26, "200k": 50, "201": [26, 53], "2010": [32, 34, 41], "20113": [27, 28, 48], "2012": [8, 27, 30], "2013": [39, 41, 52], "201332": 37, "2014": [23, 33, 41], "2015": [40, 41, 52], "20150630": [41, 52], "2016": [8, 40, 41], "20160101": 41, "2017": [34, 41, 52], "201810": 31, "201862": 35, "202": [26, 28], "2020": 43, "2022": 41, "2023": [10, 41], "2024": [0, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52], "20248": 27, "2024w1": 40, "2025": 1, "2025s1": [0, 11], "20274": 41, "202839": 31, "203": 26, "20310": 41, "20311": 35, "20319": 41, "203265": 34, "20334": 41, "203421": 32, "203500": 27, "20357847293371892": 29, "204": [24, 25, 26, 30, 39, 46], "204167": 25, "2043": 42, "204302": [41, 52], "20433": 35, "204583": 25, "2046": 28, "204600": [26, 30], "204692": 32, "204734": 31, "20485": 41, "205": [24, 25, 26, 43, 46], "205000": [27, 28, 32, 34, 48], "205059": 35, "20509": 41, "20514": 41, "205144": 35, "205323": [41, 52], "205479": 29, "205597": 32, "20564": 41, "206": [24, 25, 26, 30, 31, 46], "206041": 34, "206073": 31, "206099": 30, "20620": 41, "206292": 27, "20639": 35, "2064": 27, "20640": [29, 35], "206724": 42, "20683258": 29, "20694": 41, "207": [24, 25, 26, 27, 30, 39, 40, 46], "207039e": 32, "2071": 35, "207814e": 32, "20794": 41, "208": [24, 25, 26, 29, 30, 46], "209": [23, 24, 25, 26, 30, 46], "209583": 25, "209746": 31, "209903": 35, "20analysi": 42, "20assumpt": 42, "20hazard": 42, "20intro": 42, "20learn": 40, "20lifelin": 42, "20with": 42, "21": [10, 23, 24, 26, 27, 28, 31, 32, 35, 36, 38, 39, 41, 43, 52], "210": 30, "210001": 31, "210240": 30, "210272": 35, "210591": [27, 28], "210779": 41, "21086181023099526": 29, "211": 30, "2110": 27, "211250": 25, "211343": 35, "211544": 31, "211892": [27, 28], "212": [25, 30], "212385": 34, "212581": 35, "21274": 41, "212870": 32, "212975": 32, "213": [30, 40, 41], "2130": 23, "21353": 41, "21382972": 33, "21389": 41, "2139": [27, 28, 48], "214": [23, 28, 30], "21405": 41, "2144": 30, "214740": 27, "214769": 40, "214821": 41, "214852": 31, "215": 30, "215245": 32, "21530": 41, "215412": 32, "21549": 41, "21571": 41, "21581": 41, "21582031": 39, "215865": 34, "21596": 41, "216": 30, "21603": 41, "21605": 41, "216123": 42, "21613": 24, "21616484": 44, "21617": 41, "216346": 34, "21634631": 34, "216585": 27, "216596": [41, 52], "21668": 41, "21670": 41, "216718": 31, "216728": 27, "21694": 41, "21697": 41, "2170": 24, "217334": 28, "21733442": 28, "2173627": 39, "21767954": 34, "21768": [34, 41], "217680": [33, 34], "21774": 41, "218207": [27, 28], "21847": 41, "21872": [32, 34], "218760": 34, "218830": 27, "219": 35, "2190": 27, "2192": 30, "219512": 35, "219700": 35, "21972656": 39, "219845e": 32, "22": [10, 26, 27, 28, 30, 31, 32, 33, 34, 35, 39, 41, 42, 43, 44, 48, 52, 53], "220": 25, "22001": 34, "220392": 42, "22057": 41, "2206": 42, "22078": 41, "2210": 23, "22114": 41, "221329": 32, "221348": [41, 52], "2214": 43, "22154": 41, "221622": [27, 28], "22168237": 44, "221900": 24, "22219": 41, "22221894": 32, "222222": 27, "22225": 41, "222307": 27, "222500": 25, "22260": 41, "222647": [32, 34], "2229": 29, "222963e": 32, "22305705": 33, "22320": 41, "223333": 25, "223460": 42, "223750": 25, "223804": 34, "224": [30, 40], "22452": 41, "2246468746": 25, "224662": 32, "22471154513694713": 29, "224865": [32, 34], "225": 40, "225301e": 32, "2254": 27, "22550": 41, "226": 30, "226415": 27, "226789": 42, "2268": 33, "22697768": 28, "226978": 28, "2270": 30, "227143": 27, "2272": 31, "227304": 41, "22741": 35, "227559": [32, 34], "227836": 31, "22788": 41, "22811601": 29, "22826": 41, "228329": 31, "2285": 41, "22851562": 39, "228603": 32, "228750": 25, "229": 40, "229000": 27, "22910": 41, "229102": 34, "2293467570951035": 33, "2295": 41, "229583": 25, "229718": 34, "23": [10, 26, 27, 28, 29, 30, 31, 32, 35, 39, 41, 42, 48, 52], "230": [26, 30], "2300": 23, "23011": 34, "2305": 34, "2307": [25, 29], "2309": 41, "23091772": 33, "2310": 41, "2311": 41, "2312": 41, "2313": 41, "23175": 41, "231815": 34, "232143": 28, "232751": 42, "23290": 41, "233": 24, "234": 42, "234040": 31, "234436": 42, "235": 35, "235096": [27, 28], "235152": 26, "235417": 25, "235706": 35, "236": [26, 30, 42], "236096": 40, "236174": 35, "236210": 36, "23621041": 36, "23640124": 29, "236456": 27, "23654": [31, 34], "236960": 30, "237": [31, 42], "237895": 31, "237935": 34, "238": [31, 42], "238192": [31, 34], "2389": 28, "239": 42, "23902": 41, "23941": 41, "239944e": 32, "24": [1, 11, 23, 26, 27, 31, 32, 33, 34, 35, 39, 40, 41, 42, 52], "240": 42, "2401": 35, "240893": 35, "241": 42, "241489": 42, "241620": 31, "24182": 41, "242015": [33, 34], "242083": 25, "242169": 31, "242381": 41, "24295676": 28, "242957": 28, "242996": [27, 28], "243": 41, "243243": 32, "2435": 35, "2436": 35, "24395": [33, 34], "24397122221206388": 41, "244": 41, "244592": 26, "2447": 33, "244814": 42, "245": 41, "2451": 30, "245329": 32, "245521": 31, "245686": 31, "246": 41, "246332": 32, "246646": 30, "246646103936": 30, "246653": 30, "247": 41, "247119": 41, "247439": 36, "24743939": 36, "247690828913": 30, "247691": 30, "248": 41, "248328": 33, "248333": 25, "2484": 23, "248457": [32, 34], "248609": 32, "248664": 35, "2488": 26, "248999": 42, "249": 43, "2496": [25, 29], "249601e": 32, "249618e": 32, "249720": 26, "24h": 31, "25": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53], "2500": [8, 43], "250000": [27, 31, 32], "25031": 41, "25037": 41, "2506": [24, 25, 46], "250900": 32, "251093": 30, "251158e": 32, "2516": 33, "25176": 41, "251769": 40, "252042": 35, "25214": 41, "252160": 26, "252859": 34, "2530": 23, "2533": [25, 29], "253312": [27, 28], "253432": 34, "253724": 26, "253914": 32, "254380": 42, "254443": 31, "255": 27, "2551": 43, "255134": 40, "2556": 33, "255751": 35, "255889": [41, 52], "256": [23, 40], "25622": 41, "256263": [33, 34], "256333": 27, "256437": 35, "25658": 35, "256813": 26, "257": 24, "2570": [23, 24], "257024": 30, "257103": 31, "2574": 35, "2580": 23, "258225": 41, "25823": 31, "258387": 34, "2584": 39, "258427": 26, "258886": 31, "259": [32, 35], "25904": 41, "2590575478171884": 29, "259286": 26, "259500": 27, "26": [8, 10, 23, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 52], "2600": [27, 28, 48], "260258": 35, "26048": 34, "260572": 32, "26063": 41, "260890": [32, 34], "261035": 32, "261953": [41, 52], "262": [32, 34, 42], "262079e": 32, "262156e": 32, "262269e": 32, "2623": 32, "262361": 35, "262500": 32, "263": 32, "2630": 27, "263541": 42, "263600": 27, "26370005": 29, "263736": 42, "263742e": 32, "26376": 41, "264195": 42, "264283e": 32, "26447953": 28, "264480": 28, "265": 33, "265273": 29, "266120": [41, 52], "266135": [27, 28], "2670": 30, "267612e": 32, "268": 30, "2683": 31, "26831": 41, "2691": [24, 25, 46], "26919": 35, "269689": 31, "269880": 26, "269972": [32, 34], "27": [8, 26, 28, 30, 31, 32, 39, 41, 42, 52], "270093": 30, "270093376167": 30, "27021": 41, "270270": 38, "27048": 31, "2705": 30, "271037": 35, "271287": 41, "271500": 35, "271738e": 32, "2720": 24, "27206": 41, "27263": 34, "272667": [27, 28], "2730": 27, "273382": [27, 28], "273606": [27, 28], "273890": 40, "273962": 35, "274": [27, 28, 41, 48], "274404": 27, "275008": [41, 52], "27502379069": 32, "275290": 31, "275352": 26, "275410": 29, "2759": 34, "276": 27, "27610135": 39, "27638": 41, "27652": 31, "276687": 32, "27676": 31, "27678": 31, "276943e": 32, "27697": 31, "2770": 30, "27705": 31, "27715": 31, "277381": 26, "2777": 42, "278441": [41, 52], "278634": 31, "27874871715903093": 29, "278755": 28, "27875502": 28, "2788": [25, 29], "2794": 29, "28": [10, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 41, 42, 52], "280": [27, 35, 43], "2800": 8, "280028": 35, "280310": [27, 28], "2806": 30, "280618": 31, "2807": 42, "280801": 42, "281": 27, "28122025543": 32, "281583": 32, "2817": 34, "2820": 30, "282021e": 32, "2822": 34, "282600": 42, "283119e": 32, "28327": 41, "283421": 32, "2836": 34, "28362": 41, "283857": 26, "283921": 27, "284": [35, 41], "2845": 42, "2846": 43, "2847": 43, "285": [27, 28, 41, 48], "285263": 34, "28526302": 34, "285467": [32, 34], "28571429": 24, "286": [25, 26, 30, 41], "286000": 30, "286200": 35, "286416": 28, "2865025": 44, "286821": 26, "287": 41, "287031": [41, 52], "287079e": 32, "287344": [27, 28], "287500": 35, "28753559": 39, "288": 41, "288002": [41, 52], "288462": 29, "28854": 41, "28868": 31, "289": 41, "2890": [26, 30], "28953": 41, "289541": [32, 34], "289799": 26, "29": [8, 26, 27, 31, 32, 39, 41, 42, 43, 52], "290": 41, "290002": 31, "290424": 32, "29045704": 32, "290961e": 32, "291": [29, 41], "291667": 38, "292": 41, "292587": 42, "293": 41, "29324459": 40, "293663": 31, "294": [27, 39], "294251": 28, "2948": [27, 28, 48], "294855": 34, "2953863599856862": 29, "295397": 31, "29545": 32, "29572402": 39, "296": [27, 43], "296601": 35, "29691": 41, "297": 29, "29802": [31, 34], "298561": 42, "298612": [41, 52], "29881": 41, "298813": 31, "299": 40, "299164": 35, "2d": 40, "2d454e5fd9a5": 42, "2e": 10, "2f": [25, 30, 38, 41], "2nd": 29, "2ndflrsf": [32, 34], "2v": 44, "2v3": 44, "3": [7, 8, 10, 11, 14, 16, 17, 18, 26, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 53], "30": [4, 10, 23, 25, 26, 29, 31, 32, 33, 34, 35, 39, 41, 42, 43, 52, 53], "300": [26, 37, 39, 44], "3000": 40, "300000": [27, 28, 41, 52], "3000000": 39, "300464": 35, "300837": 31, "301": 42, "3010": 35, "301200": 30, "3014": 35, "30146": 41, "301563": 32, "30167": 41, "301784": 42, "3019": [24, 25, 29, 46], "301952": 35, "302": [32, 34], "302131": 32, "30279": 41, "302801": 42, "302844": 42, "303": [32, 34], "303000": 27, "303004": 35, "303030": 29, "303109": 28, "303790": 30, "3038": 43, "3038344082": 34, "303916": 26, "304": 26, "3040": 41, "3041": 41, "3042": 41, "3043": 41, "3044": 41, "304784": 32, "305": 23, "30504657": 36, "305047": 36, "30530902": 26, "305346": 26, "305674": 35, "3057": [25, 29], "30573": 35, "306": 43, "306500": 26, "306564": 40, "307": 27, "3075": 43, "307516": 40, "307521": 29, "30792853": 39, "30798381": 39, "308120": 27, "30815": 32, "308216": 40, "308220": 31, "308448": 26, "3089": 30, "309": 35, "3092": [24, 25, 46], "309249": 40, "309859": 29, "31": [10, 23, 26, 27, 28, 29, 31, 32, 33, 34, 36, 39, 41, 42, 43, 48, 52], "310": 53, "310000": 27, "31000e": 26, "310284": 34, "31038074": 39, "310405": 31, "311": 27, "3110": 27, "311151": 42, "31127015": 34, "311310": 23, "311769": 35, "31196406381465247": 29, "3120": 27, "3125": 27, "312500": 38, "312501": [32, 34], "312696": 43, "3129": 43, "31297381": 28, "312974": 28, "31298589e": 40, "313": [28, 32], "3130": 43, "31384": 31, "314": 27, "3140": 27, "314000": 30, "31449687e": 34, "31454": 35, "314582": 34, "314840": 35, "314929": [41, 52], "315134": [41, 52], "315630": 31, "316164": 35, "316230": 35, "31634363": 39, "316363": 26, "316395e": 32, "316426": 35, "316552": 28, "31655231": 28, "316798": 35, "317": [27, 34], "317277": 35, "317761": 31, "318": 27, "3180": 30, "3180174485124284": 27, "318937": [27, 28], "319": [24, 27], "31908384": 40, "319630": 42, "31984311": 32, "31st": 41, "32": [8, 26, 27, 28, 29, 30, 32, 36, 39, 41, 42, 48, 52], "320": 27, "320155": 31, "320430": 32, "32064171": 33, "321": 34, "32127053": 32, "322": 35, "32240": [33, 34], "32247597e": 34, "322755": 26, "323045": [27, 28], "32323": 23, "32397724e": 34, "3245": 23, "3252": 35, "325319": 35, "32561": 31, "326": [27, 35], "326730": 31, "326741e": 42, "326933": [26, 30], "327188": 31, "3272": 42, "327283": 32, "32734": 35, "3274": 42, "327408": 31, "32791718": 39, "328": 35, "328077e": 32, "328799": 31, "328953": 26, "3298721": 40, "3299": [39, 43], "33": [8, 23, 26, 27, 28, 29, 30, 31, 32, 35, 39, 41, 42, 52], "330": [9, 10, 11, 23, 24, 40, 41, 43, 53], "33000e": 26, "330346": 42, "3310": 27, "33191802": 39, "332125": 31, "332130": 32, "33223002": 39, "3322447": 39, "33224516": 39, "33224759": 39, "332671": 34, "3327": 41, "332710": 32, "332746": 42, "332791": 42, "332824": 32, "3330": 27, "33308783": 28, "333088": 28, "333139": 31, "333333": [24, 27, 30, 38], "3333333333333333": [38, 40], "333340": 26, "3334": 43, "33380649": 39, "33380754": 39, "33380761": 39, "33381373": 39, "33394593": 39, "3339473": 39, "33394769": 39, "33395626": 39, "33397112": 39, "334": 35, "33400489": 39, "33411086": 39, "33425967": 39, "33435326": 39, "33439238": 39, "33440682": 39, "334411": 26, "334576": 32, "33462759": 39, "33476534": 39, "335": 33, "335309": 32, "3355": [27, 28, 48], "3356700488_183566145b": 40, "33590": 41, "336389": 34, "33641142": 34, "3364114233677307": 34, "336411423367732": 34, "336735": 30, "336826": 28, "33682642": 28, "33683087": 29, "336831": 29, "337034": 35, "33726089": 32, "33732465": 39, "33782315": 39, "33797555": 39, "338": [26, 30], "33888659": 8, "339": 31, "339368": 42, "339889": 42, "34": [23, 26, 27, 28, 29, 31, 32, 35, 39, 41, 42, 48], "340": [3, 10, 24, 33, 35, 40, 41, 42], "34000e": 26, "340988": 31, "341109": 32, "341300": 35, "341571": 42, "34161762": [32, 34], "341712": [41, 52], "34182": 34, "3420": 27, "342200": 35, "342605e": 32, "3436": [41, 52], "3437": 43, "3438": 43, "344": 27, "3442": 42, "34426571": 32, "34441": 32, "345": 34, "345136": 26, "345386e": 32, "3454": [42, 43], "3455": 43, "345831": 23, "346": [27, 28, 48], "346850": 31, "34691": 41, "347523": 30, "348": [27, 35], "34806": 32, "34900": 32, "34924955": 39, "35": [26, 27, 29, 31, 32, 33, 34, 39, 41, 42, 43, 47, 51, 52], "350": 23, "3500": 47, "350000": 27, "351351": 38, "351366": 31, "3515": 42, "3517": 43, "351821": 42, "3520": 42, "3521": 23, "352100": 35, "352930": [27, 28], "353": 40, "35375221": 44, "353961": 30, "354114": [32, 34], "354604": 31, "3547": 35, "354759e": 32, "35561437": 39, "356689": [33, 34], "35671794": 34, "357": 27, "3573886": 39, "357500": [27, 28], "3576": 23, "3577": 43, "35771821": 39, "357823": 23, "358": [23, 30], "358032": 34, "3582": [42, 43], "358264": [32, 34], "3583": 43, "358333": 26, "358500": 35, "358913": 28, "3589134": 28, "359": [26, 30], "3590": 30, "359784": 30, "359887": 36, "359992": 26, "35p": 23, "36": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 41, 42, 52], "360": 28, "360172": 31, "360918": [41, 52], "361": 42, "361718": 31, "362": [42, 43], "362009": 41, "362185e": 32, "362553": 35, "36269995": 28, "362700": 28, "363": 42, "363192": 26, "363913": 31, "364": [41, 42], "364352": 29, "365": 41, "36525": 34, "365420": 43, "365603": 29, "365623": 26, "366": [28, 41, 42], "366005": 31, "3663": 42, "366626": 26, "36695134": 39, "367": 41, "367329e": 42, "367423": 30, "368": [41, 43], "3681": 34, "368304": 29, "3684": 42, "368922": 37, "369": 32, "369875": 26, "369896": 40, "37": [27, 28, 29, 32, 35, 39, 41, 42, 43, 48, 52], "37050406": 8, "370643": 31, "371": [35, 41, 52], "3717": 34, "371722": 34, "372": 27, "372706": [41, 52], "372763": [32, 34], "373031": 26, "373275": [41, 52], "373656": 41, "374": 27, "374584": 40, "37546": 34, "376": [27, 32], "376089": 32, "37647072": 33, "3768": 43, "3769": 43, "377032": 32, "377619": 30, "377619120792": 30, "37797291": 28, "377973": 28, "37807203": 39, "378159": 32, "378764": 26, "378971e": 32, "37906": 31, "379416e": 32, "379875e": 32, "38": [8, 26, 27, 29, 31, 32, 35, 39, 41, 42, 52], "3803": 42, "380436": 28, "38043616": 28, "380495": 26, "380504": [27, 28], "380643": 26, "381190": 35, "3814": 28, "381416e": 42, "381428": [32, 34], "381676": 26, "38192364": 36, "381924": 36, "382558": 31, "3828125": 39, "383": [27, 35], "384111": 43, "384127": 26, "384613e": 30, "3851": 31, "3856": 26, "385639": 36, "386": 30, "386071e": 32, "386530": 34, "387": 30, "388023": 31, "388169": 35, "38853": 32, "3889": 28, "389": [30, 35], "389065": 34, "389349": 35, "389736": [27, 28], "39": [26, 30, 31, 32, 36, 39, 41, 51, 52], "390428669205": 30, "390429": 30, "390725": 32, "39095422e": 34, "391": 27, "3912": 42, "39163": 31, "391996": 40, "392": [23, 42], "392082": 34, "392221": 29, "392385": 42, "392612": 32, "392893": [26, 30], "393": [24, 28], "3932": 42, "39375": 41, "394113e": 32, "394920": 27, "395282e": 32, "395686e": 32, "395688": 42, "395697e": 32, "396": [27, 42], "396266": 40, "396752e": 32, "396991": [27, 28], "397": 42, "398": 35, "398495": [41, 52], "39896994": 28, "398970": 28, "399": 27, "3990": [24, 25, 46], "3991": 32, "39931": 34, "399827": 31, "39x15": 39, "3blue1brown": 40, "3d": [35, 40], "3f": [24, 25, 26, 27, 31, 32, 38, 39, 43], "3h": 41, "3m": 40, "3rd": 39, "3ssnporch": [32, 34], "3v": 44, "4": [0, 1, 8, 9, 10, 14, 16, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 53], "40": [8, 23, 26, 29, 30, 31, 32, 33, 34, 35, 37, 41, 42, 47, 52, 53], "400": [24, 27, 30, 49], "40000": [40, 41, 52], "400000": [30, 41, 52], "400047": 42, "400157": 35, "400164": 40, "400649628005": 30, "400650": 30, "401": [26, 30], "4011": 39, "401102": 41, "401541": 31, "401623": 32, "401830": 34, "401895": 30, "402": 23, "402808": 34, "404": [26, 35], "405": 33, "405227e": 32, "405415": 26, "405650": 32, "406": 40, "406202": 30, "40689": 35, "407": 31, "407234": 40, "40725012": 40, "407510": 31, "40756124": 33, "407862": 42, "4084": 42, "40_000": 40, "40b5a809b05a": 42, "41": [26, 27, 31, 32, 34, 35, 36, 38, 41, 42, 52], "410": 27, "410240": [31, 34], "410599": 35, "411412": 32, "41150573": 32, "412": [23, 26, 30], "41210938": 39, "412500": 35, "413050": 40, "413718": 42, "413796": 32, "413958": 31, "414": 43, "4143": 42, "4151": 33, "4153": 35, "4158382658": 27, "416": 34, "4165": 33, "4169": 42, "418": 39, "418031": 26, "418069": 30, "41901484361": 30, "419015": 30, "419355": 29, "4195": 34, "4197": [24, 25, 29, 46], "419973": 31, "42": [23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 47, 50, 51], "420": 30, "420000": 23, "42060": 35, "421": 40, "42104086": 34, "421215": 36, "42121526": 36, "421875": 29, "422": 32, "4234": 34, "4236": 34, "4238": 31, "423852": 31, "424222": 32, "424337e": 32, "425": 33, "425365": 42, "42541681": 44, "425419": 32, "426067": 27, "426410": 26, "427": 42, "428": 42, "429": [32, 34], "429217": 31, "429634": 42, "4296875": 39, "43": [26, 29, 30, 31, 32, 41, 42], "430": [30, 32, 34, 42], "430323": 27, "430571": 31, "430704": 36, "4307043": 36, "430868": 29, "431": [25, 42], "4310": [26, 27, 30], "431137": 29, "4314": 31, "432": 42, "433": 42, "433514": [41, 52], "433814": 42, "434": [26, 29, 30, 42], "43445": 35, "435": 42, "435186": 26, "435489": 31, "435792": 30, "436": 42, "436492": 32, "43697758253484614": 29, "437": 43, "4372": 36, "437367": [27, 28], "4375": [35, 38], "437500": 38, "437684": 41, "438": 38, "438231": 40, "438275": 28, "43827545": 28, "43833466": 32, "438592": 34, "438906": 34, "439": 27, "4390": [26, 30], "439209": 31, "439360": 27, "439779": 31, "44": [25, 26, 27, 29, 31, 32, 35, 39, 41, 42, 43, 52], "440": [30, 41], "441": 32, "441404": 40, "441445": 35, "442377e": 32, "442806": 26, "4430": 42, "44311": 35, "4432": 35, "443317": 26, "443419": [32, 34], "444297": 35, "444444": 27, "4448": 35, "445": 30, "445111e": 32, "445124e": 32, "44586935": 33, "44586935141902073": 33, "446216": 35, "446284e": 32, "446869": 35, "447": [27, 34], "447461": [41, 52], "447517": 34, "44787197": 39, "4482": 23, "4484": 26, "448757": 42, "449": 43, "449666": 26, "44966612": 26, "45": [8, 24, 25, 26, 29, 31, 32, 39, 41, 42, 46, 52, 53], "450000": 38, "450132": [41, 52], "450739": 32, "450822": 35, "451888": 31, "452600": 35, "453367": 35, "4537": 42, "454427": [27, 28], "454677": 36, "45467725": 36, "454788": 34, "454966": 31, "455": 28, "4552": 34, "45555535": 34, "45587": [41, 52], "45588": [41, 52], "45589": [41, 52], "45590": [41, 52], "45591": [41, 52], "456": 40, "456419": 35, "45653693": 28, "456537": 28, "456904786": 43, "457435": [41, 52], "45756": 43, "458": 27, "458333": 38, "458524": 42, "459": 32, "4591": 27, "459214e": 32, "459873": 42, "459937": 39, "45a": [41, 52], "45am": [41, 52], "46": [8, 24, 25, 26, 27, 28, 29, 31, 32, 41, 42, 43, 46, 48, 52], "460047": 42, "46019608e": 34, "46021": 43, "46075": 43, "4608": [24, 25, 46], "460950": 36, "461": [27, 30], "462060": 42, "462545": 34, "462963": 29, "46299": 43, "463": 31, "463582": 33, "464104e": 32, "465279e": 32, "46530779": 28, "465308": 28, "466246": 40, "4664": 23, "46729488": 32, "467379": 34, "467628": 35, "468": [26, 30, 34], "468232": [41, 52], "4687": 35, "46880": 43, "469": [27, 31], "469383": 31, "4695": 31, "469571": 35, "47": [10, 23, 24, 25, 26, 27, 29, 30, 32, 35], "470": [27, 43], "4700": 30, "470060": 32, "470666": 32, "471032": 34, "472": 43, "47242662": 44, "4726": 42, "472603": 32, "472790": 31, "473": 39, "473691": 26, "474": 31, "474552": 26, "47491": 31, "475099": 34, "475540": 39, "476": 24, "4760": 30, "47606": 35, "476092": [32, 34], "476406": 34, "476412": 36, "47641249": 36, "477": 30, "477291": 35, "47799": 43, "478060": [41, 52], "479109": 26, "479132": 35, "479773": 39, "48": [24, 25, 26, 29, 31, 32, 38, 41, 42, 46, 52], "480": 32, "4800": 23, "480249": 26, "4806334": 39, "48073598": 36, "4809": 30, "481": 27, "4813": [25, 29], "481514": 32, "481793": 27, "481893": 31, "481960": 31, "4822": 42, "483751": 26, "48390": 43, "48407": 43, "484937": 29, "485": 40, "48535": 43, "4854": 34, "485722": 39, "486": 34, "4861": [27, 28, 48], "486266": 27, "486664": 39, "487": 27, "48721": 43, "487740": 39, "4879": 43, "488": 27, "488163": 39, "488753": [41, 52], "489130": 29, "489593": 39, "49": [26, 29, 31, 32, 35, 41, 42, 51, 52], "490": [35, 44], "490000": 27, "490033": 32, "490568": 30, "490797": 39, "490930": 39, "491217": 31, "491366": 34, "491379": [27, 35], "491968": 39, "492": [27, 31], "492270": 28, "492307": 39, "492551": 39, "493": [24, 25, 27], "493489": 39, "493544": 27, "493921": 28, "494": [26, 27, 30], "4943": 30, "49575": 31, "496": 35, "496213": 32, "496757": 34, "497143": 39, "497386": 26, "497787": 32, "497949": 39, "498": 31, "498133e": 32, "498562": 26, "499900": 27, "4f": [26, 28, 31, 39], "4m": 40, "4th": [31, 33, 34, 50], "4x": 53, "5": [4, 10, 23, 29, 30, 32, 33, 37, 38, 41, 43, 44, 45, 46, 53], "50": [10, 23, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 49, 50, 52, 53], "500": [23, 27, 31, 33, 34, 35, 50], "5000": [23, 24], "50000": [41, 52], "500000": [27, 28, 31, 32, 37, 41, 43, 52], "500000e": 30, "500001": 27, "5002": 32, "500625": 26, "50062e": 26, "500924": [27, 28], "501": [27, 43], "501071": 40, "501191": 39, "501250": 26, "501304e": 32, "501875": 26, "5024752475247525": 30, "502500": 26, "502985": 31, "503000": 27, "503090": 31, "503125": 26, "503750": 26, "503807": 39, "504": [26, 35], "504231": 42, "504375": 26, "504429": 28, "504644": 30, "50475372e": 34, "504fde4fcf8": 42, "505180": 39, "505335": 31, "505592e": 32, "505625": 26, "5057": 32, "50596432e": 44, "506023": 33, "506035e": 32, "506079e": 32, "506084e": 32, "506211": [27, 30], "506410": 29, "506875": 26, "507130": 30, "507359": [27, 30], "507500": 26, "50774": 30, "507740": 27, "50775": 30, "507750": 30, "507752": [27, 30], "507995": 29, "508": [27, 32], "508125": 26, "508133": [27, 30], "508371": 30, "508534": 39, "508741": 39, "50884": 35, "50899": 30, "509000": 23, "509001": 32, "509317": [27, 30], "5098": 39, "509859": 39, "509930": [41, 52], "50k": [31, 33, 34, 50], "51": [26, 27, 28, 30, 31, 32, 34, 36, 41, 42, 48, 52], "510000": [24, 26, 30], "510421": 39, "510505": 39, "5106": 43, "510836": 30, "5109": 34, "511": 9, "5112": 24, "51137414e": 34, "51143": 35, "51150": 31, "511620e": 32, "5118": 34, "512": 40, "5120": 23, "512000": [26, 30], "51226051": 36, "5123": 39, "512319": 27, "512408": [32, 34], "512897": 26, "512x640": 40, "513": 27, "5131": 39, "513678": 42, "514150": 39, "514155": [27, 28, 32], "514347": 39, "514598e": 32, "5146": 29, "515000": 26, "51503393": 28, "515034": 28, "515351e": 32, "5156": [27, 35], "515848": 35, "516199": 39, "516394": 35, "516858": 39, "517273": 39, "517346": 31, "518113": 39, "519029": 31, "52": [26, 27, 29, 31, 32, 35, 41, 42, 43, 52], "520495": 39, "52061": 41, "520700": 39, "520782": 39, "5208": 24, "520857": 31, "5209": 32, "5212": 32, "521284e": 32, "521567e": 32, "521578e": 32, "521743e": 32, "521772": 39, "522": 32, "522563e": 32, "5227966": 39, "523595": 39, "523684": 39, "5238095238095238": 24, "52398": 35, "524": [24, 38], "524364": 42, "5253": 34, "525554": 35, "525757": 26, "526046": 39, "526078": [27, 28], "526214": 34, "526596": 35, "526602": 32, "5274": 42, "527500": 27, "528": 32, "5282": 42, "528403": 26, "52881619": 26, "529210": 31, "529388e": 32, "5294": 33, "529412": 27, "53": [29, 32, 41], "530052": 30, "530978": 31, "531116e": 32, "531353": 40, "5315": 30, "532034": 32, "533454": 40, "533498": 26, "534": 43, "534114": 30, "534342": 35, "535": [27, 35], "535014": 27, "53520104": 26, "535604": 27, "535622": 35, "536362": 36, "53636249": 36, "537267": 27, "537732": 39, "538000": 24, "538702": 26, "538816": 31, "5390": [31, 34], "5391": [27, 35], "539116": [41, 52], "539376": 42, "539459": 43, "54": [32, 41, 42, 51, 52], "540": 41, "540000": 27, "540039": 39, "540359": 35, "541117": 32, "541347": 39, "541488": 35, "54152": 31, "541667": 28, "541795": 31, "54240": 31, "542624": 34, "542873": [27, 28], "543297": 30, "543351": 34, "543464": 39, "544": 30, "544462": 34, "545": [32, 43], "546": 27, "5461": 32, "546473": 29, "546610": 26, "54676006e": 34, "547": [30, 32, 34], "547090": 39, "547993": 31, "548831": 34, "549": 43, "549682": 31, "5498": 26, "549946": 39, "55": [24, 25, 26, 29, 31, 32, 33, 34, 41, 42, 46], "55000": 30, "550000": [27, 28, 30], "550004": 33, "550616": 31, "55101": 41, "5513": 30, "5514": [33, 34], "5515": 42, "551579e": 32, "551862e": 32, "551975": 32, "552": [27, 32], "552721": 33, "553965": 34, "553979": 31, "5540": 42, "5541306485809793": 33, "55413065": 33, "554180": [41, 52], "554463": 39, "554621": 35, "5551": 29, "555740": 26, "5566": [27, 28, 48], "557197": 40, "557242": 31, "557739": 32, "558": [32, 34, 35], "558564": 31, "55862988e": 34, "55873324": 40, "5588": 23, "558824": 31, "558889": 32, "559": [30, 32, 34], "56": [26, 28, 31, 32, 41, 42, 51, 52], "560225": 27, "560768": 32, "561": [10, 26, 30, 34, 35], "561467": [27, 28], "561602": 34, "561645e": 32, "562112": 27, "5623062252998352": 39, "562712": 39, "563": 10, "5630224174651539": 29, "5630921721458435": 39, "563314": [32, 34], "563467": 27, "5644": 32, "564483": 35, "565": 35, "5650": 24, "565062": 42, "56521734": 8, "565679": 31, "565746": 42, "565888": 27, "566": 27, "566092": 27, "566222": 40, "5667": 31, "567724": 40, "567856e": 32, "568": 40, "568009": 26, "56804591": 32, "568663": 32, "5690201394302518": 34, "56902014": 34, "569375": 26, "5694": 35, "57": [26, 27, 28, 31, 32, 34, 41, 42, 48, 52], "57000": 42, "570015": 32, "570449": 31, "570473": 35, "5707": 42, "570739": 35, "571": [36, 44], "571431": 39, "571500": 35, "571901e": 32, "571969": 35, "572": 10, "572105": 26, "572549": 27, "572962": 42, "573": 44, "573050": 31, "573129": [32, 34], "5732": 31, "573542": 35, "573818": 31, "57415": [41, 52], "574260": 35, "575000": 38, "57510": 35, "5755444169044495": 39, "575907": 35, "576": 27, "57640869": 28, "576409": 28, "576921": 39, "578523": 29, "578654": 31, "5789": 32, "579091": 35, "579245": 39, "579432": 29, "579559e": 32, "579660": 33, "5798": 33, "57994": 31, "58": [24, 25, 26, 29, 32, 41, 42, 46], "580": 40, "5804311633110046": 39, "580539e": 32, "581": 34, "58137177": 28, "581372": 28, "5814": 23, "581687": 35, "581787": 42, "582": [23, 33], "582090": 31, "5824530720710754": 39, "582469": 32, "58387198": 36, "583872": 36, "584": 27, "584615": [27, 35], "585": 27, "585513": 29, "5857": 42, "586095": [27, 28], "587773": 31, "588": [26, 30], "588125": 26, "588235": 29, "588307": 27, "589286": 43, "59": [1, 26, 32, 41, 42], "590243": 39, "59049": 31, "59050": 31, "590618": 35, "59082668": 28, "590827": 28, "5915": 28, "592": 43, "592401": 23, "59243876": 33, "5925410985946655": 39, "59300": 35, "5931": 32, "593370": 32, "593508": 36, "5938": 27, "594": 27, "594595": 26, "594982": 31, "594995": 31, "5950": 27, "595427": 40, "595569e": 32, "596088e": 32, "596151": 35, "596810": 26, "596864": 32, "5970": 33, "59700": 31, "597015": 29, "59708": 31, "597326": 31, "597555": 23, "597924": [32, 34], "598": 27, "59810": 31, "598100": 29, "598149": [32, 34], "598750": 26, "599": 43, "5993570685386658": 39, "599492": 29, "599860": 26, "599894": [41, 52], "5fin": 32, "5th": [31, 33, 34, 50], "5unf": 32, "6": [8, 10, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53], "60": [8, 23, 27, 31, 32, 34, 35, 36, 38, 39, 41, 42], "600": [27, 29, 39], "60000": [41, 52], "600000": [25, 26, 30, 41, 52], "600193": 31, "60023631": 32, "600k": 32, "601": 30, "601042": 23, "601504": 29, "601712": 31, "601790": 29, "602": [27, 28, 48], "602000": 27, "602649": 26, "6028": 31, "602941": 31, "602954": 33, "6031432151794434": 39, "60319915": 44, "603684e": 30, "603970": 42, "604": 26, "6040": [26, 30], "604000": 24, "604032": 31, "60429913": 32, "604320": 29, "60455": [41, 52], "604619": 29, "604797": 29, "6048": 41, "604807": 42, "60495488": 26, "605060": 31, "6051": [27, 28, 48], "605100": 29, "605101": 29, "605102": 29, "605263": 26, "605625": 26, "605696": 29, "606": 27, "606061": 29, "6063088774681091": 39, "606557": 29, "606567": 29, "606811": 30, "606875": 26, "606902": 29, "607062": [41, 52], "608050": 29, "608125": 26, "6082": 27, "608468": 29, "608532": 40, "608565": 42, "60860": 27, "6086405515670776": 39, "609": 27, "6092": 23, "6093292236328125": 39, "609375": 26, "60943": 31, "60k": 32, "61": [26, 28, 29, 31, 32, 36, 41, 42], "61029914": 32, "610407": 31, "610931": 37, "611": 28, "611007": 40, "6111123561859131": 39, "611178": [41, 52], "612349": 28, "61234944": 28, "6124": 42, "612546": 31, "612621": 29, "612755": 26, "613507": 29, "613738": 30, "613738418384": 30, "614": 27, "61420598": 28, "614206": 28, "614567": 35, "615": 27, "6154": 35, "615730": 33, "616": 30, "616099": 30, "6168": 24, "617342": 42, "617431": 37, "6176": 31, "617647": 31, "618": 27, "618012": 30, "6186580061912537": 39, "618967": 39, "619": 43, "61912405": 34, "62": [26, 30, 31, 32, 41, 42, 52], "622255": 27, "622454": 30, "622500": 26, "6226": 35, "622612": 31, "622709": 29, "623000": 27, "62320": 41, "62352928": 33, "624049": 32, "6241": 23, "624375": 26, "624450e": 32, "624615": 32, "6250": 27, "625387": 30, "6257": 42, "626206": 32, "62657": 41, "626875": 26, "62688064": 34, "627": 42, "6273": 30, "6275": [24, 25, 46], "627722": 34, "627966": 27, "628032": 35, "628139": 31, "62873917": 34, "629792e": 32, "63": [26, 30, 31, 32, 41, 42, 43, 52], "6303": [27, 28, 48], "6306": [27, 35], "631899": 42, "632": 43, "6320": 29, "6320979595184326": 39, "6322": 35, "632353": 31, "632786": [41, 52], "63316788": 44, "63362": 32, "633933424949646": 39, "634397": 29, "634490": 28, "634686": 31, "635": 27, "635200": 35, "635239": [27, 28], "635648": 29, "636": [23, 27, 28, 42, 48], "636364": 43, "636410": 33, "636849e": 32, "637": 40, "637982": 26, "638169": 34, "6389": [27, 35], "6391518364256": 42, "6392": 35, "639754": 32, "64": [11, 26, 29, 32, 40, 41, 42], "640": [30, 40, 43], "6400": 27, "640000": [31, 43], "640266": [27, 28], "640x480": 26, "641216": 41, "641538": 42, "641873": 32, "642676": 41, "642965": 31, "643": 30, "6431": 35, "643311e": 32, "644106": 31, "64417243": 40, "64454": 31, "644770": 37, "645519": 31, "6458": [24, 25, 46], "645963": 30, "646050": 34, "6464": 42, "647796": 35, "648": [26, 27, 30], "6480": 33, "648195": 31, "648550": 40, "649658": 34, "64994": [41, 52], "65": [24, 28, 32, 42], "650": 31, "65000": 30, "650000": 30, "65000e": 26, "65013704": 36, "65125032": 44, "6513": 34, "651446": 41, "65243": 32, "652487": 35, "6526853": 32, "652828": 30, "652986": 35, "653": 27, "653205": 30, "653205232272": 30, "654": 27, "65424895": 32, "65486": 39, "656297e": 32, "656349": 26, "656827": 31, "657675": 35, "658047": 29, "658645": 29, "659056": 32, "66": [24, 25, 27, 29, 31, 32, 40, 41, 46, 52], "6601256728172302": 39, "660171": 26, "6604": [27, 28, 48], "660714": 28, "661023": 39, "66214339": 26, "66221": 41, "6622507572174072": 39, "662450": 31, "662541e": 32, "662745": 27, "662879": 33, "66368": 34, "663680": [32, 34], "6637": 42, "6638": 42, "663822": 34, "6639": 42, "6639009118080139": 39, "6641": 42, "6642": 42, "664207": 31, "6643": 42, "6644": 42, "6645": 42, "664625": 39, "664707": 29, "66473": [41, 52], "665": 27, "665307": 39, "665351e": 32, "665625": 26, "665882": 33, "666": [27, 28], "666166": [41, 52], "6666666666666666": 40, "666667": [25, 27, 38], "666754": 40, "667450": 41, "668": 39, "668787": 26, "6688": 23, "669614": 31, "669725": 31, "669805e": 32, "67": [24, 25, 28, 29, 31, 32, 41, 42], "670344": 26, "6709133982658386": 39, "67186503136": 32, "6731126308441162": 39, "673277": 30, "6733849048614502": 39, "6734487414360046": 39, "6744": 34, "674490": 30, "674721": 33, "675000": 23, "67501": 41, "67512181": 32, "67562658": 28, "675627": 28, "675676": 38, "675814": 26, "676250": 26, "676373": 31, "67672595": 32, "677": 27, "6771429181098938": 39, "6772": 42, "677268": 42, "677579": 26, "677601": 30, "677629": 26, "6778583526611328": 39, "678": [26, 30], "678689": 29, "679478": 27, "679877": [32, 34], "68": [24, 25, 26, 28, 31, 32, 34, 36, 37, 41, 42, 44, 52], "680000": 23, "6800296306610107": 39, "680657": 27, "681223": 26, "681716": 39, "683015": 33, "683171": 31, "68323": 30, "68339": [41, 52], "684211": 26, "684447": 27, "684960": [27, 28], "685103e": 32, "68523": 41, "685786": 33, "6858": 29, "686": 27, "686348e": 32, "687": 32, "687055": 31, "687307": 30, "687500": 25, "687504": 39, "688": 30, "6880359361853475": 29, "688043475151062": 39, "688135": 30, "689338": [32, 34], "69": [24, 25, 26, 28, 32, 36, 41, 42, 52], "690": 43, "69027185e": 34, "690402": 30, "690778": 34, "691241": 31, "691617": 39, "691640": 26, "691877": 30, "691924": 36, "69192445": 36, "692308": 27, "693": 27, "693498": 30, "693590": 28, "6938": [23, 41], "693890": 41, "693898": 41, "693936": 28, "69393613": 28, "69411": 35, "694155": 26, "694334": 33, "6950": 34, "695532": 27, "695783": 39, "696034e": 32, "6962": 27, "6963": 34, "696373": 27, "696429": 31, "696712": 41, "696859": 30, "696875": 26, "696970": 29, "69698010e": 34, "697": [27, 35], "697248": 31, "6973": 27, "698": 27, "698167": [41, 52], "698206": 32, "698384608345687": 30, "698385": 30, "6984": 35, "698857": 30, "699224": 26, "699706": 40, "699901396097971": 37, "6th": [31, 33, 34, 50], "6x6": 49, "7": [10, 11, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 53], "70": [24, 25, 28, 31, 32, 36, 37, 41, 42, 52], "70000": [41, 52], "700000": [41, 52], "700855": 31, "701128": [41, 52], "701173": 30, "701186e": 32, "70162085e": 34, "7017": 42, "701863": 30, "702703": 26, "703406": 42, "704": [26, 27, 32], "704099": 28, "7041": 39, "7042": 42, "7043": 42, "7046136400143138": 29, "70472": 35, "704969": 30, "705000": 27, "705470": 39, "705511": 30, "70560276": 28, "705603": 28, "70568": 32, "705696": 26, "705882": [25, 30], "70588235": 25, "705898": 35, "706": 28, "706128": 26, "706444": 31, "706783": 28, "70678332": 28, "706966": 41, "707681": 26, "707712": 42, "707899": 36, "70789903": 36, "70799": 30, "708": [27, 28, 30, 33, 48], "708075": 30, "708527": 27, "708978": 30, "709185": 26, "70978": 35, "709874": 30, "709880": 30, "709893": 41, "7099": 35, "71": [23, 24, 25, 28, 29, 31, 32, 36, 41, 42, 52], "710000": 27, "710031": 34, "710526": 26, "710896": 31, "71096": 35, "711": [28, 30], "711077": 27, "711086": 30, "711717": 30, "711754": [27, 28], "711819": 39, "711852": 35, "71199006": 32, "712": 27, "712074": 30, "71219761": 28, "712198": 28, "712324": 30, "712402": 33, "7129": 30, "713": 28, "71327467": 32, "714": 40, "714077": [27, 28], "714286": 30, "714402": 31, "715072": 40, "71517": 30, "7153": 42, "715424": 30, "715728": 31, "715992": 40, "716157": 31, "716655": 30, "716657": 30, "716792": 31, "716985": 26, "717289": 30, "717391": 30, "717829": 27, "718242": 30, "718266": 30, "718524": 41, "71866979": 32, "718750": 26, "7188": 28, "719": [23, 27, 35], "719056": 33, "719427e": 32, "719500": 26, "719747": 31, "72": [24, 25, 26, 31, 32, 41, 42, 46, 49], "720357": [41, 52], "72036": 41, "720497": 30, "720859": 27, "720893": 42, "720904": 41, "7210": 24, "721006": 30, "721008": 30, "7212512828409691": 29, "721616": 30, "721705": 27, "7218": [24, 25, 46], "721818": 35, "721921": 27, "722": 27, "722241": 30, "722249": 30, "723": 27, "72345029": 32, "723602": 30, "723613": 26, "7242": 24, "724458": 30, "724539": [41, 52], "724891": 31, "725": [29, 30], "7250894": 44, "726": [27, 31, 35], "726412": [27, 28], "726474": 40, "726573": 30, "726583": 30, "726634": 31, "7266666666666667": 44, "726788": 32, "727014": 41, "727198": 30, "727273": 26, "727554": 30, "7277854625841886": 42, "727821": 30, "7278214718381631": 30, "727829": 30, "728": [27, 31], "728235": [27, 28], "7283": 31, "728324": 31, "728777": 26, "729": 30, "729109": 43, "729143": 31, "7292": 35, "729814": 30, "73": [24, 25, 28, 29, 30, 31, 32, 37, 41, 42], "730383": 31, "731498": 42, "7315": 29, "7315558717766282": 30, "731572": 29, "731583": 26, "73183": 39, "7328": 27, "732919": 30, "733102": [27, 28], "733333": [25, 27, 28], "733746": 30, "734": [30, 32, 42], "734011": 30, "734385": 31, "734816": 41, "735": 32, "735043": 31, "735261": 30, "7352614272253524": 30, "7356575131416321": 39, "735879": 30, "736285": 31, "7363681793212891": 39, "736498": 30, "736900": 27, "7379": 24, "738": [27, 32], "738564": 41, "738701": [27, 28], "738715": 42, "738839": 29, "738977": 30, "739": 43, "739264": [27, 35], "7395977155164125": 30, "739598": 30, "739938": 30, "74": [24, 25, 27, 28, 29, 30, 31, 32, 37, 48], "740542": 23, "740844": 30, "741": 42, "741037": [41, 52], "741250": 26, "741463": 30, "7418": 34, "741935": 43, "742084": 30, "742088": 30, "742703": 30, "742981": 31, "743": [26, 27, 30, 42, 43], "743133": 26, "743135": 31, "743321": 30, "743323": 30, "743324": 30, "743391": 26, "743555": 34, "7436": [24, 25, 46], "743917": [27, 28], "7440": 23, "744201": 31, "744565": 30, "745": 33, "745178": 30, "746114": 33, "746328": 26, "747": 23, "74720920774": 32, "74798624e": 34, "748510": 31, "748725": 42, "748749e": 30, "748797": 29, "749118": 34, "75": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 41, 42, 48, 52], "750": 23, "7500": 32, "750000": 32, "7503": 24, "7504": 43, "750401": 39, "751": 43, "7524": 41, "753286": [27, 28], "754": 27, "754165": 43, "754386": 31, "754874": 35, "755": 42, "755000": 32, "7551": 30, "755364": 26, "755418": 30, "755477": 26, "756": 42, "7562": 23, "75625": [41, 52], "757": 31, "7574257425742574": 30, "75745416": 36, "757545": 32, "757591": 41, "757932": 42, "757985": [33, 34], "758": [33, 34, 42], "758062e": 32, "75826": [33, 34], "758514": 30, "7588186": 40, "7588527798652649": 39, "759561": 36, "75956122": 36, "7599": 29, "76": [25, 27, 29, 30, 31, 32, 34, 35, 42], "760": 42, "760262": 30, "760678": 41, "76161": 30, "761945e": 32, "762": [25, 42], "7620": 23, "762093e": 32, "76270194": 34, "763": 27, "7639": 24, "764052": 35, "76470588": 25, "764706": [25, 26, 30], "765": 31, "765591": 31, "765601": 32, "766317e": 32, "766423": 32, "766430": 26, "767": [32, 34], "767742": 29, "767802": 30, "767819": 41, "767852": 26, "768": [27, 28, 32, 34, 48], "768176": 42, "768512": 31, "76908228": 33, "769231": 27, "77": [24, 25, 28, 29, 31, 32, 37, 41, 42, 45, 51], "770": 24, "7706532429048965": 33, "770833": 38, "770898": 30, "771": 27, "771969": 26, "772532": 31, "773017": [32, 34], "7736": 30, "773851": 41, "774261": 41, "774844": 28, "77484447": 28, "7750553478074826": 41, "775270": 32, "7752884548630529": 29, "775311": 34, "77536150e": 34, "7758": 30, "776": 30, "7763": [27, 35], "776427": 42, "77694295": 33, "77709": 30, "777934": 26, "778": 43, "7781845435415525": 41, "779": [27, 35], "779271": 35, "78": [23, 24, 25, 27, 28, 31, 32, 35, 36, 41, 42, 45], "7800": 30, "780000": 33, "780296": 32, "780298": 32, "780316": 32, "780497": 32, "78058051e": 34, "780864": 31, "781": 27, "781004": 26, "781531": 31, "7816": 32, "782183": 32, "782219": 26, "7827": 31, "783282": 30, "783582": 26, "783784": 38, "783789": 26, "784424": 29, "784573": 35, "785": 28, "785105": 32, "785108": 32, "785134": 32, "78521263": 39, "785399": 32, "785483": [41, 52], "785714": 27, "786115": 35, "78617028": 33, "786555": 32, "787": 27, "787574": 32, "787879": [26, 29], "787933": 32, "788": 25, "788374": 40, "788647472858429": 39, "7887": 34, "7891381897690047": 29, "789436": 27, "789657": [41, 52], "79": [24, 25, 27, 28, 29, 31, 32, 41, 42, 46], "790": 31, "790000": 27, "79041": 32, "790731": 29, "791017": 42, "791467": 27, "792": 44, "792023": 34, "79250": 27, "792577": 32, "792603": 26, "792828": 32, "793": 35, "793243": 27, "79378": 31, "7938": 28, "794": 42, "794118": 26, "794236": 27, "794820": 27, "795": [26, 30], "79500e": 26, "7951": 30, "7951559890417761": 32, "795902": [41, 52], "796": 27, "7964215270662811": 29, "797": 27, "797355": [27, 28], "7978563117812038": 27, "798": 27, "7982": 26, "7986546": 32, "799983": 26, "79998417": 44, "7f688092391a": 40, "7pm": 35, "7th": [31, 33, 34, 50], "8": [9, 10, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 52], "80": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 41, 42, 45, 52], "800": [23, 25, 30, 39, 49], "800000": [30, 41, 52], "8001": 29, "800190": 26, "80062924": 26, "801219e": 32, "801666": 31, "801863": 26, "802502": 35, "802902": 32, "802987": 26, "803": [26, 27, 43], "803617": 31, "804": [26, 42, 43], "804818": [27, 28], "80482065": 28, "804821": 28, "805198": 32, "805342": 41, "805970": [26, 29], "806": 28, "8062": 24, "806899": 40, "8076": 32, "807684": 26, "807735": 31, "8078": 23, "808": 42, "8080": 24, "808208": 31, "808958": 26, "809": 27, "8098": 42, "81": [24, 25, 26, 28, 29, 30, 31, 32, 34, 36, 41, 42, 52], "810073": [32, 34], "810098": 35, "810368": 26, "81071706": 30, "810811": 38, "8112": 23, "812272": 32, "812363": 32, "812500": 25, "812593": 40, "812875": 42, "813": 27, "813586": 31, "815669": 31, "816717791411044": 42, "817": 33, "817034": 43, "817558": [27, 28], "8180": 27, "818041": 42, "818868": 27, "819152": 26, "819213": 42, "8195": 29, "819549": 26, "819584": 26, "81970188": 28, "819702": 28, "82": [24, 28, 30, 31, 37, 41, 42, 52], "820": 26, "820033": 32, "820143": 29, "82025568e": 34, "820564": 32, "821040": 34, "821327": 39, "821807": 32, "8219": 27, "8221": 28, "8225": 43, "82273995": 28, "822740": 28, "823511": 31, "823529": [25, 26, 29], "82352941": 25, "823543": 35, "824849": 31, "824884": 32, "825": 27, "825123": 35, "8253": 26, "825306": 30, "825470": 42, "825697": 32, "826142": 32, "826203": 29, "826216": 32, "826513": [41, 52], "826553": 32, "82670": [41, 52], "826739": 32, "826758": 32, "826760": 32, "827039": 29, "827068": 29, "827130": 31, "827261": 32, "827842": 29, "827907": 30, "8280229354283182": 32, "82804": 30, "828332": [32, 34], "828358": 26, "828405": 41, "828682": 30, "82869879": 39, "828891": 30, "828976": 30, "83": [24, 25, 28, 30, 31, 37, 38, 39, 41, 42, 45, 52], "830382": 31, "830712e": 32, "831135": 26, "831611": [32, 34], "831989": 30, "832": 27, "832320": 29, "832370": 31, "832866": 32, "833": [26, 30], "83320": 41, "8334": 34, "8340": 26, "834109": 30, "834356e": 32, "83437": 32, "834455": 26, "8356": 34, "835651": 30, "835749": [32, 34], "83603": [32, 34], "8361313": 32, "836189": 26, "836735": 31, "836878e": 32, "836880e": 32, "837022e": 32, "837838": 26, "837848": 26, "838": [26, 30], "83848729e": 40, "83876": 30, "8388866943476283": 29, "838951": 32, "8389756947416362": 29, "839225": 32, "84": [24, 25, 28, 41, 42, 43, 44, 45], "840": 27, "84002795": 28, "840028": 28, "840074": 25, "840183": 32, "840492": [32, 34], "84062193": 34, "841": 32, "841208": 30, "841886": 30, "841983": 30, "842": 27, "842028": 31, "842064": 42, "842105": 26, "843": 33, "843281": 34, "843284": [26, 29], "843842": [27, 28], "843992": [32, 34], "844409": 28, "84440919": 28, "844921": 36, "845": 30, "846154": [27, 43], "8462": 35, "846260e": 32, "846650": 32, "84679073": 26, "84698489": 40, "847178": 31, "847287": 30, "8475": 41, "84772": 31, "847799": 30, "847808": 31, "8478316682480326": 41, "848": [33, 34], "8481": 43, "84893192": 30, "849": [33, 34], "849102e": 32, "849438e": 32, "849612": 30, "85": [24, 25, 28, 31, 32, 33, 34, 35, 41, 42, 45, 52], "850": [23, 33, 34], "8502": 30, "850283": [41, 52], "850503": 30, "850746": 26, "851460": 32, "851852": 29, "852": [42, 43], "852053": 30, "852104": 32, "852941": 29, "853125": 26, "853399": 31, "854129": 32, "854167": 38, "854500": 42, "8546143543902771": 42, "854744525547446": 42, "854749": 41, "85545875": 26, "85597188": 28, "855972": 28, "856": 30, "856175": 27, "856589": 30, "857": 32, "857874": 30, "858": 29, "8580": [27, 28, 48], "858209": [26, 29], "858915": 30, "859": 33, "859318": 32, "859439": 36, "85943906": 36, "859455": 42, "85969": 30, "859799": 30, "86": [24, 26, 28, 29, 30, 31, 35, 41, 42], "860": [31, 34], "86000e": 26, "8601643854446082": 32, "860677": 31, "861": 27, "86102": [41, 52], "861348": 30, "862432": 32, "862552": 27, "8625888648969532": 42, "86267067": 28, "862671": 28, "862997": 35, "863014": 29, "863889": 41, "863941": 32, "864": 33, "86400": [41, 52], "8641864337292489": 42, "864205": 34, "865562": 42, "8661": 43, "866110": 29, "866667": [25, 31], "866980": 32, "867434": 40, "867558": 35, "868003": 32, "868281": 32, "868305": 32, "868308": 32, "869077": 28, "86907725": 28, "869094": 30, "8691": 28, "869531": 26, "869964": 30, "87": [24, 27, 28, 31, 41, 42], "870": [33, 34], "870503": 40, "871": [30, 33], "871094": 41, "8711": 31, "872": [33, 34], "872093": 30, "872603": 40, "872722908439952": 34, "8727229084399575": 34, "872961060": 32, "8729610607986": 32, "873": 33, "8731": [32, 34], "873103": 26, "873182": 41, "873356": 26, "873643": 30, "873704": 32, "874062": 28, "87406235": 28, "874305": 41, "874516": 30, "874532": 32, "874767e": 32, "875": 31, "8750": [27, 35], "875000": 25, "876065": 30, "876540": 42, "876574": [27, 28], "87681182": 39, "877046": 35, "877390": 34, "877519": 30, "877551": 31, "878183": 26, "87844893": 32, "87849316": 29, "879": 27, "87907": 30, "879938": 30, "88": [24, 25, 27, 28, 29, 31, 35, 42, 43, 48], "880": 35, "8801": 39, "880348": 30, "880831": [41, 52], "881395": 30, "881720": 31, "883138": 30, "884586": 30, "885": [23, 28], "885044": [32, 34], "885968": 42, "886047": 30, "886759": 29, "887": 33, "887017": 31, "887159": [41, 52], "8873": 31, "887324": 31, "887343": 26, "887597": 30, "887701": 31, "8878117": 28, "887812": 28, "888": [30, 33, 34], "888066": 34, "888372": 30, "888513": 31, "888811": 30, "888889": [27, 29], "888961": 34, "889086": 32, "889147": 30, "889429": 41, "889921": 41, "89": [24, 25, 28, 31, 37, 41, 42, 45, 52], "890": 33, "890457": 32, "890933": 42, "891001": 31, "891557": 30, "892476": 31, "892477": 26, "892491": 27, "89270": 35, "892733": 41, "892961": 35, "893000": 27, "893260": 28, "8937442459553657": 34, "894": 27, "895": 33, "895349": 30, "895541": 32, "89572": [41, 52], "895833": 31, "895963": 29, "897010": [27, 28], "89706451e": 34, "897674": 30, "898": 34, "898016": 30, "898703e": 32, "899": [27, 28, 30, 33, 48], "8994": 34, "8997": 32, "899969": [41, 52], "8m": 40, "8th": [31, 33, 34, 50], "9": [4, 10, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53], "90": [8, 23, 24, 25, 26, 28, 31, 32, 37, 38, 41, 42, 45], "900": [28, 30, 31], "90000": [41, 52], "900000": [25, 41, 52], "900662": 25, "901085": 29, "9010852321946792": 29, "901262": 41, "90159483": 36, "901595": 36, "902401": 30, "903101": 30, "904": [26, 30], "90403853": 28, "904039": 28, "904226": 26, "9047619047619048": 24, "904902": 40, "905": [26, 27], "905327": 41, "906667": 25, "90669": 35, "906865": 25, "907": 42, "907143": 43, "907595": 41, "908": 27, "908140": [27, 28], "908215": 32, "909091": 27, "90982": 35, "91": [24, 25, 27, 28, 30, 31, 35, 36, 41, 45, 52], "910": 24, "9100": 41, "910018": 32, "910174": 32, "9103": 41, "910456e": 32, "91063776": 34, "910714": 43, "910843": 32, "911615": 32, "911846": 32, "912": 27, "912395": 34, "913333": 25, "913767": 32, "913849": 32, "914003": 34, "914451894267": 32, "914585": 34, "91515735": 32, "915714e": 32, "915952": 32, "916254": 26, "916722": 34, "917526": 31, "917837": 31, "918": 33, "918124": 31, "918191": 40, "9182": 41, "919198": 34, "9196": 23, "92": [24, 25, 28, 31, 37, 40, 41, 42, 45], "920000": 25, "9203": 30, "920305": 35, "920462": 34, "92120500e": 44, "921422": 42, "921438": 32, "921850": 32, "92195464": 34, "921955": 34, "922": 28, "923077": 31, "923283": [27, 28], "923432": 34, "924485": 35, "9245": [25, 29], "925272e": 32, "925288e": 32, "925593": 26, "925768": 31, "926657": 32, "926733e": 32, "926829": 31, "928": 30, "92809": 35, "92852376": 26, "929": 30, "9295": 30, "93": [24, 25, 28, 29, 30, 36, 41, 42, 45], "930000": 27, "930123": 26, "930561": 26, "931439e": 32, "931786": 29, "932": 27, "932070": 42, "932124": 26, "932143": 43, "93279": 41, "9336": 27, "934205": 26, "934269": [27, 28], "934783": 31, "9351": 35, "935512": 42, "935802": 26, "93665": [41, 52], "9375": 25, "937500": [25, 28], "938": 31, "9383": [26, 29], "93869659": 28, "938697": 28, "939006": 31, "9391": 32, "939394": [26, 29], "94": [24, 25, 27, 28, 29, 30, 31, 32, 41, 45, 48], "9401": 41, "9406": [24, 25, 46], "941": 42, "941176": [25, 28], "94117647": 25, "943609": 35, "944": 23, "944092": 31, "944354": 28, "946783": 26, "947": [27, 30, 43], "9471": 30, "948482": 42, "94888": 31, "949": 27, "9490": 27, "9492": 32, "94933723": 32, "94959681": 28, "949597": 28, "95": [24, 25, 28, 31, 37, 41, 42], "950000": 27, "950088": 35, "9505": 34, "950564": 35, "9506": 34, "950696": 42, "950733": 26, "951294": 32, "951574": 35, "951644": 35, "951669": 35, "951696": 26, "953": 33, "95511263": 26, "955113": 26, "9558": 41, "956": 27, "956966": 35, "957075": 35, "9573": 41, "9576": 23, "957886": 40, "957919": 26, "957987": 26, "9583333333333334": 40, "958393": [27, 35], "95886206e": 40, "959": 27, "959139": 34, "959402e": 32, "959870": 31, "959873": 42, "96": [24, 28, 29, 30, 31, 35, 41], "960": 29, "961106": 31, "961109802000133": 37, "961404": [27, 28], "961498": [32, 34], "961771": 29, "961898": 29, "962776": 31, "96319": 41, "96320": 41, "96321": 41, "96322": 41, "96323": 41, "96325": 41, "963689": 35, "96554": 35, "9661": 32, "966131": [27, 28], "9664": [24, 25, 46], "966491": 31, "967102": 31, "967907": 31, "968": 27, "968233": 35, "96833": 39, "96834506": 26, "968493": 42, "968514e": 32, "96875": 40, "969048e": 32, "9691": 32, "9692602666681306": 29, "96965253": 34, "969653": 34, "97": [24, 25, 28, 29, 30, 34, 37, 41, 42], "970518": 31, "970683": 35, "971": 28, "97203586": 28, "972036": 28, "97217": 41, "972198": 30, "97223953": 28, "972240": 28, "972440": 31, "97253": 41, "9730": 28, "973225": 31, "973280": 28, "97328024": 28, "973482e": 30, "973750": 26, "974": 27, "974480": 35, "9748": 29, "974801e": 32, "975895": 41, "976": [27, 31, 33], "977": [27, 41, 52], "977278": 35, "9773": [24, 25, 26, 46], "978": 29, "9781449369880": 41, "9781789957211": 40, "97823755": 29, "9785299": 39, "978738": 35, "979": [33, 34], "979562": 42, "98": [24, 27, 28, 29, 32, 34, 36, 39, 41, 42], "980": [41, 52], "98007": 23, "98028": 24, "98045": 23, "98052": 23, "98055": 23, "980634": 42, "98072": 23, "98074": 24, "98075": 23, "9808": 29, "98107": 23, "98112": 23, "98116": 23, "981195": 41, "98125": 24, "98136": 24, "981735": 29, "98178": 24, "982": 28, "982184": 30, "982570": 42, "983": 40, "9837": [25, 29], "984": 30, "984653": 29, "984664": 32, "985283": 30, "9854": [24, 25, 29, 46], "985457": 42, "985816": 25, "986047": 30, "9862": 43, "986207": 30, "987": [30, 40], "987062": 32, "987597": 30, "9876": [33, 34], "987681": 35, "988": 35, "9881": [24, 25, 46], "988381": 30, "988841": 30, "988901": 32, "989": 24, "989147": 30, "989156": 30, "989443": 42, "989922": 30, "989973": 29, "99": [24, 25, 27, 28, 30, 31, 41, 50, 52], "990631": [41, 52], "990754": 41, "9912": [26, 29], "9915": [41, 52], "991966": 42, "992": [25, 30], "992254": 30, "99240562": 34, "992406": 30, "9926": 28, "992857": 25, "992908": 25, "993023": 30, "993029": 30, "993065": 42, "9931": [24, 25, 46], "9934531067299874": 29, "993666": 34, "993969": [32, 34], "994": 23, "994266": 30, "994574": 30, "994764": 41, "995": [35, 40], "9950": 35, "9951": [24, 25, 46], "99515": 41, "995434": 32, "996588e": 32, "996765": 34, "996788": 42, "996820": 42, "996899": 30, "99744241e": 34, "9977957422135844": 34, "998": [31, 42, 43], "9983": 31, "998302": 31, "99845": 30, "998451": 30, "999": [29, 43], "99907": 30, "999122": 31, "999147": 31, "999172": 31, "999183": 31, "999185": 31, "999192": 31, "999210": 31, "999214": 31, "999221": 31, "999223": 31, "999225": 30, "999254": 31, "999298": 31, "999317": 31, "99931882": 32, "999335": 31, "999535": 30, "999577": 41, "999622": 27, "9am": 35, "9th": [31, 33, 34, 50], "A": [0, 8, 9, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 52, 53], "AND": [0, 32], "AS": 0, "And": [23, 24, 30, 32, 39, 41, 42, 46, 47], "As": [4, 25, 28, 30, 32, 33, 34, 38, 41, 42, 44, 47, 49, 51, 53], "At": [4, 23, 25, 29, 31, 33, 35, 36, 40, 41], "BE": [0, 39], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 26, 34, 45, 47], "Being": 40, "But": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 47, 49, 51, 52, 53], "By": [23, 25, 26, 28, 31, 33, 36, 39, 40, 42, 47, 49, 53], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 52, 53], "IN": [0, 25, 29], "IT": 29, "If": [4, 5, 6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53], "In": [6, 7, 8, 9, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53], "Ines": 43, "It": [2, 4, 7, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 47, 49, 51, 53], "Its": 42, "NEAR": [27, 28, 35, 48], "NO": 0, "NOT": [0, 8, 28, 29], "No": [0, 23, 24, 32, 33, 34, 35, 37, 41, 42, 45, 52], "Not": [31, 32, 33, 34, 35, 36, 38, 41, 42, 50], "OF": 0, "OR": [0, 8, 32], "Of": [9, 28, 30], "On": [4, 7, 23, 27, 28, 30, 31, 32, 33, 34, 35, 37, 40, 42, 43], "One": [5, 8, 16, 24, 25, 28, 29, 30, 31, 34, 36, 37, 42, 45, 50, 52], "Or": [26, 28, 30, 47], "Such": [6, 38, 41], "THE": [0, 25], "TO": [0, 39], "That": [24, 25, 27, 29, 30, 32, 33, 34, 36, 37, 38, 39, 41, 42, 50], "The": [0, 1, 2, 5, 7, 8, 10, 23, 24, 26, 27, 28, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53], "Their": 5, "Then": [24, 29, 33, 36, 41, 50], "There": [2, 5, 8, 9, 10, 11, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 53], "These": [4, 11, 24, 25, 26, 29, 31, 32, 33, 34, 35, 36, 38, 41, 51, 53], "To": [8, 11, 23, 24, 25, 26, 27, 28, 29, 32, 33, 35, 37, 39, 40, 41, 43, 47, 49, 51, 52, 53], "WITH": 0, "Will": [31, 42, 43, 45, 50], "With": [0, 23, 24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 40, 42, 44, 47, 53], "_": [33, 39, 40, 42, 43], "__call__": 28, "__class__": [29, 41], "__finalize__": 42, "__getitem__": [25, 27], "__init__": 43, "__name__": [29, 41], "__testing_word2vec": 39, "_arg": 43, "_array_api": 43, "_astype_nansaf": 42, "_c": 43, "_california_housing_dataset": 29, "_call_func_on_transform": 28, "_callback": 43, "_column_transform": 28, "_constructor_from_mgr": 42, "_context": 43, "_data": 30, "_distn_infrastructur": 30, "_encod": 28, "_get_default_devic": 43, "_get_sequential_output": 28, "_i": 40, "_logist": 44, "_mgr": 42, "_proba": 33, "_pseudo_sync_runn": 43, "_run": 43, "_run_cel": 43, "_run_cod": 43, "_run_module_as_main": 43, "_run_onc": 43, "_score": 28, "_scorer": 28, "_set_output": 28, "_temp": 43, "_time_fit_was_cal": 42, "_transform": 28, "_transform_on": 28, "_valid": 28, "ab": [29, 31, 32, 34], "abbrevi": 39, "abil": [23, 28, 30, 34, 39, 41, 47], "abl": [8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 47, 49, 53], "about": [2, 4, 7, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53], "abov": [0, 5, 8, 11, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 47, 49, 52, 53], "absenc": [28, 34, 38], "absolut": [29, 31, 32, 34, 36, 43, 53], "abspath": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52], "academ": [7, 35], "accept": [5, 8, 31, 32, 39], "accept_spars": 28, "access": [10, 11, 25, 27, 30, 33, 36, 38, 39, 41, 49], "accessori": 41, "accident": [26, 27], "accommod": 7, "accompani": [7, 23, 24], "accord": [29, 31, 32, 35, 38, 42, 49, 50, 51, 53], "account": [7, 10, 25, 31, 35, 38, 42, 45, 50], "accur": [23, 25, 33, 34, 35, 38, 42, 45, 46], "accuraci": [24, 25, 26, 27, 30, 31, 33, 34, 35, 37, 40, 42, 43, 45, 46, 50, 51, 53], "accuracy_scor": 31, "acdm": [31, 33, 34, 50], "acf": 41, "achiev": [8, 26, 31, 49, 51, 52], "acinonyx": [23, 40], "acoust": [26, 27, 30, 49], "acquir": 53, "acquisit": 38, "across": [23, 24, 25, 27, 31, 34, 40, 53], "act": [29, 53], "action": [0, 23, 33, 34, 36, 38, 39, 42, 53], "activ": [4, 11, 23, 30, 43, 45, 53], "actor": [38, 39], "actual": [7, 23, 29, 31, 33, 34, 36, 38, 39, 41, 42, 49, 51], "ad": [28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 42, 43, 49, 52], "adapt": [0, 27, 28, 31, 33, 39, 41, 43], "add": [7, 8, 11, 27, 28, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 48, 50, 51, 52], "add_pip": 43, "addit": [0, 4, 32, 38, 50, 53], "addition": [46, 47, 53], "address": [18, 37, 50], "adelaid": [41, 52], "adj": [39, 43], "adject": 39, "adjust": [26, 30, 37, 41, 47], "adm": [31, 33, 34], "admin": 53, "administr": 1, "admit": 25, "adopt": [6, 38], "adp": [39, 43], "adult": [31, 33, 34, 50], "adult_df_larg": [33, 34], "adv": 39, "advanc": [28, 30, 36, 37, 38, 39, 40, 46, 53], "advantag": [27, 28, 29, 33, 37, 38, 39, 45, 53], "advic": 42, "advis": 23, "advisor": 53, "af": 34, "affect": [11, 26, 27, 29, 30, 31, 36, 41, 42, 43, 47], "affix": 39, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 31, 32, 34, 36, 37, 39, 40, 41, 42, 43, 45, 51, 52, 53], "ag": [23, 29, 31, 32, 33, 34, 35, 38, 50, 51], "again": [11, 24, 25, 27, 37, 38, 39, 40, 42, 47, 50, 51, 52], "against": [38, 39, 41, 49], "agenc": [39, 43], "agent": 10, "agglomerativeclust": 37, "aggress": 39, "agnost": 34, "ago": [40, 41], "agre": 47, "agreement": [42, 53], "ahead": 50, "ai": [7, 9, 31, 35, 39, 40, 50], "aight": 23, "aim": 45, "ain": 39, "airport": 31, "aka": [29, 42], "al": [33, 39], "alamine_aminotransferas": 23, "alan": 10, "alaska": 29, "alberta": 39, "album": 30, "albumin": 23, "albumin_and_globulin_ratio": 23, "alburi": [41, 52], "alexnet": 40, "algebra": [38, 39], "algorithm": [2, 15, 23, 25, 27, 28, 31, 32, 33, 34, 37, 39, 40, 46, 47, 48, 50, 53], "align": [8, 23, 24, 25], "align_kei": 42, "alkaline_phosphotas": 23, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 25, 26, 28, 30, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53], "all_cap": 43, "all_featur": [41, 52], "allei": [32, 34], "allen": 43, "alley_grvl": 32, "alley_miss": 32, "alley_pav": 32, "alloc": [8, 39, 40], "allow": [5, 7, 11, 25, 27, 30, 31, 35, 39, 41, 42, 46, 47, 49, 52, 53], "allpub": [32, 34], "almost": [29, 30, 32, 35, 37, 38, 39, 50], "along": [7, 24, 28, 31, 40, 41, 46], "alpha": [26, 27, 41, 47, 52], "alpha_": 32, "alphabet": 29, "alphago": [23, 36], "alq": [32, 34], "alreadi": [4, 8, 11, 31, 32, 34, 36, 39, 41, 42, 43, 46, 49, 52, 53], "also": [2, 4, 5, 7, 8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "altar": 40, "altern": [8, 30, 36, 49, 53], "although": [25, 33, 36, 38, 42], "alwai": [23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 43, 45, 46, 47, 49, 53], "am": [27, 36, 39, 43], "amatriain": 38, "amazon": [23, 36, 38, 43], "ambigu": 39, "amer": 31, "america": [28, 39], "american": 36, "aml": 27, "among": [23, 24, 30, 31, 33, 34, 38, 51], "amongst": 43, "amount": [4, 23, 25, 29, 30, 31, 32, 34, 36, 40, 41, 42, 49, 52], "amp": [33, 34], "amplifi": [31, 39, 50], "amuel": 27, "an": [0, 2, 4, 6, 7, 8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 48, 49, 51, 52, 53], "anaconda": [11, 34, 43], "analogi": [15, 37, 39], "analysi": [2, 9, 10, 24, 31, 32, 36, 37, 39, 50, 53], "analyt": 41, "analyz": [31, 35, 41, 42, 52, 53], "anatinu": 40, "anca": 53, "ancestor": 35, "ancestr": 53, "ancuta": 53, "andrea": [9, 10], "andrew": [9, 10, 30, 35], "anemon": 40, "angel": [42, 43], "ani": [0, 11, 24, 25, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 53], "anim": [31, 40], "animal_fac": 40, "anneal": 35, "annot": [34, 36], "announc": 7, "annoyingli": 32, "annual": 43, "anomali": [31, 32, 36], "anonym": 41, "anoth": [8, 11, 24, 26, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 48, 51, 52], "answer": [4, 6, 7, 23, 24, 25, 30, 33, 36, 38, 39, 41, 44, 46, 47, 50, 51, 52, 53], "anteat": 40, "anti": 42, "anymor": [32, 36, 38, 47], "anyth": [0, 25, 28, 31, 38, 39, 42, 49], "anytim": 53, "anywher": 28, "ap": [45, 53], "ap_lr": 31, "ap_svc": 31, "apart": [26, 37], "apeendixa": 35, "api": [31, 39, 41, 45], "app": [24, 43, 45], "appeal": 39, "appear": [2, 7, 28, 33, 47, 51, 53], "append": [4, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 50, 51], "appendix_b": 39, "appendixb": 40, "appl": 39, "appli": [0, 2, 6, 9, 10, 23, 24, 25, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 53], "applic": [0, 5, 23, 28, 30, 31, 32, 34, 35, 39, 42, 43, 45, 50, 53], "appreci": [36, 53], "approach": [10, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 45, 47, 52, 53], "appropri": [0, 4, 11, 24, 25, 28, 31, 32, 36, 37, 41, 42, 45, 53], "approv": [31, 50, 53], "approx": [26, 34], "approxim": [24, 30, 35], "april": 41, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 28, 30, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "arang": [8, 25, 26, 29, 30, 31, 32, 47, 49], "arbitrari": [34, 36, 37, 41], "architectur": 40, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "area": [30, 32, 33, 35, 36, 49], "aren": [7, 32, 35, 36, 39, 40, 41, 43, 52], "arena": 35, "arg": [25, 28, 43], "argh": 42, "argmin": [25, 26, 31, 36], "argsort": [34, 39], "argu": [36, 39, 49], "argument": [8, 24, 28, 30, 31, 32, 34, 43, 45, 48], "arima": 41, "arima_model": 41, "aris": [0, 23, 39], "aristotl": 26, "arithmet": 8, "around": [7, 26, 28, 31, 32, 41, 42, 46], "aroundn": 23, "arr": 42, "arr1": 8, "arr2": 8, "arrai": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49], "array_equ": 8, "arriv": 35, "arthur": 23, "articl": [10, 24, 25, 27, 31, 36, 38, 39, 40], "articul": 45, "artifici": [10, 39], "artist": [26, 27, 30, 49], "as_fram": [26, 47], "ascend": [8, 28, 29, 30, 32, 33, 34, 35, 41, 42, 45, 51], "ased": 37, "asi": 43, "asia": 28, "asid": [4, 25, 33, 47], "ask": [3, 7, 11, 23, 24, 25, 26, 28, 31, 35, 36, 38, 39, 42, 43, 46, 53], "asleep": 29, "aspartate_aminotransferas": 23, "aspect": [29, 34, 35, 37, 38, 42, 45], "assault": 53, "assert": [7, 28, 31, 33, 34, 50], "assess": [6, 10, 23, 24, 25, 27, 31, 34, 36, 53], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 41, 42, 43, 45, 46, 48, 50, 52], "assist": 23, "assoc": [31, 33, 34, 50], "associ": [0, 23, 25, 26, 31, 32, 34, 35, 36, 39, 40, 41, 42, 45, 51, 53], "assum": [23, 24, 28, 29, 31, 32, 37, 38, 39, 41, 45, 50], "assumpt": 42, "asterisk": 30, "astyp": [8, 41, 42, 52], "astype_arrai": 42, "astype_array_saf": 42, "async_": 43, "async_help": 43, "asyncio": 43, "asyncio_loop": 43, "atabak": 53, "atratu": 40, "attack": 24, "attempt": [25, 49, 50], "attend": 53, "attent": [6, 39], "attic": 32, "attract": 39, "attribut": [0, 1, 23, 24, 26, 27, 29, 30, 35, 36, 39, 40, 49, 51], "attrit": 42, "auc": [42, 45, 50, 53], "audienc": [50, 53], "audio": [40, 53], "audit": 53, "auditor": 53, "augment": 31, "august": 41, "austin": 39, "australia": [41, 52], "authent": 36, "author": [0, 39, 53], "auto": [23, 30, 31, 35, 36], "autocorrel": 41, "autom": [24, 32, 39], "automat": [27, 28, 32, 35, 39, 41, 42, 52], "autoregress": 29, "autumn": 41, "autumn_month": 41, "aux": [39, 43], "av": [32, 34, 39], "avail": [0, 1, 7, 9, 10, 11, 25, 28, 30, 31, 32, 37, 38, 39, 40, 41, 42, 45, 50, 51, 52, 53], "avebedrm": 29, "aveoccup": 29, "averag": [25, 26, 28, 29, 30, 32, 34, 36, 37, 39, 42, 43, 45, 47, 53], "average_precis": 31, "average_precision_scor": 31, "average_word_length": 43, "averaging_model": [33, 51], "averaging_model_ndt": 33, "averoom": 29, "avg": [31, 38, 41], "avg_sent_emb": 39, "avoid": [7, 8, 24, 27, 31, 32, 37, 41, 42, 44, 45, 47, 50, 53], "awai": [4, 6, 24, 29, 36, 38, 40, 42, 45], "await": 43, "awar": [28, 42, 53], "award": 53, "awesom": 9, "ax": [25, 26, 29, 31, 36, 37, 40, 42, 47, 50], "axi": [7, 8, 23, 24, 25, 27, 28, 29, 34, 36, 37, 39, 40, 41, 52], "axvlin": 36, "az": 43, "b": [8, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42], "b3": [27, 34], "babe": 23, "babi": [35, 39], "bachelor": [31, 33, 34, 50], "back": [8, 27, 30, 39, 45], "backdrop": 41, "background": [24, 53], "bad": [8, 24, 25, 26, 28, 31, 32, 33, 34, 35, 36, 40, 41], "badgeryscreek": 41, "bag": [35, 39, 40, 45, 49], "bai": [27, 28, 35], "baidu": 25, "bal_scor": 31, "balanc": [6, 26, 33, 36, 38, 44, 50, 51], "ballarat": [41, 52], "balust": 40, "balustrad": 40, "bambi": 38, "banist": 40, "bank": [31, 34, 41, 42, 50], "bannist": 40, "bar": [31, 32, 34, 40, 41, 42, 52], "baranski": 43, "barbu": 53, "barri": 29, "base": [5, 8, 11, 15, 24, 25, 27, 28, 29, 30, 31, 32, 34, 36, 37, 39, 42, 43, 45, 46, 49, 50, 51, 53], "base_ev": 43, "base_scor": 33, "base_valu": 34, "baseblockmanag": 42, "baselin": [14, 42, 45, 46, 48, 49, 52], "baseline_hazard_": 42, "bash": 5, "basi": [24, 26], "basic": [2, 8, 24, 30, 35, 38, 40, 42, 43, 51, 52], "batch": [39, 40], "batch_siz": 40, "batch_t": 40, "bath": 23, "bathroom": [23, 24, 29], "bayesian": 30, "bayesopt": 30, "beagl": [23, 40], "bear": 40, "beat": [33, 42], "beauti": [38, 39], "becam": 40, "becaus": [7, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 52, 53], "becom": [4, 25, 26, 29, 30, 31, 34, 35, 36, 39], "bed": 31, "bedroom": [23, 24, 29], "bedroomabvgr": [32, 34], "bedrooms_per_household": [27, 28, 48], "beef": 39, "been": [4, 6, 10, 23, 24, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 53], "befor": [4, 10, 11, 23, 24, 25, 26, 28, 29, 32, 33, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 51, 52], "begin": [24, 29, 35, 38, 41, 42, 45], "beginn": 40, "behav": [30, 34], "behavior": [25, 27, 31, 38], "behaviour": [28, 50, 51], "behind": [23, 29, 53], "being": [4, 23, 25, 27, 31, 32, 33, 34, 37, 39, 42, 47, 53], "believ": [30, 34, 41], "bell": 40, "belong": [24, 29, 37, 46], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53], "bench": 40, "benchmark": 40, "bendigo": [41, 52], "benefici": 28, "benefit": [4, 26, 33, 37, 39, 45], "bengio": 30, "ber": 39, "bergstra": 30, "berri": 39, "bertop": 39, "best": [2, 24, 25, 26, 30, 31, 32, 33, 34, 36, 37, 38, 42, 46, 47, 49, 51], "best_alpha": 32, "best_depth": 25, "best_estimator_": [30, 32], "best_n_neighbour": 26, "best_param": 30, "best_paramet": 30, "best_params_": [30, 32, 49], "best_scor": 30, "best_score_": [30, 32, 49], "bestalpha_coeff": 32, "better": [6, 23, 24, 26, 27, 28, 29, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53], "between": [2, 8, 11, 23, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 53], "bewar": 39, "beyond": [25, 30, 35], "bia": [29, 31, 34, 42, 45, 50], "bias": [31, 34, 39, 42, 50, 53], "bicycl": [24, 41], "big": [7, 26, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 42, 47], "bigalpha_coeff": 32, "bigger": [26, 28, 29, 32, 34, 37, 39, 40, 41], "biggest": [32, 35, 52], "bike": 41, "bill": 40, "billboard": 41, "billie_holidai": 39, "billion": 32, "billionth": 41, "bin": [27, 30, 32, 35, 41, 42, 43, 46], "binar": [24, 28], "binari": [24, 27, 28, 29, 40, 42, 44, 45, 50], "binary_feat": 28, "binary_featur": [31, 33, 34, 50, 51], "binary_transform": [31, 33, 34, 50, 51], "bincount": [31, 33, 50], "bind": [26, 47], "binomi": 30, "biolog": 35, "biologi": 28, "bit": [11, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 42, 49, 50, 52], "black": [26, 34, 36, 40, 41, 52], "blackhawk": 39, "bld": 43, "bldgtype": [32, 34], "bldgtype_1fam": 32, "bldgtype_2fmcon": 32, "bldgtype_duplex": 32, "bldgtype_twnh": 32, "bldgtype_twnhs": 32, "blei": 39, "blend": 39, "blindli": [31, 32], "blob": 44, "block": [29, 42], "blog": [39, 41], "bloomberg": [9, 10], "blq": [32, 34], "blue": [24, 26, 30, 31, 34, 35, 36, 41], "bluesman": 39, "bmatrix": [35, 38], "board": 4, "boathous": 40, "bob_dylan": 39, "bodi": 43, "boggl": 33, "bond": 31, "bonu": 33, "book": [1, 9, 31, 32, 38, 39, 41, 53], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "bool": [32, 41], "boom": 43, "boost": [19, 20, 39, 45], "booster": 33, "bootstrap": 11, "border": [24, 29, 37, 39, 44, 46], "bore": 29, "boston": 29, "both": [2, 6, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 48, 49, 50, 53], "bother": 34, "bottom": 37, "bought": 38, "bound": [35, 42], "boundari": [25, 37, 39, 47], "bow_df": 28, "box": [9, 34, 45], "boxplot": 34, "boyc": 24, "br": 39, "bracket": 8, "brain": [35, 40], "branch": [24, 37, 39, 42], "break": [31, 45, 47], "breakwat": 40, "breath": 45, "breathtak": 39, "breed": 45, "breiman": 33, "brief": [4, 29, 33], "briefli": [23, 31, 33, 35], "bring": [6, 34, 37, 43, 45], "british": [1, 39], "british_columbia": 39, "broad": [26, 39, 47], "broadcast": 39, "broader": [2, 33, 39], "broadest": 39, "broadli": [24, 26, 29, 31, 33, 36, 37, 39], "brownle": 35, "browser": 11, "brush": 40, "bsmtcond": [32, 34], "bsmtexposur": [32, 34], "bsmtfinsf1": [32, 34], "bsmtfinsf2": [32, 34], "bsmtfintype1": [32, 34], "bsmtfintype2": [32, 34], "bsmtfullbath": [32, 34], "bsmthalfbath": [32, 34], "bsmtqual": [32, 34], "bsmtunfsf": [32, 34], "btw": 34, "bubbl": [38, 40], "bucket": [35, 43], "budget": [30, 38], "bug": [4, 8], "bui": 38, "build": [0, 2, 11, 25, 27, 28, 33, 35, 36, 39, 41, 44, 47, 52, 53], "built": [8, 23, 24, 25, 29, 30, 34, 41, 52], "bullshit": [10, 42], "bulwark": 40, "bunch": [8, 11, 24, 32, 33, 40, 42, 47], "bundl": [7, 11], "bureau": 29, "busi": [31, 36, 42, 43], "businesswoman": 39, "bustl": 41, "butterfli": 37, "buzz": 23, "bypass": 53, "c": [0, 5, 8, 9, 10, 11, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 49, 53], "c1": 37, "c2": 37, "c_1": 36, "c_2": 36, "c_3": 36, "c_log": [26, 47], "c_widget": [26, 47], "ca": [5, 9, 43, 53], "ca_transform": 28, "cal_hous": 29, "calcul": [7, 25, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 41, 43, 44, 45, 47, 50, 52], "calgary_flam": 39, "california": [27, 35], "california_h": 35, "californian": 27, "call": [8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52], "callback": 33, "calm": 45, "came": 41, "camera": 28, "campu": [35, 53], "can": [4, 6, 7, 10, 11, 23, 24, 26, 28, 29, 30, 31, 32, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "canada": [5, 25, 26, 28, 29, 39, 43, 45], "canada_usa_c": [24, 25, 26, 29, 46], "canadian": 39, "canadien": 39, "canberra": [41, 52], "cancel": 53, "cancer": [23, 35], "candid": [30, 33, 39, 47], "cannot": [0, 8, 25, 26, 30, 31, 33, 34, 35, 37, 41, 42, 43, 53], "canuck": 39, "canva": [1, 7, 10], "capabl": 9, "capit": [31, 33, 34, 50], "caption": [7, 40], "captiv": 39, "captur": [25, 27, 29, 33, 35, 37, 38, 39, 41, 42, 45, 53], "car": [23, 39, 40], "card": [23, 24, 31, 42, 50], "care": [5, 7, 25, 27, 30, 31, 32, 34, 35, 36, 41, 42, 45, 49, 51, 52], "carefulli": [1, 31, 32, 50, 53], "carpentri": 5, "carri": [24, 25, 26, 28, 30, 31, 32, 33, 36, 38, 39, 41, 43, 47, 49, 52], "caruana": 34, "case": [6, 11, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 52, 53], "cash": 23, "cast": [30, 38, 43], "castl": 40, "cat": [23, 31, 33, 39, 40, 43, 45], "catamount": [23, 40], "catboost": [34, 45, 53], "catboostclassifi": 33, "catboostregressor": 33, "catch": [31, 53], "categor": [24, 30, 31, 32, 33, 35, 36, 38, 39, 42, 45, 47, 48, 50, 52], "categori": [26, 27, 31, 32, 33, 34, 35, 36, 40, 45, 50], "categorical_feat": [28, 30, 45, 49], "categorical_featur": [28, 31, 32, 33, 34, 41, 42, 50, 51, 52], "categorical_transform": [28, 31, 32, 33, 34, 41, 50, 51, 52], "categories_": [27, 28], "cater": 36, "caus": [31, 34, 35, 38, 42, 49], "causal": [34, 35], "caution": 41, "cbar": 29, "cbtf": [10, 53], "cc": [0, 1], "cc_df": [31, 50], "cconj": 39, "cell": [7, 8, 23, 27, 28, 30, 31, 32, 33, 34, 35, 38, 40, 42, 43, 46, 47, 49, 51], "cell_nam": 43, "censor": [10, 45, 53], "censu": [29, 31, 33, 34, 50], "census_df": [31, 50], "cent": 32, "center": [26, 36, 37, 40, 44], "centercrop": 40, "centers_idx": 36, "central": 5, "centralair": [32, 34], "centralair_i": 32, "centralair_n": 32, "centric": 53, "centroid": [36, 37], "centroids_idx": 36, "centroids_idx_init": 36, "centuri": 39, "certain": [11, 26, 29, 30, 31, 34, 35, 36, 39, 42, 50], "certainli": 46, "certainti": 31, "cezannec": 40, "chaat": 39, "chage": 49, "chain": 28, "challeng": [6, 25, 35, 36, 38, 40, 41, 45, 51, 53], "chanc": [24, 25, 30, 31, 32, 35, 36, 42, 50], "chang": [0, 5, 7, 8, 11, 24, 25, 26, 27, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 49, 50, 51, 52, 53], "channel": [1, 11, 40], "chapter": 10, "charact": [28, 31, 39], "characterist": [24, 25, 29, 49], "charg": [0, 23, 42], "charl": 29, "charm": 39, "chart": [34, 41, 42, 52], "chat": 53, "chatgpt": 39, "che210d": 9, "cheaper": 35, "cheat": 9, "check": [4, 7, 10, 11, 23, 24, 25, 27, 29, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 47, 50, 51, 52], "check_assumpt": 42, "check_invers": 28, "checklist": 45, "checkmark": 38, "checkout": 30, "cheetah": [23, 40], "chest": 25, "chestpaintyp": 51, "chetah": [23, 40], "chi": 42, "chicago": 43, "chicken": 36, "child": [31, 34], "children": 38, "chines": 39, "chn": 8, "choic": [2, 30, 32, 33, 34, 36, 37, 38, 41, 43, 47, 48, 49], "cholesterol": 51, "choos": [23, 30, 31, 33, 37, 45, 47], "chop": [30, 39], "choreograph": 43, "chosen": [25, 30, 31, 42, 45, 51], "chrbv": 42, "christin": 43, "christma": 43, "chunki": 36, "churn": 45, "ciml": 10, "cinematographi": 39, "cinereu": 40, "circl": [26, 31], "circumst": 7, "citat": 7, "cite": 42, "citi": [24, 25, 26, 39, 41, 45, 46], "citibik": 41, "cities_df": [26, 29], "citizen": 42, "cityscap": 41, "civ": [31, 33, 34], "clai": 34, "claim": [0, 30, 31], "clarif": 36, "clarifi": 45, "clariti": 53, "class": [4, 5, 11, 23, 24, 25, 26, 27, 28, 29, 35, 36, 39, 41, 42, 46, 47, 50, 51, 52], "class_attend": [24, 25, 45], "class_attendance_enc": 28, "class_attendance_level": 28, "class_label": 31, "class_labels_fil": 23, "class_nam": [24, 26, 33, 40], "class_sep": 31, "class_weight": [33, 50], "classes_": [29, 31, 33, 34, 40, 44], "classic": [26, 40, 44], "classif": [2, 10, 25, 26, 27, 28, 29, 32, 33, 34, 35, 38, 39, 41, 42, 44, 46, 47, 49, 50, 51, 53], "classifi": [25, 26, 27, 28, 30, 31, 34, 40, 44, 46, 48, 50, 51], "classification_df": [24, 25], "classification_report": [31, 40, 50], "classifiers_ndt": 33, "classify_imag": [23, 40], "classmat": [6, 47, 48, 49, 50, 51, 52, 53], "classroom": 10, "clean": [2, 23, 37, 52, 53], "clean_text": 39, "cleaned_hm": 31, "cleaner": [31, 34], "clear": [7, 31, 36, 47, 53], "clearli": [4, 6, 7, 30, 33, 34, 41], "cleric": [31, 33, 34], "clf": [23, 24, 26, 29, 40], "click": [5, 7, 10, 31, 38], "client": 38, "clinic": 24, "clip": 23, "clone": [5, 7, 11], "close": [2, 25, 26, 29, 30, 31, 36, 37, 39, 41, 43, 44, 47, 53], "close_default_lr": 31, "close_zero_svm": 31, "closer": [26, 27, 29, 38, 46, 49, 53], "closest": [26, 27, 31, 36, 37, 39, 41], "cloth": 41, "cloud": [23, 24, 28, 29, 30, 32, 33, 43], "cloud3pm": [41, 52], "cloud9am": [41, 52], "clust_label": 36, "cluster": [2, 10, 38, 39, 41, 53], "cluster_cent": 36, "cluster_centers_": 36, "cluster_std": [37, 40], "clutter": 24, "cm": [26, 29, 31, 34, 38, 47, 50], "cmap": [27, 30, 31, 34, 40, 49], "cmn": 32, "cmp": 42, "cnn": [40, 41], "co": [28, 39], "coast": 40, "code": [4, 7, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52], "code_ast": 43, "code_obj": 43, "codecademi": 9, "coef": [41, 42, 43, 52], "coef_": [29, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 51], "coef_df": [29, 34], "coef_nonzero": 41, "coeff": 29, "coeff_df": 41, "coeffici": [32, 33, 35, 38, 40, 41, 42, 43, 44, 45, 51, 52], "coefs_df": 35, "coher": 36, "col": [24, 28, 29, 38, 41, 45], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 27, "colinear": 34, "collabor": [5, 38, 53], "collaps": 34, "colleagu": [8, 9], "collect": [23, 24, 27, 28, 31, 33, 34, 35, 38, 39, 40, 41, 42, 45, 51, 53], "colleg": [31, 33, 34, 50], "collinear": 35, "color": [19, 29, 34, 35, 36, 37, 41], "color_continuous_scal": 35, "color_threshold": 37, "colorbar": [27, 29], "colour": [28, 29, 30, 34, 36, 37, 40], "colsample_bylevel": 33, "colsample_bynod": 33, "colsample_bytre": 33, "columbia": [1, 9, 39], "column": [7, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "column_nam": 28, "column_stack": 35, "columntranform": 48, "columntransform": [10, 16, 17, 27, 30, 31, 32, 33, 34, 35, 41, 42, 43, 49, 50, 51, 52], "columntransformer__countvectorizer__max_featur": [30, 49], "columntransformercolumntransform": [28, 30, 32, 33, 35, 43], "columntransformerifittedcolumntransform": [28, 32], "columntransformerinot": [28, 33], "com": [0, 5, 8, 9, 11, 23, 24, 28, 29, 31, 32, 33, 40, 41, 42, 43, 50], "comat": 39, "combin": [24, 27, 28, 30, 31, 35, 38, 40, 41, 42, 46, 47, 49, 51], "come": [11, 23, 24, 27, 28, 31, 35, 38, 39, 40, 41, 42, 46], "comedi": 38, "comfort": 5, "command": [4, 11, 31, 39], "comment": [8, 9, 52], "commerci": 0, "commit": [7, 31, 53], "common": [1, 8, 24, 25, 26, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 44, 47, 53], "commonli": [24, 27, 30, 31, 36, 42], "commonwealth": 39, "commun": [2, 10, 11, 28, 30, 32, 53], "commut": 8, "comp_dict": 31, "compact": [30, 35], "compani": [31, 36, 38, 39, 42, 43, 50], "compar": [8, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 45, 49, 50, 51, 52, 53], "comparison": [37, 40, 42, 45], "compassion": 53, "compat": [8, 34, 43], "compatibitl": 8, "compel": 41, "compet": 43, "competit": [33, 40, 44], "compil": 43, "complain": [6, 43], "complaint": [6, 53], "complement": 39, "complet": [1, 6, 7, 23, 27, 30, 33, 34, 35, 37, 39, 42, 46, 47, 50, 51, 53], "complex": [24, 26, 29, 30, 32, 33, 34, 35, 37, 39, 40, 41, 47, 53], "compli": 0, "complic": [4, 24, 25, 30, 32, 35], "compon": [28, 31, 38, 41, 53], "components_": 39, "compos": [26, 28, 30, 31, 32, 33, 34, 35, 40, 41, 42, 43, 48, 49, 50, 51, 52], "composit": 28, "compound": [39, 40, 42, 43], "comprehend": 39, "comprehens": [36, 45, 53], "compress": [28, 36, 39], "compris": [23, 24, 36], "comput": [7, 9, 10, 11, 23, 28, 30, 31, 33, 34, 35, 36, 37, 39, 41, 44, 50, 51, 53], "computation": 35, "compute_class_weight": 31, "computer_programm": 39, "coms4995": 27, "con": [36, 39, 40], "concat": [23, 26, 27, 28, 29, 34], "concaten": [28, 39], "concav": 35, "concensu": 25, "concentr": [30, 45], "concept": [10, 24, 25, 34, 35, 36, 41, 45, 47, 53], "conceptnet": 39, "conceptu": 33, "concern": [4, 28, 33, 53], "concess": 7, "concis": 24, "concord": 42, "concordance_index": 42, "concordance_index_": 42, "concret": 23, "conda": [23, 31, 32, 33, 34, 36, 39, 42, 43], "condit": [0, 23, 24, 28, 35, 39, 42, 53], "condition1": [32, 34], "condition1_arteri": 32, "condition1_feedr": 32, "condition1_norm": 32, "condition1_posa": 32, "condition1_posn": 32, "condition1_rra": 32, "condition1_rran": 32, "condition1_rrn": 32, "condition1_rrnn": 32, "condition2": [32, 34], "condition2_arteri": 32, "condition2_feedr": 32, "condition2_norm": 32, "condition2_posa": 32, "condition2_posn": [32, 34], "condition2_rra": 32, "condition2_rran": 32, "condition2_rrnn": 32, "conditional_aft": 42, "confer": 39, "confid": [23, 25, 34, 42, 45, 47, 50, 51], "confidenti": 31, "config": [11, 43], "configur": [30, 32, 33], "confirm": 11, "conflict": [11, 37, 53], "confound": 35, "confus": [8, 18, 26, 28, 32, 36, 47, 50], "confusion_matrix": [31, 40, 42], "confusionmatrixdisplai": [31, 50], "congrat": 28, "conjunct": 35, "connect": [0, 24, 37, 38], "connot": 39, "conort": 35, "consciou": 53, "consecut": 41, "consequ": [7, 23, 28, 31, 38, 50], "consid": [4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 45, 47, 53], "consider": [2, 31, 33, 36, 38, 42, 53], "consist": [6, 7, 24, 25, 27, 36], "const": 39, "constant": [24, 31, 32, 33, 34, 41, 42, 50, 52], "constitu": 33, "constitut": [39, 53], "construct": 38, "constructor": [24, 27], "consult": [26, 47, 53], "consum": [23, 35, 36, 38, 45], "consumpt": 41, "contact": [23, 53], "contain": [8, 11, 19, 23, 24, 27, 28, 29, 32, 38, 39, 40, 43, 44, 53], "content": [1, 4, 11, 36, 39, 40, 45, 53], "contest": 6, "context": [24, 27, 29, 30, 31, 33, 34, 35, 37, 38, 40, 41, 45, 47, 53], "contextu": 53, "contin": 28, "conting": 37, "continu": [15, 28, 30, 32, 33, 35, 39, 41, 52], "contract": [0, 42], "contract_month": 42, "contract_on": 42, "contract_two": 42, "contrast": [45, 53], "contribut": [26, 29, 34, 40, 51, 53], "control": [5, 8, 24, 25, 26, 28, 29, 32, 33, 40, 53], "convei": 53, "conveni": [8, 30, 31, 36, 39, 41, 42], "converg": 36, "convers": [31, 32, 34, 39, 49], "convert": [23, 27, 28, 29, 33, 34, 35, 39, 41, 42, 52], "convinc": 28, "convolut": [35, 40], "convolutional_neural_network": 40, "cooccurrencematrix": 39, "cook": 36, "cool": 40, "coolwarm": 29, "coordin": 53, "copi": [0, 7, 8, 11, 24, 30, 33, 34, 36, 38, 40, 41, 42, 51, 52, 53], "copy_arrai": 43, "copyright": 0, "cor": 34, "coral": 40, "core": [9, 25, 27, 28, 30, 31, 32, 35, 37, 38, 41, 42, 43, 45, 52, 53], "corefer": 39, "corgi": [23, 40], "coro": 43, "corona_nlp_test": 43, "coronapocalyps": 43, "coronaviru": 43, "corpor": [5, 43], "corpora": [28, 39], "corpu": [28, 31, 39], "corr": 34, "corr_df": 34, "correct": [7, 23, 24, 25, 26, 31, 33, 34, 42, 46, 47, 51], "correctli": [10, 11, 24, 25, 31], "correl": [41, 45], "correspond": [10, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 36, 38, 41, 47, 49], "cosin": 39, "cosine_similar": 39, "cost": [8, 23, 40, 53], "cost_rep": 8, "costco": 39, "costli": 31, "cot": 40, "cote": 40, "could": [6, 8, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 38, 39, 41, 42, 47, 49, 50, 52, 53], "couldn": 39, "count": [8, 24, 27, 28, 31, 32, 35, 39, 40, 41, 42, 43, 44, 47, 49, 50, 52, 53], "counter": 31, "counti": 47, "countri": [25, 26, 28, 29, 31, 33, 34, 39, 50, 53], "country_columbia": 34, "country_dominican": 34, "country_guatemala": 34, "country_hondura": 34, "country_hong": 34, "country_hungari": 34, "country_india": 34, "country_iran": 34, "country_miss": [33, 34], "country_puerto": 34, "country_scotland": 34, "country_south": 34, "country_taiwan": 34, "country_thailand": 34, "country_trinadad": [33, 34], "country_unit": [33, 34], "country_vietnam": [33, 34], "country_yugoslavia": [33, 34], "countvector": [23, 29, 30, 31, 39, 43, 45, 49], "countvectorizercountvector": [28, 30, 43], "countvectorizeroriginaltweet": 43, "countvectorizersong_titl": 30, "coupl": [4, 24, 30, 37, 43, 52], "cour": 39, "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49], "coursera": [9, 10], "coursework": 53, "court": 39, "covari": [24, 42], "cover": [8, 31, 33, 36, 40, 41, 53], "coverag": 31, "covid": 43, "covid2019": 43, "cox": 53, "coxph_fitt": 42, "coxphfitt": 42, "cph": [42, 45], "cph_param": 42, "cpp": 43, "cpsc": [9, 10, 11, 23, 24, 33, 35, 39, 40, 41, 43, 53], "cpsc330": [0, 11, 23, 24, 25, 28, 30, 34, 39, 40, 42, 43, 53], "cpsc330env": 11, "cpu": [30, 40, 43], "craft": [26, 31, 33, 34, 36, 47], "crash": [10, 43], "crate": 40, "creat": [8, 9, 11, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "create_lag_df": 41, "create_lag_featur": [41, 52], "create_y_from_r": 38, "creativ": [1, 39], "credit": [0, 24, 31, 33, 39, 41, 42, 50], "creditcard": [31, 50], "crime": 29, "crimin": 34, "criteria": [24, 37], "criterion": 37, "critic": 53, "cross": [15, 24, 26, 28, 30, 32, 33, 34, 36, 38, 42, 43, 45, 48, 49, 50, 51, 52], "cross_val": 33, "cross_val_predict": [31, 33, 42], "cross_val_scor": [27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 48, 49, 50, 51, 52], "cross_valid": [26, 27, 28, 29, 30, 31, 33, 34, 35, 38, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52], "cross_validate_std": 25, "crowd": [33, 37], "crown": 53, "crown_princ": 39, "crucial": [23, 25, 29, 34, 36, 37, 38, 39], "crude": 39, "cs189": 9, "cs189_ch7": 9, "csrc": 43, "csv": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "ct": 28, "cuda": 40, "cui": 53, "cultiv": 53, "cultur": [40, 53], "cupi": 43, "curios": 23, "curiou": [23, 47], "current": [33, 39, 40, 41, 42, 43], "curriculum": 53, "curv": [7, 8, 36, 45, 47, 53], "custom": [5, 8, 23, 24, 28, 31, 32, 38, 43, 45], "custom_plot_tre": [24, 25, 33, 34], "customerid": 42, "customiz": 43, "cut": 37, "cv": [25, 28, 31, 32, 33, 34, 35, 41, 42, 45, 47, 49], "cv_feat": 43, "cv_results_": [30, 32, 49], "cv_score": [25, 32], "cv_train_scor": 47, "cv_valid_scor": 47, "cycl": 8, "cyclic": 41, "cycling_data": 8, "cygnu": 40, "d": [4, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 50, 51, 52], "d1b": 53, "d1c": 53, "d1e": 53, "d1f": 53, "d3": 36, "da": 23, "dabeaz": 9, "dad": 35, "dai": [4, 8, 10, 35, 40, 42, 45, 52, 53], "daili": [42, 45], "dall": 41, "damag": [0, 31], "dan": 39, "danceabl": [26, 27, 30, 49], "dark": 43, "darker": 30, "dashboard": [26, 47], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 37, 39, 42, 44, 45, 46, 48, 49, 50, 51, 53], "data_dict": 29, "data_dir": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52], "data_to_wrap": 28, "data_transform": 40, "data_transforms_bw": 40, "data_url": [31, 50], "datacamp": 9, "datafram": [23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52], "dataload": 40, "dataloaders_bw": 40, "datapoint": 29, "dataquest": 9, "dataset": [8, 18, 23, 25, 26, 33, 34, 35, 36, 37, 42, 43, 44, 45, 47, 49, 50, 53], "dataset2": 36, "dataset_s": 40, "date": [7, 11, 23, 24, 38, 39, 42, 43, 45, 47, 52, 53], "date_rang": 41, "dates_rain": [41, 52], "datetim": 42, "datetime64": [41, 52], "datetimeindex": 41, "datum": 39, "daughter": 31, "daum\u00e9": 10, "daunt": 38, "dave": 39, "david": [10, 39], "day_nam": [41, 52], "daylight": [41, 52], "dayofweek": 41, "days_sinc": 41, "dbscan": 53, "dc": [41, 42, 43], "dcc": 29, "dd": [41, 52], "de": [39, 41], "deactiv": 11, "deadlin": 53, "deal": [0, 25, 26, 27, 32, 39, 42, 45, 48], "death": 53, "debat": [8, 34], "debbi": 43, "debug": [4, 34], "decad": 40, "decemb": [41, 52], "decid": [8, 24, 26, 29, 33, 34, 35, 36, 37, 39, 41, 42, 45], "decis": [2, 6, 10, 14, 25, 27, 30, 31, 33, 35, 40, 44, 45, 46, 48, 51, 53], "decision_boundari": 44, "decision_funct": 31, "decisiontreeclassifi": [25, 26, 27, 28, 29, 30, 34, 46, 47, 48, 49, 51], "decisiontreeclassifierdecisiontreeclassifi": 33, "decisiontreeregressor": [24, 32, 46, 47], "deck": 9, "declar": 53, "decomposit": [37, 38, 39], "decor": 43, "decreas": [25, 29, 30, 33, 34, 36, 47], "deduct": 7, "deem": 6, "deep": [2, 9, 30, 34, 35, 39, 42], "deepen": [45, 53], "deeper": [2, 30, 31, 32, 34], "deepexplain": 34, "def": [25, 26, 27, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 43, 47, 49, 52], "defalut": 49, "default": [5, 11, 24, 25, 28, 29, 30, 31, 32, 33, 36, 37, 40, 41, 42, 44, 49, 50, 53], "default_threshold": 31, "defaultdict": 38, "defin": [24, 26, 27, 28, 31, 33, 34, 36, 37, 38, 41, 52], "definit": [8, 26, 34, 36, 39, 41, 44, 45, 46], "degre": 31, "degrees_freedom": 42, "degrees_of_freedom": 42, "del": 33, "delai": [10, 11, 35], "deleg": 39, "delet": [4, 7, 27], "delgado": 33, "delight": 39, "deliver": 7, "delv": [39, 53], "demo": [10, 33, 53], "demograph": [24, 38], "demonstr": [24, 25, 27, 29, 30, 32, 33, 36, 38, 39, 40], "denomin": [32, 43], "denot": [24, 38], "dens": [37, 39], "densenet": 40, "densenet121": 40, "densenet121_weight": 40, "densiti": [34, 37, 45], "dep": 39, "department": 53, "departur": 35, "depend": [2, 8, 11, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 51], "dependence_plot": 34, "dependents_no": 42, "dependents_y": 42, "deploi": [25, 31, 38, 45], "deploy": [34, 41, 53], "deprec": [25, 27, 31, 32, 42, 44], "deprecationwarn": [33, 42], "depth": [10, 24, 25, 30, 33, 37, 46, 47], "dequ": [33, 34, 51], "deriv": [0, 24, 29, 31, 38, 42, 45, 50], "descend": [8, 37, 40, 45], "descent": 41, "descr": 29, "describ": [8, 23, 24, 25, 26, 27, 29, 31, 32, 38, 39, 41, 47, 50, 52, 53], "descript": [32, 42, 43], "deserv": 6, "design": [24, 34, 37, 40, 49, 53], "desir": [31, 39, 42, 48], "desk": 53, "despit": [35, 39], "det": [39, 43], "detach": 40, "detail": [7, 26, 28, 33, 39, 40, 53], "detect": [23, 24, 31, 32, 36, 37, 41, 50], "determin": [26, 36, 37, 39, 42, 47, 51, 53], "detriment": [31, 38, 50], "dev": [25, 44], "develop": [9, 10, 23, 25, 27, 28, 30, 31, 32, 33, 39, 40, 43, 45, 53], "devianc": 42, "deviat": [6, 25, 27, 33, 34], "devic": [33, 40, 43], "deviceprotect": 42, "deviceprotection_no": 42, "deviceprotection_y": 42, "df": [23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 40, 41, 42, 43, 46, 52], "df_concat": 23, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 41, "df_locat": [41, 52], "di": 42, "diagnos": [25, 34, 45], "diagnosi": 31, "diagnost": 42, "diagon": [26, 31, 34], "diagram": [28, 30, 33, 34], "dialogu": 39, "dict": [31, 38], "dict_kei": 33, "dictionari": [8, 27, 30, 31, 33, 34], "did": [6, 24, 26, 34, 36, 39, 41, 43, 47, 49, 50, 51, 53], "didn": [30, 33, 34, 37, 39, 41, 42], "die": 43, "diet": [24, 39], "diff": [41, 52], "differ": [2, 5, 7, 8, 10, 11, 23, 24, 25, 26, 28, 29, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 52, 53], "differenti": [23, 24, 53], "difficult": [4, 6, 7, 31, 35, 36], "difficulti": [36, 45], "dig": [31, 32], "digit": 41, "dilemma": 38, "dim": 40, "dimens": [8, 29, 35], "dimension": [2, 8, 29, 30, 31, 33, 35, 36, 39], "direct": [29, 34, 35, 37, 39, 43], "direct_bilirubin": 23, "directli": [8, 10, 28, 32, 40, 42, 53], "director": 38, "directori": [11, 24, 25, 27], "dirichlet": [39, 40], "disabl": 39, "disadvantag": [30, 33, 37, 38, 48], "disast": 23, "discard": [35, 39], "disciplin": [31, 35], "disclos": [43, 53], "discourag": 8, "discours": 38, "discov": [35, 36], "discoveri": 23, "discret": [24, 35, 53], "discrete_scatt": [24, 25, 26, 29, 36, 37, 40, 44, 46, 47], "discretization_feat": 35, "discrimin": 33, "discuss": [1, 4, 25, 26, 27, 29, 34, 35, 36, 37, 41, 45, 47, 48, 49, 51, 52, 53], "diseas": [24, 31, 42], "dispatch": 43, "dispatch_queu": 43, "dispatch_shel": 43, "displaci": [39, 43], "displai": [7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 37, 38, 40, 41, 42, 46, 47, 48, 49, 50, 52], "display_heatmap": [30, 49], "display_label": [31, 50], "displaystyl": 39, "disput": 39, "disrespect": 4, "dist": [26, 36, 37], "distanc": [8, 27, 35, 37, 38, 39], "distinct": [31, 35, 41], "distinguish": [24, 26, 28, 31, 47], "distract": 53, "distribut": [0, 11, 25, 31, 34, 35, 37, 39, 40, 41, 49, 52, 53], "district": [27, 29], "districtdatalab": 36, "disturb": 23, "dive": 34, "divers": [33, 36, 38, 41, 53], "divid": [29, 31, 33, 34, 41, 47], "divis": 34, "divorc": [33, 34], "dktal": 42, "dlwqn": 42, "dmp": 53, "do": [0, 4, 5, 6, 7, 8, 10, 11, 23, 24, 25, 26, 29, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "do_execut": 43, "dobj": 39, "doc": [8, 9, 34, 39, 40, 43, 53], "doc_id": 39, "doctor": [31, 33, 34, 50], "document": [0, 1, 7, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 45, 49, 50, 51, 53], "document_top": 39, "documentari": 38, "doe": [5, 8, 11, 23, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 47, 49, 51, 52, 53], "doesn": [7, 8, 25, 27, 28, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 45], "dog": [31, 40], "dollar": [4, 29, 32], "dolli": 43, "domain": [0, 23, 34, 36, 39], "domin": [27, 32, 40], "domingo": [10, 25, 35], "dominican_republ": 39, "don": [4, 23, 25, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "done": [5, 11, 25, 28, 30, 31, 40, 41, 45, 48, 50], "dont": 43, "door": 40, "dosa": 39, "dot": [26, 29, 31, 33, 34, 35, 37, 39], "dot_product": 39, "doubl": 30, "down": [25, 31, 34, 39, 42, 47, 51, 53], "downfal": 38, "downgrad": 43, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 31, 32, 34, 39, 40, 43, 47, 51], "dpi": 35, "dr": [39, 53], "draft": 10, "drag": 7, "drama": 38, "drastic": 31, "draw": [29, 30, 39], "drawback": [34, 38, 53], "drawn": 33, "dream": 40, "dreampharmaceut": 39, "drinker": 39, "drive": [23, 34], "driven": [11, 30, 31], "droit": 39, "drop": [7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53], "drop_dupl": [26, 30], "drop_feat": [28, 45], "drop_featur": [31, 32, 33, 34, 41, 42, 43, 50, 52], "dropdown": 19, "dropdrop": [28, 32, 33, 43], "drope": 27, "dropna": [31, 41, 52], "dropoff": 36, "drug": 23, "dsci": [9, 10, 34, 44], "dsl": 42, "dt": 47, "dt88trtd17lf726d55bq16c40000gr": 43, "dt_best": 47, "dt_pipe": 30, "dtype": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 50, 51, 52], "dual": 31, "duan": 53, "duck": 40, "duckbil": 40, "due": [7, 29, 33, 35, 38, 53], "dummi": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 46, 48, 49, 50, 51, 52], "dummy_clf": [24, 46], "dummy_scor": 26, "dummy_valid_accuraci": 26, "dummyclassifi": [25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 40, 43, 46, 47, 48, 49, 50, 51, 52], "dummyregressor": [28, 33, 34, 35, 43, 48, 51], "dun": 23, "dunno": 23, "duplex": 32, "duplic": 8, "durat": [7, 35, 41, 42], "duration_col": 42, "duration_m": [26, 27, 30], "dure": [4, 8, 10, 23, 24, 26, 28, 29, 30, 33, 34, 35, 38, 39, 45, 46, 47, 48, 49, 50, 51, 52, 53], "dwell": 32, "e": [6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 52, 53], "e737c5242822": 42, "e_": 25, "each": [7, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53], "earli": [34, 42], "earlier": [27, 33, 35, 41, 42], "early_stopping_round": 33, "earn": 53, "earnest": 53, "easi": [7, 26, 27, 29, 33, 34, 35, 36, 37, 39, 43], "easier": [5, 7, 31, 34, 35, 38], "easiest": [34, 42, 43], "easili": [33, 35, 41, 46, 52], "echidna": 40, "econom": [28, 41], "ecosystem": 40, "ed": 1, "eda": [25, 39, 42, 45, 52], "edg": [24, 30], "edgecolor": [30, 41, 52], "edit": [30, 39], "edu": 9, "educ": [31, 33, 34, 38, 50], "education_level": [31, 33, 34, 50], "effect": [26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 45, 47, 50], "effici": 30, "effort": [4, 11, 30, 35, 36, 38, 40, 53], "egg": 36, "eghbal": 53, "either": [4, 24, 25, 26, 28, 31, 34, 36, 37, 39, 40, 41, 47, 49], "elast": 42, "elbow": 37, "elect": 39, "electr": [32, 34], "electrical_engin": 39, "electrical_fusea": 32, "electrical_fusef": 32, "electrical_fusep": 32, "electrical_miss": 32, "electrical_mix": 32, "electrical_sbrkr": 32, "electron": [42, 53], "eleg": [27, 39], "elegantli": 39, "element": [0, 9, 10, 25, 28, 39, 46], "eli5": 34, "elif": [24, 41, 42], "elimin": 53, "els": [24, 28, 31, 40, 41, 42, 43, 50], "email": [23, 25, 31, 53], "emb": [7, 26, 31, 36, 37], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 28, 40, 45, 53], "emoji": 43, "emoticon": [35, 36], "emp": 34, "empathi": 39, "emphas": 53, "emphasi": 53, "emploi": [41, 42, 45], "employ": 38, "employe": 24, "empti": [29, 39, 40, 41, 52], "en": [41, 42, 43, 52], "en_core_web_lr": 39, "en_core_web_md": [39, 43], "enabl": [11, 38, 39, 41], "enable_categor": 33, "enable_halving_search_cv": 30, "enc": [27, 28, 41], "enclosedporch": [32, 34], "encod": [16, 17, 23, 25, 30, 31, 32, 34, 38, 42, 45, 48, 50, 52], "encompass": [42, 45], "encount": [28, 30], "encourag": [11, 53], "end": [4, 8, 23, 25, 26, 29, 30, 31, 35, 36, 37, 38, 39, 41, 42, 47, 53], "endors": 0, "endpoint": 42, "energi": [26, 27, 30, 41, 49], "engag": 53, "engin": [9, 10, 28, 31, 32, 36, 38, 39, 42, 52, 53], "england": 43, "english": [23, 27, 30, 31, 39, 40, 43, 49], "enhanc": 53, "enjoi": [10, 29], "enjoy_class": 28, "enjoy_cours": [28, 45], "enjoy_course_enc": 28, "enjoy_the_mo": 31, "enough": [7, 26, 28, 31, 32, 33, 36, 38, 45, 49, 50, 52], "ensembl": [10, 19, 20, 32, 34, 35, 37, 38, 41, 42, 43, 51, 52, 53], "ensiti": 37, "ensur": [7, 27, 33, 41, 52, 53], "ent": [39, 43], "enter": [28, 42, 49], "enterpris": 5, "entertain": 39, "enthusiast": 23, "entir": [4, 8, 25, 32, 40, 41, 43, 51, 53], "entiti": [35, 38, 39, 43], "entitl": 28, "entlebuch": [23, 40], "entri": [26, 27, 28, 29, 31, 32, 35, 38, 41, 42, 52], "entropi": 24, "enumer": 33, "env": [11, 24, 25, 28, 30, 34, 42, 43, 44], "environ": [3, 5, 8, 23, 27, 28, 30, 31, 32, 33, 34, 35, 39, 40, 42, 43, 53], "environemnt": 11, "environment": 45, "ep": [24, 25, 26, 29, 37, 46], "epoch": 41, "epsilon": 37, "equal": [8, 26, 28, 31, 32, 33, 34, 37, 38, 41, 45, 52, 53], "equat": [4, 29], "equip": [26, 42, 53], "equival": [8, 31, 33, 50], "erik": 39, "err": 39, "error": [4, 6, 7, 8, 11, 24, 26, 28, 29, 33, 34, 35, 39, 42, 43, 45, 47, 51, 53], "error_": 25, "erupt": 23, "erythrocebu": [23, 40], "es": [41, 52], "eskimo": 31, "esl": 10, "especi": [2, 24, 26, 30, 31, 33, 35, 38, 41], "essenti": [42, 45], "estat": 24, "estim": [25, 26, 28, 29, 30, 35, 36, 42, 45, 51], "estimators_": 33, "et": [33, 39], "etc": [2, 7, 8, 24, 35, 39, 40, 41, 42, 43, 53], "ethic": [10, 53], "euclidean": [36, 37, 39], "euclidean_dist": [26, 27, 36, 37, 39], "ev": 43, "eva": 38, "eva_model": 38, "eval": 40, "eval_metr": [33, 34], "eval_on_featur": 41, "evalu": [8, 10, 24, 25, 30, 32, 34, 36, 41, 47, 51, 53], "evapor": [41, 52], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 29, 30, 31, 35, 36, 37, 38, 41, 42, 43, 45, 47, 48, 50, 53], "event": [0, 31, 32, 43, 53], "event_col": 42, "event_observ": 42, "ever": [24, 44], "everi": [8, 24, 25, 33, 37, 41, 47], "everydai": [8, 39], "everyon": [6, 34, 45], "everyth": [28, 31, 38, 41, 51], "everywher": 41, "evict": 43, "evok": 39, "ex": [32, 34], "ex1_idx": 34, "ex2_idx": 34, "exact": [4, 42], "exactli": [7, 23, 25, 34, 47, 49], "exam": [6, 10], "examin": [25, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 50, 52], "exampl": [0, 4, 5, 6, 7, 8, 11, 32, 37, 38, 40, 41, 44, 45, 46, 47, 49, 50, 52, 53], "example1": 24, "example2": 24, "exceedingli": 47, "excel": [28, 29, 32, 34, 42, 45, 48], "except": [0, 7, 8, 25, 41, 42, 52, 53], "exception": 4, "exchang": [31, 45], "excit": 38, "exec": 43, "execut": [4, 7, 36], "execute_request": 43, "exercis": [7, 9, 10, 39, 43, 47, 48, 49, 50, 51, 52, 53], "exerciseangina": 51, "exhaust": 49, "exist": [8, 31, 35, 42, 50], "exp": [29, 42], "expand": [10, 24, 53], "expect": [1, 4, 7, 8, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 52, 53], "expected_valu": 34, "expenditur": 41, "expens": [23, 31, 32, 35, 36, 38], "experi": [23, 30, 38, 39, 53], "experienc": 53, "experiment": 30, "expert": [23, 24, 25, 30, 34, 35, 50], "explain": [4, 7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 50, 51, 53], "explan": [4, 25, 26, 45, 50], "explanatori": 24, "explicit": [31, 42], "explicitli": [8, 23], "exploit": 6, "explor": [24, 25, 28, 30, 31, 34, 35, 38, 39, 40, 47, 49], "exploratori": [32, 42, 45], "explos": 43, "expm1": 32, "expon": 30, "exponenti": 30, "export_graphviz": [24, 46], "exposur": 38, "express": [0, 8, 28, 29, 35, 39], "extend": [39, 40, 44, 53], "extend_block": 42, "extens": [26, 31, 34, 36, 37, 39, 41, 47, 53], "extent": [36, 39], "extercond": [32, 34], "exterior": 34, "exterior1st": [32, 34], "exterior1st_asbshng": 32, "exterior1st_asphshn": 32, "exterior1st_brkcomm": 32, "exterior1st_brkfac": 32, "exterior1st_cblock": 32, "exterior1st_cemntbd": 32, "exterior1st_hdboard": 32, "exterior1st_imstucc": [32, 34], "exterior1st_metalsd": 32, "exterior1st_plywood": 32, "exterior1st_ston": 32, "exterior1st_stucco": 32, "exterior1st_vinylsd": 32, "exterior1st_wd": 32, "exterior1st_wdsh": 32, "exterior2nd": [32, 34], "exterior2nd_asbshng": 32, "exterior2nd_asphshn": 32, "exterior2nd_brk": 32, "exterior2nd_brkfac": 32, "exterior2nd_cblock": 32, "exterior2nd_cmentbd": 32, "exterior2nd_hdboard": 32, "exterior2nd_imstucc": 32, "exterior2nd_metalsd": 32, "exterior2nd_oth": 32, "exterior2nd_plywood": 32, "exterior2nd_ston": 32, "exterior2nd_stucco": 32, "exterior2nd_vinylsd": 32, "exterior2nd_wd": 32, "exterqu": [32, 34], "extra": [4, 36, 41, 52, 53], "extract": [35, 36, 38, 39, 40, 43, 52, 53], "extractor": 45, "extrapol": [41, 42], "extratreesclassifi": 33, "extrem": [6, 28, 31, 33, 34, 38, 42, 43], "ey": 43, "f": [8, 11, 23, 24, 25, 26, 27, 28, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 47, 51, 52, 53], "f1": [18, 32, 45, 53], "f1_score": 31, "f403": 43, "fa": [32, 34], "face": [23, 24, 26, 38, 40], "facebook": [38, 39, 53], "facial": 26, "facil": 53, "facilit": [8, 53], "fact": [23, 30, 31, 33, 40, 41, 42, 52], "factor": [24, 30, 34, 35, 37, 38, 42], "fail": [7, 8, 10, 11, 25, 27, 28, 35, 37, 39, 42, 43], "failur": [7, 23, 42, 51, 53], "fair": [6, 25, 27, 32, 34, 36, 45, 53], "fairli": [25, 30, 31, 34, 50], "fake": 26, "fall": [26, 36, 39, 41], "fals": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 45, 50, 51, 52], "famili": [23, 30, 31, 32, 33, 34, 36, 53], "familiar": [8, 11, 24, 27, 47, 52, 53], "famou": [9, 10, 39, 40], "fanci": [4, 23, 30], "fancier": 35, "far": [24, 26, 27, 28, 29, 31, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 47, 49, 51], "farm": 31, "farthest": 24, "fashion": [33, 39], "fast": [25, 26, 29, 33, 34, 39, 42, 53], "faster": [23, 30, 33, 35, 40], "fastest": 33, "fastingb": 51, "fasttext": 39, "favourit": 39, "fc": 29, "fcluster": 37, "feat": [30, 41, 43], "feat1": 36, "feat2": 36, "feat_nam": [41, 43], "feat_vec": 38, "featur": [10, 16, 17, 21, 22, 25, 31, 33, 36, 37, 39, 42, 44, 47, 48, 49, 50, 51, 53], "feature_extract": [23, 28, 29, 30, 31, 39, 43, 49], "feature_importances_": 35, "feature_nam": [24, 25, 29, 33, 34, 35, 39], "feature_names_out": 28, "feature_select": 35, "feature_typ": 33, "features_lag": 41, "features_nonzero": 41, "features_poli": 41, "februari": 41, "feder": [31, 34, 39, 41], "feedback": [24, 45], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 36, 45], "feli": [23, 40], "fell": 29, "femal": [31, 33, 34, 42, 50], "female_cm": [31, 50], "female_pr": [31, 50], "fenc": [32, 34, 40], "fernandez": 33, "fetch_california_h": 29, "few": [8, 10, 23, 29, 32, 33, 35, 38, 39, 40, 41, 42, 46, 51], "fewer": [11, 33, 35, 37], "fewest": 51, "fiber": 42, "fiction": 43, "field": [2, 4, 23, 28, 39, 40, 41, 53], "fig": [25, 26, 29, 31, 35, 36, 37, 40, 47, 50], "figsiz": [24, 25, 26, 27, 29, 31, 34, 35, 36, 37, 40, 41, 42, 47, 50], "figur": [4, 8, 11, 23, 24, 26, 30, 32, 34, 35, 36, 37, 40, 41, 42, 47], "file": [0, 1, 4, 5, 7, 8, 11, 19, 24, 28, 31, 34, 40, 42, 43, 50, 52], "filenam": 40, "fill": [26, 29, 30, 38, 47, 51, 53], "fill_diagon": 26, "fill_valu": [31, 32, 33, 34, 41, 50, 52], "film": [39, 43], "filter": [4, 23, 25, 36, 41, 45, 52, 53], "filterwarn": [26, 42, 51], "final": [6, 7, 10, 25, 27, 33, 35, 46, 48, 51], "final_estim": 33, "final_estimator_": [33, 51], "financ": [40, 41], "find": [7, 8, 10, 23, 24, 27, 30, 32, 33, 34, 36, 37, 38, 39, 43, 44, 49, 50, 53], "fine": [7, 27, 28, 31, 38, 40, 41, 51], "finish": [23, 32], "fira": [0, 1, 53], "firasm": [31, 50], "fireplac": [32, 34], "fireplacequ": [32, 34], "first": [4, 8, 10, 24, 26, 28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 51, 53], "first_dai": 41, "first_day_retail": 41, "firth": 39, "fish": [31, 34], "fist": 41, "fit": [0, 23, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52], "fit_intercept": 31, "fit_predict": 37, "fit_resampl": 31, "fit_tim": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43], "fit_transform": [27, 28, 31, 33, 34, 35, 37, 38, 39, 41, 45, 50], "fittedcolumntransform": [28, 33], "fittedpipelin": [28, 30, 32], "fittedvotingclassifi": 33, "fitter": 42, "five": 30, "fix": [27, 28, 33, 42, 44, 47, 53], "flag": 42, "flagstaff": 43, "flaki": 31, "flashcard": 45, "flat": 37, "flatten": [33, 34, 37, 41, 51], "flatten_train": 40, "flatten_transform": 40, "flatten_valid": 40, "flaw": [25, 27], "flawless": 29, "flexibl": [7, 23, 35, 40, 45, 53], "flibbertigibbet": 39, "flickr_cat_000002": 40, "flight": 35, "flip": [10, 25, 31, 32], "flip_i": 31, "float": [8, 32, 35, 42, 43], "float32": [39, 40], "float64": [24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 41, 42, 52], "floatlogslid": [26, 47], "floatslid": [26, 31, 36, 37, 47], "floor": [23, 24], "flower": [26, 31, 47], "fmt": 30, "fn": 31, "fnlwgt": [31, 33, 34, 50], "focu": [10, 23, 27, 28, 29, 34, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 53], "focus": [23, 29, 36, 39, 45, 52], "fold": [25, 27, 28, 30, 31, 32, 33, 47], "folder": [5, 6, 25, 27, 34, 43], "folk": [42, 53], "follow": [0, 5, 6, 7, 8, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 47, 53], "font": [23, 24, 25, 36, 37, 38, 41, 42], "font_scal": 34, "fontsiz": [24, 25, 26, 31, 33, 34, 36, 40, 46, 47], "food": [36, 39, 40, 53], "foot": [32, 34], "footag": 29, "footstal": 40, "forc": [31, 34, 47], "force_plot": 34, "forecast": [24, 42, 45, 52, 53], "forest": [31, 32, 40, 41, 42, 45, 51, 53], "forev": 41, "forg": [11, 31, 32, 33, 34, 39, 42, 43], "forget": [24, 28, 33, 51], "form": [10, 28, 31, 35, 37, 38, 39, 42, 45], "formal": 53, "format": [0, 10, 24, 31, 37, 39, 41, 42, 52], "former": 42, "formul": [4, 30], "formula": [29, 32, 40, 44], "forum": [6, 7], "forward": 42, "found": [7, 10, 25, 28, 30, 32, 36, 38, 39, 43, 45, 49, 51, 53], "foundat": [9, 10, 31, 32, 34, 53], "foundation_brktil": 32, "foundation_cblock": 32, "foundation_pconc": 32, "foundation_slab": 32, "foundation_ston": 32, "foundation_wood": 32, "fountain": 40, "four": [24, 25, 35, 37, 45], "fourth": 37, "foxhound": [23, 40], "foyer": 32, "fp": 31, "fpr": 31, "fpr_lr": 31, "fpr_svc": 31, "frac": [24, 29, 31, 32, 36, 39, 40], "fractal": 35, "fraction": [28, 31, 38], "fragment": 47, "frame": [27, 28, 31, 32, 35, 41, 42, 52], "framework": [24, 30], "fraud": [24, 31, 32, 36, 41, 50], "fraudul": [24, 31, 50], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 28, 32, 39, 42], "freedom": [0, 43], "french": [27, 39], "freq": [41, 52], "frequenc": [28, 39, 41, 42, 45, 52], "frequent": [24, 27, 38, 39, 42], "fresh": [38, 39], "fri": [10, 41], "fridai": [10, 53], "friend": [24, 25, 31, 34, 37, 38, 45, 53], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "from_block": 42, "from_estim": [31, 50], "front": 53, "frozen": 43, "fruit": 39, "frustrat": [4, 6, 30], "full": [30, 33, 40, 41, 42, 53], "fullbath": [32, 34], "fulli": 37, "fun": [31, 39, 40], "func": [8, 28, 29, 32], "function": [2, 23, 24, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 52], "functiontransform": [28, 42], "fund": 43, "fundament": [2, 9, 10, 15, 27, 29, 30, 32, 35, 40, 42, 53], "funni": [23, 33, 43], "furnish": 0, "furnitur": 45, "further": [31, 33, 35, 36, 39, 40, 42, 47, 49, 50], "futur": [25, 27, 30, 32, 42, 45, 49, 52, 53], "futurewarn": [25, 27, 32, 34, 44], "fyi": 42, "g": [6, 7, 8, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 52, 53], "g26r0dcx4b35vf3nk31216hc0000gr": [27, 34], "gain": [6, 24, 31, 33, 34, 50, 53], "game": [24, 34, 39], "gamma": [29, 30, 33, 47, 49], "gamma_log": [26, 47], "gamma_widget": [26, 47], "gap": [25, 41, 42, 45, 47], "garagearea": [32, 34], "garagecar": [32, 34], "garagecond": [32, 34], "garagefinish": [32, 34], "garagefinish_fin": 32, "garagefinish_miss": 32, "garagefinish_rfn": 32, "garagefinish_unf": 32, "garagequ": [32, 34], "garagetyp": [32, 34], "garagetype_2typ": 32, "garagetype_attchd": 32, "garagetype_bas": 32, "garagetype_builtin": 32, "garagetype_carport": 32, "garagetype_detchd": 32, "garagetype_miss": 32, "garageyrblt": [32, 34], "garlic": 36, "gauss": 39, "gaussian": 37, "gaussianmixtur": 37, "gave": [38, 41], "gbr": 8, "gca": [36, 37, 42], "gd": [23, 32, 34], "gdprv": [32, 34], "gdwo": [32, 34], "gelbart": [0, 1, 24, 39, 49], "gender": [23, 28, 31, 39, 41, 42, 50], "gender_femal": 42, "gender_mal": 42, "gener": [7, 9, 15, 24, 27, 28, 30, 31, 32, 34, 37, 39, 40, 41, 42, 44, 45, 47, 49, 50, 52, 53], "genet": 35, "genom": 35, "genr": 38, "gensim": 39, "gentl": 53, "geograph": 29, "geometr": 24, "georg": 39, "geq": 29, "ger": 8, "german": 39, "get": [4, 5, 6, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53], "get_avg_word_length": 43, "get_cmap": 27, "get_depth": 47, "get_dummi": 27, "get_featur": 40, "get_feature_names_out": [27, 28, 31, 32, 33, 34, 35, 39, 41, 42, 43, 50, 52], "get_length_in_word": 43, "get_lr_data_per_us": 38, "get_permutation_import": 34, "get_relative_length": 43, "get_season": 41, "get_senti": 43, "get_stat": 38, "get_user_profil": 38, "getattr": 42, "gif": [36, 37], "gift": 43, "gigaword": 39, "gini": [24, 34], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 23, 27, 28, 30, 31, 32, 33, 34, 35, 40, 43, 49, 50], "githubusercont": 8, "gitlf": 31, "giulia": [0, 1], "give": [0, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 50], "given": [0, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 52], "gladwel": 36, "glob": [23, 40], "global": [27, 31, 33, 36, 39, 45], "glove": [39, 53], "glq": [32, 34], "gmail": [23, 36], "go": [5, 7, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52], "goal": [2, 26, 27, 30, 31, 36, 37, 38, 39, 43, 49, 51, 52, 53], "goe": [2, 25, 26, 28, 31, 33, 34, 37, 38, 40], "gold": 8, "goldcoast": 41, "golden": [26, 45, 47], "good": [9, 11, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52], "googl": [4, 10, 23, 24, 33, 34, 35, 36, 39, 43], "google_news_vector": 39, "got": [26, 29, 30, 31, 32, 40], "gotten": [42, 51], "gov": [31, 33, 34], "govern": [39, 53], "gpe": 39, "gpt": [38, 39], "gpu": [33, 39, 40], "grad": [31, 33, 34, 50], "grade": [3, 7, 10, 23, 25, 28, 30, 45, 47, 48, 49, 50, 51, 52], "grader": 6, "grades_df": 45, "gradescop": [1, 6, 10, 53], "gradient": [19, 20, 45], "gradientboostingclassifi": 33, "gradientboostingregressor": 33, "gradientexplain": 34, "grading_concern": 6, "graduat": 40, "grai": 40, "grain": [29, 34], "gram": 39, "grammat": 39, "grandma": 35, "grandmoth": 31, "grant": 0, "grant_macewan": 39, "granular": 37, "graph": [10, 40, 41], "graphic": 40, "graphic_design": 39, "graphviz": [24, 46], "grasp": [45, 53], "grayscal": 40, "great": [23, 24, 26, 28, 29, 34, 35, 39, 40, 41, 43], "greater": [11, 35, 36], "greater_is_bett": 32, "greedili": 37, "green": [26, 30, 36, 44], "grei": 53, "grid": [29, 32, 41, 42, 45, 49, 52], "grid_search": [30, 49], "gridsearchcv": [26, 33, 34, 49, 51], "gridsearchcvifittedgridsearchcv": 30, "grip": 39, "grlivarea": [32, 34], "groak": 39, "groceri": [40, 43], "groin": 40, "ground": [25, 35, 37, 38, 53], "ground_truth_categori": 31, "group": [7, 24, 26, 28, 29, 33, 35, 45, 47, 48, 51, 53], "groupbi": [41, 52], "grow": [30, 33, 35], "grow_polici": 33, "growth": [41, 42], "groyn": 40, "grv": 32, "gt": [28, 29, 30, 31, 32, 33], "gtl": 34, "guarante": [30, 31, 33, 36, 40], "guenon": 40, "guess": [26, 27, 39, 43], "guid": [7, 9, 10, 35, 40, 53], "guidanc": 34, "guidelin": [34, 35], "guido": 10, "h": [31, 33, 34, 36, 39, 40, 42, 43, 50], "ha": [2, 5, 6, 10, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 47, 50, 51, 52, 53], "hab": 39, "habit": 28, "hacki": [40, 44], "had": [23, 27, 28, 29, 31, 38, 39, 40, 41, 42], "hadn": [39, 42], "hal": 10, "half": [6, 10, 24, 29, 35, 37], "halfbath": [32, 34], "halvingrandomsearchcv": 30, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 30, "ham": 23, "hand": [4, 9, 31, 38, 50, 53], "handi": 31, "handl": [33, 34, 37, 42, 43, 44, 45, 47, 53], "handle_unknow": 28, "handle_unknown": [27, 28, 30, 31, 32, 33, 34, 41, 42, 45, 49, 50, 51, 52], "handler": [31, 34], "handrail": 40, "handwritten": 31, "hang": 31, "happen": [4, 6, 23, 26, 28, 30, 33, 34, 35, 38, 41, 42, 45, 52, 53], "happi": [31, 36, 42], "happier": 53, "happydb": 31, "hard": [8, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 45, 51], "hardli": 38, "hardwar": 40, "harmon": 31, "harri": 39, "has_cupi": 43, "has_emoji": 43, "has_rais": 43, "hasn": [4, 38, 39, 42], "hassl": [8, 34, 41], "hat": [29, 32, 33], "have": [0, 4, 6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "haven": [25, 39, 42, 45], "haylei": 24, "hazard": 53, "hc_truncation_toy_demo": 37, "hdbscan": 37, "he": [25, 28, 39, 53], "head": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52], "headlin": 39, "health": 39, "healthcar": 34, "healthi": 39, "heard": 25, "heart": [24, 43, 51], "heart_df": 51, "heartdiseas": 51, "heat": [30, 32, 34, 49], "heating_floor": 32, "heating_gasa": 32, "heating_gasw": 32, "heating_grav": 32, "heating_othw": [32, 34], "heating_wal": 32, "heatingqc": [32, 34], "heatmap": 34, "heavi": [33, 43], "heavili": [38, 40, 41, 50], "heeren": 39, "height": [24, 25, 31, 39, 43, 46], "hell": 43, "help": [3, 7, 11, 23, 25, 27, 28, 30, 31, 34, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 52, 53], "henc": [5, 31, 32, 34, 36], "her": [23, 38, 39], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53], "herebi": 0, "herself": [39, 43], "herta": 26, "heurist": [24, 30], "hi": [39, 47], "hidden": [35, 39, 40], "hide": [8, 40], "hier_label": 37, "hier_labels1": 37, "hier_labels2": 37, "hierarch": [45, 53], "hierarchi": [24, 37], "high": [6, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 53], "high_corr": 34, "higher": [24, 25, 26, 29, 31, 32, 33, 34, 35, 36, 38, 42, 47, 49, 50], "highest": [33, 34, 38, 39, 40, 44, 47, 50], "highland": 43, "highli": [10, 11, 27, 34, 38], "highlight": [4, 40, 45], "highwai": 29, "him": 39, "himself": 39, "hinder": 53, "hindi": 27, "hint": [34, 47], "hist": [27, 30, 32, 35, 42], "histgradientboostingclassifi": 33, "histgradientboostingregressor": 33, "histogram": 42, "histor": 45, "histori": [29, 38, 41, 53], "hit": [23, 30], "hitter": 43, "hl": [32, 34], "hmid": 31, "hmmm": 42, "hockei": 39, "hold": 49, "holder": 0, "holdout": 31, "holidai": [10, 38, 53], "home": [24, 29, 31, 40], "homemak": 39, "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 26, 29, 30, 39, 45, 53], "honour": 53, "hood": 25, "hope": 25, "hopefulli": 49, "hopeless": 35, "hopelessli": 26, "horizont": [24, 28], "host": [5, 42], "hot": [16, 25, 28, 34, 45, 52], "hound": [23, 40], "hour": [4, 11, 31, 33, 34, 35, 38, 41, 45, 50, 53], "hourli": [42, 45], "hous": [18, 32, 34, 35, 42, 47], "houseag": 29, "household": [27, 28, 29, 35, 48], "housestyl": [32, 34], "housestyle_1": 32, "housestyle_1stori": 32, "housestyle_2": 32, "housestyle_2stori": 32, "housestyle_sfoy": 32, "housestyle_slvl": 32, "housewif": 39, "housing_df": [24, 27, 28, 35, 47, 48], "housing_median_ag": [27, 28, 35, 48], "houston": 43, "how": [0, 3, 8, 11, 23, 28, 30, 31, 32, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "howard": 36, "howev": [2, 8, 27, 28, 31, 32, 34, 36, 38, 41, 42, 44, 47, 50], "hsjcy": 42, "hstack": 41, "html": [7, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 42, 43, 46, 48, 50], "http": [0, 5, 8, 9, 11, 23, 24, 25, 27, 28, 29, 31, 32, 33, 40, 41, 42, 43, 50, 53], "hug": 38, "huge": [28, 32, 39, 40, 41, 42, 52], "human": [0, 23, 26, 27, 28, 29, 30, 31, 34, 35, 36, 39, 40, 50], "humidity3pm": [41, 52], "humidity3pm_lag1": [41, 52], "humidity9am": [41, 52], "hummu": [36, 39], "humour": [10, 39], "hundr": 29, "hurrai": 51, "hurrican": 23, "husband": [31, 33, 34], "hussar": [23, 40], "hw": 23, "hw1": [4, 10, 46], "hw2": [10, 26, 27, 49], "hw3": 10, "hw4": 10, "hw5": [10, 53], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 38, "hyperband": 30, "hyperopt": 30, "hyperparamet": [10, 25, 31, 37, 38, 39, 40, 49], "hyperparamt": [25, 30, 42], "hyperparlan": 29, "hyperplan": 29, "hypothesi": [39, 42], "hypothet": [29, 36], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 29, 32, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "i1": 33, "i2": 33, "ia": 43, "ibm": 43, "ic": 39, "icc": 53, "iclick": 10, "id": [23, 24, 32, 34, 38, 47], "idea": [8, 24, 25, 27, 30, 34, 36, 37, 38, 39, 40, 41, 42, 45, 47, 52], "ideal": [4, 31, 33, 35, 38, 42], "ident": [39, 40, 43], "identif": [23, 43], "identifi": [24, 25, 26, 27, 30, 31, 32, 36, 37, 39, 40, 41, 45, 50, 52, 53], "idf": 28, "idli": 39, "idx": 40, "idxmax": 26, "if_binari": [28, 31, 33, 34, 45, 48, 50, 51], "ifram": [25, 31], "igloo": 39, "ignor": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 41, 42, 45, 49, 50, 51, 52], "ignore_index": 8, "ii": 31, "iii": 10, "ij": [29, 38], "ik": 33, "ill": 53, "illus": [31, 50], "illustr": [37, 41], "iloc": [8, 24, 25, 26, 27, 28, 33, 34, 39, 41, 43, 46, 51, 52], "im": 43, "imag": [7, 25, 31, 34, 35, 36, 37, 41, 45, 50, 53], "image_dataset": 40, "image_datasets_bw": 40, "image_s": 40, "imagefold": 40, "imagenet": 44, "imagenet1k_v1": 40, "imagenet_class": [23, 40], "imagin": [23, 24, 25, 27, 29, 31, 34, 35, 36, 39, 42, 45, 46, 50], "imaginari": [25, 39], "imbal": [18, 36, 42, 50], "imbalanc": [31, 32, 44], "imblearn": 31, "img": [23, 40], "img_classifi": 23, "img_path": 23, "img_t": 40, "immedi": [34, 38, 53], "imp": [27, 28, 41], "impact": [7, 28, 29, 33, 34, 37, 41, 47, 52, 53], "implement": [2, 4, 23, 27, 31, 32, 33, 35, 37, 38, 39, 42, 44], "impli": [0, 42], "implic": [27, 45, 53], "implicit": 39, "import": [8, 10, 21, 22, 44, 48, 49, 50, 51, 53], "importance_typ": 33, "importances_mean": 34, "impos": 27, "imposs": 36, "impress": 34, "improv": [30, 31, 32, 33, 35, 36, 37, 38, 41, 42, 45, 49, 53], "impur": [24, 33], "imput": [16, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 43, 45, 48, 49, 50, 51, 52], "imread": 40, "imshow": [23, 40], "inbox": 25, "inc": [34, 39], "incept": [38, 40], "inception": 40, "incl": 32, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 24, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53], "include_bia": [35, 41], "incom": [25, 29, 31, 33, 34, 50], "incomplet": 42, "inconsist": 28, "incorpor": [30, 32, 35, 42, 45], "incorrect": 42, "incorrectli": [23, 31], "increas": [8, 25, 26, 28, 29, 33, 34, 35, 36, 37, 40, 47, 49], "increasingli": 23, "incred": 40, "inde": 34, "independ": [8, 9, 24, 30, 32, 33, 35, 41, 53], "index": [23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 47, 50, 51, 52], "index_col": [8, 26, 27, 30, 31, 38, 49], "india": 39, "indian": 31, "indian_liver_pati": 23, "indic": [0, 28, 36, 38, 39, 40, 41, 42], "individu": [33, 34, 36, 38, 39, 42, 51, 53], "industri": [33, 35, 39, 40], "inequ": [31, 50], "inertia_": 36, "inertia_valu": 36, "inf": [26, 42], "infeas": 30, "infer": [24, 39, 40, 41, 46], "infin": 26, "infinit": 30, "inflamm": 9, "inflat": 34, "inflect": [36, 39], "influenc": [24, 25, 30, 34, 36, 38, 42, 47], "info": [1, 3, 8, 27, 28, 31, 32, 35, 39, 41, 42, 47, 51, 52], "infom": 39, "infor_m": 39, "inform": [1, 4, 7, 11, 24, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 47, 50, 51, 52, 53], "informa_t": 39, "informaion": 39, "informaiton": 39, "informationabout": 39, "informationon": 39, "inhabit": 53, "inher": [31, 41, 42, 50], "initi": [37, 40, 43], "initj": 34, "inject": [35, 38, 45], "inland": [27, 28, 35, 48], "inlin": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 46, 47, 49, 50, 51], "inner": [28, 30, 39], "inplac": [8, 23, 24, 30], "input": [8, 24, 27, 29, 33, 34, 37, 39, 40, 41, 43, 45, 52], "input_img": 40, "inputs_bw": 40, "insid": [9, 28, 31], "insight": [2, 26, 31, 34, 36, 53], "inspct": 31, "inspect": [34, 37], "inspir": [24, 31, 33], "instal": [23, 26, 31, 32, 33, 34, 36, 39, 40, 42, 43], "instanc": [23, 24, 25, 28, 29, 31, 36, 37, 38, 39, 40, 41, 44], "instanti": [30, 47], "instead": [5, 8, 11, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 49, 50, 51], "institut": [39, 43], "instruct": [3, 4, 5, 11, 26, 53], "instructor": [4, 6, 23, 53], "instrument": [26, 27, 30, 49], "int": [27, 28, 31, 33, 34, 39, 41, 43, 50, 51, 52], "int32": [26, 36, 37, 41], "int64": [24, 26, 28, 31, 32, 38, 39, 41, 42, 43], "integ": [8, 25, 27, 30, 33, 34, 41], "integr": 53, "intellig": [10, 39], "intelligen": 39, "intend": 0, "intens": 39, "inter": 43, "interact": [9, 26, 30, 31, 34, 36, 37, 38, 41, 43, 47], "interaction_constraint": 33, "interaction_onli": [35, 41], "interactive_plot": [26, 47], "interactiveshel": 43, "intercept": [34, 40, 44], "intercept_": [29, 33, 40, 44], "intercept_sc": 31, "interest": [2, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 49, 51, 52], "interfac": 33, "intermedi": [37, 40], "intern": [0, 1, 24, 40, 41, 42, 43], "internet": 42, "internetservic": 42, "internetservice_dsl": 42, "internetservice_fib": 42, "internetservice_no": 42, "internship": 23, "interpret": [10, 11, 21, 22, 26, 27, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 50, 53], "interv": [41, 42, 45, 49, 53], "intrins": 41, "intro": [10, 19, 20, 39, 40], "introduc": [28, 31, 42], "introduct": [9, 10, 11, 13, 16, 41, 42, 47, 53], "intslid": [26, 47], "intuit": [26, 27, 28, 30, 32, 34, 36, 37, 42, 43, 53], "invalid": 30, "inventori": 45, "invers": [29, 32], "inverse_func": 32, "investig": [26, 34, 47], "involv": [2, 4, 30, 32, 33, 37, 39, 40], "io": [9, 27, 40, 42, 43], "io_loop": 43, "ipkernel": 43, "ipykernel": 43, "ipykernel_19402": 34, "ipykernel_32469": 27, "ipykernel_79734": 25, "ipykernel_86208": 43, "ipykernel_launch": 43, "ipynb": [7, 8], "ipython": [23, 24, 25, 26, 27, 28, 29, 31, 39, 43, 46, 48, 50], "ipywidget": [26, 47], "ir1": [32, 34], "ir2": [32, 34], "iri": [26, 47], "iris_df": [26, 47], "irregular": 53, "irregularli": 45, "irrelev": [26, 35, 39], "irrelevant_po": 39, "irrespect": [25, 29, 53], "is_avail": 40, "is_leap_year": [41, 52], "is_stop": 39, "is_year_end": [41, 52], "isinst": 42, "island": [27, 28], "isn": [25, 26, 31, 32, 33, 39], "isnul": 27, "isol": [11, 31, 32, 34], "issu": [4, 6, 7, 33, 38, 42, 45, 49, 53], "issubclass": 42, "isupp": 43, "itali": 39, "item": [23, 33, 34, 36, 38, 39, 40, 42, 45, 51], "item_inverse_mapp": 38, "item_kei": 38, "item_mapp": 38, "iter": [30, 35, 36, 37, 40], "iterable_with_config": 28, "iterrow": 38, "its": [8, 23, 25, 26, 28, 29, 31, 34, 36, 37, 39, 40, 41, 42, 43, 44, 47, 49, 52, 53], "itself": [7, 31, 33, 37, 39], "j": [8, 29, 34, 35, 36, 38, 40], "j6": 43, "jackin": 30, "jackpot": 28, "jaguar": [23, 40], "jalebi": 39, "jam": 30, "jame": [39, 42, 43], "jan": 1, "januari": 41, "japan": 39, "jargon": 24, "jason": [10, 35], "javascript": 34, "jazz_musician": 39, "jellyfish": 40, "jennif": 43, "jerri": 38, "jet": 27, "jetti": 40, "jieba": 39, "jim": 38, "jmlr": 30, "joan_baez": 39, "job": [28, 41, 42, 52], "joblib": 28, "john": 33, "johnny_cash": 39, "join": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53], "jointli": 41, "joke": [23, 38], "jolen": 43, "joni_mitchel": 39, "joseph": 53, "journal": 39, "journei": [10, 37, 53], "jpg": 40, "ju": 23, "jubatu": [23, 40], "judg": 35, "juic": 39, "juli": 41, "jun": 53, "june": [10, 41], "junh": 53, "jupyt": [1, 7, 8, 9, 11, 23, 27, 28, 30, 31, 32, 33, 34, 35, 40, 43], "jupyter_notebook": 42, "jupyterlab": 34, "jurafski": 39, "jurisdict": 39, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 47, 51, 52, 53], "justic": [34, 39, 53], "justif": 51, "k": [7, 10, 15, 25, 29, 31, 32, 33, 35, 39, 40, 42, 43, 44, 47, 53], "k_neighbor": 31, "k_valu": 26, "kaggl": [24, 27, 31, 32, 33, 34, 35, 40, 50, 51], "kaggler": 35, "kangaroo": 40, "kaplan": 53, "kaplanmeierfitt": 42, "kb": [28, 32, 42], "kbinsdiscret": 35, "kbinsdiscretizer__latitude_0": 35, "kbinsdiscretizer__latitude_1": 35, "kbinsdiscretizer__latitude_2": 35, "kbinsdiscretizer__latitude_3": 35, "kbinsdiscretizer__latitude_4": 35, "kbinsdiscretizer__latitude_5": 35, "kbinsdiscretizer__latitude_6": 35, "kbinsdiscretizer__latitude_7": 35, "kbinsdiscretizer__latitude_8": 35, "kbinsdiscretizer__latitude_9": 35, "kbinsdiscretizer__longitude_11": 35, "kbinsdiscretizer__longitude_12": 35, "kbinsdiscretizer__longitude_13": 35, "kbinsdiscretizer__longitude_14": 35, "kbinsdiscretizer__longitude_15": 35, "kbinsdiscretizer__longitude_16": 35, "kbinsdiscretizer__longitude_17": 35, "kbinsdiscretizer__longitude_18": 35, "kbinsdiscretizer__longitude_19": 35, "kbinsdiscretizerkbinsdiscret": 35, "kc_house_data": [23, 24, 47], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 31, 33, 34, 35, 36, 38, 39, 42, 47, 48, 53], "keep_empty_featur": 38, "kei": [9, 24, 25, 26, 27, 30, 31, 32, 33, 38, 39, 42, 49, 51, 53], "kelbowvisu": 36, "kellei": 29, "kelli": 53, "kept": 25, "kera": 34, "kernel": [7, 10, 15, 27, 29, 30, 34, 35, 47], "kernelapp": 43, "kernelbas": 43, "kernelexplain": 34, "keyword": [4, 30, 43], "kfold": 31, "kick": 39, "kilian": 34, "kill": 42, "kimia": 53, "kind": [0, 23, 24, 25, 27, 28, 29, 31, 32, 34, 36, 37, 38, 40, 41, 42, 44, 52], "king": [38, 39, 47], "kitchenabvgr": [32, 34], "kitchenqu": [32, 34], "kiwi": 39, "kk": 36, "km": [42, 45], "km_label": 36, "kmean": [36, 37, 45], "kmf": 42, "kmqfw": 42, "kneighborregressor": 27, "kneighborsclassifi": [27, 28, 29, 35, 47, 48], "kneighborsregressor": [27, 28, 29, 48], "kneighborsregressorkneighborsregressor": [27, 28], "knew": 36, "knn": [2, 15, 25, 26, 27, 28, 29, 34, 35, 38, 40, 44, 45, 51], "knn1": 26, "knn100": 26, "knn_pipe": 28, "knn_scale": 27, "knn_unscal": 27, "knn_valid_accuraci": 26, "knnimput": 38, "knob": 24, "know": [8, 10, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53], "knowledg": [8, 24, 28, 30, 35, 36, 39, 45], "knowleg": 45, "known": [38, 39, 42], "koala": 40, "kolhatkar": [0, 1, 39], "kr9rkqfj4w78h49djkz8yy9r0000gp": 25, "ksatr": 42, "kvarada": [11, 24, 25, 28, 30, 34, 39, 40, 42, 44], "kvarada01": 11, "kwantlen": 39, "kwarg": [25, 27, 28, 42, 43], "l": 11, "l1": [10, 42], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 31, "l2": [10, 31, 39, 42], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "lab": [11, 24, 25, 36, 38], "lab1": [24, 25, 28, 45], "lab2": [24, 25, 28, 45], "lab3": [24, 25, 28, 45], "lab4": [24, 25, 28, 45], "label": [7, 8, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 48], "label_": [39, 43], "label_encod": [33, 34], "label_n_clust": 37, "labelencod": [33, 34], "labels": [31, 36], "labels_": [36, 37], "lack": [25, 38], "lag": [42, 45], "lag_df": 41, "lakehead_univers": 39, "lakeshor": 40, "lakesid": 40, "lambda": [8, 24, 29, 37, 40, 41, 42, 43], "land": 42, "landcontour": [32, 34], "landcontour_bnk": 32, "landcontour_hl": 32, "landcontour_low": 32, "landcontour_lvl": 32, "landmark": 45, "landown": 43, "landscap": [36, 39], "landslop": [32, 34], "landslope_gtl": [32, 34], "landslope_mod": [32, 34], "landslope_sev": [32, 34], "langara_colleg": 39, "languag": [2, 9, 27, 28, 38, 40, 43], "language_enc": 27, "language_english": 27, "language_french": 27, "language_hindi": 27, "language_mandarin": 27, "language_spanish": 27, "language_vietnames": 27, "laptop": 23, "lar": 23, "larg": [23, 25, 26, 27, 29, 31, 32, 36, 37, 39, 40, 45, 47, 50], "larger": [24, 25, 26, 27, 29, 30, 32, 33, 34, 36, 37, 42], "largest": 32, "larvatu": [23, 40], "last": [8, 24, 25, 26, 27, 28, 31, 34, 38, 40, 41, 42, 43, 47, 49, 51, 52, 53], "last_row": 8, "lastp": 37, "lat": [23, 24], "late": [31, 53], "latent": [38, 39, 40], "latentdirichletalloc": 39, "later": [11, 24, 28, 31, 40, 41, 47], "latest": [28, 34, 42], "latex": [4, 7], "latin": [23, 31, 50], "latitud": [25, 26, 27, 28, 29, 35, 48], "latitude_0": 35, "latitude_1": 35, "latitude_10": 35, "latitude_11": 35, "latitude_12": 35, "latitude_13": 35, "latitude_14": 35, "latitude_15": 35, "latitude_16": 35, "latitude_17": 35, "latitude_18": 35, "latitude_19": 35, "latitude_2": 35, "latitude_3": 35, "latitude_4": 35, "latitude_5": 35, "latitude_6": 35, "latitude_7": 35, "latitude_8": 35, "latitude_9": 35, "latter": 32, "launch_inst": 43, "launch_new_inst": 43, "lauvagrand": 43, "law": 39, "lawsuit": 39, "layer": 40, "layout": [26, 47], "lazi": 26, "lbfg": 31, "lda": 40, "ldot": 30, "lead": [8, 10, 25, 29, 32, 37, 38, 39, 42], "leaf": [24, 37, 39], "leagu": 39, "leak": [27, 42, 45], "leakag": 45, "leaner": 25, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "learner": [25, 26, 33], "learning_method": 39, "learning_r": 33, "learnxinyminut": 9, "least": [4, 10, 25, 26, 31, 32, 34, 35, 36, 37, 51, 52, 53], "least_confident_i": 29, "least_confident_x": 29, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 37, 40, 42, 44], "lec11": 19, "lectur": [5, 7, 8, 11, 19, 45, 50], "lecun": 34, "lee": 34, "left": [7, 23, 30, 31, 32, 36, 37, 39, 41, 42, 53], "legal": [0, 39], "legend": [7, 8, 26, 29, 31, 32, 35, 36, 40, 41, 42, 44], "legendari": 43, "leisur": 31, "lemma": 39, "lemma_": 39, "lemmat": 39, "lemon": 36, "len": [25, 27, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 43], "length": [24, 25, 26, 29, 32, 34, 36, 37, 39, 41, 42, 43, 47, 52], "leo": 33, "leopard": [23, 40], "leq": [35, 36], "less": [5, 6, 10, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 42, 45, 47, 50], "lesson": [9, 27, 43], "lesssim": 25, "let": [23, 24, 25, 29, 30, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "letter": [29, 43], "lev": 32, "level": [26, 29, 31, 32, 33, 34, 35, 37, 39, 40, 41, 50, 53], "leverag": [34, 38], "lewi": 43, "lexic": 39, "lexicon": 43, "lg": 19, "lgbm": [33, 34, 45, 53], "lgbmclassifi": [23, 33, 34, 51], "lgbmclassifierifittedlgbmclassifi": [23, 34], "lgbmclassifierlgbmclassifi": 33, "lgbmregressor": [23, 33], "li": 29, "liabil": 0, "liabl": 0, "liao": 23, "lib": [24, 25, 28, 30, 34, 42, 43, 44], "librari": [4, 8, 11, 25, 31, 34, 35, 39, 40, 41, 43, 47], "licensor": 0, "life": [24, 29, 36, 38, 46, 53], "lifelin": [42, 53], "lifetim": 42, "lighter": 30, "lightgbm": [23, 34, 51], "lightweight": 39, "like": [2, 4, 7, 8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53], "likelihood": 42, "likewis": 7, "lime": 34, "limit": [0, 23, 24, 25, 28, 33, 34, 43, 45, 46, 49, 53], "linalg": 39, "line": [4, 8, 11, 24, 28, 29, 30, 31, 32, 36, 39, 40, 41, 42, 43, 47, 49], "line2d": 8, "linear": [10, 17, 21, 22, 30, 31, 33, 35, 37, 38, 40, 41, 42, 44, 45], "linear_model": [23, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 50, 51, 52], "linear_svc": 29, "linearli": [29, 35, 41], "linearregress": [29, 32, 35, 42, 43], "linestyl": [36, 41, 52], "linewidth": 41, "linger": 26, "lingual": 39, "linguist": 28, "link": [0, 4, 5, 7, 10, 23, 24, 28, 29, 32, 33, 37, 42], "linkag": 37, "linkage_arrai": 37, "linkage_typ": 37, "linkedin": 38, "linspac": [29, 30, 32, 35, 49], "lion": 38, "list": [4, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 42, 51, 53], "listedcolormap": 29, "liter": 43, "literatur": 33, "littl": [8, 31, 40], "live": [10, 11, 26, 27, 28, 30, 36, 42, 49], "liver": 24, "livestream": 53, "ll": [6, 7, 10, 11, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 52, 53], "llazx": 42, "llm": 10, "lo": 43, "load": [8, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 43, 47, 48, 50], "load_breast_canc": 35, "load_citibik": 41, "load_iri": [26, 47], "loan": [31, 50], "loc": [8, 26, 29, 31, 34, 38, 41, 42, 52], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 31, 33, 34, 35, 40, 43], "locat": [8, 28, 36, 38, 39, 41, 43, 51, 52, 53], "location_katherin": 41, "location_mountginini": 41, "location_townsvil": 41, "location_witchcliff": 41, "location_wollongong": 41, "lock": 25, "log": [26, 32, 33, 42, 47, 51, 53], "log10": 32, "log1p": 32, "log2": 42, "log_likelihood_ratio_test": 42, "logarithm": [26, 47], "logic": 35, "logical_xor": 35, "login": 38, "logisit": 40, "logist": [17, 33, 34, 41, 42, 43, 44, 45, 50, 51, 52], "logisticregress": [23, 29, 32, 33, 34, 35, 39, 40, 43, 44, 50, 51, 52], "logisticregressionifittedlogisticregress": 40, "logisticregressionlogisticregress": [31, 33, 40, 43], "logloss": 34, "lognorm": 30, "logspac": [30, 49], "loguniform": [30, 49], "lol": 28, "london": 43, "lone": 37, "long": [0, 23, 24, 29, 31, 33, 37, 38, 42, 45, 53], "longer": [7, 30, 31, 40, 42], "longest": 24, "longitud": [25, 26, 27, 28, 29, 35, 48], "longitude_0": 35, "longitude_1": 35, "longitude_10": 35, "longitude_11": 35, "longitude_12": 35, "longitude_13": 35, "longitude_14": 35, "longitude_15": 35, "longitude_16": 35, "longitude_17": 35, "longitude_18": 35, "longitude_19": 35, "longitude_2": 35, "longitude_3": 35, "longitude_4": 35, "longitude_5": 35, "longitude_6": 35, "longitude_7": 35, "longitude_8": 35, "longitude_9": 35, "look": [1, 11, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51], "lookatm": 23, "loop": [30, 33, 41, 44, 45], "loos": 37, "lose": [6, 28], "loss": [2, 31, 32, 33, 34, 39, 42, 50], "lot": [5, 9, 23, 24, 26, 28, 29, 30, 31, 32, 34, 35, 37, 40, 41, 42, 49, 53], "lotarea": [32, 34], "lotconfig": [32, 34], "lotconfig_corn": 32, "lotconfig_culdsac": 32, "lotconfig_fr2": 32, "lotconfig_fr3": 32, "lotconfig_insid": 32, "lotfrontag": [32, 34], "lotshap": [32, 34], "lotshape_ir1": 32, "lotshape_ir2": 32, "lotshape_ir3": 32, "lotshape_reg": 32, "loud": [26, 27, 30, 45, 49], "loui": 41, "lourenzutti": 30, "love": 43, "low": [6, 25, 26, 30, 31, 32, 34, 35, 36, 37, 42], "lower": [25, 26, 31, 32, 34, 36, 38, 39, 42, 49, 53], "lowercas": [27, 28], "lowest": [47, 53], "lowqualfinsf": [32, 34], "lr": [29, 31, 32, 34, 40, 41, 42, 43, 44], "lr_1": 35, "lr_2": 35, "lr_3": 35, "lr_coef": [34, 41, 42, 52], "lr_coefs_landslop": 34, "lr_flatten_pip": 40, "lr_item": 38, "lr_pipe": [32, 34, 41], "lr_pred": [31, 32], "lr_scale": 34, "lr_schedul": 40, "lr_x": 38, "lr_y": 38, "ls15hb": 23, "lstm": 41, "lt": [25, 27, 28, 30, 31, 32, 33, 34, 35, 42], "ltorgo": 29, "lucki": [26, 30], "luckili": [49, 51], "lundberg": 34, "luster": 37, "lvert": 39, "lvl": [32, 34], "lwq": [32, 34], "lynx": [23, 40], "l\u00e9cuyer": 39, "m": [11, 23, 25, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "m_neighbor": 31, "ma": [30, 39], "macaqu": [23, 40], "macbook": 11, "mach": 39, "machin": [2, 9, 10, 11, 13, 14, 15, 27, 28, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 47, 52, 53], "mackworth": 10, "made": [0, 6, 7, 8, 23, 24, 31, 33, 34, 38, 39, 40, 41, 49], "magazin": 39, "magnitud": [30, 32, 34, 39, 41, 52], "maguir": 38, "mahsa": 53, "mai": [0, 7, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53], "mail": 42, "main": [8, 11, 24, 26, 28, 33, 36, 37, 45, 53], "mainland": 29, "maintain": [33, 38, 45], "mainten": 33, "maj1": [32, 34], "maj2": [32, 34], "major": [2, 25, 26, 27, 28, 39, 45, 46, 51], "major_biologi": 28, "major_comput": 28, "major_econom": 28, "major_linguist": 28, "major_mathemat": 28, "major_mechan": 28, "major_phys": 28, "major_psychologi": 28, "make": [2, 4, 5, 6, 7, 11, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53], "make_blob": [26, 36, 37, 40, 44], "make_circl": 37, "make_classif": [26, 31], "make_column_transform": [30, 31, 32, 33, 34, 35, 41, 42, 43, 48, 49, 50, 51, 52], "make_forg": 26, "make_grid": 40, "make_imb_pipelin": 31, "make_moon": 37, "make_num_tree_plot": 33, "make_pipelin": [23, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 48, 49, 50, 51, 52], "make_scor": [32, 35, 43], "malcolm": [36, 38], "malcom": 36, "male": [31, 33, 34, 42, 50], "male_cm": [31, 50], "male_pr": [31, 50], "mall": 43, "man": [38, 39], "manag": [5, 41, 42, 45, 53], "mandarin": 27, "mango": 39, "mani": [2, 5, 8, 10, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 49, 51, 52, 53], "manner": [0, 33], "manual": [11, 23, 28, 31, 35, 36, 37, 39, 49], "manufactur": 40, "map": [10, 24, 25, 28, 30, 38, 49], "mape": 45, "mape_scor": 32, "maple_leaf": 39, "mapper": 38, "march": 41, "marit": [31, 33, 34, 50], "mark": [6, 7, 30, 31, 37, 53], "marker": [26, 29, 36], "markers": [29, 31], "market": [23, 36, 40, 41], "markov": 39, "marri": [31, 33, 34], "martin": 39, "mask": 30, "massiv": [28, 30], "master": [8, 30, 31, 33, 34, 39, 50], "masvnrarea": [32, 34], "masvnrtyp": [32, 34], "masvnrtype_brkcmn": 32, "masvnrtype_brkfac": 32, "masvnrtype_miss": 32, "masvnrtype_ston": 32, "match": [28, 29, 31, 33, 34, 41, 51, 52], "materi": [8, 11, 19, 23, 24, 25, 26, 36, 39, 42, 45, 53], "matern": 35, "math": [2, 36, 38, 42], "mathcal": 26, "mathemat": [2, 28, 33, 45], "mathematician": 39, "mathia": 43, "matlab": 8, "matplotlib": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "matplotlibdeprecationwarn": 34, "matric": [26, 31, 38, 50], "matrix": [18, 28, 37, 39, 45, 50], "matter": [27, 28, 31, 33, 37, 45], "max": [8, 25, 27, 29, 30, 31, 32, 33, 36, 37, 41, 52], "max_bin": 33, "max_cat_threshold": 33, "max_cat_to_onehot": 33, "max_clust": 37, "max_colwidth": [23, 24, 25, 26, 27, 28, 29, 30, 31, 37, 38, 46, 47, 48, 49, 50], "max_delta_step": 33, "max_depth": [25, 26, 30, 33, 34, 46, 47], "max_depth_widget": [26, 47], "max_df": 28, "max_displai": 34, "max_featur": [23, 28, 30, 33, 49], "max_it": [23, 31, 33, 34, 35, 39, 40, 41, 42, 43, 44, 50], "max_leaf_nod": 24, "max_leav": 33, "max_opt": [26, 31, 36, 37], "max_row": 42, "maxclust": 37, "maxent": 44, "maxhr": 51, "maxim": [23, 31, 32, 36], "maximum": [24, 27, 32, 33, 36, 37, 47, 53], "maxosx": 11, "maxtemp": [41, 52], "may": 10, "mayb": [31, 34, 41, 53], "maybe_coerce_valu": 42, "mb": [27, 28, 31, 35, 41, 42, 52], "md": [11, 24, 39], "me": [8, 23, 30, 39, 43], "mean": [5, 6, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53], "mean_absolute_percentage_error": 32, "mean_cv_error": 25, "mean_cv_scor": [26, 29, 30], "mean_fit_tim": [30, 32], "mean_scor": [25, 27, 30, 43], "mean_score_tim": [30, 32], "mean_squared_error": [32, 35, 43], "mean_std_cross_val_scor": [25, 27, 28, 33, 34, 42, 43], "mean_test_neg_mean_squared_error": 32, "mean_test_scor": [30, 32, 49], "mean_train_error": 25, "mean_train_neg_mean_squared_error": 32, "mean_train_scor": [26, 29, 30, 32], "meaning": [26, 28, 31, 34, 36, 39, 48, 53], "meaningless": 37, "measur": [0, 23, 24, 25, 26, 31, 32, 34, 36, 37, 38, 39, 41, 42, 45, 47, 51, 52], "mechan": [28, 45], "mechanical_engin": 39, "medal": 8, "median": [24, 27, 28, 29, 32, 34, 35, 41, 42, 52], "median_house_valu": [27, 28, 35, 48], "median_incom": [27, 28, 35, 48], "medic": [31, 36, 53], "medinc": 29, "medit": 31, "medium": [0, 26, 42, 45], "meet": 39, "meier": 53, "melbourneairport": [41, 52], "member": [29, 33, 53], "membership": [28, 36, 37], "memori": [8, 27, 28, 31, 32, 33, 35, 40, 41, 42, 45, 52], "mention": [0, 4, 29, 42], "menu": 11, "merchant": 0, "merg": [0, 5, 11, 37], "meshgrid": 35, "mess": [38, 42], "messag": [4, 6, 11, 25, 28], "messi": [35, 39], "met": 53, "meta": 33, "metacademi": 10, "method": [2, 24, 26, 27, 29, 31, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 51, 52, 53], "methodologi": [27, 41], "metric": [10, 26, 28, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 50, 51, 53], "mexico": 31, "mglearn": [24, 25, 26, 27, 28, 29, 30, 31, 36, 39, 40, 41, 44, 46, 47, 49, 50], "mi": [23, 30, 31], "microsoft": 43, "midnight": 41, "midterm": [6, 10], "might": [6, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 47, 53], "mightn": 39, "mike": [0, 1, 9, 24, 49], "mikolov": 39, "milk": 39, "mill": 33, "millennia": 53, "million": 40, "min": [10, 29, 32, 37, 41, 52], "min1": [32, 34], "min2": [32, 34], "min_child_weight": 33, "min_df": 28, "min_sampl": 37, "min_samples_leaf": 24, "min_samples_split": 24, "min_token_len": 39, "min_token_length": 39, "mind": [25, 27, 28, 33, 34, 38, 42, 45, 53], "mine": 10, "minibatchkmean": 37, "miniconda": 11, "miniconda3": [11, 43], "miniforge3": [24, 25, 28, 30, 34, 42, 44], "minim": [5, 24, 32, 36, 37], "minimum": [8, 25, 27, 37, 39], "minmaxscal": [27, 28], "minor": [6, 42], "mintemp": [41, 52], "minut": [4, 24, 35, 42, 45], "miracl": 43, "miscalcul": 10, "miscfeatur": [32, 34], "miscfeature_gar2": 32, "miscfeature_miss": 32, "miscfeature_othr": 32, "miscfeature_sh": 32, "miscfeature_tenc": 32, "misclassifi": 50, "misconduct": 53, "miscval": [32, 34], "mislead": [25, 31], "miss": [11, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 41, 42, 45, 47, 49, 50, 52, 53], "mistak": [27, 33, 42, 47], "mit": [0, 1], "mitig": [38, 53], "mitlp": 42, "mitt": 39, "mitten": 39, "mix": 32, "mixtur": [37, 39, 40], "ml": [2, 9, 10, 14, 15, 24, 27, 33, 37, 39, 40, 53], "ml_experi": [24, 25, 28, 45], "mlpclassifi": 40, "mlpregressor": 40, "mm": [41, 52], "mmsto": 23, "mn": [32, 34], "mnprv": [32, 34], "mnww": [32, 34], "mo": 39, "mobil": [28, 40], "mobilenet": 40, "mod": [32, 34], "mode": [26, 27, 30, 49], "model": [2, 10, 19, 20, 21, 22, 30, 31, 36, 37, 38, 41, 44, 46, 49, 52, 53], "model_nam": 38, "model_select": [23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52], "modern": [10, 26, 39], "modif": 42, "modifi": [0, 11, 31, 42, 53], "modul": [9, 10, 24, 25, 31, 43], "moe": 30, "mole": 40, "mom": 35, "moment": [31, 49, 51, 53], "mon": [10, 41], "monarch": 39, "monarchi": 39, "mondai": [10, 41, 53], "monei": [8, 42], "monitor": 39, "monkei": [23, 40], "monotone_constraint": 33, "montani": 43, "month": [25, 28, 32, 42, 52], "month_nam": [41, 52], "monthli": 42, "monthlycharg": 42, "montreal": [39, 43], "moon": 37, "moosvi": [0, 1, 39, 53], "moral": [0, 36], "more": [1, 2, 5, 6, 8, 10, 11, 14, 25, 30, 33, 34, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53], "morn": 23, "morpholog": 39, "moskowitz": 36, "mosold": [32, 34], "mosold_1": 32, "mosold_10": 32, "mosold_11": 32, "mosold_12": 32, "mosold_2": 32, "mosold_3": 32, "mosold_4": 32, "mosold_5": 32, "mosold_6": 32, "mosold_7": 32, "mosold_8": 32, "mosold_9": 32, "most": [7, 8, 11, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 51, 53], "most_confident_i": 29, "most_confident_x": 29, "most_frequ": [24, 26, 27, 31, 32, 34, 46], "most_similar": 39, "mostli": [8, 28, 41], "motiv": [19, 20, 21, 22, 23, 28], "mountginini": 41, "move": [7, 12, 29, 34, 35, 46, 51, 53], "movi": [29, 39, 43], "movie_feats_df": 38, "movie_id": 38, "movie_nam": 38, "movies_rated_by_pat": 38, "movies_to_pr": 38, "movieto": 43, "mpimg": 40, "mri": 45, "mrtssm448usn": 41, "mse": [24, 38, 45], "msg": [28, 42], "mssubclass": [32, 34], "mssubclass_120": 32, "mssubclass_160": 32, "mssubclass_180": 32, "mssubclass_190": 32, "mssubclass_20": 32, "mssubclass_30": 32, "mssubclass_40": 32, "mssubclass_45": 32, "mssubclass_50": 32, "mssubclass_60": 32, "mssubclass_70": 32, "mssubclass_75": 32, "mssubclass_80": 32, "mssubclass_85": 32, "mssubclass_90": 32, "mszone": [32, 34], "mszoning_c": [32, 34], "mszoning_fv": 32, "mszoning_rh": 32, "mszoning_rl": 32, "mszoning_rm": 32, "much": [4, 5, 8, 24, 25, 26, 27, 28, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 47, 49, 53], "mueller": 10, "multi": [32, 34, 36, 39, 41], "multi_class": [31, 44], "multi_strategi": 33, "multiclass": [40, 44], "multicoliniar": 34, "multicultur": 39, "multilevel": 32, "multimod": 36, "multinomi": 44, "multipl": [7, 8, 25, 29, 30, 33, 34, 39, 40, 41, 42, 52], "multiplelin": 42, "multiplelines_no": 42, "multiplelines_y": 42, "multipli": [29, 30, 31, 33, 35, 42], "music": [38, 43], "musqueam": 53, "must": [0, 6, 7, 8, 24, 25, 27, 34, 37, 39, 42, 43, 53], "mustn": 39, "mutual": 37, "mwf": 53, "my": [6, 11, 23, 30, 31, 36, 39, 43, 53], "my_heatmap": [30, 49], "my_map": 32, "mypreprocessor": 39, "myself": [24, 39], "m\u00fcller": 9, "n": [10, 24, 26, 29, 30, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 47, 52], "n_bin": 35, "n_class": [26, 31, 50], "n_cluster": [36, 37], "n_clusters_per_class": 31, "n_compon": 39, "n_constitu": 33, "n_estim": [35, 41, 42], "n_exampl": 36, "n_feat": 26, "n_featur": [26, 31, 36, 49], "n_features_to_select": 35, "n_inform": 31, "n_init": 36, "n_iter": 49, "n_job": [28, 31, 32, 33, 49], "n_neighbor": [38, 47], "n_neighbors_selector": 26, "n_neighbors_widget": [26, 47], "n_redund": 31, "n_rental": 41, "n_rentalsin3hour": 41, "n_rentalsin6hour": 41, "n_repeat": 34, "n_resourc": 30, "n_sampl": [26, 31, 36, 37, 40, 44, 50], "n_split": 41, "n_threshold": 31, "n_topic": 39, "n_train": 41, "n_word": [39, 43], "na": [32, 34], "nafter": 39, "nah": 28, "naiv": 37, "name": [4, 5, 6, 7, 8, 11, 24, 26, 27, 28, 30, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 47, 51, 52, 53], "named_estimators_": 33, "named_step": [29, 31, 32, 33, 34, 35, 41, 43, 52], "named_transformers_": [28, 31, 32, 33, 34, 35, 41, 42, 43, 50, 52], "nan": [27, 28, 31, 32, 33, 34, 35, 38, 41, 42, 43, 45, 50, 52], "nanmean": 38, "nanosecond": 41, "narr": 39, "narrow": 38, "nasali": [23, 40], "nation": 53, "nativ": [31, 33, 34, 40, 44, 50], "natur": [2, 23, 28, 31, 33, 35, 40, 44, 53], "navig": [7, 11], "nbsp": [23, 27, 28, 30, 32, 33, 34, 35, 40], "nbviewer": [23, 27, 28, 30, 31, 32, 33, 34, 35, 40, 43], "nc": 1, "ncol": 29, "ndarrai": [8, 28], "ndate": 43, "ndframe": [35, 42], "ndim": 8, "ne": [41, 52], "nearbi": [26, 36], "nearest": [15, 31, 37, 47], "necessari": [0, 7, 24, 30, 45, 48], "necessarili": [25, 32, 33, 38], "necvq": 42, "need": [5, 7, 8, 11, 23, 24, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53], "needn": 39, "neg": [24, 25, 26, 29, 32, 33, 34, 39, 41, 42, 43, 47, 50], "neg_mean_absolute_percentage_error": 32, "neg_mean_squared_error": 32, "neg_root_mean_square_error": 32, "neg_root_mean_squared_error": 32, "neigh": 26, "neighbor": [26, 27, 28, 29, 31, 35, 37, 47, 48], "neighborhood": [29, 32, 34], "neighborhood_blmngtn": 32, "neighborhood_bluest": 32, "neighborhood_brdal": 32, "neighborhood_brksid": 32, "neighborhood_clearcr": 32, "neighborhood_collgcr": 32, "neighborhood_crawfor": 32, "neighborhood_edward": 32, "neighborhood_gilbert": 32, "neighborhood_idotrr": 32, "neighborhood_meadowv": 32, "neighborhood_mitchel": 32, "neighborhood_nam": 32, "neighborhood_noridg": [32, 34], "neighborhood_npkvil": 32, "neighborhood_nridght": [32, 34], "neighborhood_nwam": 32, "neighborhood_oldtown": [32, 34], "neighborhood_sawy": [32, 34], "neighborhood_sawyerw": [32, 34], "neighborhood_somerst": [32, 34], "neighborhood_stonebr": [32, 34], "neighborhood_swisu": [32, 34], "neighborhood_timb": [32, 34], "neighborhood_veenk": [32, 34], "neighbour": [15, 25, 34, 36, 37, 39, 47], "neighbourhood": [29, 35, 37, 48], "neither": [25, 28, 38], "neq": [34, 38], "ner": 39, "nervou": 24, "nest": [30, 45], "net": [40, 42], "netflix": [38, 43], "network": [10, 23, 28, 33, 35, 36, 38, 39, 41, 53], "neu": 43, "neural": [10, 35, 41, 53], "neutral": 43, "never": [31, 33, 34, 38, 40, 42], "new": [10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 48, 49, 51, 52], "new_cent": 36, "new_column": [32, 34, 41, 42, 52], "new_data": 42, "new_df": [41, 52], "new_exampl": [24, 36], "new_feature_nam": [41, 52], "new_valu": 42, "newaxi": 8, "newcastl": 43, "newer": 32, "newli": [27, 32, 35, 37], "newsgroup": 39, "newswir": 39, "next": [11, 24, 25, 26, 27, 28, 31, 32, 33, 39, 40, 41, 48, 49, 50, 51, 53], "nfeat": 26, "nfeats_accuraci": 26, "ng": [9, 10, 30, 35], "ngram": 35, "ngram_rang": 28, "nhl": 39, "nhqxu": 42, "nice": [4, 30, 31, 33, 34, 37, 40, 42], "nicki": 30, "night": [31, 41], "niki": 53, "nlemma": 39, "nlp": [28, 40, 43], "nltk": [39, 43], "nltk_data": [39, 43], "nn": [10, 27, 40, 43, 47], "nne": [41, 52], "nnw": [41, 52], "nnz": 28, "no_grad": 40, "nobodi": 23, "node": [24, 33, 37, 40, 46], "nois": [37, 45, 47], "non": [1, 8, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 45, 50, 52, 53], "noncommerci": 1, "none": [10, 25, 27, 28, 29, 30, 31, 33, 35, 37, 41, 42, 43, 51], "noninfring": 0, "nonzero": 28, "noqa": [30, 43], "nor": [7, 25, 28, 39], "norg": [39, 43], "norm": [30, 39], "normal": [6, 31, 32, 33, 34, 36, 37, 39, 40, 41, 43, 50, 51], "north": 39, "norvig": 10, "notat": 26, "note": [0, 3, 7, 9, 10, 11, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 38, 44, 45, 49, 50, 52, 53], "notebook": [5, 7, 9, 11, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 40, 43, 48, 52], "notic": [0, 28, 29, 31, 32, 35], "notion": [26, 30, 36, 38], "notna": [41, 52], "noun": [39, 43], "nov": 41, "novel": 45, "novemb": 41, "novic": 9, "now": [8, 11, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 46, 47, 48, 49, 50, 51], "np": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "nperson": 43, "npie": 8, "npo": 39, "npr": [35, 39, 43, 45], "nsubj": 39, "ntest": [26, 30, 47], "ntoken": 39, "ntree": 33, "null": [27, 28, 31, 32, 35, 41, 42, 52], "null_distribut": 42, "num": [31, 33, 34, 50], "num_output_channel": 40, "num_parallel_tre": 33, "num_sent": 31, "num_work": 40, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 42, 45, 47, 49, 52, 53], "number_test": 30, "numberbatch": 39, "numer": [2, 24, 27, 28, 29, 31, 32, 33, 38, 39, 41, 42, 47, 48, 50, 52], "numeric_feat": [28, 30, 35, 45, 49], "numeric_featur": [28, 31, 32, 33, 34, 41, 42, 43, 50, 51, 52], "numeric_looking_column": 32, "numeric_transform": [28, 31, 32, 33, 34, 41, 50, 51, 52], "numpi": [9, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "numpy_dtyp": 42, "nutrit": 39, "nw": [41, 52], "nwith": 26, "ny": 43, "o": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "obelisk": 40, "object": [25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 43, 45, 46, 47, 49, 50, 52], "observ": [23, 24, 25, 26, 33, 34, 36, 37, 41, 42, 47, 50, 51, 52], "obtain": [0, 29, 36, 37, 38, 42, 47, 49], "obviou": [37, 39], "occasion": 31, "occup": [31, 33, 34, 50], "occupation_farm": 34, "occupation_miss": 34, "occupation_priv": 34, "occupi": 53, "occur": [8, 24, 25, 28, 39, 42], "occurr": [39, 42], "ocean": [27, 28, 35, 48], "ocean_proxim": [27, 28, 35, 48], "ocean_proximity_": [27, 28], "ocean_proximity_inland": [27, 28], "ocean_proximity_island": [27, 28], "ocean_proximity_near": [27, 28], "oct": 29, "octob": 41, "oe": [28, 45], "oe_encod": 45, "off": [29, 30, 31, 32, 35, 36, 39, 40, 42, 45, 49, 53], "off_shelf": 51, "offens": 4, "offer": [8, 33, 38, 39, 42, 53], "offic": [4, 11, 45, 53], "offici": [39, 53], "offlin": 38, "offset": 29, "often": [8, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47], "ogunrind": 23, "oh": [34, 35, 40, 41, 42, 45, 49, 52], "ohe_column": [32, 34], "ohe_enc": 28, "ohe_encod": 45, "ohe_feature_nam": [34, 41, 52], "ohehotencod": 28, "ois": 37, "ok": [23, 26, 32, 41, 42, 45, 52], "okai": 36, "ola": 39, "old": [9, 33, 34], "old_cent": 36, "older": 32, "oldpeak": 51, "olymp": 8, "omit": 34, "omw": 39, "onc": [6, 7, 8, 11, 24, 25, 27, 28, 30, 35, 37, 38, 39, 40, 49, 50, 51, 53], "onca": [23, 40], "one": [6, 8, 9, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53], "one_c": 26, "one_ex_preprocess": 34, "one_ex_preprocessed_perturb": 34, "one_exampl": 34, "one_example_perturb": 34, "onehot": [28, 35], "onehotencod": [27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 48, 49, 50, 51, 52], "onehotencoder__major_biologi": 28, "onehotencoder__major_comput": 28, "onehotencoder__major_econom": 28, "onehotencoder__major_linguist": 28, "onehotencoder__major_mathemat": 28, "onehotencoder__major_mechan": 28, "onehotencoder__major_phys": 28, "onehotencoder__major_psychologi": 28, "onehotencoderonehotencod": [28, 30, 32, 33], "ones": [8, 23, 26, 27, 33, 34, 36, 38, 39, 47, 51], "onevsoneclassifi": 44, "onevsrestclassifi": 44, "onli": [2, 4, 8, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 47, 48, 50, 53], "onlin": [3, 5, 7, 11, 24, 39, 53], "onlinebackup": 42, "onlinebackup_no": 42, "onlinebackup_y": 42, "onlinesecur": 42, "onlinesecurity_no": 42, "onlinesecurity_y": 42, "ontario": 39, "ontonot": 39, "op": 31, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 40, 53], "openporchsf": [32, 34], "oper": [4, 8, 11, 28, 35, 39], "operand": 8, "opinion": 33, "opportun": 38, "oppos": [32, 33], "opposit": [8, 32, 33, 34, 52], "opt": [11, 33], "optic": 42, "optim": [2, 10, 24, 25, 26, 28, 31, 33, 34, 35, 36, 37, 40, 42, 49], "optimist": 30, "option": [7, 8, 10, 24, 32, 36, 39, 49, 51, 52], "oracl": 10, "orang": 29, "order": [5, 7, 8, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45], "ordering_ordinal_oth": [32, 34], "ordering_ordinal_reg": [32, 34], "ordin": [32, 45, 48], "ordinal_feat": 28, "ordinal_featur": [31, 33, 34, 50], "ordinal_features_oth": [32, 34], "ordinal_features_reg": [32, 34], "ordinal_transform": [31, 33, 34, 50], "ordinal_transformer_oth": [32, 34], "ordinal_transformer_reg": [32, 34], "ordinalencod": [27, 28, 31, 32, 33, 34, 35, 41, 42, 43, 45, 48, 50, 51, 52], "ordinalencoderordinalencod": [28, 32, 33], "ordinari": 32, "oreilli": [40, 41], "org": [9, 23, 25, 27, 28, 30, 31, 32, 33, 34, 35, 39, 40, 43], "organ": [23, 24, 27, 39], "orgin": 8, "orig_featur": [41, 52], "orig_pr": 34, "orig_scor": 31, "origin": [27, 28, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 47, 49, 52, 53], "original_hm": 31, "originaltweet": 43, "ornithorhynchu": 40, "oscar": 29, "ostblom": 39, "other": [0, 1, 4, 5, 6, 7, 11, 24, 25, 27, 28, 29, 30, 31, 33, 34, 37, 38, 40, 43, 44, 45, 47, 49, 50, 51, 52, 53], "otherwis": [0, 7, 28], "ounc": [23, 40], "our": [5, 6, 8, 11, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53], "ourselv": [24, 31, 39, 40, 41], "out": [0, 4, 7, 8, 11, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 45, 47, 49, 51, 52, 53], "out_col": [25, 27, 43], "out_step": 31, "outcom": 12, "outer": 43, "outlier": [32, 37, 45], "outlook": 42, "output": [7, 8, 11, 23, 24, 25, 28, 29, 31, 33, 34, 39, 40, 41, 45, 51, 52, 53], "outsid": [7, 31, 33, 34, 38, 39, 41, 42], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 30, 32, 39, 40, 41, 42, 45, 53], "over_confident_i": 29, "over_confident_x": 29, "over_sampl": 31, "overal": [11, 31, 34, 36, 39, 40, 45, 50, 51, 53], "overallcond": [32, 34], "overallqu": [32, 34], "overconfid": [34, 35], "overfit": [10, 26, 29, 32, 33, 35, 40, 47, 49, 51, 53], "overflow": 7, "overhead": 28, "overlap": [2, 25, 36], "overli": [26, 30, 47], "overload": [38, 42], "overpredict": 32, "oversample_pip": 31, "overshadow": 39, "overus": 33, "overview": [36, 37, 38, 39], "overwhelm": 36, "overzeal": 6, "own": [4, 5, 8, 25, 27, 31, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 52], "p": [29, 30, 37, 39, 42], "p_i": 36, "p_value_threshold": 42, "pace": [29, 36, 39, 53], "packag": [5, 8, 24, 25, 28, 30, 31, 34, 36, 37, 38, 39, 40, 42, 43, 44, 53], "pad": 40, "page": [1, 4, 10, 23, 27, 28, 30, 31, 32, 33, 34, 35, 39, 40, 43, 51, 53], "pai": 34, "pain": [4, 40, 41, 52], "pair": [37, 39, 44], "pairwis": [26, 37], "panda": [9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "pane": [26, 47], "panel": [26, 31, 34, 36, 37, 47], "panic": 43, "panther": [23, 40], "panthera": [23, 40], "paper": [7, 34, 35, 39, 40, 42, 43], "paperlessbil": 42, "paperlessbilling_no": 42, "paperlessbilling_y": 42, "paradigm": [23, 24, 36, 39], "paradox": 38, "paragraph": 39, "paraleg": 39, "parallel": [28, 30, 33], "param": [26, 28, 30, 32, 47], "param_columntransformer__countvectorizer__max_featur": 30, "param_dist": [30, 49], "param_distribut": [30, 49], "param_grid": [25, 26, 30, 32, 49], "param_grid1": [30, 49], "param_grid2": [30, 49], "param_grid3": 30, "param_grid4": 30, "param_ridge__alpha": 32, "param_svc__c": 30, "param_svc__gamma": 30, "paramet": [26, 27, 28, 32, 33, 34, 36, 37, 39, 41, 42, 43, 46, 47, 49, 50, 51, 52], "parametr": 37, "params_": 42, "params_str": 30, "paramter": 26, "pardu": [23, 40], "parent": [37, 43], "park": [35, 40, 43], "pars": 39, "parse_d": [8, 41, 52], "parser": 39, "part": [4, 9, 10, 11, 27, 28, 29, 30, 31, 33, 34, 35, 37, 39, 41, 43, 51, 53], "part1": 38, "part2": 38, "parti": 39, "partial": [4, 42], "particip": 53, "particular": [0, 9, 11, 27, 28, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 47, 50], "particularli": [33, 38, 53], "partit": [28, 36, 37], "partner": [42, 53], "partner_no": 42, "partner_y": 42, "parton": 43, "pass": [8, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 47], "passthrough": [28, 30, 42, 43, 49, 51], "passthrough__ml_experi": 28, "passthrough_feat": [28, 30, 45, 49], "passthrough_featur": [42, 43, 51], "passthroughpassthrough": [28, 30, 43], "past": [24, 25, 33, 41, 42, 45], "pat": 38, "pat_i": 38, "pat_model": 38, "pat_x": 38, "pata": [23, 40], "path": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "patial": 37, "patient": [24, 51], "patio": 40, "patric": 34, "patrick": 53, "pattern": [23, 24, 25, 28, 30, 35, 36, 39, 41, 47, 52], "pav_bhaji": 39, "pave": [32, 34], "paveddr": [32, 34], "paveddrive_i": 32, "paveddrive_n": 32, "paveddrive_p": 32, "paymentmethod": 42, "paymentmethod_bank": 42, "paymentmethod_credit": 42, "paymentmethod_electron": 42, "paymentmethod_mail": 42, "pca": [31, 37, 38], "pcarter": 9, "pd": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "pdf": [7, 9, 19], "peac": 39, "pedest": 40, "pedro": [10, 25, 35], "peek": 52, "peer": [45, 53], "pembrok": [23, 40], "penal": [6, 42], "penalti": [31, 39, 53], "peopl": [4, 24, 25, 27, 29, 31, 33, 36, 38, 39, 40, 41, 42, 43, 45, 47, 50, 53], "per": [8, 29, 31, 32, 33, 34, 38, 40, 41, 44, 45, 49, 50, 52], "perceiv": 6, "percent": 32, "percent_error": 32, "percentag": [24, 31, 38], "perfect": [6, 24, 25, 31, 32, 34, 38, 42, 43], "perfectli": [2, 38, 39], "perform": [24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 46, 48, 49, 50, 51, 52, 53], "performac": 25, "perhap": [32, 41, 44], "perimet": 35, "period": [39, 41, 42, 43, 53], "perm_sorted_idx": 34, "perman": 8, "permiss": [0, 53], "permit": [0, 27, 31, 53], "permut": 34, "persist": 38, "person": [0, 4, 6, 10, 23, 31, 36, 39, 40, 41, 42, 43, 53], "perspect": [33, 38], "pertain": 5, "perthairport": [41, 52], "perturb": [34, 37], "perturbed_pr": 34, "pete_seeg": 39, "peter": 10, "ph": 39, "phascolarcto": 40, "phase": 25, "phd": 39, "phdei": 42, "phenomenon": [38, 42, 47], "philippin": 43, "philosoph": 39, "phone": [23, 42, 53], "phoneservic": 42, "phoneservice_no": 42, "phoneservice_y": 42, "photo": [43, 45], "photograph": 53, "phrase": 39, "physic": [28, 41], "pi": 8, "pick": [24, 29, 31, 33, 34, 35, 36, 37, 40, 44, 46, 47, 49, 50, 51], "pictur": [33, 34, 37, 39, 41], "pie": 8, "piec": [29, 42], "pil": [23, 40], "pin": 40, "pineappl": 39, "pip": [11, 34, 39, 40, 43], "pipe": [27, 28, 29, 30, 31, 33, 39, 40, 43, 49, 50], "pipe_bestalpha": 32, "pipe_bigalpha": 32, "pipe_catboost": 33, "pipe_dt": [33, 34, 51], "pipe_forward": 35, "pipe_knn": 51, "pipe_lgbm": [33, 34, 51], "pipe_lr": [31, 33, 34, 50, 51], "pipe_lr_all_feat": 35, "pipe_lr_balanc": [31, 50], "pipe_lr_model_bas": 35, "pipe_lr_weight": [31, 50], "pipe_rf": [33, 34, 51], "pipe_rf_demo": 33, "pipe_ridg": [29, 32], "pipe_sklearn_gb": 33, "pipe_sklearn_histgb": 33, "pipe_smallalpha": 32, "pipe_svc": 31, "pipe_svm": [30, 49], "pipe_xgb": [33, 34], "pipe_xor": 35, "pipelin": [2, 10, 16, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 43, 48, 49, 50, 51, 52, 53], "pipeline__lab1": 28, "pipeline__lab2": 28, "pipeline__lab3": 28, "pipeline__lab4": 28, "pipeline__quiz1": 28, "pipeline__rooms_per_household": 35, "pipeline__university_year": 28, "pipelineifittedpipelin": [27, 28, 30, 31, 35, 40, 43], "pipelineinot": [28, 30, 32], "pipelinepipelin": 30, "pitfal": 41, "pixel": 34, "pizza": 39, "pkg": 11, "pla": 39, "place": [5, 39, 41, 53], "plagiar": 53, "plai": [24, 26, 30, 34, 37, 39, 46, 47], "plain": 36, "plan": [11, 23, 32, 35, 42, 43, 48, 51, 53], "plane": 29, "plant": 45, "plastic": 39, "platform": [4, 43], "platypu": 40, "player": [34, 39, 40], "pleas": [1, 4, 7, 11, 23, 27, 28, 30, 31, 32, 33, 34, 35, 40, 43, 49, 53], "plinth": 40, "plot": [7, 24, 25, 26, 27, 29, 30, 31, 32, 35, 37, 38, 39, 40, 41, 47, 49, 50, 52], "plot_2d_scor": 29, "plot_2d_separ": [26, 29, 47], "plot_confusion_matrix": 31, "plot_confusion_matrix_exampl": 31, "plot_cross_valid": [25, 41], "plot_dbscan": 37, "plot_dbscan_with_label": 37, "plot_dendrogram_clust": 37, "plot_elbow": 36, "plot_example_dist": 36, "plot_fruit_tre": 24, "plot_grid_search_overview": 30, "plot_k_means_dbscan_comparison": 37, "plot_km_initi": 36, "plot_km_it": 36, "plot_km_iter": 36, "plot_kmean": 37, "plot_knn_clf": 26, "plot_knn_decision_boundari": 26, "plot_knn_regress": 26, "plot_lda_w_vector": 39, "plot_linkage_criteria": 37, "plot_logistic_regress": 29, "plot_logistic_regression_graph": 40, "plot_multiclass_lr_ovr": 44, "plot_original_clust": 37, "plot_partial_effects_on_outcom": 42, "plot_result": [26, 47], "plot_scal": 27, "plot_silhouette_dist": 36, "plot_single_hidden_layer_graph": 40, "plot_support_vector": 26, "plot_survival_funct": 42, "plot_svc_c": 26, "plot_svc_gamma": 26, "plot_time_spacing_distribut": [41, 52], "plot_train_test_point": 26, "plot_tree_decision_boundari": 25, "plot_tree_decision_boundary_and_tre": [24, 25, 46], "plot_two_hidden_layer_graph": 40, "plot_typ": 34, "plot_x_dendrogram": 37, "plotli": [35, 39], "plotting_funct": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 44, 46, 47, 48, 49, 50, 51], "plotting_functions_unsup": [36, 37, 38, 39], "plt": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "plu": [29, 40], "plural": 28, "pm": [1, 10, 41, 52, 53], "pmltt": 10, "pn": [26, 31, 36, 37, 47], "po": [25, 27, 29, 32, 34, 39, 43], "pobox": 23, "poet": 39, "point": [4, 10, 23, 24, 25, 27, 28, 29, 30, 32, 35, 37, 42, 44, 45, 47, 50, 53], "point_ind": 36, "point_index": 36, "pointless": 49, "polarity_scor": 43, "pole": 40, "polici": [3, 4, 7, 53], "polit": [38, 39, 40], "poly_transform": 41, "polynomialfeatur": [35, 41], "pomegran": 40, "pool": 10, "poolarea": [32, 34], "poolqc": [32, 34], "poor": [28, 32, 35, 45, 48], "poorli": [26, 32, 37, 41], "pope": 39, "popul": [27, 28, 29, 35, 41, 48], "popular": [8, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 53], "population_per_household": [27, 28, 48], "porter": 39, "porterstemm": 39, "portion": [0, 25, 27, 30, 32, 34, 51, 52, 53], "portug": [31, 34], "pos_": [39, 43], "pos_label": 32, "posit": [24, 25, 26, 27, 29, 32, 33, 34, 39, 41, 42, 43, 50], "posix": 42, "possibl": [4, 5, 6, 8, 23, 24, 25, 27, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 45, 47, 48, 49, 50, 53], "possibli": [7, 39], "post": [4, 6, 8, 10, 39, 41, 53], "postprocess": 40, "potenti": [26, 27, 36, 39, 53], "powder": 39, "power": [8, 25, 33, 38, 39, 40], "pplicat": 37, "pr": 45, "practic": [0, 6, 9, 10, 25, 27, 35, 40, 45, 48, 49, 53], "prairielearn": [10, 53], "pre": [10, 11, 19, 23, 33, 35, 39, 43, 45], "precis": [18, 32, 45, 50, 53], "precision_lr": 31, "precision_recall_curv": 31, "precision_scor": 31, "precision_svc": 31, "precisionrecallcurvedisplai": 31, "precisionrecalldisplai": 31, "pred": [31, 32, 38, 41, 42], "pred_df": [23, 38], "pred_dict": 23, "pred_g": 38, "pred_lin_reg": 38, "pred_train": 32, "pred_x": 38, "prediciton": 42, "predict": [2, 17, 25, 26, 27, 30, 31, 32, 35, 36, 37, 39, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53], "predict_expect": 42, "predict_for_usr": 38, "predict_proba": [31, 33, 34, 40, 44, 51], "predict_survival_funct": 42, "predicted_categori": 31, "predicted_n_rent": 41, "predicted_quiz2": 24, "predicted_sal": 41, "predicted_target": 23, "predictor": [24, 45], "prefer": [23, 33, 36, 38, 49], "prefix": 8, "preliminari": [27, 35], "prepar": [27, 35, 40], "prepend": 11, "preprocess": [10, 16, 18, 25, 26, 29, 30, 31, 33, 34, 35, 37, 38, 40, 42, 43, 47, 48, 49, 51, 53], "preprocess_featur": [41, 52], "preprocessing_fin": 42, "preprocessing_notenur": 42, "preprocessor": [28, 30, 31, 32, 33, 34, 41, 42, 43, 48, 49, 50, 51, 52], "preprocessor1": 35, "preprocessor2": 35, "preprocessor3": 35, "prerequisit": [2, 42, 53], "preschool": [31, 33, 34, 50], "presenc": [28, 34, 42], "present": [7, 25, 31, 38, 39, 40, 41, 42, 45, 47, 52], "preserv": [31, 36], "pressure3pm": [41, 52], "pressure9am": [41, 52], "pretend": [24, 25, 41], "pretrain": [39, 40, 43], "pretti": [24, 28, 29, 31, 33, 36, 39, 41, 42, 52], "prevent": [30, 39, 42, 53], "previou": [24, 32, 33, 36, 37, 41, 42, 45, 49, 50, 52], "previous": [38, 40, 41], "price": [8, 18, 27, 29, 32, 34, 35, 42, 47], "primari": [8, 19, 26], "primarili": [24, 34, 40], "prime": 23, "princ": 39, "princess": 39, "principl": [9, 24, 45, 53], "print": [7, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 52], "print_top": 39, "prior": [36, 41, 45], "priorit": [35, 45], "privaci": [0, 36, 53], "privat": [7, 31, 33, 34], "privileg": 6, "prize": 28, "pro": [36, 40], "prob": [29, 33], "proba": 40, "probabilist": [2, 39], "probabl": [17, 23, 26, 27, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 45, 50, 51, 52], "problem": [4, 6, 10, 23, 28, 29, 31, 32, 33, 34, 36, 37, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53], "problemat": [31, 34, 42], "probosci": [23, 40], "proce": 53, "procedur": 33, "proceed": [25, 52], "process": [2, 5, 7, 24, 26, 27, 28, 30, 35, 36, 37, 40, 43, 47, 49, 53], "process_on": 43, "prod": [28, 30], "produc": [2, 7, 32, 34, 37, 42, 45, 47], "product": [5, 30, 38, 39], "prof": [31, 33, 34, 50], "profession": 38, "profil": 32, "profile_df": 38, "profilereport": 32, "program": [0, 4, 9, 11, 23, 39, 53], "programm": 39, "progress": 36, "project": [11, 27, 33, 35, 40, 45, 53], "promin": 39, "promis": [23, 39, 41], "promot": 42, "prompt": [11, 53], "pron": [39, 43], "prone": 30, "proper": [40, 46], "properli": [7, 42], "properti": [24, 32, 34, 35], "prophet": 41, "propn": [39, 43], "proport": [24, 25, 28, 29, 31, 32, 33, 34, 50, 53], "proportional_hazard_test": 42, "prostitut": 39, "prototyp": 45, "prove": 31, "provid": [0, 5, 7, 11, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 49, 50, 51, 52, 53], "provinc": [28, 39], "provinci": 39, "proxi": 25, "proxim": [29, 39, 53], "prune": 35, "psychologi": [28, 45], "pt": [29, 30, 40], "public": [0, 4, 7, 39, 43], "publish": [0, 10, 29, 39], "puck": 39, "pud": 32, "pull": [11, 29, 39], "punct": [39, 43], "punctuat": [28, 39], "punkt": 43, "punkt_tab": 43, "purchas": [23, 38], "pure": [24, 41], "purpos": [0, 24, 25, 27, 38, 39, 41, 45, 46, 47, 51, 53], "push": [7, 34], "put": [7, 8, 11, 24, 25, 27, 28, 35, 36, 37, 38, 49], "px": [35, 39], "py": [24, 25, 27, 28, 30, 33, 34, 36, 37, 42, 43, 44], "pybind11": 43, "pybo": 30, "pydata": 35, "pyplot": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "pysurviv": 42, "python": [3, 4, 10, 23, 30, 32, 38, 39, 40, 41, 42, 43, 53], "python3": [9, 24, 25, 28, 30, 34, 42, 43, 44], "pythonwarn": 32, "pytorch": [23, 40], "pytorch_1711403226120": 43, "pyviz": 31, "q": 10, "qualiti": [31, 34, 36, 37], "quantifi": [31, 50], "queen": 39, "queen_consort": 39, "queri": [27, 31, 33, 36, 38, 39, 41, 42, 50, 52, 53], "query_point": 26, "quest": 35, "question": [6, 7, 53], "quick": [4, 39, 53], "quickli": [24, 26, 27, 30, 37, 42, 45, 53], "quickstart": 9, "quirk": 25, "quit": [6, 23, 24, 27, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43], "quiz": [1, 10, 39], "quiz1": [24, 25, 28, 45], "quiz2": [25, 28, 45], "quizz": 24, "r": [24, 28, 29, 31, 41, 51, 53], "r1": 33, "r2": [32, 33, 45, 47], "r2_score": [32, 35, 43], "r4": 33, "race": [28, 31, 33, 34, 50, 53], "radial": 26, "radiu": [35, 37], "rail": 40, "rain": [41, 52], "rain_df": [41, 52], "rain_df_modifi": [41, 52], "rainfal": [41, 52], "rainfall_lag1": [41, 52], "rainfall_lag2": [41, 52], "rainfall_lag3": [41, 52], "raintodai": [41, 52], "raintoday_miss": [41, 52], "raintoday_no": [41, 52], "raintoday_y": [41, 52], "raintomorrow": [41, 52], "rais": [6, 28, 31, 41, 42, 52], "rand": [8, 33], "randint": [30, 49], "randn": [29, 35], "random": [6, 8, 25, 26, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 51, 53], "random_forest_data": 33, "random_search": [30, 49], "random_st": [23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51], "randomforestclassifi": [34, 35, 41, 51, 52], "randomforestclassifierrandomforestclassifi": 33, "randomforestregressor": [32, 33, 34, 35, 41, 42, 43, 51], "randomhorizontalflip": 40, "randomizedsearchcv": [26, 33, 34, 49, 51], "randomizedsearchcvifittedrandomizedsearchcv": 30, "randomli": [25, 29, 30, 31, 33, 42, 50], "randomoversampl": 31, "randomresizedcrop": 40, "randomst": [35, 37], "randomundersampl": 31, "rang": [4, 8, 25, 26, 27, 28, 29, 33, 36, 38, 39, 40, 41, 42, 43, 49, 53], "rangeindex": [28, 35, 41, 42, 52], "rank": [31, 35, 38, 39, 42, 50], "rank_test_mape_scor": 32, "rank_test_neg_mean_squared_error": 32, "rank_test_scor": [30, 32], "ranking_": 35, "rare": [28, 31, 32, 36, 39, 45], "rate": [23, 29, 31, 33, 36, 42, 45, 50], "rated_item": 38, "rather": [23, 28, 30, 31, 32, 33, 34, 36, 39, 40], "ratings_df": 38, "ratio": [31, 33, 39, 42], "ravel": [31, 45], "raw": [8, 28, 31, 34, 35, 39, 40, 44, 50], "raw_model_output": 29, "raw_scor": 34, "rbf": [10, 15, 25, 27, 29, 30, 33, 34, 35, 45, 47, 49], "rcparam": [23, 24, 25, 31, 36, 37, 38, 40, 41, 42, 46, 52], "re": [4, 7, 8, 11, 23, 24, 25, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 52], "reach": [6, 36, 53], "read": [1, 4, 7, 10, 26, 27, 28, 31, 32, 33, 34, 39, 41, 51, 52], "read_csv": [8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 53, "readi": [7, 25, 26, 27, 29], "readlin": 40, "readm": 42, "readthedoc": 42, "real": [25, 26, 27, 28, 29, 31, 34, 36, 37, 38, 39, 40, 43, 45], "realdonaldtrump": 43, "realist": [27, 41, 52], "realiti": [25, 32, 42], "realli": [8, 25, 29, 30, 33, 35, 37, 38, 40, 41, 42], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 30, 31, 32, 34, 36, 38, 39, 41, 42, 45, 53], "rebuild": 43, "rec": [32, 34], "recal": [18, 24, 25, 26, 27, 28, 29, 32, 36, 41, 45, 50, 53], "recall_lr": 31, "recall_scor": 31, "recall_svc": 31, "receiv": [6, 7, 28, 37, 40, 41], "recent": [8, 11, 23, 28, 35, 38, 39, 41, 42, 43], "recip": 25, "recogn": [25, 37, 41, 53], "recognit": [23, 24, 26, 31, 39, 53], "recommend": [2, 4, 8, 10, 11, 23, 25, 26, 30, 31, 36, 39, 40, 51, 53], "record": [24, 42], "recreat": 52, "rectangular": 36, "recurr": 41, "recurs": 53, "red": [24, 26, 31, 34, 35, 36, 41], "redbon": 30, "redefin": 42, "redistribut": 0, "reduc": [7, 8, 23, 26, 30, 31, 32, 33, 34, 35, 38, 39, 40, 44, 47, 50, 53], "reduct": [2, 31, 33, 35, 36], "redund": [29, 34], "ref": [31, 42, 50], "refer": [8, 24, 25, 26, 27, 28, 29, 31, 34, 36, 38, 39, 40, 47, 53], "referenc": 53, "referenti": 39, "refin": [26, 47], "refit": 32, "reflect": [26, 32, 34, 39, 47, 49, 53], "reflection_period": 31, "reg": [24, 33, 51], "reg_model": 24, "regard": 53, "regardless": 7, "regex": 39, "region": [24, 31, 37, 41, 44, 49, 52], "region_data": [41, 52], "regist": 53, "registered_nurs": 39, "registri": 43, "regrad": 6, "regress": [2, 10, 17, 23, 27, 28, 34, 35, 38, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53], "regression_df": 24, "regressor": [24, 27, 28, 32, 41, 51], "regular": [26, 28, 29, 33, 39, 41, 42, 45], "regulatori": 34, "reinforc": [23, 36], "reject": [31, 50], "rel": [29, 34, 37, 39, 43, 44, 50], "rel_char_len": 43, "relabel": 36, "relat": [2, 6, 11, 23, 29, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 51, 53], "relationship": [31, 33, 34, 35, 39, 41, 43, 45, 46, 47, 50, 52, 53], "relationship_husband": 34, "relationship_own": 34, "releas": [7, 10], "relev": [4, 8, 10, 24, 26, 27, 30, 34, 41, 53], "reli": [25, 26, 35, 37, 38, 41, 47], "reliabl": [23, 36], "religi": 39, "remain": [5, 32, 35, 38, 41], "remaind": 6, "rememb": [7, 26, 28, 30, 31, 34, 35, 37, 40, 41, 42, 46, 47, 49, 52], "remind": 46, "remix": 0, "remov": [7, 27, 31, 33, 34, 35, 39, 40, 42, 44, 49, 50, 52], "renam": [23, 31, 34, 41], "render": [4, 7, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 43], "rent": 41, "rental": 41, "rentals_df": 41, "rentals_lag5": 41, "rentals_lag5_i": 41, "rentals_lag5_x": 41, "rentals_model": 41, "repair": [31, 33, 34], "repeat": [8, 35, 36, 37, 40, 49, 50, 51], "repeatedli": 6, "replac": [23, 27, 31, 33, 34, 38, 42, 50], "reply_cont": 43, "repo": [10, 31], "report": [6, 24, 30, 32, 35, 41, 43, 50], "repositori": [0, 5, 10, 11, 29, 31, 53], "repres": [24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 51], "represent": [23, 24, 27, 30, 31, 32, 33, 34, 35, 36, 37, 39, 43, 45], "reproduc": [4, 25, 30, 33, 53], "republ": 34, "request": [6, 39, 53], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 47, 52], "rerun": [23, 27, 28, 30, 31, 32, 33, 34, 35, 40, 43], "res_mean": 25, "resampl": 31, "research": [23, 25, 30, 38, 39], "reserv": [41, 53], "reset_index": 23, "reshap": [8, 29, 30, 40, 41, 49], "resid": 29, "residu": 33, "resiz": 40, "resnet": 40, "resolut": 39, "resolv": 53, "resort": 29, "resourc": [3, 5, 10, 24, 33, 34, 39, 40, 45], "respect": [29, 30, 31, 33, 34, 49], "respons": [4, 7, 24, 36, 39, 53], "rest": [29, 30, 40, 42, 45, 52], "restart": [7, 11], "restaur": 38, "restingbp": 51, "restingecg": 51, "restrict": [0, 32, 33, 39], "result": [2, 7, 8, 10, 11, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 47, 49, 50, 51, 52, 53], "result_block": 42, "result_img": 40, "results_df": [25, 26, 29, 47], "results_dict": [25, 26, 27, 28, 30], "results_single_valid_df": 47, "retail": [43, 45], "retail_df": 41, "retail_df_test": 41, "retail_df_train": 41, "retail_lag_5": 41, "retail_model": 41, "retail_test_5": 41, "retail_test_5_pr": 41, "retail_train_5": 41, "retail_train_5_d": 41, "retail_train_5_i": 41, "retail_train_5_x": 41, "retent": 42, "retrain": [30, 49], "return": [5, 8, 11, 24, 25, 26, 27, 28, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 49, 52], "return_gener": 28, "return_train_scor": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 47, 49, 51], "reus": [31, 53], "revenu": 38, "revers": [28, 32], "review": [4, 10, 29, 36, 43, 45, 49, 50, 51, 53], "revisit": [31, 45], "revok": 0, "reward": [23, 28, 36], "rf": [41, 42], "rf_imp_df": 34, "rfe_cv": 35, "rfe_pip": 35, "rfecv": 35, "rgb": 23, "rhode_island": 39, "rich": [34, 39, 42, 45], "rico": 34, "rid": [11, 28, 33, 34, 39, 42], "ridg": [34, 35, 38, 41, 42, 43], "ridge__alpha": 32, "ridge_pr": 32, "ridge_tun": 32, "ridgecv": [35, 43], "ridgecv_pip": 32, "ridgeridg": [32, 35], "right": [0, 10, 23, 29, 30, 31, 32, 35, 36, 37, 38, 39, 45, 49, 50, 53], "rightarrow": [24, 26, 29, 31, 32, 33, 36, 37, 38, 39, 45], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 39, "rise": [35, 39], "risk": [10, 31, 35, 47, 51], "river": 29, "rl": [32, 34], "rmse": [38, 45], "rng": [35, 37], "rnn": 41, "ro": 31, "roast": 36, "robot": [38, 39], "robust": [23, 25, 26, 27, 30, 33, 37, 47, 49], "roc": [45, 53], "roc_auc": 31, "roc_auc_scor": 31, "roc_curv": 31, "roc_lr": 31, "roc_svc": 31, "roccurvedisplai": 31, "rodolfo": 30, "rodr\u00edguez": 39, "roger": 35, "role": [29, 30, 34, 40], "roman": 38, "romanc": 38, "romant": 38, "ronald": 29, "roof": 34, "roofmatl": [32, 34], "roofmatl_clytil": [32, 34], "roofmatl_compshg": [32, 34], "roofmatl_membran": 32, "roofmatl_met": 32, "roofmatl_rol": 32, "roofmatl_tar": 32, "roofmatl_wdshak": 32, "roofmatl_wdshngl": [32, 34], "roofstyl": [32, 34], "roofstyle_flat": 32, "roofstyle_g": 32, "roofstyle_gambrel": 32, "roofstyle_hip": 32, "roofstyle_mansard": 32, "roofstyle_sh": 32, "room": [23, 24, 29, 32, 35, 43, 53], "rooms_per_household": [27, 28, 35, 48], "rooms_per_household_0": 35, "rooms_per_household_1": 35, "rooms_per_household_10": 35, "rooms_per_household_11": 35, "rooms_per_household_12": 35, "rooms_per_household_13": 35, "rooms_per_household_14": 35, "rooms_per_household_15": 35, "rooms_per_household_16": 35, "rooms_per_household_17": 35, "rooms_per_household_18": 35, "rooms_per_household_19": 35, "rooms_per_household_2": 35, "rooms_per_household_3": 35, "rooms_per_household_4": 35, "rooms_per_household_5": 35, "rooms_per_household_6": 35, "rooms_per_household_7": 35, "rooms_per_household_8": 35, "rooms_per_household_9": 35, "root": [11, 24, 26, 38, 40, 45], "rose": 39, "rostin": 53, "rotat": [41, 52], "rough": 4, "roughli": [5, 25, 39, 45], "round": [8, 26, 27, 30, 31, 33, 37, 40, 47], "rout": [5, 24, 41], "row": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 51, 52, 53], "rry": 39, "rsh": 30, "ru": [8, 31], "rubric": 29, "rule": [1, 8, 23, 24, 26, 29, 31, 33, 39, 45, 47, 50], "run": [4, 5, 7, 10, 11, 23, 25, 26, 28, 30, 31, 32, 34, 36, 37, 39, 40, 43, 44, 46, 47, 49, 51], "run_ast_nod": 43, "run_cel": 43, "run_cell_async": 43, "run_cod": 43, "run_forev": 43, "runner": 43, "runpi": 43, "runtimewarn": 30, "ruscorpora": 39, "rush": 35, "russel": 10, "rv": 30, "rv_continuous_frozen": 30, "rv_discrete_frozen": 30, "rvert_2": 39, "s1": [8, 39], "s19": 27, "s2": [8, 39], "s_lag": [41, 52], "sa": 1, "sabr": 39, "sabrina": 10, "sadli": 39, "safe": 27, "safeti": 40, "sai": [8, 24, 26, 27, 28, 31, 32, 33, 34, 39, 41, 45, 50], "said": [25, 27, 29, 34, 37, 38, 39], "sal": [32, 34], "sale": [8, 31, 32, 41, 47], "salecondit": [32, 34], "salecondition_abnorml": 32, "salecondition_adjland": 32, "salecondition_alloca": 32, "salecondition_famili": 32, "salecondition_norm": 32, "salecondition_parti": 32, "salepric": [32, 34], "sales_data": 41, "salesforc": 43, "saleswoman": 39, "saletyp": [32, 34], "saletype_cod": 32, "saletype_con": 32, "saletype_conld": 32, "saletype_conli": 32, "saletype_conlw": 32, "saletype_cwd": 32, "saletype_new": 32, "saletype_oth": 32, "saletype_wd": 32, "salt": [29, 34], "sam": 38, "same": [6, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 50, 52], "samosa": 39, "sampl": [24, 26, 27, 29, 30, 34, 37, 40, 41, 42, 46, 47, 50, 51, 52], "sample_df": 31, "sample_text": 43, "sampling_strategi": 31, "samuel": 23, "sand": 40, "sandbar": 40, "saniti": [24, 42], "sarah": 10, "sat": 41, "satisfactori": 36, "satisfi": [36, 53], "saturdai": 41, "save": [7, 8, 28, 30, 34, 39, 40, 41, 43, 48, 49, 52], "saw": [27, 29, 30, 31, 37, 45], "sb": 35, "scalabl": [23, 37], "scalar": 8, "scale": [16, 25, 26, 28, 30, 31, 32, 33, 35, 37, 40, 42, 45, 47, 48, 49], "scale_pos_weight": 33, "scaler": [27, 34, 35], "scan": 45, "scatter": [27, 32, 34, 35], "scatter_3d": 35, "scatterplot": 35, "scc": 39, "scenario": [25, 28, 33, 34, 35, 37, 41, 42, 45, 53], "schedul": [42, 45], "schmidt": 30, "school": [23, 31, 33, 34, 38, 50], "schoolteach": 39, "scienc": [2, 9, 10, 11, 28, 36, 41, 45, 47, 53], "scientif": [38, 39], "scientist": [9, 10, 37], "scikit": [9, 11, 16, 17, 24, 26, 29, 30, 31, 33, 36, 37, 40, 41, 43, 44, 49, 50, 53], "scipi": [11, 30, 37, 39, 49], "scm": 5, "scope": [39, 41], "score": [17, 18, 23, 26, 27, 28, 33, 34, 37, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53], "score_func": 32, "score_lr_print_coeff": [41, 52], "score_param": 28, "score_tim": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43], "scorer": [28, 32], "scores_averag": 51, "scores_dict": 29, "scores_imag": 29, "scores_stack": 51, "scoring_method": 42, "scoring_metr": [33, 34, 43], "scotland": 39, "scratch": [2, 40], "screen": 7, "screennam": 43, "screenplai": 39, "screenporch": [32, 34], "script": 11, "scroog": 43, "sd": 19, "sdng": 32, "se": [41, 42, 52], "sea": 40, "seaborn": [34, 35, 36, 37, 38], "seacoast": 40, "search": [4, 5, 11, 32, 39, 45, 49], "search_multi": 32, "seashor": 40, "season": 52, "season_autumn": 41, "season_fal": 41, "season_summ": 41, "season_wint": 41, "seat": [40, 53], "seattl": 43, "seawal": 40, "second": [4, 6, 24, 29, 33, 34, 37, 40, 41], "secondari": 23, "secpompeo": 43, "section": [7, 11, 24, 25, 35, 51, 53], "secur": [34, 53], "see": [1, 4, 6, 7, 8, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53], "seed": [29, 30, 36, 37], "seem": [24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 41, 42, 43, 44, 47, 49, 50], "seemingli": [31, 50], "seen": [8, 23, 25, 26, 27, 28, 29, 35, 37, 38, 42, 45, 47, 49, 51], "sefa": 53, "segment": [31, 39, 40, 42, 45, 53], "select": [5, 6, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 41, 42, 53], "select_dtyp": 32, "select_knn": 35, "select_rf": 35, "select_svc": 35, "selectfrommodel": 35, "self": [23, 28, 42, 43, 53], "sell": [0, 8, 24], "semant": [36, 37, 39, 53], "semest": 53, "semi": [10, 39], "semicolon": 8, "semilogx": 32, "send": [4, 23, 43], "senior": 42, "seniorcitizen": 42, "sens": [6, 25, 28, 29, 31, 32, 34, 35, 36, 38, 39, 41, 42, 44], "sensibl": 7, "sensit": [25, 27, 30, 31, 32, 36, 42], "sent": [23, 39], "sent_token": 39, "sentenc": 39, "sentiment": [24, 29, 39, 43], "sentimentintensityanalyz": 43, "sepal": [26, 47], "separ": [24, 25, 27, 28, 29, 31, 35, 36, 38, 39, 41, 44, 45, 46, 47, 48, 49, 50], "septemb": 41, "sequenc": [25, 28, 40, 41], "sequenti": [24, 33, 41, 42, 45], "sequentialfeatureselector": 35, "ser": [25, 27, 42], "seri": [2, 10, 25, 27, 28, 31, 35, 40, 42, 43, 53], "serial": 33, "seriou": [6, 31, 38, 39, 42, 53], "serv": [5, 24, 34, 53], "server": 5, "servic": [33, 34, 38, 42, 43], "session": [36, 45, 53], "set": [7, 8, 9, 10, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52], "set_config": [30, 33], "set_index": [25, 26, 30, 31, 32], "set_opt": [23, 24, 25, 26, 27, 28, 29, 30, 31, 37, 38, 46, 47, 48, 49, 50], "set_properti": 23, "set_titl": [26, 29, 31, 40, 47, 50], "set_xlabel": [26, 29, 36, 47], "set_ylabel": [26, 29, 36, 47], "settl": [49, 50], "setup": [3, 7, 11, 46], "setup_default_warn": 43, "sev": [32, 34], "sever": [11, 27, 29, 36, 37, 39, 40, 41, 44, 52, 53], "sex": [31, 33, 34, 35, 50, 51], "sexual": 53, "sfu": 39, "shadab": 53, "shadow": 19, "shaikh": 53, "shall": [0, 39], "shallow": 33, "shan": 39, "shape": [24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 52], "shape_df": 25, "shape_dict": 25, "share": [0, 35, 53], "sharealik": 1, "sharex": 27, "shashwat": 53, "she": [23, 38, 39, 43], "shed": [32, 34], "sheet": [9, 45], "shelf": [33, 39, 49], "shell": [5, 9, 43], "shelv": 43, "shift": [41, 52], "shit": 43, "shng": 32, "shop": 38, "short": [10, 11, 25, 30, 33, 39, 53], "shorter": 42, "shorthand": 27, "shot": 35, "should": [5, 7, 8, 11, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53], "shouldn": [31, 33, 39, 47], "show": [4, 7, 11, 23, 25, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 49, 51, 52], "show_plot": 42, "showcas": 39, "shown": [7, 11, 23, 24, 26, 31, 33, 36, 37, 41], "shrink": [30, 35], "shuffl": [25, 40, 41, 52], "si": 23, "sibl": 35, "sick": [36, 43], "sid": 43, "side": [6, 40], "sift": 38, "sigma": 40, "sign": [4, 32, 34, 40, 47, 49, 51, 53], "signal": [25, 39], "signific": [27, 40, 53], "significantli": [28, 31, 38], "sigoptsearchcv": 30, "silhouett": 37, "silhouettevisu": [36, 37], "sim": 34, "sim_word": 39, "simard": 34, "similar": [10, 11, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 42, 44], "similarity_": 39, "similarli": [34, 36, 42], "simon_fras": 39, "simp": 41, "simpl": [10, 24, 26, 27, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 45, 46, 50], "simplefilt": [33, 34], "simpleimput": [27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 48, 49, 50, 51, 52], "simpleimputersimpleimput": [27, 28, 32, 33, 35], "simpler": [29, 30, 47], "simplest": 28, "simpli": [27, 35, 36, 39], "simplic": [24, 28, 38], "simplist": [26, 34, 47], "simul": 35, "sin": 8, "sinc": [5, 29, 32, 34, 35, 36, 38, 40, 41, 42, 44, 45, 46, 52], "singer_songwriter_bob_dylan": 39, "singl": [8, 26, 27, 29, 30, 31, 33, 34, 37, 41, 42, 45, 46, 47, 49, 50], "sit": 53, "sitarist_ravi_shankar": 39, "site": [5, 24, 25, 28, 30, 34, 42, 43, 44, 53], "situat": [6, 23, 31, 33, 36, 40, 42, 53], "six": [25, 33, 41], "size": [23, 24, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 51, 52, 53], "skew": 32, "skill": [33, 53], "skin": 43, "skip": 50, "skipna": 42, "sklearn": [10, 23, 25, 26, 29, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "sklearn_gb": 33, "sklearn_histgb": 33, "sktime": 41, "skyblu": [41, 52], "skyscrap": 41, "sl": 39, "slate": 52, "slice": 8, "slide": [9, 10, 19, 27, 40, 53], "slightli": [28, 29, 31, 33, 42], "slope": 29, "sloppi": 27, "slot": 53, "slow": [26, 33, 35, 40], "slower": [33, 36], "slowest": 51, "sm": [23, 28], "smac": 30, "small": [11, 25, 26, 28, 30, 32, 33, 34, 35, 36, 38, 40, 42, 45, 47, 49, 51], "small_citi": 26, "small_train_df": 26, "smallalpha_coeff": 32, "smaller": [26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 41, 42, 47, 49], "smallest": [29, 32, 36, 37], "smart": [36, 43], "smile": 43, "smooth": [26, 47], "smoothli": 11, "smote_pip": 31, "sms_df": 23, "sn": [34, 36, 37], "snake": [29, 40], "snake_length": 29, "snakes_df": 29, "snbf": 33, "snippet": 7, "snow": [23, 40], "snp": 35, "so": [0, 4, 5, 7, 8, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53], "social": [36, 37, 38, 41], "societ": 53, "societi": [31, 39, 50], "sofist": 47, "soft": [29, 33, 51], "softmax": 45, "softwar": [1, 5, 11, 42], "solar": 38, "sold": [8, 32], "sole": [31, 37], "solidifi": 45, "solut": [23, 24, 25, 33, 36, 42, 43, 45, 53], "solv": [4, 23, 24, 26, 35, 39, 47, 53], "solver": 31, "some": [4, 6, 7, 8, 11, 23, 25, 26, 27, 28, 29, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53], "someon": [23, 24, 25, 35, 42], "someth": [4, 7, 11, 24, 28, 31, 32, 33, 34, 36, 41, 42, 45, 53], "sometim": [6, 24, 25, 28, 29, 30, 33, 34, 39], "somewhat": 32, "somewher": [23, 32], "song": [26, 27, 38, 43, 49], "song_titl": [26, 27, 30, 49], "soo": 53, "soon": [23, 26, 27, 41], "sopha": 23, "sophist": [30, 34, 39], "sort": [5, 10, 24, 25, 27, 34, 38, 39, 40, 41, 52], "sort_index": [8, 30, 32, 41, 52], "sort_valu": [27, 28, 29, 30, 32, 33, 34, 35, 41, 42, 43, 51, 52], "sound": [34, 35], "soundtrack": 39, "sourc": [11, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 43, 46, 49, 53], "south": 28, "space": [26, 29, 30, 35, 36, 37, 39, 43, 52, 53], "spaci": 35, "spacymoji": 43, "spam": [25, 31, 36], "spam_predict": 23, "span": [39, 41], "spanish": 27, "spars": [26, 29, 33, 38, 39, 45], "sparse_output": [27, 28, 31, 32, 33, 34, 41, 42, 45, 50, 51, 52], "spatial": 29, "speak": 5, "spearmint": 30, "speci": [26, 45, 47], "special": [23, 28, 38, 39, 40, 41, 42, 47, 53], "specialti": [31, 33, 34], "specif": [8, 24, 25, 30, 31, 34, 36, 38, 39, 40, 41, 42, 45, 47, 49, 51, 53], "specifi": [8, 24, 25, 28, 30, 31, 36, 37, 40, 49, 51], "spectrogram": 35, "speech": [35, 39, 43], "speechi": [26, 27, 30, 49], "speed": [8, 24, 33, 40], "spell": 23, "spend": [23, 27, 35, 43, 53], "spent": [6, 27, 35], "spheric": [37, 45], "spici": 36, "spini": 40, "spit": 40, "split": [15, 24, 26, 28, 29, 30, 32, 33, 35, 38, 39, 42, 43, 45, 50, 51, 52, 53], "split0_test_r2": 32, "split0_test_scor": 30, "split0_train_neg_mean_squared_error": 32, "split0_train_scor": 30, "split1_test_r2": 32, "split1_test_scor": 30, "split1_train_neg_mean_squared_error": 32, "split1_train_scor": 30, "split2_test_r2": 32, "split2_test_scor": 30, "split2_train_neg_mean_squared_error": 32, "split2_train_scor": 30, "split3_test_r2": 32, "split3_test_scor": 30, "split3_train_neg_mean_squared_error": 32, "split3_train_scor": 30, "split4_test_scor": 30, "split4_train_neg_mean_squared_error": 32, "split4_train_scor": 30, "spoken": 28, "sport": [39, 40, 41], "spot": [31, 32, 47], "spotifi": [26, 38, 49], "spotify_df": [26, 27, 30, 49], "spotlight": [5, 11], "spous": [31, 33, 34], "spread": 37, "spring_month": 41, "sqft": 34, "sqft_abov": [23, 24], "sqft_basement": [23, 24], "sqft_live": [23, 24], "sqft_living15": [23, 24], "sqft_lot": [23, 24], "sqft_lot15": [23, 24], "sqrt": [26, 32, 34, 38, 39], "squar": [8, 24, 26, 29, 34, 38, 42, 43, 45, 53], "squash": [29, 40], "squeez": [8, 42], "src": [25, 31], "sse": [41, 52], "ssw": 41, "st": [41, 43], "st_slope": 51, "stabil": 11, "stabl": [25, 31, 33, 47], "stack": [7, 45, 53], "stack_method": 51, "stacking_model": [33, 51], "stacking_model_tre": 33, "stackingclassifi": [33, 51], "stackingregressor": 33, "staff": 6, "stai": [31, 42], "stakehold": 53, "stale": 36, "stand": [26, 30, 39], "standard": [4, 6, 25, 27, 30, 33, 34, 35, 39], "standardscal": [28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52], "standardscalerstandardscal": [27, 28, 30, 31, 32, 33, 35, 40, 43], "stanford": 39, "star": [26, 36, 38, 43], "start": [7, 8, 11, 24, 25, 26, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52], "startswith": 34, "starttim": 41, "stat": [30, 42, 49], "state": [6, 8, 25, 31, 33, 34, 38, 39, 43, 50], "statement": [7, 25, 26, 27, 28, 29, 30, 31, 32, 35, 40, 42], "station": 41, "statist": [9, 10, 24, 29, 34, 38, 39, 42, 53], "statistician": 26, "statlib": 29, "statsmodel": [41, 42], "statu": [31, 33, 34, 50], "status_marri": 34, "status_nev": 34, "std": [25, 26, 27, 31, 32, 40, 41, 43, 44, 52], "std_cv_error": 25, "std_cv_score": 26, "std_fit_tim": [30, 32], "std_score": [25, 27, 43], "std_score_tim": [30, 32], "std_test_neg_mean_squared_error": 32, "std_test_scor": [25, 30], "std_train_error": 25, "std_train_neg_mean_squared_error": 32, "std_train_scor": [25, 26, 30], "stdki": 42, "stem": 39, "step": [7, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53], "stereotyp": 39, "stick": 41, "still": [4, 11, 30, 31, 32, 33, 35, 36, 41, 42, 43, 47, 48, 49, 50], "stochast": [35, 36], "stock": [23, 41], "stop": [8, 36, 39, 40, 42, 47], "stop_word": [30, 31, 39, 43, 49], "stopword": 39, "storag": 26, "store": [7, 8, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43], "stori": [32, 33, 43], "storylin": 39, "str": [30, 34, 39, 41, 42, 43, 52], "straight": 42, "straightforward": 34, "strain": 7, "strang": [34, 42], "strata": 42, "strategi": [24, 26, 27, 28, 31, 32, 34, 36, 38, 41, 42, 45, 46, 50, 52], "stratif": 42, "stratifi": 42, "stratifiedkfold": [25, 31], "stream": [42, 43], "streamingmovi": 42, "streamingmovies_no": 42, "streamingmovies_y": 42, "streamingtv": 42, "streamingtv_no": 42, "streamingtv_y": 42, "street": [32, 34], "street_grvl": 32, "street_pav": 32, "strength": [39, 45], "stress": 36, "strftime": [41, 42], "string": [8, 11, 26, 31, 32, 33, 34, 39, 41, 42, 47, 51], "strip": [34, 40], "strong": [33, 42, 45], "stronger": 33, "strongli": 33, "structur": [8, 36, 39, 40], "struggl": [36, 41], "stuart": [10, 33], "stuck": [4, 8], "student": [4, 5, 6, 7, 23, 24, 29, 31, 32, 34, 35, 36, 37, 38, 40, 43, 53], "studi": [23, 28, 35, 39, 42], "stuff": [26, 40, 42], "stump": [24, 25, 26, 33, 46], "stupid": 43, "style": [23, 32, 35, 36, 38, 39, 40, 43], "sub": [30, 36, 39, 42, 45], "subdirectori": 34, "subgroup": 42, "subject": [0, 42, 53], "sublicens": 0, "submiss": [3, 53], "submit": [8, 10, 53], "subplot": [25, 26, 29, 31, 36, 40, 42, 47, 50], "subplot_kw": 25, "subprocess": 32, "subscrib": 42, "subscript": [41, 42], "subset": [24, 25, 30, 33, 40, 41, 44, 47], "substanti": 0, "substitut": 0, "subtl": 39, "subtleti": [25, 32], "subtract": [26, 31, 34], "suburb": 43, "subword": 39, "succe": [35, 53], "success": [5, 8, 11, 23, 31, 33, 38, 39, 40, 41], "successfulli": [11, 23, 43], "sudo": 5, "suei": 30, "suffer": 30, "suffici": [7, 39], "suggest": [0, 10, 24, 38, 42], "suicid": 39, "suit": 38, "suitabl": [11, 23, 36, 38, 45, 51, 53], "sultan": 39, "sum": [8, 26, 27, 28, 29, 33, 34, 36, 40, 43], "sum_": [26, 32, 36, 39, 40], "sum_i": [34, 39], "sum_prob_ex1_class_0": 33, "sum_prob_ex1_class_1": 33, "summar": [10, 23, 29, 31, 32, 36, 39], "summari": [0, 44, 45, 47], "summary_plot": 34, "summat": 33, "summer": [1, 38, 41], "summer_month": 41, "sun": [39, 41], "sundai": 41, "sundial": 40, "sunshin": [41, 52], "super": [28, 43, 45], "superfici": 26, "superior": 53, "supermarket": 43, "supervis": [27, 28, 30, 31, 32, 35, 37, 39, 41, 42, 45, 52, 53], "suppli": 53, "support": [11, 15, 24, 27, 31, 33, 34, 35, 37, 39, 43, 44, 47, 53], "support_": [26, 35], "suppos": [23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 45, 46], "suppress": 8, "suprem": 39, "supr\u00eam": 39, "sure": [4, 7, 8, 11, 25, 26, 28, 31, 32, 33, 34, 37, 40, 41, 47, 50, 51, 52, 53], "surgeri": 42, "suri": 53, "surpris": [34, 38], "surprisingli": [28, 29], "surround": [4, 53], "survei": 36, "surviv": [2, 10, 53], "survival_function_": 42, "suscept": 37, "suspect": 30, "svc": [26, 27, 28, 29, 30, 33, 34, 35, 40, 43, 47, 48, 49, 51], "svc__c": [30, 49], "svc__gamma": [30, 49], "svc_pipe": 30, "svc_pred": 31, "svcsvc": [28, 30, 31], "svm": [10, 25, 27, 28, 30, 33, 34, 35, 40, 41, 43, 44, 45, 47, 48, 49, 51], "svm_estim": 31, "svr": [26, 28, 34], "svr_c_pipe": 28, "svr_pipe": 28, "sw": [41, 52], "swai": 23, "swamp": 26, "swan": 40, "swcarpentri": 9, "sweep": 31, "sweet": 43, "switch": [34, 36, 41, 42, 52], "sy": [23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51], "sydnei": 41, "syllabu": [3, 7, 10, 12], "symbol": 24, "symmetri": 35, "sync": 5, "synonym": 39, "synopsi": 39, "syntact": 39, "syntax": [4, 8, 23, 35, 42], "synthet": [35, 44], "system": [2, 4, 5, 6, 10, 11, 23, 25, 26, 28, 31, 34, 36, 41, 50, 53], "systemat": [24, 28, 30, 34, 39], "t": [4, 5, 7, 8, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 51, 52, 53], "ta": [7, 23, 32, 34, 46, 47, 48, 49, 50, 51, 52], "tabbi": [23, 40], "tabl": [7, 51], "tabular": [8, 23, 40, 41], "tackl": [25, 27, 31, 37, 47], "taco": 35, "tag": [4, 39, 43], "tail": [8, 41], "tailor": [36, 53], "take": [2, 4, 5, 6, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53], "taken": [41, 44, 49, 53], "talk": [24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 53], "tall": 39, "target": [25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52], "target_column": [33, 34, 42, 51], "target_nam": 31, "target_names_toi": 31, "tariff": 39, "task": [27, 28, 29, 30, 34, 35, 36, 38, 40, 41, 42, 43, 45, 49, 52, 53], "tast": [36, 38], "taught": [28, 39, 53], "tba": 10, "tbd": [19, 53], "teach": [4, 23, 27, 39, 45], "team": [4, 8, 23, 33, 34, 39, 51], "tech": [26, 31, 34], "technic": 53, "techniqu": [10, 26, 30, 35, 38, 40, 42, 44, 45, 53], "technolog": 0, "technologi": 39, "techsupport": 42, "techsupport_no": 42, "techsupport_y": 42, "ted": 36, "tediou": 37, "telco": 42, "telecom": 42, "telephon": 39, "tell": [25, 26, 27, 29, 31, 34, 35, 38, 39, 41, 42, 47, 49, 52], "temp3pm": [41, 52], "temp9am": [41, 52], "temperatur": 24, "tempo": [26, 27, 30, 49], "tempor": [42, 45, 52], "tend": [25, 26, 29, 33, 35, 38, 41, 42, 53], "tendenc": 25, "tensor": 40, "tensor_numpi": 43, "tensorflow": [11, 34, 40], "tent": 53, "tenur": [42, 45], "tenure_lm": 42, "tenure_predict": 42, "term": [0, 2, 24, 26, 28, 29, 31, 34, 35, 38, 39, 42, 45], "termin": [5, 11, 24, 36], "terminologi": [14, 25, 31, 45, 46], "terrac": 40, "terribl": [32, 38], "territori": 53, "tesoro": 30, "test": [1, 7, 8, 11, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 37, 42, 44, 45, 47, 49, 50, 51, 52, 53], "test_accuraci": 31, "test_average_precis": 31, "test_df": [23, 27, 28, 29, 31, 32, 33, 34, 35, 41, 42, 43, 48, 50, 51, 52], "test_df_churn": 42, "test_df_nan": [31, 33, 34, 50], "test_df_sort": 41, "test_df_surv": 42, "test_exampl": 33, "test_f1": 31, "test_format": 26, "test_g50k": 33, "test_imag": [23, 40], "test_l50k": 33, "test_mape_scor": 32, "test_nam": 42, "test_neg_mean_squared_error": 32, "test_neg_root_mean_square_error": 32, "test_point": [26, 44], "test_precis": 31, "test_r2": 32, "test_recal": 31, "test_roc_auc": 31, "test_sampl": 51, "test_scor": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 47], "test_shap_valu": 34, "test_siz": [23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 43, 44, 47, 48, 49, 50, 51], "test_sklearn": 32, "test_statist": 42, "test_x": 42, "text": [7, 10, 16, 17, 23, 24, 29, 30, 31, 32, 33, 34, 35, 38, 40, 45, 49, 53], "text_feat": [30, 49], "text_featur": 43, "text_pp": 39, "textbook": [3, 9], "textrm": 25, "textual": 53, "textur": 35, "tf": 28, "tfidfvector": 29, "th": [29, 38, 53], "than": [6, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 50, 51, 53], "thank": [23, 39, 47], "thankfulli": [41, 52], "thei": [7, 8, 10, 24, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 51, 52, 53], "theirs": 39, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53], "theme": 39, "themselv": [36, 37, 39], "theoret": [27, 31, 33, 45], "theori": 34, "thepopbreak": 43, "therefor": 47, "thermostat": 24, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 24, 25, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "thick": 36, "thinc": 43, "thing": [5, 7, 8, 10, 24, 25, 26, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 51, 52], "think": [4, 23, 24, 25, 26, 28, 29, 31, 32, 34, 35, 36, 38, 40, 41, 42, 45, 46, 47, 49, 50, 52, 53], "third": 37, "thk": 23, "thorough": [11, 51], "thoroughli": 45, "those": [5, 8, 11, 27, 32, 33, 34, 38, 39, 42, 53], "though": [25, 28, 29, 36, 37, 38, 43], "thought": [4, 26, 34, 42, 45], "thousand": [29, 37, 38], "thrasher": 39, "threahold": 35, "threaten": 43, "three": [8, 24, 27, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 50, 53], "thresh": 8, "threshold": [24, 29, 33, 35, 37, 39, 42], "thresholds_lr": 31, "thresholds_svc": 31, "through": [7, 11, 24, 31, 32, 35, 37, 38, 39, 40, 53], "throughout": 25, "throw": [28, 40, 42, 45], "thu": [6, 30, 41, 42], "thumb": [24, 43], "thursdai": 53, "ti": 28, "tick": 41, "tick_label": 34, "tick_param": 36, "tiffin": 39, "tiger": [23, 40], "tight": [26, 37, 47], "tight_layout": 40, "tightrop": [26, 47], "tile": 34, "till": [26, 39, 42], "timber": 39, "time": [2, 4, 8, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 46, 47, 49, 50, 51, 53], "time_diff": [41, 52], "time_signatur": [26, 27, 30, 49], "timedelta": [41, 52], "timeit": [8, 44], "timeseri": [40, 41], "timeseriessplit": [41, 42, 45, 52], "timestamp": [41, 52], "timezon": [10, 42], "tinder": 38, "tini": [7, 25, 31, 37], "tip": 39, "tire": 43, "titan": 38, "titi": 23, "titl": [7, 25, 26, 29, 32, 35, 37, 40, 41, 42, 47, 52], "tn": 31, "to_datetim": [41, 52], "to_html": [23, 24, 25], "to_notebook_ifram": 32, "to_numpi": [26, 38, 41], "to_str": [23, 40], "toarrai": [28, 34, 41], "tobago": [33, 34], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 38, 40, 41, 42, 45, 51, 52], "todens": [34, 35], "togeth": [5, 8, 24, 26, 27, 28, 36, 39, 47, 53], "toi": [8, 25, 26, 35, 36, 37, 38, 41, 45], "toilet": [40, 43], "token": [7, 43, 53], "token_pattern": 28, "tol": [31, 35], "told": [5, 53], "tolist": [23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 52], "tomasbeuzen": 8, "tomorrow": [24, 41, 42, 45, 52], "ton": 30, "tone": 43, "too": [6, 7, 25, 26, 28, 30, 32, 33, 34, 39, 41, 42, 47, 49, 52, 53], "took": 41, "tool": [7, 8, 10, 11, 28, 29, 31, 32, 34, 37, 38, 40, 41, 42, 45, 53], "toolbox": [26, 33, 39], "toolkit": 39, "top": [24, 28, 30, 31, 37, 41, 52], "topi": 39, "topic": [2, 8, 10, 24, 31, 32, 36, 38, 40, 45, 53], "topic2vec": 39, "topics_per_chunk": 39, "topn": [23, 40], "torch": [40, 43], "torchvis": [23, 40], "tornado": 43, "toronto": [39, 43], "tort": 0, "total": [8, 10, 24, 27, 28, 31, 32, 33, 34, 35, 39, 41, 42, 52], "total_bedroom": [27, 28, 35, 48], "total_bilirubin": 23, "total_protien": 23, "total_room": [27, 28, 35, 48], "total_second": [41, 52], "totalbsmtsf": [32, 34], "totalcharg": 42, "totem": 40, "totensor": 40, "toti": [0, 1, 39], "totrmsabvgrd": [32, 34], "toward": [29, 34, 39, 50, 53], "towardsdatasci": [40, 42], "town": 43, "townsvil": 41, "toy_clust": 39, "toy_clust_df": 36, "toy_df": [28, 39], "toy_lda_data": 39, "toy_movie_feat": 38, "toy_rat": 38, "toy_spam": 28, "toy_x": 39, "tp": 31, "tpot": 30, "tpr": 31, "tpr_lr": 31, "tpr_svc": 31, "tr_score": 47, "traceback": [4, 8, 28, 42, 43], "track": [28, 53], "trade": [29, 31, 35, 36, 45, 53], "tradeoff": [15, 26, 27, 29, 32, 35, 36, 40], "tradit": [23, 38, 40, 42, 53], "tradition": 53, "trail": 8, "train": [7, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "train_accuraci": 31, "train_dataload": 40, "train_df": [23, 27, 28, 29, 31, 32, 33, 34, 35, 41, 42, 43, 48, 50, 51, 52], "train_df_churn": 42, "train_df_nan": [31, 33, 34, 50], "train_df_ord": [41, 52], "train_df_sort": 41, "train_df_surv": 42, "train_df_surv_not_churn": 42, "train_f1": 31, "train_flatten": 40, "train_for_usr": 38, "train_load": 40, "train_mape_scor": 32, "train_mat": 38, "train_mat_imp": 38, "train_neg_mean_squared_error": 32, "train_neg_root_mean_square_error": 32, "train_precis": 31, "train_r2": 32, "train_recal": 31, "train_scor": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 47], "train_shap_valu": 34, "train_sklearn": 32, "train_test_split": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52], "train_x": 38, "traitlet": 43, "transact": [24, 31, 41, 50], "transfer": 42, "transfer_learning_tutori": 40, "transform": [0, 26, 30, 31, 33, 34, 37, 39, 40, 41, 42, 43, 45, 47, 48, 52], "transformed_exampl": 33, "transformed_oh": 27, "transformedtargetregressor": [32, 35, 43, 45], "transformedtargetregressortransformedtargetregressor": 32, "transformerdecod": 43, "transformerencod": 43, "translat": [9, 10, 23], "transpar": [31, 45], "transpos": [35, 40], "trasform": 27, "trash": 46, "traumat": 53, "treat": [8, 25, 27, 28, 31, 32, 38, 41, 42, 45, 50, 52], "treati": 53, "treatment": 28, "tree": [2, 10, 14, 19, 20, 25, 26, 27, 28, 29, 30, 32, 35, 37, 40, 41, 42, 44, 45, 46, 48, 49, 51], "tree1": 33, "tree2": 33, "tree3": 33, "tree_numeric_transform": 34, "treeexplain": 34, "trend": [42, 45, 53], "tri": [33, 34, 44, 49, 50, 51], "trial": [30, 42], "triangl": [26, 36], "trick": [5, 32], "tricki": [28, 30, 34, 38], "trigger": [26, 43], "trigram": 39, "trivial": 37, "troubl": 11, "true": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52], "truli": [32, 39], "truncat": 37, "truncate_mod": 37, "truncation_mod": 37, "trust": [23, 27, 28, 30, 31, 32, 33, 34, 35, 38, 40, 43], "trustworthi": [37, 51], "truth": [33, 35, 36, 37, 38, 41], "try": [4, 5, 8, 10, 11, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53], "tsa": 41, "tscv": 41, "tslearn": 41, "tsunami": 23, "ttr": 32, "ttr_pipe": 32, "tue": 41, "tuesdai": [10, 35, 41, 52, 53], "tuggeranong": 41, "tumor": 45, "tune": [25, 30, 33, 37, 38, 40, 49, 51], "turn": [4, 25, 39, 40, 42, 48, 49, 53], "tusker": 40, "tutori": [4, 5, 9, 10, 11, 38, 40, 45, 53], "tweak": [26, 47], "tweet": [39, 43], "tweetat": 43, "twice": [8, 25, 28, 29], "twist": 39, "twitter": 39, "twitter_allowed_char": 43, "two": [4, 6, 7, 8, 9, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 48, 50, 53], "two_citi": 26, "two_song": 27, "two_songs_subset": 27, "tx": [29, 43], "txt": [23, 40], "typ": [32, 34], "type": [4, 8, 11, 24, 26, 27, 28, 30, 33, 35, 37, 38, 39, 40, 43, 45, 47, 48, 49, 52, 53], "typeerror": 42, "typic": [2, 7, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 38, 41, 49], "u": [4, 11, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 51, 52], "u6": 24, "u_1": 26, "u_2": 26, "u_i": 26, "u_n": 26, "ubc": [0, 4, 5, 8, 9, 10, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53], "ubc_img": 40, "ubc_okanagan": 39, "ubco": 39, "ubyssei": 39, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 32, "ufv": 39, "ultim": [4, 25], "ultralyt": 40, "uluru": [41, 52], "umbrella": 38, "un": [32, 42], "unabl": [23, 27, 28, 30, 31, 32, 33, 34, 35, 37, 40, 42, 43, 53], "unambigu": 39, "unassign": [36, 37], "unbalanc": 50, "unbias": [31, 50], "unced": 53, "uncertain": [29, 51], "uncertain_indic": 51, "uncertainti": [29, 31], "unchang": 34, "uncia": [23, 40], "uncomfort": 38, "uncorrel": 34, "under": [0, 1, 7, 24, 25, 32, 39, 40, 42], "under_sampl": 31, "underestim": 42, "underfit": [26, 29, 30, 40, 47, 49], "underli": [2, 34, 35, 36], "underneath": 7, "underpredict": 32, "undersample_pip": 31, "understand": [0, 1, 4, 7, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 50, 53], "understood": 31, "unemploi": 42, "unexpect": [28, 29, 30, 39], "unexplain": 32, "unf": [32, 34], "unfinish": 32, "unfortun": [6, 30, 34, 36, 37, 49], "uniform": [30, 31, 37, 49], "unimport": [30, 34], "uninstal": 11, "uninterpret": 34, "unintuit": 8, "union": 8, "uniqu": [27, 28, 31, 32, 33, 34, 38, 39, 41, 42, 50, 52], "unit": [29, 31, 32, 33, 34, 39, 40, 42, 43], "unitless": 32, "univers": [1, 9, 39], "university_year": [28, 45], "unix": [5, 41], "unknown": [6, 39, 45], "unlabel": [23, 25, 37], "unless": [7, 53], "unlik": [8, 25, 26, 28, 32, 34, 36, 37], "unlimit": 41, "unlucki": 25, "unmarri": [33, 34], "unnam": 23, "unoffici": 53, "unqualifi": [31, 50], "unreason": [6, 32], "unreli": 25, "unscal": 27, "unseen": [24, 35, 36, 40, 47], "unsqueez": 40, "unstructur": 39, "unsupervis": [23, 38, 39, 40, 53], "unsur": 7, "until": [4, 24, 25, 30, 35, 36, 37, 39, 42], "unus": 47, "unwieldi": [24, 27], "unzip": 34, "uoft": 39, "up": [7, 8, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 49, 53], "uparrow": 37, "upcom": 36, "updat": [10, 11, 26, 27, 28, 33, 36, 47], "update_cent": 36, "update_plot": [26, 47], "update_z": 36, "upei": 39, "upgrad": [39, 43], "upload": 7, "upon": [0, 24, 25, 28, 31, 33, 34, 35, 36, 37, 39], "upper": [31, 42], "uppercas": 43, "upto": 41, "ur": 23, "urgent": [28, 39], "url": [4, 25, 31, 42, 50], "us": [0, 2, 4, 5, 10, 11, 29, 30, 34, 37, 38, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52], "usa": [8, 25, 26, 29, 39], "usag": [27, 28, 31, 32, 35, 39, 41, 42, 52], "usec_": 42, "useless": [30, 34, 35], "user": [11, 23, 24, 25, 27, 28, 30, 33, 34, 36, 37, 39, 40, 42, 43, 44, 45, 49], "user_global_n": 43, "user_id": 38, "user_inverse_mapp": 38, "user_kei": 38, "user_mapp": 38, "user_n": 43, "user_nam": 38, "usernam": 43, "userwarn": [24, 25, 28, 33, 34, 43], "usf": 28, "using_copy_on_writ": 42, "using_cow": 42, "usual": [10, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 52, 53], "utc": [41, 42], "utcnow": 42, "util": [5, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 42, 43, 45, 46, 47, 48, 49, 51], "utilities_allpub": 32, "utilities_nosewa": 32, "utility_mat": 38, "uvic": 39, "v": [3, 7, 10, 28, 29, 37, 39, 41, 42, 45], "v1": [23, 31], "v10": 31, "v11": 31, "v12": 31, "v13": 31, "v14": 31, "v15": 31, "v16": 31, "v17": 31, "v18": 31, "v19": 31, "v2": [23, 31], "v20": 31, "v21": 31, "v22": 31, "v23": 31, "v24": 31, "v25": 31, "v26": 31, "v27": 31, "v28": 31, "v3": 31, "v4": 31, "v5": 31, "v6": 31, "v7": 31, "v8": 31, "v9": 31, "v_1": 26, "v_2": 26, "v_i": 26, "v_n": 26, "vacat": 29, "vaccin": 43, "vada_pav": 39, "vader": 43, "vader_lexicon": 43, "vader_senti": 43, "vain": 30, "val": [38, 42], "valenc": [26, 27, 30, 43, 49], "valid": [10, 15, 24, 26, 28, 32, 33, 34, 35, 36, 38, 40, 42, 43, 45, 48, 49, 50, 51, 52], "valid_dataload": 40, "valid_flatten": 40, "valid_load": 40, "valid_mat": 38, "valid_sample_df": 33, "valid_sample_i": 33, "valid_sample_x": 33, "valid_scor": 47, "valid_x": 38, "valu": [7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52], "valuabl": [35, 37, 53], "value_count": [24, 28, 31, 33, 34, 41, 42, 43, 50, 51, 52], "value_throttl": [26, 47], "valueerror": [8, 27, 28, 42], "values_format": [31, 50], "vancouv": 39, "vancouver_canuck": 39, "vanilla": 29, "var": [25, 27, 34, 43, 49], "var_": 34, "varada": [0, 1], "vari": [24, 30, 33, 37, 42, 47, 53], "variabl": [7, 8, 24, 27, 28, 29, 30, 32, 34, 35, 41, 42, 47, 52], "varianc": [32, 34, 37, 41, 47], "variant": [34, 37], "variat": [25, 29, 31, 32, 35], "varieti": [23, 33, 39], "variou": [23, 26, 32, 34, 40, 41, 42, 45, 47, 49, 53], "vault": 25, "ve": [7, 8, 23, 25, 26, 31, 32, 34, 38, 39, 40, 41, 44, 52], "vec": [28, 39, 40], "vec1": 39, "vec1_i": 39, "vec2": 39, "vec2_i": 39, "vec8": 28, "vec8_binari": 28, "vec_binari": 28, "vecom": 30, "vector": [15, 24, 29, 31, 38, 40, 47, 51], "verb": [39, 43], "verbos": [23, 31, 33, 34], "veri": [2, 4, 5, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 52, 53], "verifi": 50, "versa": [32, 47, 50], "version": [4, 5, 7, 8, 11, 25, 27, 29, 30, 32, 34, 37, 39, 41, 42, 43, 44, 50, 52, 53], "versu": 9, "vert": 34, "vertic": [24, 31, 41], "vgg": 40, "vgg16": 40, "vgg16_weight": 40, "via": [1, 4, 7, 11, 31, 35, 53], "vice": [32, 47, 50], "video": [1, 7, 8, 9, 10, 11, 19, 38, 40, 42, 47, 50, 53], "vietnames": 27, "view": [6, 7, 11, 23, 24, 34, 37, 40, 41, 42], "viewpoint": 38, "vif": 34, "vikski": 39, "violat": [27, 28, 42, 53], "virginia": 40, "viridi": [30, 49], "visibl": 49, "vision": [10, 44], "visit": [8, 53], "visual": [10, 24, 25, 26, 28, 29, 31, 32, 33, 34, 36, 37, 40, 41, 42, 43, 45, 48, 49, 53], "viu": 39, "voc": [31, 33, 34, 50], "vocab": 39, "vocabulari": [28, 29, 39], "vocabulary_": 28, "voic": 23, "volcano": 23, "vote": [26, 27, 33, 44, 51], "voting_ndt": 33, "votingclassifi": [33, 51], "votingclassifierinot": 33, "votingregressor": 33, "w": [11, 28, 29, 32, 36, 39, 41, 52, 53], "w_0": 29, "w_1": 29, "w_1x_1": 29, "w_2x_2": 29, "w_3x_3": 29, "w_4x_4": 29, "w_d": 29, "w_dx_d": 29, "w_j": 29, "wa": [4, 5, 11, 24, 25, 27, 29, 31, 33, 34, 38, 39, 40, 42, 43, 44, 46, 47, 49, 52, 53], "wa_fn": 42, "wai": [0, 2, 6, 8, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 49, 50, 52, 53], "wait": [4, 23, 24, 26, 28, 42, 53], "waitlist": 53, "waiv": 53, "walk": [26, 31, 47], "walker": [23, 40], "wallabi": 40, "want": [4, 6, 7, 8, 11, 23, 24, 25, 26, 27, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 45, 48, 49, 50, 52, 53], "war": 38, "ward": 37, "warm": 27, "warm_start": 31, "warn": [6, 25, 26, 28, 32, 33, 34, 42, 44, 51], "warranti": 0, "washington": 43, "washroom": 53, "wasn": 39, "wast": [4, 28], "watch": [10, 11, 26, 29, 38, 39, 45], "waterfal": 34, "waterfront": [23, 24], "wavelet": 35, "wd": [32, 34], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "weak": 45, "weather": [24, 41], "weatherau": [41, 52], "web": [5, 39, 45], "weblog": 39, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "wed": [10, 41], "wednesdai": [10, 41, 53], "week": [6, 13, 14, 25, 26, 27, 28, 31, 32, 33, 34, 38, 39, 41, 50, 53], "weekdai": 41, "weekend": [8, 41], "weekli": 43, "weight": [26, 33, 35, 38, 39, 40, 50, 53], "weighted_averag": 31, "weinberg": 34, "weird": 32, "welcom": [46, 53], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 45, 49, 52, 53], "welsh": [23, 40], "went": [32, 43, 49, 51], "were": [0, 6, 28, 29, 31, 32, 39, 40, 41, 42, 49, 51, 53], "weren": 39, "what": [7, 8, 9, 24, 26, 30, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "whatev": 35, "when": [4, 6, 7, 11, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 50, 51, 52, 53], "wher": 43, "where": [0, 7, 10, 11, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 45, 47, 50, 52], "wherea": [2, 24, 29, 30, 32, 34, 37], "whether": [0, 4, 7, 8, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 46, 51, 52, 53], "which": [4, 6, 8, 11, 25, 26, 27, 28, 29, 30, 32, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53], "whichev": 33, "while": [24, 25, 29, 30, 31, 33, 34, 36, 38, 39, 42, 43, 49], "white": [31, 33, 34, 37, 39], "whitespac": [39, 42], "who": [4, 5, 6, 23, 31, 34, 36, 37, 39, 41, 42, 43, 45, 53], "whole": [25, 30, 32, 34, 38, 49], "whom": [0, 39, 43], "whose": 4, "why": [8, 25, 26, 31, 32, 33, 36, 37, 39, 41, 42, 45, 46, 47, 48, 49], "wid": 31, "wide": [11, 29, 30, 33, 35, 38, 40], "wider": [26, 47], "widespread": 39, "widget": [26, 31, 36, 37, 47], "width": [24, 25, 26, 31, 39, 46, 47], "wife": [23, 31, 33, 34], "wiki": 39, "wiki_df": 39, "wiki_dict": 39, "wikipedia": [39, 40], "wikipedia2vec": 39, "wild": [23, 25, 40], "willing": 31, "win": [26, 28, 33, 34, 35, 38, 44], "wind": 24, "winddir3pm": [41, 52], "winddir3pm_miss": [41, 52], "winddir3pm_ss": [41, 52], "winddir3pm_ssw": [41, 52], "winddir3pm_sw": [41, 52], "winddir3pm_w": [41, 52], "winddir3pm_wnw": [41, 52], "winddir3pm_wsw": [41, 52], "winddir9am": [41, 52], "windgustdir": [41, 52], "windgustspe": [41, 52], "window": [10, 42], "windsor": 43, "windspeed3pm": [41, 52], "windspeed9am": [41, 52], "wine_1": 8, "winter": 41, "winter_month": 41, "wire": 38, "wisdom": 33, "wish": [23, 24, 36, 53], "within": [24, 27, 29, 33, 35, 36, 37, 42, 45, 49], "without": [0, 7, 23, 24, 31, 33, 34, 35, 38, 40, 41, 42, 49, 53], "wnw": [41, 52], "wolv": 37, "woman": 39, "wombat": 40, "won": [5, 11, 24, 25, 26, 28, 29, 35, 38, 39, 40, 41, 42, 43], "wonder": [23, 25], "wooddecksf": [32, 34], "word": [23, 29, 30, 31, 35, 36, 37, 38, 40, 41, 42, 45, 49, 53], "word1": 39, "word2": 39, "word2vec": [39, 40, 53], "word3": 39, "word_pair": 39, "word_token": [39, 43], "wordnet": 39, "wordnetlemmat": 39, "work": [0, 4, 5, 7, 8, 11, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 49, 51, 52, 53], "work_of_art": 43, "workclass": [31, 33, 34, 50], "workclass_feder": [33, 34], "workclass_loc": [33, 34], "workclass_miss": 34, "workclass_nev": [33, 34], "workclass_priv": [33, 34], "workclass_self": 34, "workclass_st": 34, "workclass_without": 34, "workflow": [24, 53], "world": [26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 45], "worm": 40, "worri": [23, 36, 37, 38, 51], "wors": [24, 30, 32, 33, 42, 46, 49, 50], "worst": [31, 35, 36], "worth": [24, 26, 31, 32, 50], "worthi": 29, "would": [4, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53], "wouldn": [28, 30, 39, 42], "wow": 34, "wrap": 28, "wrapper": 35, "write": [4, 7, 23, 30, 34, 35, 36, 39, 43, 47, 51, 53], "written": [7, 28, 34, 41, 52], "wrong": [11, 25, 29, 32, 35, 36, 42, 49], "wrote": [39, 41, 52], "wsw": [41, 52], "www": [9, 29], "x": [4, 8, 11, 25, 26, 27, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50], "x0": 35, "x0_male": 31, "x1": [35, 38], "x139": 53, "x1x2": 35, "x2": [35, 37, 38], "x27": [27, 28, 30, 31, 32, 33, 35, 40, 43], "x_": 29, "x_1": [29, 35, 36], "x_1x_2": 35, "x_2": [29, 35, 36], "x_binari": 24, "x_citi": 26, "x_count": 28, "x_d": 29, "x_femal": [31, 50], "x_hour": 41, "x_hour_week": 41, "x_hour_week_onehot": 41, "x_hour_week_onehot_poli": 41, "x_hour_week_onehot_poly_lag": 41, "x_i": [29, 38], "x_imp_ohe_train": 27, "x_init": 36, "x_int": 28, "x_label": [24, 25, 26, 46], "x_lag_featur": 41, "x_lag_features_imp": 41, "x_male": [31, 50], "x_mask": 28, "x_multi": 44, "x_n": 35, "x_orig": 37, "x_re": 31, "x_small_citi": 26, "x_spotifi": [26, 30, 49], "x_subset": [24, 25], "x_test": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51], "x_test_big": 30, "x_test_enc": [34, 41, 42, 52], "x_test_happi": 31, "x_test_imp": 27, "x_test_multi": 44, "x_test_pr": 41, "x_test_predict": 27, "x_test_scal": 27, "x_test_transform": 27, "x_toi": [26, 27, 28, 41], "x_toy_oh": 27, "x_toy_ord": [27, 28], "x_tr": 47, "x_train": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51], "x_train_big": [31, 50], "x_train_enc": [31, 32, 34, 41, 42, 50, 52], "x_train_happi": 31, "x_train_hous": 35, "x_train_imp": 27, "x_train_imp_sc": 27, "x_train_multi": 44, "x_train_oversampl": 31, "x_train_perm": 34, "x_train_pp": 28, "x_train_predict": 27, "x_train_scal": [27, 35], "x_train_subsampl": 31, "x_train_tini": 30, "x_train_transform": 27, "x_train_usr": 38, "x_transform": 28, "x_valid": [31, 38, 47, 50], "x_vari": 37, "x_xor": 35, "xanni": 30, "xavier": [35, 38], "xcode": 5, "xgbclassifi": [33, 34], "xgbclassifierxgbclassifi": 33, "xgboost": 34, "xgbregressor": [23, 33], "xia": 53, "xlabel": [8, 24, 25, 26, 29, 30, 31, 32, 34, 37, 40, 41, 42, 44, 46, 49, 52], "xlim": 42, "xor": [29, 35], "xt": 28, "xtick": [25, 31, 41, 52], "xticklabel": [30, 49], "xticks_rot": 31, "xwm\u0259\u03b8kw\u0259y": 53, "xx": [35, 36], "y": [8, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 52], "y_": 38, "y_citi": 26, "y_femal": [31, 50], "y_hat": [29, 33], "y_i": [32, 33, 35, 38], "y_init": 36, "y_label": [24, 25, 26, 46], "y_male": [31, 50], "y_mat": 38, "y_multi": 44, "y_pred": [31, 41], "y_pred_lower_threshold": 31, "y_pred_toi": 31, "y_pred_train": 41, "y_re": 31, "y_small_citi": 26, "y_spotifi": [30, 49], "y_test": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52], "y_test_big": 30, "y_test_happi": 31, "y_test_multi": 44, "y_test_num": [33, 34], "y_toi": [26, 41], "y_tr": 47, "y_train": [23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52], "y_train_big": [31, 50], "y_train_happi": 31, "y_train_hous": 35, "y_train_multi": 44, "y_train_num": [33, 34], "y_train_ord": [41, 52], "y_train_oversampl": 31, "y_train_subsampl": 31, "y_train_tini": 30, "y_train_usr": 38, "y_true_toi": 31, "y_valid": [31, 38, 40, 47, 50], "y_vari": 37, "y_xor": 35, "yale": 39, "yann": 34, "ycxmx": 42, "ye": [4, 23, 24, 27, 28, 34, 36, 37, 38, 40, 41, 43, 45, 52], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 38, 39, 40, 41, 42], "yearbuilt": [32, 34], "yearremodadd": [32, 34], "yellow": 30, "yellowbrick": [36, 37], "yesterdai": [41, 52], "yet": [10, 11, 29, 34, 38, 41, 42, 47, 53], "yield": 49, "yifei": 53, "yjh": [23, 24, 28, 29, 32, 33], "ylabel": [8, 24, 25, 26, 29, 30, 31, 32, 37, 40, 41, 42, 44, 46, 47, 49, 52], "ylim": 42, "yml": 11, "yolo": 40, "yolo8": 40, "yolo_input": 40, "yolo_result": 40, "yolo_test": 40, "yolov8n": 40, "york": [41, 43], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 34, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "your": [0, 2, 4, 6, 7, 8, 10, 11, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "your_miniconda_path": 43, "your_nam": 11, "yourself": [4, 28, 31, 38, 39, 53], "yourselv": 39, "youtub": [1, 10, 38, 39, 53], "yr_built": [23, 24], "yr_renov": [23, 24], "yrpxn": 42, "yrsold": [32, 34], "ytick": [25, 31], "yticklabel": [30, 49], "yy": [35, 41, 52], "yyyi": [41, 52], "z": [8, 29, 35, 36, 37, 38, 40, 42], "z_i": 40, "z_j": 40, "z_km": 36, "z_train": 40, "z_valid": 40, "zachari": 42, "zarei": 53, "zero": [8, 25, 28, 30, 38, 39], "zero_divis": 31, "zhu": 53, "zip": [26, 29, 38, 47], "zipcod": [23, 24, 47], "zmqshell": 43, "zone": [41, 52], "zoom": [7, 49, 53], "\u0259m": 53, "\u03bc": 44}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Class Meeting 4B", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [23, 25, 26, 27, 28, 31, 32, 34, 41], "0": 33, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 42, 45, 46, 47, 48, 49, 50, 51, 52], "10": [18, 32, 51], "11": [20, 33], "12": [21, 33, 34], "13": [22, 35], "14": [35, 36], "15": [36, 37], "16": [37, 38], "17": [38, 39], "18": 40, "19": [40, 41], "1a": 13, "1b": 14, "1c": 15, "2": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 42, 45, 46, 47, 48, 49, 50, 51, 52], "20": 42, "2025s1": 1, "21": 42, "2a": 16, "2b": 17, "3": [15, 23, 24, 25, 27, 35, 36, 37, 42, 46, 47, 48, 49, 50, 51, 52], "330": [1, 2, 3, 6, 8], "340": 2, "3a": 18, "3b": 19, "3c": 20, "4": [15, 24, 25, 26, 46, 47, 48, 49, 50, 51, 52], "4a": 21, "4b": 22, "5": [8, 16, 24, 25, 26, 27, 28, 31, 34, 35, 36, 39, 40, 42, 47, 48, 49, 50, 51, 52], "6": [16, 28, 47, 49, 50, 51, 52], "7": [17, 29, 49, 51, 52], "8": [17, 30, 49, 51], "9": [18, 31, 51], "A": [4, 31, 37, 41, 43], "No": 8, "Not": 45, "One": [27, 41, 44], "The": [25, 29, 30, 33, 35, 36, 51], "__": 30, "about": [8, 35, 38], "academ": 53, "access": [7, 29, 53], "accommod": 53, "acknowledg": 53, "activ": [31, 34, 35, 36, 39, 50], "actual": 28, "ad": 8, "addit": [7, 34], "address": 31, "advantag": 30, "advic": 35, "ai": 53, "algorithm": [24, 26, 35, 36], "all": [23, 24, 27, 29, 31, 36, 37, 38], "alpha": [29, 32], "altern": [24, 27], "an": [33, 43], "analogi": 26, "analysi": [41, 42, 45, 47, 52], "announc": [24, 26, 28, 29, 33], "answer": 42, "ap": 31, "api": 27, "appendix": [43, 44], "appli": [1, 8, 27, 28, 32], "applic": 36, "applymap": 8, "approach": [38, 41, 42, 44], "approxim": 25, "ar": [5, 23, 24, 27, 29, 31, 36, 37, 38], "area": 31, "argument": [25, 26], "arrai": 8, "articl": 9, "ask": 4, "assign": [7, 53], "associ": 29, "assum": 42, "attent": [24, 26], "attribut": 34, "auc": 31, "autom": 30, "averag": [31, 33, 38, 51], "avoid": 25, "b": [36, 44], "backward": 35, "bad": 30, "bag": [28, 43], "balanc": 31, "base": [26, 33, 35, 38, 41, 52], "baselin": [24, 27, 31, 33, 34, 38, 47], "basic": 39, "befor": 27, "best": 35, "better": [25, 30, 31, 35], "between": [24, 26, 46], "beyond": [34, 38], "bia": [25, 30], "big": [24, 25, 27], "binari": 31, "book": 10, "boost": 33, "bootstrap": 33, "boundari": [24, 26, 29, 46], "bow": 28, "box": 40, "break": [8, 24, 25, 26, 27, 28, 35, 39, 40, 42], "broadcast": 8, "build": [23, 24, 32, 38], "c": [26, 30], "calcul": 29, "california": [28, 29, 48], "can": [8, 25, 27, 33, 34, 35, 36], "canada": [24, 46], "care": 38, "carri": [27, 35], "case": [28, 29, 37], "catboost": 33, "categor": [27, 28, 34, 41], "categori": 28, "censor": 42, "centr": 53, "certain": 28, "cfa": 53, "chang": 31, "charact": 23, "characterist": 31, "cheatsheet": 8, "choos": [26, 36], "churn": 42, "cite": 7, "citi": 29, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 30, 31, 32, 33, 34, 38, 40, 44, 53], "class_attend": 28, "class_weight": 31, "classif": [24, 31, 40, 45], "classifi": [24, 29, 33, 43], "clearli": 35, "cluster": [36, 37, 45], "co": 53, "code": [11, 53], "coeffici": [29, 34], "color": [46, 47, 48, 49, 50, 51, 52], "column": [8, 27, 28, 41], "columntransform": [28, 48], "combin": 33, "come": [25, 26], "command": 5, "comment": [24, 30, 31, 32, 36, 37, 38], "common": [27, 36], "commonli": 39, "commun": 45, "compact": 27, "companion": 9, "complet": 38, "complex": 25, "complic": [41, 52], "compon": 29, "comprehens": 48, "comput": [40, 45], "con": [26, 37, 45], "concern": 6, "concess": 53, "conda": 11, "conduct": 53, "confid": 29, "confus": 31, "consid": 42, "construct": 33, "content": 38, "context": 39, "continu": 24, "conveni": 28, "correct": 36, "correl": 34, "countri": [24, 46], "countvector": 28, "cours": [9, 10, 23, 53], "cover": [38, 42], "cox": 42, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 24, 25, 28, 38], "credit": [11, 53], "cross": [25, 27, 31, 35, 41, 47], "cross_val_scor": 25, "cross_valid": [25, 32], "csv": 8, "curs": 26, "curv": [31, 42], "custom": [36, 42], "cv": 30, "dai": 41, "data": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 47, 52], "datafram": [8, 28], "dataset": [7, 24, 27, 28, 29, 30, 31, 32, 40, 41, 48, 51, 52], "date": [10, 41], "datetim": [41, 52], "dbscan": 37, "deal": [28, 31], "debug": 11, "decis": [24, 26, 29, 34, 47], "decisiontreeclassifi": [24, 33], "decreas": 31, "deep": [40, 41], "defin": 35, "definit": 23, "deliver": 10, "demo": [35, 41, 43], "demonstr": 31, "dendrogram": 37, "depend": 35, "deploy": [25, 45], "descript": 53, "desktop": 5, "detail": [31, 32, 37], "detect": 40, "df": 8, "did": [25, 27, 28, 31, 32, 38, 42], "differ": [27, 30, 31, 32, 34, 45], "dimens": 26, "dimension": 26, "discuss": [30, 31, 38, 39, 50], "diseas": 23, "distanc": [26, 36], "distribut": 30, "do": [27, 28, 30, 31, 33, 34, 35], "document": [3, 8, 36], "doe": [24, 29, 37], "domain": 35, "drop": 8, "due": 10, "dummi": 43, "dummyclassifi": [24, 33, 41, 42], "dummyregressor": [24, 27, 32], "eda": [27, 31, 32, 47], "effect": 33, "elbow": 36, "element": 8, "elimin": 35, "embed": 39, "encod": [27, 28, 35, 41], "engin": [35, 41, 43, 45], "ensembl": [33, 45], "environ": 11, "error": [25, 30, 31, 32, 38], "estim": [27, 33], "ethic": 45, "euclidean": 26, "eva": [23, 25], "evalu": [31, 37, 38, 42, 45, 50], "evalut": 31, "event": 42, "everyon": 42, "exactli": 29, "exam": [45, 53], "examin": [28, 32, 45], "exampl": [23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 39, 42, 43], "exercis": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 40, 42, 46], "exhaust": 30, "explain": 34, "explan": 34, "explor": [26, 36], "exploratori": [41, 47, 52], "extract": [28, 41], "extractor": 40, "f1": 31, "failur": 37, "fair": [31, 50], "fancier": 30, "faster": 8, "fastest": 8, "featur": [23, 24, 26, 27, 28, 29, 32, 34, 35, 38, 40, 41, 43, 45, 52], "feature_importances_": 34, "few": [31, 37], "fictiti": 23, "figur": 7, "filter": [8, 38], "final": [24, 30, 36, 37, 38, 41, 45, 47, 53], "find": [26, 35], "first": 27, "fit": [24, 27, 33], "flatten": 40, "follow": [23, 24, 25, 36, 37, 38], "font": [46, 47, 48, 49, 50, 51, 52], "forecast": 41, "forest": [33, 34], "format": [7, 8], "formul": 38, "forum": 4, "forward": 35, "from": [8, 43], "function": [8, 29, 32], "fundament": [25, 26, 33, 45], "further": [41, 43], "futur": 41, "gamma": 26, "garbag": 35, "gener": [4, 6, 25, 26, 29, 33, 35], "geometr": 26, "get": 34, "git": [5, 11], "github": 5, "given": [23, 24], "global": 38, "goal": 25, "golden": [25, 27, 28], "good": 31, "grade": [4, 6, 24, 53], "gradescop": 7, "gradient": 33, "grid": 30, "gridsearchcv": [30, 32], "group": [31, 36, 50], "guid": 45, "guidelin": [4, 6, 7], "ha": 23, "halv": 30, "handl": 31, "have": [33, 34], "hazard": 42, "heatmap": 30, "help": [4, 35], "here": 25, "hierarch": 37, "home": 37, "homework": 7, "hot": [27, 35, 41], "hous": [23, 24, 27, 28, 29, 48], "how": [4, 7, 24, 25, 26, 27, 29, 33, 34, 35, 37], "hyper": 30, "hyperparamet": [24, 26, 28, 29, 30, 32, 33, 36, 45, 47], "i": [23, 25, 27, 28, 30, 31, 33, 34, 35, 36, 38, 39, 43], "iclick": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 42, 53], "idea": [26, 31, 33, 35], "identifi": [28, 34], "imag": [23, 40], "imagenet": 40, "imbal": [31, 32, 33, 34], "import": [1, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 52], "improv": 43, "imput": [27, 38], "incorpor": 28, "increas": 31, "index": 8, "inertia": 36, "info": 7, "inform": [34, 41], "initi": 36, "inject": 33, "input": [23, 36], "instal": [5, 11], "instruct": [0, 7], "interact": 35, "intercept": 29, "interim": [31, 34, 35, 41], "interpret": [29, 34], "intra": 36, "intro": 38, "introduct": [8, 23, 34, 35, 36, 37, 39, 40, 45], "intuit": 29, "involv": 41, "jupyterlab": 11, "k": [26, 27, 36, 37, 38], "kaplan": 42, "kei": 34, "kernel": 26, "kind": 33, "kneighborsclassifi": 26, "label": [23, 36], "lag": [41, 52], "land": 53, "languag": 39, "larg": 30, "late": 7, "latitud": [24, 46], "lda": 39, "learn": [1, 5, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 53], "least": 29, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 53], "lecture03": 15, "let": [26, 27, 28, 31, 32, 34], "licens": [0, 1], "lightgbm": 33, "limit": [6, 29, 37], "line": 5, "linear": [29, 32, 34], "link": 1, "list": 9, "liver": 23, "ll": 25, "lo": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 41], "logist": [29, 31, 40], "logisticregress": [31, 41, 42], "longitud": [24, 46], "look": [31, 36], "loop": 8, "lower": 30, "mac": 5, "machin": [1, 23, 24, 25, 26, 31, 36], "maco": 11, "macro": 31, "magnitud": 29, "mai": 35, "main": [29, 38], "make": [8, 29], "make_column_transform": 28, "make_pipelin": 27, "mani": [28, 30], "manual": 30, "mape": 32, "materi": [0, 9, 10], "matplotlib": 8, "matric": 28, "matrix": [31, 38], "max_depth": 24, "mean": [32, 36, 37, 39], "measur": 35, "media": 39, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 53], "meier": 42, "messag": [23, 37], "meta": 44, "method": [8, 30, 35, 36], "metric": [31, 32, 45], "midterm": [36, 53], "might": 42, "min": [8, 24, 25, 26, 27, 28, 31, 34, 35, 36, 39, 40, 42], "minor": 31, "misc": [9, 10], "miscellan": 38, "ml": [23, 25, 26, 31, 34, 45, 50], "model": [23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 39, 40, 42, 43, 45, 47, 50], "model_select": 30, "month": 41, "more": [24, 26, 27, 28, 29, 31, 32, 35, 37, 41, 52], "most": 29, "motiv": [25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41], "movi": 38, "mse": 32, "much": 30, "multi": [31, 40, 44], "multiclass": 45, "multipl": [26, 28, 32], "multipli": 8, "n_estim": 33, "n_iter": 30, "n_job": 30, "n_neighbor": 26, "name": [25, 32, 38], "natur": 39, "nearest": [26, 27, 36, 38], "need": [27, 30], "neg": 31, "neighbour": [26, 27, 38], "nest": 8, "netflix": 33, "network": 40, "neural": 40, "nlp": [39, 45], "nn": 26, "non": [26, 28, 34], "notat": 8, "note": [8, 25, 41, 47], "now": 42, "number": [33, 36, 41], "numer": [34, 35], "numpi": 8, "object": [24, 33, 39, 40, 41, 42, 53], "observ": 31, "occasion": 27, "off": [25, 26, 33], "oh": [27, 28], "ok": [27, 28], "onc": 31, "one": [28, 35], "onehotencod": 28, "onli": [28, 42], "onlin": [9, 10], "oper": 31, "optim": [30, 45], "option": [11, 26, 27, 30, 31, 33, 35, 42], "ordin": [27, 28, 34, 53], "other": [8, 26, 32, 35, 36, 39, 41, 42], "our": [7, 25, 27, 43], "out": [27, 35, 40], "outcom": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38], "outlin": [46, 47, 48, 49, 50, 51, 52], "output": 36, "over": [8, 26, 29, 31], "overfit": [25, 30], "oversampl": 31, "overview": [26, 31], "ovo": 44, "ovr": 44, "packag": [11, 41], "panda": 8, "pandas_profil": 32, "paper": [31, 33], "paradigm": 27, "paramet": [24, 29, 30, 31, 45], "parametr": 26, "pars": [41, 52], "part": 45, "pass": [30, 53], "patient": 23, "perfect": 36, "permutation_import": 34, "persona": 23, "pick": [25, 30], "pictur": [24, 25, 27], "pipelin": [27, 39], "plan": 37, "playground": [26, 47], "plot": [8, 34, 36, 42], "point": [26, 31, 34, 36, 41], "polici": 6, "poll": 36, "popular": 23, "posit": 31, "posix": 41, "possibl": [28, 32, 36, 43], "post": 9, "pr": 31, "practic": [24, 26], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 22, 40], "precis": 31, "predict": [23, 24, 28, 29, 33, 34, 38, 40, 42, 44, 46], "predict_proba": 29, "prepar": [7, 45], "preprocess": [27, 28, 32, 39, 41, 45, 50, 52], "preval": 23, "price": [23, 24], "prize": 33, "pro": [26, 37, 45], "probabl": [29, 30], "problem": [24, 25, 26, 27, 30, 35, 38, 41, 43], "procedur": 31, "process": 39, "product": 23, "profil": 38, "program": 24, "project": 43, "proport": 42, "python": [8, 9, 11], "q": 4, "qualiti": 35, "queri": [8, 26], "question": [4, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52], "quick": 26, "quiz": 24, "quiz2": 24, "quot": 35, "r": 32, "random": [30, 33, 34], "random_st": 25, "randomforestclassifi": [33, 42], "randomizedsearchcv": [30, 32], "rang": 30, "rate": 38, "raw": 29, "rbf": 26, "read": [8, 24, 30, 40], "real": [24, 46], "realist": 28, "reason": 6, "recal": 31, "recap": [24, 26, 37, 42, 46, 48], "receiv": 31, "recommend": [27, 38, 45], "record": 53, "recurs": 35, "red": [46, 47, 48, 49, 50, 51, 52], "refer": [9, 10, 42], "reflect": [24, 25, 36, 37], "registr": 53, "regress": [24, 26, 29, 31, 32, 33, 40], "regressor": 26, "relat": [4, 24, 26], "relev": [9, 31, 33, 35], "remark": 41, "rememb": 36, "remind": [24, 38], "remov": 8, "renam": 8, "report": [7, 31], "repositori": 7, "represent": [28, 40], "requir": 53, "rescu": 25, "resourc": [9, 30, 31, 35, 36, 37, 38], "rest": 44, "result": 30, "retail": 41, "review": 19, "rfe": 35, "ridg": [29, 32], "ridgecv": 32, "right": 42, "rmse": 32, "roc": 31, "root": 32, "row": 8, "rule": [25, 27, 28], "run": 27, "same": 8, "sampl": [31, 33, 36], "sauc": 36, "save": 23, "scale": [23, 27, 29, 34], "schedul": [10, 53], "scheme": 53, "scikit": [25, 27, 28, 32], "score": [24, 25, 29, 30, 31, 32, 35, 36, 43], "search": [26, 30, 35], "season": 41, "segment": 36, "select": [23, 24, 35, 36, 37, 38, 45], "separ": [32, 34], "seri": [8, 41, 45, 52], "set": [5, 11, 25, 30, 31], "set_config": 28, "shap": 34, "shape": [8, 37], "shaplei": 34, "short": 9, "should": [33, 38], "show": 34, "sigmoid": [29, 40], "sign": 29, "silhouett": 36, "similar": 26, "simpl": [25, 43], "simplefeatur": 34, "simul": 51, "singl": 25, "size": 8, "sklearn": [24, 27, 28, 30, 31, 33, 34], "slide": [13, 14, 15, 16, 17, 18, 20, 21, 22], "slowest": 8, "smote": 31, "social": 39, "softmax": 40, "softwar": [0, 40, 41], "solv": 30, "some": [24, 30, 31, 33, 35], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 41, "spaci": [39, 43], "spaghetti": 36, "spam": [23, 28], "spars": 28, "specif": [4, 35], "split": [25, 27, 31, 41, 47], "spotifi": [27, 30], "squar": 32, "stack": [33, 51], "standardscal": 27, "statement": [23, 24, 36, 37, 38], "step": [24, 39, 48], "strategi": [33, 44], "stratifi": 31, "strength": [29, 33], "studi": 45, "submiss": 7, "submit": 7, "success": 30, "summari": [8, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "summer": 10, "supervis": [23, 24, 25, 26, 36, 38], "support": 26, "surviv": [42, 45], "svc": 31, "svm": [26, 29], "syllabu": [1, 53], "syntax": [27, 28, 30], "synthet": 31, "system": [38, 45], "ta": 53, "tabular": [24, 26], "tackl": 32, "take": 37, "target": [23, 24, 28, 32, 36], "task": 39, "teach": [10, 53], "team": 53, "techniqu": [27, 31], "templat": 7, "tempor": 41, "ten": 10, "tent": 10, "terminologi": [24, 40], "test": [5, 25, 30, 41], "test_df": 25, "test_siz": 25, "text": [28, 39, 43], "than": [28, 30, 35], "thei": 33, "them": 8, "thi": [8, 23, 27, 28, 34], "thing": 27, "threshold": 31, "time": [6, 23, 41, 42, 45, 52], "tip": 45, "todai": [25, 27, 28, 31, 32], "toi": [24, 28, 31, 39], "token": 39, "tool": 39, "topic": 39, "trade": [25, 26, 33], "tradeoff": [25, 31, 33], "tradit": [24, 41], "train": [23, 24, 25, 28, 29, 31, 40, 41, 50], "train_df": 25, "train_siz": 25, "transfer": 40, "transform": [27, 28, 32, 35], "transpar": 34, "tree": [24, 33, 34, 47], "trend": 41, "true": [23, 36, 37, 38], "try": [27, 32], "tune": [32, 36, 47], "tutori": [46, 47, 48, 49, 50, 51, 52], "two": 28, "type": [23, 25, 31, 32, 34, 36, 41, 42], "typic": [25, 39], "ubc": 1, "ubuntu": 5, "under": 31, "underfit": 25, "undersampl": 31, "unequ": 41, "unknown": 28, "unlabel": 36, "unseen": [23, 25], "unsupervis": [24, 36], "up": [5, 11, 25, 26], "updat": 7, "url": 8, "us": [7, 8, 23, 24, 25, 26, 27, 28, 31, 32, 33, 35, 36, 39, 40, 44, 46, 53], "usa": [24, 46], "user": [5, 38], "usual": 35, "util": 38, "v": [2, 24, 25, 26, 31, 34, 36, 40, 44], "valid": [25, 27, 30, 31, 41, 47], "varianc": 25, "vector": [8, 26, 39], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 36, 37, 39], "view": [26, 28], "violat": 25, "virtual": 11, "vision": [40, 45], "visual": [9, 30], "wai": [30, 35], "want": [28, 34, 42], "warn": [24, 35], "we": [8, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42], "weak": 33, "weight": [29, 31], "what": [5, 11, 23, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 42], "when": [8, 27, 30], "where": [28, 42], "whether": 23, "which": [23, 24, 31, 33, 36, 37, 38], "why": [11, 23, 28, 30, 34, 35, 38, 40], "window": [5, 11], "wise": 8, "without": 36, "word": [28, 39, 43], "work": [24, 33, 37], "workflow": [23, 25, 31], "would": 25, "wrapper": 44, "write": 24, "x": [23, 24, 32, 34], "xgboost": 33, "y": [23, 24, 32, 34], "ye": 42, "yield": 30, "you": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42], "your": [5, 24]}})