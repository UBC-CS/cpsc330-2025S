Search.setIndex({"alltitles": {"(Optional) Changing the data": [[35, "optional-changing-the-data"]], "(Optional) Evaluation": [[46, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[35, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[34, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[34, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[34, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[37, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[39, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[35, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[30, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[34, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[37, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[39, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[39, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[34, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Some more details": [[35, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[27, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[39, "id1"]], "(iClicker) Exercise 21.1": [[46, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[46, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[30, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[30, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[31, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[31, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[31, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[32, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[32, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[33, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[33, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[34, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[40, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[40, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[40, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[40, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[41, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[41, "id2"]], "16.3 Select all of the following statements which are True": [[41, "select-all-of-the-following-statements-which-are-true"]], "<font color='red'>Question 10</font>": [[55, "question-10"]], "<font color='red'>Question 1</font>": [[50, "question-1"], [51, "question-1"], [53, "question-1"], [54, "question-1"], [55, "question-1"], [56, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[51, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[50, "question-2"], [53, "question-2"], [54, "question-2"], [55, "question-2"], [56, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[51, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[50, "question-3"], [53, "question-3"], [54, "question-3"], [55, "question-3"], [56, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[51, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[50, "question-4"], [53, "question-4"], [54, "question-4"], [55, "question-4"], [56, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[51, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[53, "question-5"], [54, "question-5"], [55, "question-5"], [56, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[51, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[53, "question-6"], [54, "question-6"], [55, "question-6"], [56, "question-6"]], "<font color='red'>Question 7</font>": [[53, "question-7"], [55, "question-7"]], "<font color='red'>Question 8</font>": [[53, "question-8"], [55, "question-8"]], "<font color='red'>Question 9</font>": [[55, "question-9"]], "<font color='red'>Recap Questions</font>": [[50, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[52, "recap-comprehension-questions"]], "A few comments on PR curve": [[35, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[41, "a-few-comments-on-clustering-evaluation"]], "AP score": [[35, "ap-score"]], "AP vs. F1-score": [[35, "ap-vs-f1-score"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[57, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[33, "accessing-learned-parameters"]], "Activity (~5 mins)": [[38, "activity-5-mins"], [38, "id3"]], "Activity: Context and word meaning": [[43, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[39, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[35, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[34, "advantages-of-randomizedsearchcv"], [34, "id1"]], "Alternative and more compact syntax: make_pipeline": [[31, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[28, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[37, "an-effective-strategy"]], "An example from a project": [[47, "an-example-from-a-project"]], "An example of a bootstrap samples": [[37, "an-example-of-a-bootstrap-samples"]], "Analogy-based algorithms in practice": [[30, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[30, "analogy-based-models"]], "Announcements": [[33, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[47, null]], "Appendix B: Multi-class, meta-strategies": [[48, null]], "Applying feature transformations": [[36, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[46, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[46, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[46, "approach-3-survival-analysis"]], "Are we doing better with class_weight=\"balanced\"?": [[35, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[35, "area-under-the-curve-auc"]], "Assignments": [[57, "assignments"]], "Attention": [[28, null], [28, null], [28, null], [30, null]], "Automated hyperparameter optimization": [[34, "automated-hyperparameter-optimization"], [34, "id3"]], "Averaging": [[37, "averaging"]], "Averaging simulation": [[55, "averaging-simulation"]], "Bad range for hyperparameters": [[34, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[32, "bag-of-words-bow-representation"]], "Bag-of-words model": [[47, "bag-of-words-model"]], "Baseline": [[35, "baseline"], [38, "baseline"]], "Baseline Approaches": [[42, "baseline-approaches"]], "Baselines": [[28, "baselines"], [37, "baselines"]], "Baselines [video]": [[28, "baselines-video"]], "Basic text preprocessing [video]": [[43, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[39, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[42, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[29, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[28, "big-picture-and-datasets"]], "Big picture and motivation": [[29, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Break (5 min)": [[8, "break-5-min"], [28, "break-5-min"], [29, "break-5-min"], [30, "break-5-min"], [31, "break-5-min"], [32, "break-5-min"], [39, "break-5-min"], [43, "break-5-min"], [44, "break-5-min"], [46, "break-5-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a supervise machine learning model": [[27, "building-a-supervise-machine-learning-model"]], "Building decision trees with sklearn": [[28, "building-decision-trees-with-sklearn"]], "Building user profiles": [[42, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[40, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[31, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[32, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[37, "catboost"]], "Categorical features": [[38, "categorical-features"]], "Categorical features [video]": [[31, "categorical-features-video"]], "Categorical features with only two possible categories": [[32, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[46, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[57, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[35, "changing-the-training-procedure"]], "Characters in this course?": [[27, "characters-in-this-course"]], "Choosing K [video]": [[40, "choosing-k-video"]], "Choosing n_neighbors": [[30, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Meeting 4B": [[22, null]], "Class Meeting 4C": [[23, null]], "Class Meeting 5A": [[24, null]], "Class Meeting 5B": [[25, null]], "Class Meeting 5C": [[26, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"], [22, "class-slides"], [23, "class-slides"], [24, "class-slides"], [26, "class-slides"]], "Class imbalance in training sets": [[35, "class-imbalance-in-training-sets"]], "Class meetings": [[57, "class-meetings"]], "Classification report": [[35, "classification-report"]], "Classification vs. Regression": [[28, "classification-vs-regression"]], "Clustering": [[49, "clustering"]], "Clustering Activity (~5 mins)": [[40, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[40, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[40, "clustering-input-and-possible-output"]], "Code of conduct": [[57, "code-of-conduct"]], "Coefficients and intercept": [[33, "coefficients-and-intercept"]], "ColumnTransformer example": [[32, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[32, "columntransformer-on-the-california-housing-dataset"], [52, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[32, "columntransformer-transformed-data"]], "Coming up \u2026": [[29, "coming-up"]], "Coming up:": [[30, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[40, "common-applications"]], "Common preprocessing techniques": [[31, "common-preprocessing-techniques"]], "Communication": [[49, "communication"]], "Completing the utility matrix with content-based filtering": [[42, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[33, "components-of-a-linear-classifier"]], "Confusion matrix (video)": [[35, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[35, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[30, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[42, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[32, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[57, "course-learning-objectives"]], "Course co-ordinator": [[57, "course-co-ordinator"]], "Course description": [[57, "course-description"]], "Cox proportional hazards model": [[46, "cox-proportional-hazards-model"]], "Create X and y": [[28, "create-x-and-y"]], "Create a classifier object": [[28, "create-a-classifier-object"]], "Create a column transformer": [[32, "create-a-column-transformer"]], "Creating train_df and test_df": [[29, "creating-train-df-and-test-df"]], "Creating utility matrix": [[42, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[35, "cross-validation-with-different-metrics"]], "Cross-validation": [[45, "cross-validation"], [45, "id4"]], "Cross-validation [video]": [[29, "cross-validation-video"]], "Cross-validation to the rescue!!": [[29, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[29, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[30, "curse-of-dimensionality"]], "Customer churn": [[46, "customer-churn"]], "Customer segmentation": [[40, "customer-segmentation"]], "DBSCAN [video]": [[41, "dbscan-video"]], "DBSCAN introduction": [[41, "dbscan-introduction"]], "DBSCAN: failure cases": [[41, "dbscan-failure-cases"], [41, "id1"]], "Data": [[32, "data"], [33, "data"], [37, "data"], [38, "data"], [38, "id1"]], "Data Splitting [video]": [[29, "data-splitting-video"]], "Data and main approaches": [[42, "data-and-main-approaches"]], "Data exploration": [[40, "data-exploration"]], "Data splitting": [[51, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[44, "dataset"]], "Dataset [video]": [[36, "dataset-video"]], "Dataset for demonstration": [[35, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[31, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[35, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[32, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[28, "decision-boundary"]], "Decision boundary for max_depth=1": [[28, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[28, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[28, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[30, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[33, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[28, "decision-tree-algorithm"]], "Decision tree feature importances": [[38, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[28, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[28, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[28, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[28, "decision-trees-video"]], "Decision trees with continuous features": [[28, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[37, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[28, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decreasing the threshold": [[35, "decreasing-the-threshold"]], "Deep learning": [[45, "deep-learning"]], "Deep learning software": [[44, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of feature engineering with numeric features": [[39, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[45, "demo-a-more-complicated-dataset"]], "Dendrogram": [[41, "dendrogram"]], "Deployment (Not examinable)": [[49, "deployment-not-examinable"]], "Different models": [[38, "different-models"]], "Different range for hyperparameters yields better results!": [[34, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[36, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[30, "dimensions-in-ml-problems"]], "Discussion question": [[43, "discussion-question"]], "Distance between feature vectors": [[30, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[32, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[37, "do-we-have-class-imbalance"], [38, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[38, "do-we-have-correlated-features"]], "Document clustering": [[40, "document-clustering"]], "Domain-specific transformations": [[39, "domain-specific-transformations"]], "Dummy classifier": [[47, "dummy-classifier"]], "DummyClassifier": [[28, "dummyclassifier"], [45, "dummyclassifier"], [46, "dummyclassifier"]], "DummyClassifier baseline": [[37, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[28, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[28, "dummyregressor"], [36, "dummyregressor"]], "EDA": [[31, "eda"], [35, "eda"], [36, "eda"]], "EDA: Exploratory Data Analysis": [[51, "eda-exploratory-data-analysis"]], "Encoding text data": [[32, "encoding-text-data"]], "Encoding time as a number": [[45, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[45, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[49, "ensembles"]], "Ethics": [[49, "ethics"]], "Euclidean distance": [[30, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[41, "evaluating-dbscan-clusters"]], "Evaluation": [[42, "evaluation"], [42, "id3"]], "Evaluation metrics": [[49, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[35, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[35, "evalution-metrics-overview"]], "Examining the preprocessed data": [[36, "examining-the-preprocessed-data"]], "Example": [[33, "example"], [37, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[27, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[40, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[28, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[28, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[27, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[27, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[38, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[39, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[27, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[40, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[28, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[28, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[35, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[31, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[27, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[42, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[42, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[28, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[28, "exercise-2-4"]], "Exercise 8.2": [[34, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[50, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[34, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[38, "explaining-a-prediction"]], "Exploratory data analysis": [[45, "exploratory-data-analysis"], [56, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[32, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[45, "extracting-date-and-time-information"]], "F1-score": [[35, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[39, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[45, "feature-engineering"]], "Feature engineering and selection": [[49, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[45, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[45, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[39, "feature-engineering-motivation"]], "Feature importances": [[38, "feature-importances"], [49, "feature-importances"]], "Feature importances in linear models": [[38, "feature-importances-in-linear-models"], [38, "id2"]], "Feature interactions and feature crosses": [[39, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[36, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[39, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[31, "feature-transformations-and-the-golden-rule"]], "Feature types": [[36, "feature-types"], [36, "id1"]], "Feature vectors": [[30, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[34, "final-comments-and-summary"], [42, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[28, "final-comments-summary-and-reflection"], [40, "final-comments-summary-and-reflection"], [41, "final-comments-summary-and-reflection"]], "Final exam": [[57, "final-exam"]], "Final exam preparation: guiding questions": [[49, null]], "Final note": [[51, "final-note"]], "Final remarks": [[45, "final-remarks"]], "Finding the distances to a query point": [[30, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[30, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[45, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[45, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[42, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "Garbage in, garbage out.": [[39, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[39, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[37, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[30, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[39, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[29, "generalization-video"]], "Generalization: Fundamental goal of ML": [[29, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[33, "generalizing-to-more-features"]], "Generalizing to unseen data": [[29, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[30, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[42, "global-average-baseline"]], "Golden rule violation: Example 1": [[29, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[29, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[37, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[37, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[57, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[35, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[29, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[41, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[33, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[29, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[38, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[37, "how-do-they-work"]], "How do we carry out feature selection?": [[39, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[28, "how-does-fit-work"], [28, "id2"]], "How does it work?": [[41, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[33, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[28, "how-does-predict-work"]], "How to approximate generalization error?": [[29, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[31, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[30, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[29, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[33, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[49, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[34, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[40, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[30, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[34, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[32, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[44, "imagenet"]], "Import": [[47, "import"]], "Importance of scaling": [[33, "importance-of-scaling"]], "Important hyperparameters": [[37, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[32, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[40, "important-points-to-remember"]], "Imports": [[27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [49, "imports"], [50, "imports"], [51, "imports"], [56, "imports"]], "Imports and LO": [[34, "imports-and-lo"], [36, "imports-and-lo"], [44, "imports-and-lo"], [45, "imports-and-lo"]], "Imports and LOs": [[35, "imports-and-los"]], "Imports and learning outcomes": [[40, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[28, "imports-announcements-los"]], "Imports, Announcements, and LO": [[32, "imports-announcements-and-lo"], [33, "imports-announcements-and-lo"]], "Imports, LOs": [[29, "imports-los"], [31, "imports-los"], [38, "imports-los"]], "Imports, announcements, LOs": [[37, "imports-announcements-los"]], "Imports, announcements, and LOs": [[30, "imports-announcements-and-los"]], "Imputation": [[31, "imputation"]], "Imputation and scaling [video]": [[31, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[32, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[35, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[40, "inertia"]], "Initialization of K-Means": [[40, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[37, "inject-randomness-in-the-classifier-construction"]], "Input data": [[27, "input-data"]], "Input features X and target y": [[27, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interim summary": [[35, "interim-summary"], [38, "interim-summary"], [39, "interim-summary"], [45, "interim-summary"]], "Interpretation of coefficients": [[33, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[33, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[38, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[41, "introduction"], [49, "introduction"]], "Introduction to NLP": [[49, "introduction-to-nlp"]], "Introduction to computer vision": [[44, "introduction-to-computer-vision"]], "Introduction to neural networks": [[44, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[40, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[47, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[35, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[32, "is-this-a-realistic-representation-of-text-data"]], "Is \u201cRelevance\u201d clearly defined?": [[39, "is-relevance-clearly-defined"], [39, "id2"], [39, "id3"], [39, "id4"], [39, "id5"], [39, "id6"], [39, "id7"]], "K-Means algorithm": [[40, "k-means-algorithm"]], "K-Means clustering [video]": [[40, "k-means-clustering-video"]], "K-Means example": [[40, "k-means-example"]], "K-Means limitations": [[41, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[41, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[41, "k-means-recap"]], "K-Means: failure case 1": [[41, "k-means-failure-case-1"]], "K-Means: failure case 2": [[41, "k-means-failure-case-2"]], "K-Means: failure case 3": [[41, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[46, "kaplan-meier-survival-curve"]], "Key point": [[38, "key-point"]], "LDA topics in social media": [[43, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[40, "labeled-vs-unlabeled-data"]], "Lag-based features": [[45, "lag-based-features"], [45, "id5"], [56, "lag-based-features"]], "Land acknowledgement": [[57, "land-acknowledgement"]], "Large datasets solve many of these problems": [[34, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[33, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[43, "learning-objectives"], [44, "learning-objectives"], [45, "learning-objectives"], [46, "learning-objectives"]], "Learning outcomes": [[27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [35, "learning-outcomes"], [36, "learning-outcomes"], [38, "learning-outcomes"], [39, "learning-outcomes"], [40, "learning-outcomes"], [41, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[42, "learning-outcomes"]], "Least confident cases": [[33, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[36, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[37, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[38, null]], "Lecture 13": [[22, "lecture-13"]], "Lecture 13: Feature engineering and feature selection": [[39, null]], "Lecture 14": [[23, "lecture-14"]], "Lecture 14: K-Means Clustering": [[40, null]], "Lecture 15": [[23, "lecture-15"]], "Lecture 15: More Clustering": [[41, null]], "Lecture 16": [[24, "lecture-16"]], "Lecture 16: Recommender Systems": [[42, null]], "Lecture 17": [[24, "lecture-17"]], "Lecture 17: Introduction to natural language processing": [[43, null]], "Lecture 18": [[26, "lecture-18"]], "Lecture 18: Multi-class classification and introduction to computer vision": [[44, null]], "Lecture 19": [[26, "lecture-19"]], "Lecture 19: Time series": [[45, null]], "Lecture 1: Course Introduction": [[27, null]], "Lecture 20: Survival analysis": [[46, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[28, null]], "Lecture 3: Machine Learning Fundamentals": [[29, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[30, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[31, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[32, null]], "Lecture 7: Linear Models": [[33, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[34, null]], "Lecture 9: Classification metrics": [[35, null]], "Lecture learning objectives": [[37, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[41, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[57, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[31, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[32, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[30, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[31, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[38, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[35, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[36, "let-s-separate-x-and-y"], [38, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[36, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[31, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[37, "lightgbm"]], "Limitations of linear models": [[33, "limitations-of-linear-models"]], "Linear SVM": [[33, "linear-svm"]], "Linear models [video]": [[33, "linear-models-video"]], "Linear regression": [[33, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Logistic regression [video]": [[33, "logistic-regression-video"]], "Logistic regression intuition": [[33, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[33, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[44, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[45, "logisticregression"], [46, "logisticregression"]], "MAPE": [[36, "mape"]], "ML fairness activity": [[54, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[35, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[49, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[27, "machine-learning-workflow"], [35, "machine-learning-workflow"]], "Magnitude of the coefficients": [[33, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[33, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[33, "main-hyperparameters"]], "Manual hyperparameter optimization": [[34, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[40, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[40, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[36, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[27, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[40, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[40, "method-2-the-silhouette-method"]], "Midterms": [[57, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[42, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[36, "model-building"]], "Model complexity and training error": [[29, "model-complexity-and-training-error"]], "Model interpretability beyond linear models": [[38, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[27, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[54, "model-training-and-evaluation"]], "Model-based selection": [[39, "model-based-selection"]], "More comments on tackling class imbalance": [[36, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[41, "more-details-on-dbscan"]], "More on feature transformations": [[32, "more-on-feature-transformations"]], "More on k-NNs [video]": [[30, "more-on-k-nns-video"]], "More terminology [video]": [[28, "more-terminology-video"]], "More than one ordinal columns?": [[32, "more-than-one-ordinal-columns"]], "Most confident cases": [[33, "most-confident-cases"]], "Motivating example": [[33, "motivating-example"]], "Motivation": [[34, "motivation"], [45, "motivation"]], "Motivation [video]": [[37, "motivation-video"]], "Motivation and big picture [video]": [[31, "motivation-and-big-picture-video"]], "Motivation and context": [[43, "motivation-and-context"]], "Motivation and distances [video]": [[30, "motivation-and-distances-video"]], "Movie features": [[42, "movie-features"]], "Multi-class classification": [[44, "multi-class-classification"]], "Multiclass classification and computer vision": [[49, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[32, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[29, null], [29, null], [45, null]], "Number of trees and fundamental trade-off": [[37, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[32, "ohe-with-many-categories"]], "Object detection": [[44, "object-detection"]], "Observations": [[35, "observations"]], "One Vs. One approach": [[48, "one-vs-one-approach"]], "One Vs. One prediction": [[48, "one-vs-one-prediction"]], "One vs. Rest": [[48, "one-vs-rest"]], "One-hot encoding (OHE)": [[31, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[45, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[45, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[32, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[35, "operating-point"]], "Optimization bias of hyper-parameter learning": [[34, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[34, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[34, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[34, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[34, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[31, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[38, "ordinal-features"]], "Other applications": [[40, "other-applications"]], "Other approaches / what did we not cover?": [[46, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[43, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[36, "other-possible-preprocessing"]], "Other software package": [[45, "other-software-package"]], "Other tools for preprocessing": [[43, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[43, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[30, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[39, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[29, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[50, "outline"], [51, "outline"], [52, "outline"], [53, "outline"], [54, "outline"], [55, "outline"], [56, "outline"]], "Over confident cases": [[33, "over-confident-cases"]], "Overfitting": [[29, "overfitting"]], "Overfitting of the validation data": [[34, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[34, "overfitting-of-the-validation-error"]], "Oversampling": [[35, "oversampling"]], "Overview": [[30, "overview"]], "POSIX time feature": [[45, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[35, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[28, "parameters"]], "Parameters and hyperparameters: Summary": [[28, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[45, "parsing-datetimes"], [56, "parsing-datetimes"]], "Part 1": [[49, "part-1"]], "Part 2": [[49, "part-2"]], "Passing Requirements": [[57, "passing-requirements"]], "Pipelines": [[31, "pipelines"]], "Playground": [[30, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[28, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 13 Videos": [[22, "pre-lecture-13-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[35, "precision"]], "Precision and recall: toy example": [[35, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[35, "precision-recall-f1-score-video"]], "Precision-recall curve": [[35, "precision-recall-curve"], [35, "id1"]], "Precision/Recall tradeoff": [[35, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[27, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[33, "predicting-probability-scores-video"]], "Predicting with learned weights": [[33, "predicting-with-learned-weights"]], "Prediction": [[46, "prediction"]], "Prediction of linear regression": [[33, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[33, "prediction-with-learned-parameters"]], "Predictions": [[44, "predictions"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[32, "preprocessing"], [45, "preprocessing"], [49, "preprocessing"], [54, "preprocessing"], [56, "preprocessing"]], "Preprocessing the targets?": [[32, "preprocessing-the-targets"]], "Prevalence of ML": [[27, "prevalence-of-ml"]], "Problem formulation": [[42, "problem-formulation"]], "Problem: Different transformations on different columns": [[31, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[34, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[29, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[30, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[49, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[30, "question"]], "Question for you": [[41, "question-for-you"]], "Questions for class discussion": [[42, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[34, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[30, "quick-recap"]], "RFE algorithm": [[39, "rfe-algorithm"]], "R^2 (not in detail)": [[36, "r-2-not-in-detail"]], "Random forest feature importances": [[38, "random-forest-feature-importances"]], "Random forests": [[37, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[37, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[37, "randomforestclassifier"], [46, "randomforestclassifier"]], "Randomized hyperparameter search": [[34, "randomized-hyperparameter-search"]], "Range of C": [[34, "range-of-c"]], "Raw scores": [[33, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[28, "reading-the-data"], [44, "reading-the-data"]], "Real boundary between Canada and USA": [[28, "real-boundary-between-canada-and-usa"], [50, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[35, "recall"]], "Recap": [[46, "recap"]], "Recap and motivation [video]": [[41, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[28, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[35, "receiver-operating-characteristic-roc-curve"]], "Recommender systems": [[49, "recommender-systems"]], "Recommender systems intro and motivation": [[42, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[42, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[39, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[46, "references"]], "Registration": [[57, "registration"]], "Regression scoring functions": [[36, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[30, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[30, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[30, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[37, "relevant-papers"]], "Relevant papers and resources": [[35, "relevant-papers-and-resources"]], "Relevant resources": [[39, "relevant-resources"]], "Reminder": [[42, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Report format": [[7, "report-format"]], "Resources": [[40, "resources"], [41, "resources"], [42, "resources"]], "Ridge": [[33, "ridge"]], "Ridge on the California housing dataset": [[33, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[36, "ridgecv"]], "Root mean squared error or RMSE": [[36, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[38, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[38, "shap-plots"]], "SMOTE idea": [[35, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[35, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[30, "svm-regressor"]], "Saving time and scaling products": [[27, "saving-time-and-scaling-products"]], "Scaling": [[31, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[31, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[57, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[30, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[45, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[27, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[44, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[33, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[40, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[30, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[47, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[29, "simple-train-test-split"]], "SimpleFeature correlations": [[38, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[37, "some-important-hyperparameters"]], "Some quotes on feature engineering": [[39, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[28, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[34, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[32, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[37, "stacking"], [55, "stacking"]], "Step 1": [[52, "step-1"]], "Step 2": [[52, "step-2"]], "Step 3": [[52, "step-3"]], "Step 4": [[52, "step-4"]], "Step 5": [[52, "step-5"]], "Steps to train a classifier using sklearn": [[28, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[35, "stratified-splits"]], "Strengths and weaknesses": [[37, "strengths-and-weaknesses"]], "Strengths of linear models": [[33, "strengths-of-linear-models"]], "Study tips": [[49, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[27, "summary"], [30, "summary"], [37, "summary"], [43, "summary"], [44, "summary"], [46, "summary"]], "Summary and reflection": [[29, "summary-and-reflection"]], "Summary of linear models": [[33, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[29, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[41, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[42, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[40, "supervised-learning"]], "Supervised learning (Reminder)": [[28, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[28, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[27, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[30, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[30, "support-vectors"]], "Survival analysis": [[49, "survival-analysis"]], "Survival plots": [[46, "survival-plots"]], "Syllabus": [[1, "syllabus"], [57, null]], "TAs": [[57, "tas"]], "Tabular data": [[28, "tabular-data"]], "Take-home message": [[41, "take-home-message"]], "Teaching Team": [[57, "teaching-team"]], "Terminology": [[44, "terminology"]], "Terminology [video]": [[28, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[37, "the-netflix-prize"]], "The __ syntax": [[34, "the-syntax"]], "The best features may be dependent on the model you use.": [[39, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[55, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[29, "the-golden-rule"]], "The random forests classifier": [[37, "the-random-forests-classifier"]], "The sigmoid function": [[33, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[29, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[40, "the-perfect-spaghetti-sauce"]], "Time series": [[49, "time-series"]], "Time series analysis on a more complicated dataset": [[56, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[46, "time-to-event-and-censoring"]], "Tokenization": [[43, "tokenization"]], "Topic modeling": [[43, "topic-modeling"]], "Topic modeling motivation": [[43, "topic-modeling-motivation"]], "Topic modeling pipeline": [[43, "topic-modeling-pipeline"]], "Topic modeling toy example": [[43, "topic-modeling-toy-example"]], "Toy datasets": [[28, "toy-datasets"]], "Traditional time series approaches": [[45, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[45, "train-test-split-for-temporal-data"]], "Train/test splits": [[45, "train-test-splits"]], "Train/validation/test split": [[29, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[27, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[33, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[29, "training-error-vs-generalization-error"]], "Training models with transformed data": [[32, "training-models-with-transformed-data"]], "Transfer learning": [[44, "transfer-learning"]], "Transformations on the toy data": [[32, "transformations-on-the-toy-data"]], "Transforming the targets": [[36, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[38, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[37, "tree-based-ensemble-models"]], "Tree-based models": [[37, "tree-based-models"]], "Tuning alpha hyperparameter of Ridge": [[36, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[50, null]], "Tutorial 2": [[51, null]], "Tutorial 3": [[52, null]], "Tutorial 4": [[53, null]], "Tutorial 5": [[54, null]], "Tutorial 6": [[55, null]], "Tutorial 7": [[56, null]], "Types of censoring": [[46, "types-of-censoring"]], "Types of errors": [[29, "types-of-errors"]], "Types of machine learning": [[27, "types-of-machine-learning"], [40, "types-of-machine-learning"]], "Types of problems involving time series": [[45, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[46, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[29, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[29, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[35, "undersampling"]], "Unequally spaced time points": [[45, "unequally-spaced-time-points"]], "Unsupervised learning": [[40, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[57, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[48, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[35, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[40, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[36, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[44, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[44, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[36, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[32, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[34, "visualizing-the-parameter-grid-as-a-heatmap"]], "Warning": [[28, null]], "Warnings about feature selection": [[39, "warnings-about-feature-selection"], [39, "id8"]], "Weaknesses": [[37, "weaknesses"]], "What all transformations we need to apply on the dataset?": [[31, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[31, "what-are-the-options"]], "What are we exactly learning?": [[33, "what-are-we-exactly-learning"]], "What did we cover?": [[42, "what-did-we-cover"]], "What did we learn today?": [[29, "what-did-we-learn-today"], [31, "what-did-we-learn-today"], [32, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [36, "what-did-we-learn-today"]], "What if we apply OHE?": [[32, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[43, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[42, "what-is-a-recommender-system"]], "What is clustering?": [[40, "what-is-clustering"]], "What is feature engineering?": [[39, "what-is-feature-engineering"]], "What is feature selection?": [[39, "what-is-feature-selection"]], "What is model interpretability?": [[38, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[27, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[35, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[37, "what-kind-of-estimators-can-we-combine"]], "What to look for in these plots?": [[40, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[31, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When is it OK to do things before splitting?": [[31, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[34, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[37, "which-model-should-i-use"]], "Which type of error is more important?": [[35, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[34, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[38, "why-do-we-want-this-information"]], "Why feature selection?": [[39, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[27, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[38, "why-model-transparency-interpretability"]], "Why neural networks?": [[44, "why-neural-networks"], [44, "id1"]], "Why not neural networks?": [[44, "why-not-neural-networks"], [44, "id2"]], "Why should we care about recommendation systems?": [[42, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[32, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[43, "word-embeddings"]], "Word vectors with spaCy": [[43, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[28, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[37, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[35, "class-weight-balanced"]], "cross_val_score": [[29, "cross-val-score"]], "cross_validate": [[29, "cross-validate"]], "fit and transform paradigm for transformers": [[31, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[28, "fit-the-classifier"]], "fit, predict , and score summary": [[28, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[57, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[36, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[36, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[37, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[37, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[39, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[44, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[28, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[28, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[28, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[29, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[29, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[35, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[35, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[30, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[42, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[34, "n-iter"]], "n_jobs=-1": [[34, "n-jobs-1"]], "pandas_profiler": [[36, "pandas-profiler"]], "predict the target of given examples": [[28, "predict-the-target-of-given-examples"]], "predict_proba": [[33, "predict-proba"]], "random_state argument": [[29, "random-state-argument"]], "score your model": [[28, "score-your-model"]], "sklearn API summary: estimators": [[31, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[31, "sklearn-api-summary-transformers"]], "sklearn set_config": [[32, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[32, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[38, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[38, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[47, "spacy"]], "test score vs. cross-validation score": [[29, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[29, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[29, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[35, "questions-for-group-discussion"], [54, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[27, "questions-for-you"], [28, "questions-for-you"], [28, "id1"], [28, "id3"], [29, "questions-for-you"], [29, "id1"], [30, "questions-for-you"], [30, "id1"], [31, "questions-for-you"], [31, "id1"], [31, "id2"], [32, "questions-for-you"], [32, "id1"], [33, "questions-for-you"], [33, "id1"], [33, "id2"], [34, "questions-for-you"], [34, "id2"], [35, "questions-for-you"], [35, "id2"], [36, "questions-for-you"], [36, "id2"], [37, "questions-for-you"], [37, "id1"], [37, "id2"], [39, "questions-for-you"], [40, "questions-for-you"], [40, "id2"], [41, "questions-for-you"], [41, "id3"], [42, "questions-for-you"], [42, "id1"], [42, "id2"], [44, "questions-for-you"], [45, "questions-for-you"], [45, "id1"], [45, "id2"], [45, "id3"], [46, "questions-for-you"], [46, "id1"], [46, "id2"], [46, "id3"], [46, "id4"]], "\ud83e\udd14 Eva\u2019s questions": [[27, "eva-s-questions"], [29, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/classes/class4B", "lectures/classes/class4C", "lectures/classes/class5A", "lectures/classes/class5B", "lectures/classes/class5C", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/classes/class4B.md", "lectures/classes/class4C.md", "lectures/classes/class5A.md", "lectures/classes/class5B.md", "lectures/classes/class5C.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 33, 34, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "0": [0, 1, 7, 8, 10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "00": [10, 27, 28, 30, 32, 33, 34, 35, 38, 41, 42, 45, 46, 56, 57], "000": [27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 43, 44, 46, 47], "0000": [31, 33, 35, 47], "00000": [34, 45, 56], "000000": [28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 45, 46, 56], "00000000e": 38, "000000e": 34, "000001": 36, "00000e": 30, "000010": 36, "000011": 35, "000021": 31, "000036": 35, "000057": 31, "000065": 34, "000067": 34, "000077": 34, "000087": 33, "000089": 33, "0001": [33, 35, 36, 46], "000100": [31, 36], "000108": 33, "000113": 35, "000114": 34, "000117": 36, "000130": 33, "000136": 44, "000137": 34, "000145": 34, "000146": 33, "000147": 34, "000149": 31, "000150": 33, "000151": 34, "000155": [31, 35], "000159": 34, "000163": 34, "000166": [33, 34], "000177": [31, 45], "000180": 31, "000181": 34, "000182": 33, "000183": 33, "000187": 33, "000188": 31, "000190": 45, "000192": 45, "000194": 33, "000195": 31, "000198": 35, "000201": 34, "000206": 34, "000208": 31, "000210": 34, "000212": 39, "000213": 33, "000218": 33, "000221": 36, "000226": 36, "000227": 35, "000231": 31, "000232": 44, "000234": [30, 34], "000235": [31, 35], "000240": 31, "000245": 34, "000247": 44, "000255": 33, "000256": 45, "000259": 31, "000260": 31, "000271": 45, "000273": 44, "000274": 44, "000281": 33, "000283": 33, "000285": 33, "000286": 34, "000289": 31, "000294": 34, "000312": 35, "000332": 36, "000336": 44, "000339": 34, "000348": 34, "000353": 34, "000354": 34, "000363": 44, "000366": 35, "000370": 34, "000371": 33, "000373": 36, "000378": 33, "00038": 34, "000397": 36, "000399": 44, "000433": 36, "000435": 44, "000437": 44, "000452": 31, "000459": 33, "000471": 45, "000472": 44, "000489": 34, "000492": 35, "000498": 45, "000503": 34, "000508": 34, "000520": 36, "000575": 45, "00058": 34, "000580": 30, "000630": 35, "000633": 30, "000637": 44, "000647": 30, "000650": 30, "000651": 30, "000652": 36, "000655": 30, "000661": 30, "000671": 30, "000678": 34, "000713": 36, "000726": 35, "000737": 45, "000747": 34, "000748": 31, "000752": 30, "000758": 44, "000765": 31, "000774": 31, "000786": 35, "000787": 30, "00079": 34, "000794": 30, "000795": 30, "000797": 30, "000803": 36, "000829": 30, "000831": 30, "000832": 36, "000867": 31, "000869": 45, "000873": 30, "000889": 30, "000891": 35, "000917": 34, "000927": 35, "000936": 30, "000945": 39, "000960": 44, "000964": 39, "000976": 34, "000977": 30, "000982": 34, "001": [27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 44, 46, 47], "0010": 33, "00100": 34, "001000": [34, 36], "001002": 29, "001006": 29, "001010": 29, "001011": [30, 36], "001014": 29, "001016": 29, "001017": 29, "001026": 29, "001027": 29, "001029": 29, "001038": 29, "001040": 35, "001043": 31, "001057": [29, 34], "001060": 31, "001063": 29, "001064": 44, "001068": 38, "001071": 29, "001078": 29, "001086": 29, "001087": 39, "001103": 29, "001111": 29, "001139": 30, "001149": 29, "001155": 39, "001162": [34, 39], "001174": 29, "001205": 35, "001220": 33, "001224": 30, "001226": 44, "001236": 34, "001239": 35, "001266": 36, "001279": 39, "001286": 35, "001294": 29, "001299": 29, "001305": 29, "001307": 29, "001315": 29, "001317": 29, "001322": 29, "001323": 29, "001325": 30, "001329": 29, "001337": 29, "001338": 33, "001347": 34, "001352": 29, "001361": 33, "001362": 33, "001365": 30, "001371": 32, "001390": 29, "001391": 29, "001392": 30, "001400": 32, "001406": 36, "001407": 29, "001412": 34, "001414": 30, "001422": 36, "001423": 34, "001429": 29, "001433": 36, "001441": 29, "001448": 32, "001453": 29, "00146": 34, "001466": 32, "001467": 34, "001492": 34, "001495": 30, "001563": 32, "001566": 36, "001585": 34, "001586": 30, "001591": 32, "001594": 34, "001595": 30, "001600": 30, "001604": 32, "001606": 32, "001608": 34, "001616": 34, "001620": 34, "001629": 34, "001641": 44, "001645": 33, "001647": 32, "001679": 34, "001682": 34, "001693": 39, "001699": 29, "0017": 35, "001700": 35, "001710": 33, "001715": 32, "001740": 36, "001769": 34, "001773": 30, "001776": 29, "001790": 36, "001792": 34, "001847": 39, "001850": 33, "001877": 30, "001894": 36, "001900": 30, "001920": 32, "001922": 32, "001933": 36, "001949": 39, "001952": 30, "001968": 29, "001994": 39, "002": [29, 33, 37, 38, 46], "002003": 34, "002022": 32, "002030": 30, "002045": 34, "002057": [31, 32], "002083": 30, "002096": 44, "002105": 34, "002116": 32, "002118": 30, "002123": 34, "002143": 29, "002146": 34, "002158": 39, "002159": 34, "002197": 34, "002221": 36, "002321": 33, "00234": 34, "002355": 39, "002385": 36, "002441": 39, "002460": 44, "002525": 44, "002561": 34, "002646": 39, "002664": 39, "002675": 34, "002682": 44, "002690": 31, "002692": 34, "002704": 34, "002711": 44, "002746": 36, "002783": 34, "002788": 32, "002789": 32, "002807": 32, "002835": 34, "002858": 32, "002867": 39, "002889": 35, "0029": 46, "002910": 32, "002934": 33, "002940": 44, "002948": 30, "002962": 44, "002986": 44, "002999": 34, "003": [34, 37], "003013": 32, "003014": 34, "003015": 34, "003027": 34, "003038": 34, "003083": 34, "003086": 32, "003115": 32, "003124": 36, "003133": 36, "003146": 32, "003148": 33, "003166": [31, 39], "003181": 31, "003183": 39, "003185": 46, "003186": 32, "003188": [31, 32], "003194": 33, "003212": 31, "003242": 44, "003257": 44, "003273": 29, "003283": 44, "003288": 36, "003300": 31, "00332": 34, "003324": 31, "003365": 32, "003401": 39, "003421": 34, "003423": 39, "003427": 39, "003472": 34, "003477": 44, "003479": 34, "003483": 34, "003493": 39, "003528": 34, "003529": 34, "003547": 36, "003563": 34, "003633": 34, "003647": 44, "00369": 34, "003748": 34, "003757": 34, "003785": 36, "003885": 34, "003919": 34, "003919287722401839": 34, "00392157": 44, "003923": 32, "003924": 39, "003933": 34, "003998": 34, "004": [30, 34, 37, 38, 44], "004057": 34, "004065": 45, "004082": 45, "004121": 36, "004143": 36, "004264": 29, "004293": 34, "004305": 34, "004337": 34, "00435173": 40, "004352": 40, "004398": 38, "004402": 34, "004466": 34, "004496": 34, "004521": 36, "004529": 38, "004556": 34, "004574": 36, "004602": 36, "00461": 34, "004714": 34, "004723": 38, "004761": 38, "004770": 31, "004801": [31, 32], "004807": 32, "004826": 36, "004829": 36, "004854": 36, "004884": 44, "004919": 34, "004934": 35, "004952": 34, "004959": 34, "00496": 34, "005": [27, 37, 38, 46], "005067": 31, "005074": 44, "005093": 31, "005098": 36, "005114": 36, "005126": 34, "005151": 34, "005157": 31, "005167": 36, "005196": 34, "005241": 36, "00525962": 31, "005269": 36, "005288": 32, "005335": 34, "005336": 36, "005387": 35, "005423": 34, "005426": 34, "00543825": 31, "005440": 44, "005478": 38, "00548": 34, "005538": 36, "005579": 36, "005641": 36, "005674": 36, "005699": 29, "005708": 34, "00573": 34, "005734": 34, "005735": 34, "005767": 34, "005809": 45, "005834": 34, "005836": 31, "005888": 31, "006": [37, 38, 46], "006012": 34, "006046": 36, "006055": 34, "006067": 36, "006106": 34, "006110": [30, 34, 36], "006236": 36, "006244": 34, "006435": 34, "006452": 33, "006476": 36, "006505": 44, "006531": 29, "006545": 34, "006546893270012566": 33, "006557": 33, "006578": [31, 32], "006652": 34, "006667": 34, "00667": 34, "006744": 36, "006805": 29, "006861": 34, "006904": 34, "00691": 34, "006973": 31, "007": [31, 37, 38, 46, 47], "007068": 39, "00715": 34, "00720988e": 38, "007228": 36, "007291": 32, "007316": 29, "007361": 35, "007362": 34, "007434": 38, "007458": [31, 32], "007517": 36, "007544": 34, "007563": 34, "007588": 40, "00758803": 40, "00759438": 38, "007655": 34, "007666": 35, "00767": 34, "007737": 36, "007776": 36, "007818": 34, "007938": 29, "007986": 36, "008": [37, 38, 47], "008040": 45, "008120": 36, "008153": 34, "008167": [31, 32], "00830586": 32, "008306": 32, "008322e": 46, "008333": 32, "008346": 36, "008377": 34, "008472": 36, "008577": 44, "008581": 36, "008606": 36, "008617": 36, "008667": 34, "00871": 34, "008735": 30, "008785": 36, "009": [32, 37, 46], "009059": 29, "009063": 34, "009082": 34, "009090": 36, "009132": 34, "009140": 36, "009297": 34, "009305": 34, "009339": 36, "009422": 29, "009512": 34, "009514e": 36, "009664": 36, "009692": 44, "009724": 39, "01": [30, 31, 33, 34, 35, 36, 38, 44, 45, 46, 48, 56], "010": [27, 33, 34, 46, 47], "0100": 33, "01000": 34, "010000": [31, 34, 36], "010027": 33, "010183": [31, 32], "0102": [30, 34], "010208": 39, "010294": 29, "010650": 29, "010679": 29, "010688": 39, "010715": 34, "010750": 39, "011": [27, 32, 44, 46], "011210": 39, "011234": 35, "011248": 36, "011252": 39, "011269e": 36, "011287": 39, "011332": 46, "011336": 30, "011440": 36, "011617": 34, "011678": 35, "011767": 36, "011773": 37, "012": [31, 32, 37, 38, 44, 46, 47], "012019": 29, "012030": 39, "012232": 36, "012240": 39, "012252": 34, "012616": 34, "012624": 36, "012707": 35, "012758": 36, "013031": 36, "01311996071": 36, "013120": 38, "013157": 34, "013161": 34, "013433": 30, "013629": 34, "013706928443177698": 34, "013707": 34, "013863": 34, "013888": 34, "014": [29, 31, 37, 38, 46], "014030": 36, "014081e": 36, "014305": 36, "01432486e": 38, "014481": 34, "014503": 34, "014650": 46, "014730": 32, "01473536": 30, "014758": 46, "015": [27, 31, 32, 37, 46, 47], "015003": 34, "015039": 35, "015056": 34, "015165": 36, "015372": 34, "015724": 39, "015755": 34, "015819": 34, "016263": 34, "016372": 34, "01647": 34, "016525": [36, 38], "016555": 33, "016587": 35, "016598": 34, "016602": 34, "016607": 34, "016676": 40, "016688": [31, 39], "016693": 36, "016807": 33, "016815": 34, "016918": 35, "016944": 30, "017": [32, 44], "017185": 34, "017226": 36, "017308": 34, "017427": 34, "017610": 38, "017696": 38, "017737": 38, "017741": 38, "017829": [45, 56], "017837": 34, "01784": 34, "017927": 34, "017959e": 36, "017972": 31, "018": 37, "018014": 38, "018046": 35, "018077": 34, "018178": 30, "018243": 34, "018310": 30, "018434": [45, 56], "018459e": 36, "018487": 33, "0185": 33, "018505": 34, "018507e": 36, "018558": 34, "018581": 36, "018653": 34, "018745": 27, "018789": 34, "018846": 34, "018854": 35, "019": 37, "019012": 34, "019163": 34, "019381838999846482": 34, "019382": 34, "019396": 34, "019444": 32, "019446": 34, "019531": 35, "019556": 46, "0195598": 33, "019574": 34, "019839": 34, "02": [30, 31, 32, 33, 34, 36, 38, 39, 45, 46, 52, 56], "02000e": 30, "020123": 36, "020403": 34, "020414": 34, "020641": 38, "020648": 36, "020653": 29, "020833": 42, "020862": 36, "020873": 31, "021": [37, 47], "021043": 35, "021100": 31, "021281": 34, "021305": 30, "021345": 34, "021523": 35, "021603": 44, "021721": 34, "021746": 34, "021813": 35, "021862": 34, "021900": [30, 34], "022039": 35, "022331": 38, "022433": 34, "022629": 34, "022686": 34, "022848": 29, "022866": 35, "023": [37, 44], "023086": 46, "023105": [45, 56], "023305": 36, "023366": 39, "023367": 35, "023511": 34, "023554": 36, "023636": 35, "023666": 34, "023810": 47, "024": 37, "024028": 34, "024122": 34, "024291": 45, "024351e": 36, "024390": 39, "02446630e": 38, "024540": 31, "025": [31, 35], "025381": 38, "025391": [31, 32], "025396": 34, "025489": 38, "025689": 34, "025910": 30, "025998": [31, 32], "026": 46, "0261": [30, 34], "026620": 34, "026777": 34, "02677733855112973": 34, "026793": [36, 38], "026972": 36, "027070": 36, "027112": [45, 56], "027321": 39, "027484": 36, "027578": 36, "028023": 35, "028337": 34, "028351": 34, "028420": 36, "028672": 39, "028772": 36, "029137": 35, "029146": 35, "029164": [45, 56], "029198": 34, "029264": 36, "029409": 36, "029475": 36, "029909": 29, "029950e": 36, "02d": 45, "03": [33, 34, 36, 38, 44, 45, 46, 47, 56], "030": 38, "03017665e": 38, "030200": 31, "030343": 36, "030349": 36, "030408": 30, "03049217": 30, "0305": 30, "030739733331869412": 33, "030786": 36, "030805": 36, "031": 32, "031070": 36, "031385": 30, "031483": 36, "031564": 31, "031794": 36, "031863": 36, "031994": 36, "032140": 36, "032280": 35, "032324": 34, "032404": 34, "032566": 32, "03256625": 32, "032656": 30, "032874": 30, "033165": 36, "033222": 46, "033267": 45, "033279": 38, "033305": 44, "033322": 36, "033459": 30, "0335": 34, "033723": 36, "033739": 36, "033780": 46, "033833": 35, "0339": 31, "034071": 35, "03411038e": 38, "034132": 36, "0344": [30, 34], "034894": 38, "034977": 36, "034979e": 36, "035": 44, "0351": 31, "03516073": 38, "035161": 38, "035223": 36, "035230": [45, 56], "035722": 36, "036": [31, 37, 44], "036136": 39, "0362": 31, "036646": 36, "036749": 35, "036764": 35, "036886": 37, "0370": 31, "0373": 31, "037414": [45, 56], "037785": 35, "0378": [31, 46], "038102": 33, "038609": 36, "038707": 38, "038948": 36, "039": 44, "039498": 33, "039741": 30, "0399": 31, "04": [31, 32, 34, 36, 38, 45, 46, 52, 56], "040": 37, "040129": 46, "040497": 35, "040698e": 36, "040954": 46, "040984": 45, "041": [37, 44], "041031": 35, "04108378": 33, "041084": 33, "041129": 30, "041201": 35, "041488": 36, "041704": 38, "041769": 36, "042081": 38, "042382": 39, "042743": 36, "042957": [31, 32], "043": 34, "043257": 32, "043319": 38, "043509": 34, "0437": [28, 29, 30, 50], "043890": 30, "044": [30, 34], "044029": [31, 32], "044166": 33, "044253": 38, "044313": 31, "044409": 36, "044614": 34, "044873": 29, "045": [28, 44], "045267": 45, "045280": 35, "045304": 30, "045415": 31, "045481": [45, 56], "046": 44, "04600e": 30, "046020": 30, "046116": 34, "046193e": 36, "046216": 34, "046638": 32, "0468": 46, "0469": 31, "046945": 34, "04709519e": 38, "0474": 33, "047567": 36, "04774884": 40, "047749": 40, "048": [29, 32], "048378": 29, "04861878": 40, "048630": 45, "048860": 31, "048889": 36, "049": [32, 44], "05": [30, 31, 34, 35, 36, 41, 45, 46, 56], "050": [27, 44], "050110e": 36, "050132": [31, 32], "051": 44, "051269": [31, 32], "05137470e": 38, "051392": 44, "051472": 30, "051620": 31, "051824": 36, "051925": 34, "052": 31, "052349": 31, "052607": 35, "052790": 35, "052819": 35, "05290827e": 38, "053156": 40, "05350962": 48, "0537": 34, "053763": 29, "053918": 34, "054054": 35, "054461": 35, "054653": 32, "05465323": 32, "054669": [36, 38], "054784": 32, "05478443": 32, "055": [29, 31, 32], "055100": 34, "055915e": 36, "05598498": 32, "055985": 32, "056": 44, "056478": [31, 32], "056703": 35, "057": [31, 44], "057003": 30, "057082": 36, "057254": 46, "057296": 35, "057331": 36, "057646": 30, "057729": 35, "057732e": 46, "057793": [31, 32], "057910": [31, 32], "058": 37, "0580": [29, 33], "058298": 36, "058311": 35, "059": [27, 31], "059077": 35, "0591": 31, "059242": [31, 32], "059360": 44, "059588": 34, "059863": 30, "06": [31, 34, 36, 41, 44, 45, 46, 48, 56], "060": 44, "060477": 36, "060543": 39, "061100": 31, "061206": 35, "061241": 30, "061312": 36, "061313": 44, "061937": 30, "062": [27, 30, 34], "062043": 34, "062449": 46, "062658e": 36, "062723": 29, "062792": 30, "063004": 39, "063110": [31, 32], "063173": 38, "064": [34, 38], "06405": 34, "064050": 34, "064200": 30, "064307": 39, "064452": 30, "065": 44, "065169": 34, "065199": 35, "065449": 36, "065463": 35, "066166": 46, "066251": 29, "066605": 34, "066667": 31, "0667579112160865": 33, "066810": 46, "066944": 34, "067119": 31, "067120": 29, "06797961": 36, "067991": 31, "068": 27, "068214": [33, 34], "068291": 44, "068498": 34, "068775": 34, "068891": 34, "069150": 38, "06915047": 38, "069188": 46, "0694": [30, 34], "069530": 30, "07": [34, 36, 39, 45, 46, 56], "070081": 34, "070195": 34, "070850": 35, "070898": 34, "070907": 29, "070929": 35, "071": 44, "071330": [45, 56], "071541": [31, 32], "071654": 39, "07174469222": 36, "071745": 38, "071975": 39, "072": 37, "072043": 34, "072243": 38, "0723": 31, "072396": 34, "07245741": 36, "072595": 34, "072707": 29, "073058": 31, "073233": 33, "073366": 31, "074": [31, 37], "0741": 30, "074141": 30, "07418": 34, "074327": 37, "074418": 44, "074475": 31, "074719": 32, "07471942": 32, "075000": 42, "075170": 45, "075453": 46, "075467": 46, "075747": 34, "076104": 36, "0762": 31, "076284": 40, "07639": 34, "076533": 36, "076798": 30, "077": [37, 44], "077204": 38, "077761": 46, "077803": 34, "078": [33, 37], "0780": [28, 29, 50], "078052": 35, "07808506982896266": 36, "078243": 34, "078387": 46, "078552": 34, "078740": 34, "07877994e": 48, "078880": 32, "079": 34, "079282": 34, "079377": 46, "0794": [30, 34], "079471e": 36, "079852e": 36, "08": [31, 34, 36, 39, 41, 44, 45, 46, 56], "080": 44, "08002986030": 32, "080084": 34, "080165": 34, "080319": 32, "08031924": 32, "080694": 38, "080734": 29, "0808": 34, "081": 27, "08116": 34, "081167": 46, "081292": 45, "08151507e": 38, "081837": 46, "082": 31, "082100": 34, "082251": 33, "082265e": 46, "082749": 30, "082835": 38, "082949": 30, "083": [30, 34, 37], "083123": [31, 32], "083338": 29, "083545": 35, "083615": 34, "083813": [31, 32], "084288": 34, "084746": [31, 32], "085150": 45, "085415": 38, "085477": 35, "085508": 36, "085546": 36, "085550": 36, "085551": 36, "085693": 34, "085698": 36, "08613": 34, "086461": 39, "086932": 29, "087": 32, "087128": 34, "087668": 34, "087996e": 34, "088": 44, "0880": 31, "088543": 34, "088948": 30, "089294": 34, "089313": 34, "089485": 29, "09": [29, 32, 34, 36, 45, 46, 56], "090000": 35, "09009799": 36, "090231": 38, "090376e": 36, "090453": 35, "090473": 34, "09058097218": 27, "090785": 36, "091": 44, "091243": 34, "091625": 39, "091819": 29, "092": 37, "092072": 34, "092123": 34, "0922": [30, 34], "092204": 29, "09245358900622544": 34, "092454": 34, "092604": 29, "092660": 46, "092670": 34, "092729": 34, "092930": 32, "093051": 34, "0931": 34, "093228": 39, "093390": 30, "09345386": 32, "093454": 32, "093624": 29, "093787": 34, "093893": 34, "094": 27, "094290": 46, "09430199": 32, "094302": 32, "094581": 32, "094586": 35, "094725": 34, "094863": 34, "095018": 34, "09503409246217484": 36, "095177": 34, "095345": 34, "09573445": 34, "096462": 36, "096692": 31, "096722": 34, "096858": 34, "096927": 35, "096960": 36, "096990": 29, "096997": 44, "097": 44, "09706504": 44, "097088": 46, "097184": 34, "097293": [31, 32], "097516": 31, "097707": 34, "097763": 34, "098": [33, 44], "098152": 34, "098307": 36, "098326": [30, 44], "098559": 34, "098629e": 34, "098663": 34, "0989147678053208": 33, "098915": 33, "098950": 34, "098966": 31, "099": 37, "099230": 38, "099240": [31, 32], "099454": 34, "099558": [31, 32], "099685": 36, "099723": 31, "099729": 34, "099749": [45, 56], "099802": 34, "099869": 34, "0x1227a36e0": 8, "0x1577111f0": 34, "0x16888d4c0": 34, "0x168921100": 34, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38, 43, 45, 47, 48, 57], "10": [4, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57], "100": [28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 44, 45, 46, 53, 56], "1000": [29, 30, 32, 33, 34, 35, 36, 38, 39, 44, 45, 46, 47, 48, 53, 54], "10000": [28, 32, 33, 34, 36, 45, 56], "100000": [30, 32, 33, 34, 36, 45, 56], "1000000": 34, "100103": 45, "100105": 34, "100139": 32, "100146": 45, "100248": 30, "100275": 39, "1004": 30, "1005": [45, 56], "1006": [45, 56], "1007": [45, 56], "1008": [45, 56], "100882": 35, "1009": [45, 56], "10092665203438746": 36, "101": [9, 10, 40, 44, 46], "1010": [45, 56], "1012": [45, 56], "101259": 36, "1014": [34, 44], "1015": [44, 45, 56], "1016": [44, 45], "101688": 34, "1017": [44, 45, 56], "101796": 36, "1018": [44, 45, 56], "101810": 29, "101832": 34, "101894": 35, "1019": [44, 45, 56], "102": [35, 36, 55], "1020": [34, 39, 44, 45, 56], "102044": 39, "1021": [44, 45, 56], "102135": 35, "1022": [44, 45, 56], "1023": [44, 45, 56], "1024": [32, 44, 45], "102435": [30, 36], "102474": 32, "10247431": 32, "1025": [45, 56], "10254": 45, "1026": [33, 45], "1027": [45, 56], "10273": 36, "10274": 35, "1028": [45, 56], "1029": [45, 56], "103": 46, "103023": 34, "1031": 45, "103219": 39, "103222": 44, "1034": 39, "103439": 32, "1039": [45, 56], "104": [30, 31, 37, 40, 44], "1040": 31, "104070": 36, "1041": [36, 38, 45, 47, 56], "10416666666666667": 42, "1042": 34, "1044": 27, "104596": 34, "104643": 36, "105": 37, "1050": 28, "105080": 39, "105089": 32, "10513": 45, "1053": 47, "105314": 45, "10556679": 40, "105656": 38, "10584063": 44, "106000": 31, "106023": 36, "106112": 45, "106180": 45, "106319": 45, "106322": 45, "106424": 45, "106452": 30, "10645223": 30, "10653": [45, 56], "106705": 45, "106764": 34, "1068": 47, "106816": 45, "1069": 47, "106996": 34, "107": 37, "1070": 39, "107050": 45, "107292": 45, "1075": 47, "107502": [45, 56], "1076": 32, "107718": 34, "10781": [37, 38], "107917": [45, 56], "10793260e": 44, "107947": 36, "107985": 36, "107991": 35, "108": 27, "1080": 27, "10800": 27, "1085": 33, "10868": 45, "108681": 30, "1089": 36, "10910": 45, "10931": 32, "109526": 35, "1099": 36, "10_000": 46, "10th": [34, 35, 37, 38, 54], "10x": 35, "11": [1, 10, 11, 19, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 46, 47, 49, 51, 56, 57], "110": [33, 44], "110316": [45, 56], "110319": [45, 56], "1104": 30, "11057": 45, "1106": 39, "110645": 36, "110915e": 36, "111": [31, 34, 35, 36, 46, 54], "11121453": 40, "111215": 40, "111220": 45, "111438": 39, "111543": 36, "112": 30, "1122": [36, 38, 47], "1123": [34, 47], "112441": 34, "112490": 34, "112527": 38, "112848": 36, "11331": 47, "11336331e": 38, "113600": [31, 32, 52], "1138": 39, "113837": 36, "1139": [36, 38], "113949e": 46, "114": 31, "1140": [27, 36, 38], "114000": [31, 39], "114079": 34, "114214": 34, "114507": 44, "11457": [36, 38], "114766": 38, "114836": 39, "114966": 38, "115": 32, "1150": 27, "115083": 31, "115089": 45, "11509": 36, "115090": 45, "115091": 45, "115092": 45, "115183": 34, "115276": 46, "115401": 36, "115406": 30, "115428": [45, 56], "115956": 33, "116": 31, "116145": 39, "116167": 33, "116443": 39, "116497": 36, "11664": 47, "11693": 36, "117": [31, 32, 33, 39, 52], "117058": 33, "117379": 34, "117380": 31, "117412": 36, "117528": 39, "11758": [45, 56], "117612": 44, "117712": 45, "117816": 31, "117899e": 36, "1179": 31, "118": [31, 32, 33, 36, 38, 39], "1180": 28, "118182": [31, 32], "118347": 36, "118450": 35, "118563": 39, "11886432": 34, "118874": 36, "118934": 35, "11898": 35, "119": [31, 32, 33, 39, 45, 52, 56], "1190": 31, "119049": [45, 56], "11909976": 40, "119100": 40, "119400": 31, "119570": 39, "119911": [45, 56], "11th": [35, 37, 38, 54], "12": [10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57], "120": [30, 31, 33, 36, 37, 44, 45, 48], "1204": 30, "120769e": 36, "121": [27, 31, 32, 33, 34, 37, 39, 45], "1210": 34, "121056e": 36, "121084e": 36, "121351": 38, "12138": 31, "1214": 36, "121438": 46, "12150684": 33, "121531": 35, "121599": 38, "121628": 30, "1217": 46, "12178": 39, "121846": 38, "121985": 36, "122": [27, 28, 29, 31, 32, 39, 44, 50, 55], "1220": [27, 31, 34], "1222": 34, "122307": [31, 32], "122331": 36, "12266": 43, "122668": 34, "123": [4, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "123367": 36, "1235387316046016": 34, "123539": 34, "124": 31, "1240": 27, "1241": [36, 39], "1243": 31, "12436984": 32, "124370": 32, "1247": 34, "12498": 38, "124982": 39, "125": [8, 36], "1250": [31, 32, 52], "12508": [36, 38], "125440e": 36, "125476": 30, "125523": [45, 56], "1256": 48, "125617": [45, 56], "125644": 36, "1258": 46, "126": 39, "126238": 39, "126398": [31, 32], "126488": 40, "12649": 31, "126500": 31, "126563": 34, "126808": [31, 32], "127": [29, 31, 33, 34], "127086": 31, "127087": 46, "1271": 37, "127107": 38, "127226": 32, "127242": 36, "1273": 38, "127326": 36, "1274": 39, "127418": 36, "127439": 36, "127441": 36, "127614": 36, "12761659": 36, "127878": 30, "1279": 36, "128": 47, "1280": [31, 34, 36], "1281": 36, "128188": [31, 32], "128384": 36, "128528": 36, "128820": 45, "128828": 45, "128829": 45, "128830": 45, "128984": 36, "129": [30, 33, 39, 46, 55], "1290": [31, 32], "12906": 27, "129257": 36, "12927": 27, "129300": [31, 32, 52], "129459": 39, "129600": 36, "129900": 35, "129904": 36, "129985": 31, "12th": [35, 37, 38, 54], "13": [8, 10, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 42, 45, 46, 47, 49, 52, 56], "130": [27, 28, 29, 30, 31, 32, 34, 36, 38, 39, 50, 52], "1300": [36, 38], "1302": 35, "130395": [45, 56], "1304": [30, 46], "130432": [45, 56], "130690e": 36, "1307": 36, "131": [31, 37, 45, 46], "131000": 36, "13107": 45, "131275": 35, "1313": 36, "1314": [36, 38], "131607": [36, 38], "131773": 46, "1319796954314723": 37, "132": 46, "1320": 39, "1321": 27, "132158": 36, "132292": 39, "13229595e": 38, "13255": 45, "132875": [31, 32], "132886": 45, "133": [34, 46], "133000": 36, "133210": 34, "133270": 36, "133337": 36, "133562": 46, "13392236": 44, "134": [28, 29, 32, 33, 50], "1340": 28, "134061": 39, "13407": 38, "134287": 35, "1346": [31, 36, 38, 39, 46, 47], "134615": 33, "134658": 31, "1347": 47, "134894": [45, 56], "135": [45, 46, 56], "135134": [45, 56], "135197": [45, 56], "13521135": 38, "135299": 39, "135305": [31, 32], "135384": 36, "135422": 36, "1357": 27, "136": [31, 32], "1360": 28, "13665": [31, 32, 52], "136714": 35, "1370": [27, 30, 34, 46], "13704": [36, 38], "137410": 40, "137500": [31, 32, 52], "1378": 36, "138": 47, "1380": 27, "138103": 44, "1383": 34, "138503": 39, "138528": 33, "138876": 46, "1389": [31, 36, 38], "139": [31, 47], "1390": 27, "139297": 35, "139317": 35, "139322": 35, "139349": 35, "13941": 35, "139554": 35, "1396": 34, "1397": 34, "14": [10, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 41, 42, 44, 45, 46, 49, 56], "140": 31, "140185": 39, "1404": [30, 46], "1405": 39, "1406": [31, 36, 38], "140641": [45, 56], "140953": [45, 56], "141": [31, 33], "141232": [45, 56], "14159265358979323": 8, "14160": 35, "141851": [45, 56], "142": 37, "142193": [45, 56], "142199": [45, 56], "1423": 35, "142398": [45, 56], "142467": 29, "142806": [45, 56], "142857": 32, "14289": [31, 32, 52], "143": [34, 35], "143693": [45, 56], "143803": 39, "1438387200": 45, "1438398000": 45, "1438408800": 45, "1438419600": 45, "1438430400": 45, "1438441200": 45, "1438452000": 45, "1438462800": 45, "1438473600": 45, "1438484400": 45, "143975": [45, 56], "144": [27, 34], "144000": [36, 38], "1441": 47, "144199": [45, 56], "144686": 38, "14471": [31, 32, 52], "144729": 45, "144730": 45, "144731": 45, "144732": 45, "144733": [45, 56], "144750": 30, "14485": 36, "145": [45, 56], "1452": 39, "145425": 36, "145454": [45, 56], "145455": [45, 56], "145456": [45, 56], "145457": [45, 56], "145458": [45, 56], "145459": [45, 56], "145460": [45, 56], "1457": [31, 32, 46, 52], "14579": 39, "1458": [31, 32, 52], "145833": 42, "146": [27, 37], "1460": [36, 46], "1465": [31, 32, 52], "146656": [45, 56], "1467": 39, "146767": [35, 38], "146809": 35, "146830": 35, "14690": 32, "147": 38, "147166": [37, 38], "14716638": 38, "147641": 36, "1477": 47, "147737": 44, "147893": 31, "147898": 35, "148": [30, 34, 38, 48], "14813": 45, "148141": 37, "148343": 36, "148349": 46, "14841": 35, "149": 46, "14970": 31, "149788": 38, "149822": [31, 32], "14999": 31, "15": [8, 10, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 45, 46, 47, 49, 50, 54, 56], "150": [30, 34, 36, 44], "150000": [35, 42], "150115": 34, "15026771": 36, "150395": 30, "1504": 30, "1505": 31, "150mb": 35, "150p": 27, "151357": 39, "152": 45, "1520": 34, "152401": 35, "152859": 35, "1530": 27, "1534": 31, "15377": [31, 39], "1540": 27, "154076": [35, 38], "154105": 39, "15429": 45, "154386": [31, 32], "1545": 39, "154795": [36, 38], "154842": 46, "155": [27, 34], "15500": 36, "155178e": 36, "15559528e": 38, "155624": 36, "156": [31, 34, 35], "1562": 34, "156311e": 36, "1564": 34, "15661": 45, "157": [27, 34, 44], "157008": 36, "157157": 47, "157234": 39, "15725": [31, 39], "15775": 45, "1578": 38, "15795": [35, 38], "158": 34, "1580": 27, "1582": 38, "158867": [45, 56], "158982": 36, "159": 34, "1590": [30, 34], "15915": 45, "15992": 38, "16": [10, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 45, 46, 47, 49, 50, 56], "160": [29, 30, 33, 34, 36, 38], "160000": [36, 38], "160258": 29, "160282": 39, "1604": 30, "160506": 35, "160634": 44, "16063983": 32, "160640": 32, "160727": 38, "160729": [45, 56], "161": 31, "1610243052583638": 33, "16111330565237164": 33, "1613": 31, "16153": 45, "16157": 45, "16160": 45, "161606": [31, 32], "161782": 35, "1619": 34, "161931": [36, 38], "162": 27, "162000": 36, "162007": 47, "162330": 35, "162667": [35, 38], "1627": 39, "162904": 46, "1631": 34, "163195": [31, 32], "163397": [31, 32], "1634": [31, 32, 34, 52], "16358": 45, "164": [39, 44], "1645": 33, "16460": 39, "164679": 35, "165": [33, 36], "1650": [30, 34], "16507": [33, 39], "16508": [33, 39], "16509": [33, 39], "16510": [33, 39], "16511": [33, 39], "16512": [33, 39], "165198e": 36, "1652": [29, 33], "16533": 45, "165485": 38, "165617": 45, "165811": 34, "16630": 39, "166631": [31, 32], "167": 29, "167214": 30, "167241": 47, "16736": 43, "167600": 39, "167620": 44, "168": 36, "1680": 28, "168151": 44, "168196": [31, 32], "168244": 38, "1687": 34, "169": [29, 33, 39], "1690": [27, 28], "169269e": 46, "169421": 34, "169693": 30, "169748": 33, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 25, 28, 30, 31, 32, 33, 34, 35, 36, 39, 45, 46, 49, 52, 56], "170": [31, 41], "170100": [31, 32, 52], "170277": [37, 38], "1704": 30, "17054987": 44, "170670": 36, "170931": 44, "171": [27, 44], "17144": 45, "171468": [36, 38], "1715": 34, "171657": 29, "171899": 46, "1720": 31, "17205": 45, "172792": 35, "173": [30, 34], "173025": 34, "17393037": 8, "1739787032867638": 34, "173979": 34, "174": [27, 30, 34], "174590": 35, "174766": 39, "1750": 31, "175000": [36, 38], "17518": 45, "176": 31, "1766": 36, "176924": 46, "177": 39, "17730": [31, 39], "177709": 46, "178": [27, 36], "178494": 36, "17896": 45, "179": [37, 46], "179080": 35, "179123": 30, "179300": 31, "179730": 34, "17973005068132514": 34, "179802": 36, "18": [10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 45, 46, 47, 49, 52, 56], "180": [34, 36, 44], "1800": [27, 28, 30, 34], "18000": 45, "180000": 28, "180279e": 36, "180388": 30, "1804": 30, "180900": 39, "18096": 45, "181": 46, "18113": 45, "18116": 45, "1813": 34, "182": [45, 46], "18201414": 38, "18245": 45, "182639": 36, "182648": 36, "18311": 45, "18313": 45, "18317085": 8, "183179": 46, "183423": 30, "183471e": 36, "18365": 32, "18391": [31, 32], "184": [45, 46], "1840": 27, "184405": 38, "1847": 32, "185": 46, "185155": 38, "185175": 46, "18533": 45, "1854": 34, "185707": [30, 34], "18571": [31, 32], "18572": [31, 32], "18573": [31, 32], "18574": [31, 32], "18575": [31, 32], "18576": [31, 32], "1858": 39, "185868": 39, "185975": 38, "18597545": 38, "186024": 27, "186814": 35, "186899": 35, "187": [29, 33, 37], "1870": 34, "187000": 31, "1872": 36, "1875": 33, "187503": 45, "187663": 30, "187700": 31, "188": [27, 29, 33], "1880": 34, "1886": 33, "1887": [35, 38], "18955": 45, "189981": 36, "19": [8, 10, 27, 28, 29, 30, 32, 34, 35, 36, 39, 42, 46, 47, 49, 56], "190": [29, 36, 39], "19000e": 30, "1901": 27, "190319": 39, "19032": 45, "1904": 30, "190617": [31, 32], "191": [29, 31], "1911": 39, "191169": [36, 38], "191204": 39, "191250": 29, "191396": 30, "191700": 39, "1918": 32, "191k": 38, "1920": 27, "19213263": 32, "192133": 32, "19266": 45, "1927": 47, "1928": 47, "193": 44, "1930": 27, "193021": 35, "193122": 35, "193247": 39, "1933": 28, "193346": 38, "193427": 34, "19365": 45, "193704": [45, 56], "19380": 45, "1940": 32, "194002": 30, "194034": [45, 56], "194040": 31, "19422": 38, "1945": 36, "1946": [27, 36], "194710": 36, "19485": 31, "194985": 36, "195": 31, "1950": 36, "1951": 28, "195228": 32, "1953": [34, 36], "19536": 35, "1954": 43, "1955": 28, "195564": 39, "1957": 43, "1959": 27, "19591": 39, "1960": 28, "1963": 34, "196385": 38, "1965": 28, "196599": 36, "1966": 36, "196717": 44, "196739": 45, "1968": 27, "1970": [33, 36, 45], "1972": 36, "197649": 39, "1977": [27, 46], "19777": [37, 38], "19781": 45, "198": [44, 47], "198127": 36, "1984": 36, "1985": 36, "198629": 44, "198645": 46, "1987": [27, 28], "1989": 27, "198924": [31, 32], "199": [27, 30, 35], "1990": [30, 33, 34], "1991": [28, 37], "1992": [45, 47], "1993": 36, "199364": 35, "1994": 27, "199412": 46, "199413": [30, 34], "19966": [31, 32, 39], "1997": [33, 34], "199771": 38, "1_000_000_000": 34, "1d": 44, "1e": [34, 36, 53], "1e3": [34, 53], "1e4": 34, "1h": [31, 32, 39], "1st": [8, 35, 37, 38, 45, 54], "1stflrsf": [36, 38], "1v": 48, "1v2": 48, "1v3": 48, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 37, 38, 39, 43, 44, 45, 47, 48, 57], "20": [4, 8, 10, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 47, 48, 49, 51, 52, 56, 57], "200": [27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 44, 50, 51, 52, 53, 54], "2000": [30, 34, 35, 36, 37, 38, 39, 44, 48, 53], "200000": [34, 45, 56], "200326e": 36, "2004": 36, "200475": 35, "2006": [36, 38], "2007": [36, 38, 45, 56], "2008": [36, 38, 45, 56], "200876": 32, "20087625": 32, "2009": [36, 38, 45], "200978": 30, "200k": 54, "201": [30, 57], "2010": [36, 38, 45], "20113": [31, 32, 52], "2012": [8, 31, 34], "2013": [43, 45, 56], "201332": 41, "2014": [27, 37, 45], "2015": [44, 45, 56], "20150630": [45, 56], "2016": [8, 44, 45], "20160101": 45, "2017": [38, 45, 56], "201810": 35, "201862": 39, "202": [30, 32], "2020": 47, "2022": 45, "2023": [10, 45], "2024": [0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56], "20248": 31, "2024w1": 44, "2025": 1, "2025s1": [0, 11], "20274": 45, "202839": 35, "203": 30, "20310": 45, "20311": 39, "20319": 45, "203265": 38, "20334": 45, "203421": 36, "203500": 31, "20357847293371892": 33, "204": [28, 29, 30, 34, 50], "204167": 29, "2043": 46, "204302": [45, 56], "20433": 39, "204583": 29, "2046": 32, "204600": [30, 34], "204692": 36, "204734": 35, "20485": 45, "205": [28, 29, 30, 47, 50], "205000": [31, 32, 36, 38, 52], "205059": 39, "20509": 45, "20514": 45, "205144": 39, "205323": [45, 56], "205479": 33, "205597": 36, "20564": 45, "206": [28, 29, 30, 34, 35, 50], "206041": 38, "206073": 35, "206099": 34, "20620": 45, "206292": 31, "20639": 39, "2064": 31, "20640": [33, 39], "206724": 46, "20683258": 33, "20694": 45, "207": [28, 29, 30, 31, 34, 44, 50], "207039e": 36, "2071": 39, "207814e": 36, "20794": 45, "208": [28, 29, 30, 33, 34, 50], "209": [27, 28, 29, 30, 34, 50], "209583": 29, "209746": 35, "209903": 39, "20analysi": 46, "20assumpt": 46, "20hazard": 46, "20intro": 46, "20learn": 44, "20lifelin": 46, "20with": 46, "21": [10, 27, 28, 30, 31, 32, 35, 36, 39, 40, 42, 45, 47, 56], "210": 34, "210001": 35, "210240": 34, "210272": 39, "210591": [31, 32], "210779": 45, "21086181023099526": 33, "211": 34, "2110": 31, "211250": 29, "211343": 39, "211544": 35, "211892": [31, 32], "212": [29, 34], "212385": 38, "212581": 39, "21274": 45, "212870": 36, "212975": 36, "213": [34, 44, 45], "2130": 27, "21353": 45, "21382972": 37, "21389": 45, "2139": [31, 32, 52], "214": [27, 32, 34], "21405": 45, "2144": 34, "214740": 31, "214769": 44, "214821": 45, "214852": 35, "215": 34, "215245": 36, "21530": 45, "215412": 36, "21549": 45, "21571": 45, "21581": 45, "215865": 38, "21596": 45, "216": 34, "21603": 45, "21605": 45, "216123": 46, "21613": 28, "21616484": 48, "21617": 45, "216346": 38, "21634631": 38, "216585": 31, "216596": [45, 56], "21668": 45, "21670": 45, "216718": 35, "216728": 31, "21694": 45, "21697": 45, "2170": 28, "217334": 32, "21733442": 32, "21767954": 38, "21768": [38, 45], "217680": [37, 38], "21774": 45, "218207": [31, 32], "21847": 45, "21872": [36, 38], "218760": 38, "218830": 31, "219": 39, "2190": 31, "2192": 34, "219512": 39, "219700": 39, "219845e": 36, "22": [10, 30, 31, 32, 34, 35, 36, 37, 38, 39, 45, 46, 47, 48, 52, 56, 57], "220": 29, "22001": 38, "220392": 46, "22057": 45, "2206": 46, "22078": 45, "2210": 27, "22114": 45, "221329": 36, "221348": [45, 56], "2214": 47, "22154": 45, "221622": [31, 32], "22168237": 48, "221900": 28, "22219": 45, "22221894": 36, "222222": 31, "22225": 45, "222307": 31, "222500": 29, "22260": 45, "222647": [36, 38], "2229": 33, "222963e": 36, "22305705": 37, "22320": 45, "223333": 29, "223460": 46, "223750": 29, "223804": 38, "224": [34, 44], "22452": 45, "2246468746": 29, "224662": 36, "22471154513694713": 33, "224865": [36, 38], "225": 44, "225301e": 36, "2254": 31, "22550": 45, "226": 34, "226415": 31, "226789": 46, "2268": 37, "22697768": 32, "226978": 32, "2270": 34, "227143": 31, "2272": 35, "227304": 45, "22741": 39, "227559": [36, 38], "227836": 35, "22788": 45, "22811601": 33, "22826": 45, "228329": 35, "2285": 45, "228603": 36, "228750": 29, "229": 44, "229000": 31, "22910": 45, "229102": 38, "2293467570951035": 37, "2295": 45, "229583": 29, "229718": 38, "22974": 43, "23": [10, 30, 31, 32, 33, 34, 35, 36, 39, 45, 46, 52, 56], "230": [30, 34], "2300": 27, "23011": 38, "2305": 38, "2307": [29, 33], "2309": 45, "23091772": 37, "2310": 45, "2311": 45, "2312": 45, "2313": 45, "23175": 45, "231815": 38, "232143": 32, "232751": 46, "23290": 45, "233": 28, "234": 46, "234040": 35, "234436": 46, "235": 39, "235096": [31, 32], "235152": 30, "235417": 29, "235706": 39, "236": [30, 34, 46], "236096": 44, "236174": 39, "236210": 40, "23621041": 40, "23640124": 33, "236456": 31, "23654": [35, 38], "236960": 34, "237": [35, 46], "237895": 35, "237935": 38, "238": [35, 46], "238192": [35, 38], "2389": 32, "239": 46, "23902": 45, "23941": 45, "239944e": 36, "24": [1, 11, 27, 30, 31, 35, 36, 37, 38, 39, 44, 45, 46, 56], "240": 46, "2401": 39, "240893": 39, "241": 46, "241489": 46, "241620": 35, "24182": 45, "242015": [37, 38], "242083": 29, "242169": 35, "242381": 45, "24295676": 32, "242957": 32, "242996": [31, 32], "243": 45, "243243": 36, "2435": 39, "2436": 39, "24395": [37, 38], "24397122221206388": 45, "244": 45, "244592": 30, "2447": 37, "244814": 46, "245": 45, "2451": 34, "245329": 36, "245521": 35, "245686": 35, "246": 45, "246332": 36, "246646": 34, "246646103936": 34, "246653": 34, "247": 45, "247119": 45, "247439": 40, "24743939": 40, "247690828913": 34, "247691": 34, "248": 45, "248328": 37, "248333": 29, "2484": 27, "248457": [36, 38], "248609": 36, "248664": 39, "2488": 30, "248999": 46, "249": 47, "2496": [29, 33], "249601e": 36, "249618e": 36, "249720": 30, "24h": 35, "25": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57], "2500": [8, 47], "250000": [31, 35, 36], "25031": 45, "25037": 45, "2506": [28, 29, 50], "250900": 36, "251093": 34, "251158e": 36, "2516": 37, "25176": 45, "251769": 44, "252042": 39, "25214": 45, "252160": 30, "252859": 38, "2530": 27, "2533": [29, 33], "253312": [31, 32], "253432": 38, "253724": 30, "253914": 36, "254380": 46, "254443": 35, "255": 31, "2551": 47, "255134": 44, "2556": 37, "255751": 39, "255889": [45, 56], "256": [27, 44], "25622": 45, "256263": [37, 38], "256333": 31, "256437": 39, "25658": 39, "256813": 30, "257": 28, "2570": [27, 28], "257024": 34, "257103": 35, "2574": 39, "2580": 27, "258225": 45, "25823": 35, "258387": 38, "258427": 30, "258886": 35, "259": [36, 39], "25904": 45, "2590575478171884": 33, "259286": 30, "259500": 31, "26": [8, 10, 27, 30, 31, 34, 35, 36, 37, 38, 39, 40, 45, 46, 56], "2600": [31, 32, 52], "260258": 39, "26048": 38, "260572": 36, "26063": 45, "260890": [36, 38], "261035": 36, "261953": [45, 56], "262": [36, 38, 46], "262079e": 36, "262156e": 36, "262269e": 36, "2623": 36, "262361": 39, "262500": 36, "263": 36, "2630": 31, "26307": 43, "263541": 46, "263600": 31, "26370005": 33, "263736": 46, "263742e": 36, "26376": 45, "264195": 46, "264283e": 36, "26447953": 32, "264480": 32, "265": 37, "265273": 33, "266120": [45, 56], "266135": [31, 32], "2670": 34, "267612e": 36, "268": 34, "2683": 35, "26831": 45, "2691": [28, 29, 50], "26919": 39, "269689": 35, "269880": 30, "269972": [36, 38], "27": [8, 30, 32, 34, 35, 36, 45, 46, 56], "270093": 34, "270093376167": 34, "27021": 45, "270270": 42, "27048": 35, "2705": 34, "271037": 39, "271287": 45, "271500": 39, "271738e": 36, "2720": 28, "27206": 45, "27263": 38, "272667": [31, 32], "2730": 31, "273382": [31, 32], "273606": [31, 32], "273890": 44, "273962": 39, "274": [31, 32, 45, 52], "274404": 31, "275008": [45, 56], "27502379069": 36, "275290": 35, "275352": 30, "275410": 33, "2759": 38, "276": 31, "27638": 45, "27652": 35, "276687": 36, "27676": 35, "27678": 35, "276943e": 36, "27697": 35, "2770": 34, "27705": 35, "27715": 35, "277381": 30, "2777": 46, "278441": [45, 56], "278634": 35, "27874871715903093": 33, "278755": 32, "27875502": 32, "2788": [29, 33], "2794": 33, "28": [10, 30, 31, 32, 33, 34, 35, 36, 39, 40, 45, 46, 56], "280": [31, 39, 47], "2800": 8, "280028": 39, "280310": [31, 32], "2806": 34, "280618": 35, "2807": 46, "280801": 46, "281": 31, "28122025543": 36, "281583": 36, "2817": 38, "2820": 34, "282021e": 36, "2822": 38, "282600": 46, "283119e": 36, "28327": 45, "283421": 36, "2836": 38, "28362": 45, "283857": 30, "283921": 31, "284": [39, 45], "2845": 46, "2846": 47, "2847": 47, "285": [31, 32, 45, 52], "285263": 38, "28526302": 38, "285467": [36, 38], "28571429": 28, "286": [29, 30, 34, 45], "286000": 34, "286200": 39, "286416": 32, "2865025": 48, "286821": 30, "287": 45, "287031": [45, 56], "287079e": 36, "287344": [31, 32], "287500": 39, "288": 45, "288002": [45, 56], "288462": 33, "28854": 45, "28868": 35, "289": 45, "2890": [30, 34], "28953": 45, "289541": [36, 38], "289799": 30, "29": [8, 30, 31, 35, 36, 45, 46, 47, 56], "290": 45, "290002": 35, "290424": 36, "29045704": 36, "290961e": 36, "291": [33, 45], "291667": 42, "292": 45, "292587": 46, "293": 45, "29324459": 44, "293663": 35, "294": [31, 43], "294251": 32, "2948": [31, 32, 52], "294855": 38, "2953863599856862": 33, "295397": 35, "29545": 36, "296": [31, 47], "296601": 39, "29691": 45, "297": 33, "29802": [35, 38], "298561": 46, "298612": [45, 56], "29881": 45, "298813": 35, "299": 44, "299164": 39, "2d": 44, "2d454e5fd9a5": 46, "2e": 10, "2f": [29, 34, 42, 45], "2nd": 33, "2ndflrsf": [36, 38], "2v": 48, "2v3": 48, "3": [7, 8, 10, 11, 14, 16, 17, 18, 30, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 48, 49, 57], "30": [4, 10, 27, 29, 30, 33, 35, 36, 37, 38, 39, 45, 46, 47, 56, 57], "300": [30, 41, 43, 48], "3000": 44, "300000": [31, 32, 45, 56], "300464": 39, "300837": 35, "301": 46, "3010": 39, "301200": 34, "3014": 39, "30146": 45, "301563": 36, "30167": 45, "301784": 46, "3019": [28, 29, 33, 50], "301952": 39, "302": [36, 38], "302131": 36, "30279": 45, "302801": 46, "302844": 46, "303": [36, 38], "303000": 31, "303004": 39, "303030": 33, "303109": 32, "303790": 34, "3038": 47, "3038344082": 38, "303916": 30, "304": 30, "3040": 45, "3041": 45, "3042": 45, "3043": 45, "3044": 45, "304784": 36, "305": 27, "30504657": 40, "305047": 40, "30530902": 30, "305346": 30, "305674": 39, "3057": [29, 33], "30573": 39, "306": 47, "306500": 30, "306564": 44, "307": 31, "3075": 47, "307516": 44, "307521": 33, "308120": 31, "30815": 36, "308216": 44, "308220": 35, "308448": 30, "3089": 34, "309": 39, "3092": [28, 29, 50], "309249": 44, "309859": 33, "31": [10, 27, 30, 31, 32, 33, 35, 36, 37, 38, 40, 45, 46, 47, 52, 56], "310": 57, "310000": 31, "31000e": 30, "310284": 38, "310405": 35, "311": 31, "3110": 31, "311151": 46, "31127015": 38, "311310": 27, "311769": 39, "31196406381465247": 33, "3120": 31, "3125": 31, "312500": 42, "312501": [36, 38], "312696": 47, "3129": 47, "31297381": 32, "312974": 32, "31298589e": 44, "313": [32, 36], "3130": 47, "31384": 35, "314": 31, "3140": 31, "314000": 34, "31449687e": 38, "31454": 39, "314582": 38, "314840": 39, "314929": [45, 56], "315134": [45, 56], "315630": 35, "316164": 39, "316230": 39, "316363": 30, "316395e": 36, "316426": 39, "316552": 32, "31655231": 32, "316798": 39, "317": [31, 38], "317277": 39, "317761": 35, "318": 31, "3180": 34, "3180174485124284": 31, "318937": [31, 32], "319": [28, 31], "31908384": 44, "319630": 46, "31984311": 36, "31st": 45, "32": [8, 30, 31, 32, 33, 34, 36, 40, 45, 46, 52, 56], "320": 31, "320155": 35, "320430": 36, "32064171": 37, "321": 38, "32127053": 36, "322": 39, "32240": [37, 38], "32247597e": 38, "322755": 30, "323045": [31, 32], "32323": 27, "32397724e": 38, "3245": 27, "3252": 39, "325319": 39, "32561": 35, "326": [31, 39], "326730": 35, "326741e": 46, "326933": [30, 34], "327188": 35, "3272": 46, "327283": 36, "32734": 39, "3274": 46, "327408": 35, "328": 39, "328077e": 36, "328799": 35, "328953": 30, "3298721": 44, "3299": 47, "33": [8, 27, 30, 31, 32, 33, 34, 35, 36, 39, 45, 46, 56], "330": [9, 10, 11, 27, 28, 44, 45, 47, 57], "33000e": 30, "330346": 46, "3310": 31, "332125": 35, "332130": 36, "332671": 38, "3327": 45, "332710": 36, "332746": 46, "332791": 46, "332824": 36, "3330": 31, "33308783": 32, "333088": 32, "333139": 35, "333333": [28, 31, 34, 42], "3333333333333333": [42, 44], "333340": 30, "3334": 47, "334": 39, "334411": 30, "334576": 36, "335": 37, "335309": 36, "3355": [31, 32, 52], "3356700488_183566145b": 44, "33590": 45, "336389": 38, "33641142": 38, "3364114233677307": 38, "336411423367732": 38, "336735": 34, "336826": 32, "33682642": 32, "33683087": 33, "336831": 33, "337034": 39, "33726089": 36, "338": [30, 34], "33888659": 8, "339": 35, "339368": 46, "339889": 46, "34": [27, 30, 31, 32, 33, 35, 36, 39, 45, 46, 52], "340": [3, 10, 28, 37, 39, 44, 45, 46], "34000e": 30, "340988": 35, "341109": 36, "341300": 39, "341571": 46, "34161762": [36, 38], "341712": [45, 56], "34182": 38, "3420": 31, "342200": 39, "342605e": 36, "3436": [45, 56], "3437": 47, "3438": 47, "344": 31, "3442": 46, "34426571": 36, "34441": 36, "345": 38, "345136": 30, "345386e": 36, "3454": [46, 47], "3455": 47, "345831": 27, "346": [31, 32, 52], "346850": 35, "34691": 45, "347523": 34, "348": [31, 39], "34806": 36, "34900": 36, "35": [30, 31, 33, 35, 36, 37, 38, 45, 46, 47, 51, 55, 56], "350": 27, "3500": 51, "350000": 31, "351351": 42, "351366": 35, "3515": 46, "3517": 47, "351821": 46, "3520": 46, "3521": 27, "352100": 39, "352930": [31, 32], "353": 44, "35375221": 48, "353961": 34, "354114": [36, 38], "354604": 35, "3547": 39, "354759e": 36, "356689": [37, 38], "35671794": 38, "357": 31, "357500": [31, 32], "3576": 27, "3577": 47, "357823": 27, "358": [27, 34], "358032": 38, "3582": [46, 47], "358264": [36, 38], "3583": 47, "358333": 30, "358500": 39, "358913": 32, "3589134": 32, "359": [30, 34], "3590": 34, "359784": 34, "359887": 40, "359992": 30, "35p": 27, "36": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 56], "360": 32, "360172": 35, "360918": [45, 56], "361": 46, "361718": 35, "362": [46, 47], "362009": 45, "362185e": 36, "362553": 39, "36269995": 32, "362700": 32, "363": 46, "363192": 30, "363913": 35, "364": [45, 46], "364352": 33, "365": 45, "36525": 38, "365420": 47, "365603": 33, "365623": 30, "366": [32, 45, 46], "366005": 35, "3663": 46, "366626": 30, "367": 45, "367329e": 46, "367423": 34, "368": [45, 47], "3681": 38, "368304": 33, "3684": 46, "368922": 41, "369": 36, "369875": 30, "369896": 44, "37": [31, 32, 33, 36, 39, 45, 46, 47, 52, 56], "37050406": 8, "370643": 35, "371": [39, 45, 56], "3717": 38, "371722": 38, "372": 31, "372706": [45, 56], "372763": [36, 38], "373031": 30, "373275": [45, 56], "373656": 45, "374": 31, "374584": 44, "37546": 38, "376": [31, 36], "376089": 36, "37647072": 37, "3768": 47, "3769": 47, "377032": 36, "377619": 34, "377619120792": 34, "37797291": 32, "377973": 32, "378159": 36, "378764": 30, "378971e": 36, "37906": 35, "379416e": 36, "379875e": 36, "38": [8, 30, 31, 33, 35, 36, 39, 45, 46, 56], "3803": 46, "380436": 32, "38043616": 32, "380495": 30, "380504": [31, 32], "380643": 30, "381190": 39, "3814": 32, "381416e": 46, "381428": [36, 38], "381676": 30, "38192364": 40, "381924": 40, "382558": 35, "383": [31, 39], "384111": 47, "384127": 30, "384613e": 34, "3851": 35, "3856": 30, "385639": 40, "386": 34, "386071e": 36, "386530": 38, "387": 34, "388023": 35, "388169": 39, "38853": 36, "3889": 32, "389": [34, 39], "389065": 38, "389349": 39, "389736": [31, 32], "39": [30, 34, 35, 36, 40, 45, 55, 56], "390428669205": 34, "390429": 34, "390725": 36, "39095422e": 38, "391": 31, "3912": 46, "39163": 35, "391996": 44, "392": [27, 46], "392082": 38, "392221": 33, "392385": 46, "392612": 36, "392893": [30, 34], "393": [28, 32], "3932": 46, "39375": 45, "394113e": 36, "394920": 31, "395282e": 36, "395686e": 36, "395688": 46, "395697e": 36, "396": [31, 46], "396266": 44, "396752e": 36, "396991": [31, 32], "397": 46, "398": 39, "398495": [45, 56], "39896994": 32, "398970": 32, "399": 31, "3990": [28, 29, 50], "3991": 36, "39931": 38, "399827": 35, "3blue1brown": 44, "3d": [39, 44], "3f": [28, 29, 30, 31, 35, 36, 42, 43, 47], "3h": 45, "3m": 44, "3rd": 43, "3ssnporch": [36, 38], "3v": 48, "4": [0, 1, 8, 9, 10, 14, 16, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 57], "40": [8, 27, 30, 33, 34, 35, 36, 37, 38, 39, 41, 45, 46, 51, 56, 57], "400": [28, 31, 34, 53], "40000": [44, 45, 56], "400000": [34, 45, 56], "400047": 46, "400157": 39, "400164": 44, "400649628005": 34, "400650": 34, "401": [30, 34], "401102": 45, "401541": 35, "401623": 36, "401830": 38, "401895": 34, "402": 27, "402808": 38, "404": [30, 39], "405": 37, "405227e": 36, "405415": 30, "405650": 36, "406": 44, "406202": 34, "40689": 39, "407": 35, "407234": 44, "40725012": 44, "407510": 35, "40756124": 37, "407862": 46, "4084": 46, "40_000": 44, "40b5a809b05a": 46, "41": [30, 31, 35, 36, 38, 39, 40, 42, 45, 46, 56], "410": 31, "410240": [35, 38], "410599": 39, "411412": 36, "41150573": 36, "412": [27, 30, 34], "412500": 39, "413050": 44, "413718": 46, "413796": 36, "413958": 35, "414": 47, "4143": 46, "4151": 37, "4153": 39, "4158382658": 31, "416": 38, "4165": 37, "4169": 46, "418031": 30, "418069": 34, "41901484361": 34, "419015": 34, "419355": 33, "4195": 38, "4197": [28, 29, 33, 50], "419973": 35, "42": [27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 50, 51, 54, 55], "420": 34, "420000": 27, "4203": 43, "42060": 39, "421": 44, "42104086": 38, "421215": 40, "42121526": 40, "421875": 33, "422": 36, "4234": 38, "4236": 38, "4238": 35, "423852": 35, "424222": 36, "424337e": 36, "425": 37, "425365": 46, "42541681": 48, "425419": 36, "426067": 31, "426410": 30, "427": 46, "428": 46, "429": [36, 38], "429217": 35, "429634": 46, "43": [30, 33, 34, 35, 36, 45, 46], "430": [34, 36, 38, 46], "430323": 31, "430571": 35, "430704": 40, "4307043": 40, "430868": 33, "431": [29, 46], "4310": [30, 31, 34], "431137": 33, "4314": 35, "432": 46, "433": 46, "433514": [45, 56], "433814": 46, "434": [30, 33, 34, 46], "43445": 39, "435": 46, "435186": 30, "435489": 35, "435792": 34, "436": 46, "436492": 36, "43697758253484614": 33, "437": 47, "4372": 40, "437367": [31, 32], "4375": [39, 42], "437500": 42, "437684": 45, "438": 42, "438231": 44, "438275": 32, "43827545": 32, "43833466": 36, "438592": 38, "438906": 38, "439": 31, "4390": [30, 34], "439209": 35, "439360": 31, "439779": 35, "44": [29, 30, 31, 33, 35, 36, 39, 43, 45, 46, 47, 56], "440": [34, 45], "441": 36, "441404": 44, "441445": 39, "442377e": 36, "442806": 30, "4430": 46, "44311": 39, "4432": 39, "443317": 30, "443419": [36, 38], "444297": 39, "444444": 31, "4448": 39, "445": 34, "445111e": 36, "445124e": 36, "44586935": 37, "44586935141902073": 37, "446216": 39, "446284e": 36, "446869": 39, "447": [31, 38], "447461": [45, 56], "447517": 38, "4482": 27, "4484": 30, "448757": 46, "449": 47, "449666": 30, "44966612": 30, "45": [8, 28, 29, 30, 33, 35, 36, 43, 45, 46, 50, 56, 57], "450000": 42, "450132": [45, 56], "450739": 36, "450822": 39, "451888": 35, "452600": 39, "453367": 39, "4537": 46, "454427": [31, 32], "454677": 40, "45467725": 40, "454788": 38, "454966": 35, "455": 32, "4552": 38, "45555535": 38, "45587": [45, 56], "45588": [45, 56], "45589": [45, 56], "45590": [45, 56], "45591": [45, 56], "456": 44, "456419": 39, "45653693": 32, "456537": 32, "456904786": 47, "457435": [45, 56], "45756": 47, "458": 31, "458333": 42, "458524": 46, "459": 36, "4591": 31, "459214e": 36, "459873": 46, "45a": [45, 56], "45am": [45, 56], "46": [8, 28, 29, 30, 31, 32, 33, 35, 36, 45, 46, 47, 50, 52, 56], "460047": 46, "46019608e": 38, "46021": 47, "46075": 47, "4608": [28, 29, 50], "460950": 40, "461": [31, 34], "462060": 46, "462545": 38, "462963": 33, "46299": 47, "463": 35, "463582": 37, "464104e": 36, "465279e": 36, "46530779": 32, "465308": 32, "466246": 44, "4664": 27, "46729488": 36, "467379": 38, "467628": 39, "468": [30, 34, 38], "468232": [45, 56], "4687": 39, "46880": 47, "469": [31, 35], "469383": 35, "4695": 35, "469571": 39, "47": [10, 27, 28, 29, 30, 31, 33, 34, 36, 39], "470": [31, 47], "4700": 34, "470060": 36, "470666": 36, "471032": 38, "472": 47, "47232": 43, "47242662": 48, "4726": 46, "472603": 36, "472790": 35, "473691": 30, "474": 35, "474552": 30, "47491": 35, "475099": 38, "476": 28, "4760": 34, "47606": 39, "476092": [36, 38], "476406": 38, "476412": 40, "47641249": 40, "477": 34, "477291": 39, "47799": 47, "478060": [45, 56], "479109": 30, "479132": 39, "48": [28, 29, 30, 33, 35, 36, 42, 45, 46, 50, 56], "480": 36, "4800": 27, "480249": 30, "48073598": 40, "4809": 34, "481": 31, "4813": [29, 33], "481514": 36, "481793": 31, "481893": 35, "481960": 35, "4822": 46, "483751": 30, "48390": 47, "48407": 47, "484937": 33, "485": 44, "48535": 47, "4854": 38, "486": 38, "4861": [31, 32, 52], "486266": 31, "487": 31, "48721": 47, "4879": 47, "488": 31, "488753": [45, 56], "489130": 33, "49": [30, 33, 35, 36, 39, 45, 46, 55, 56], "490": [39, 48], "490000": 31, "490033": 36, "490568": 34, "491217": 35, "491366": 38, "491379": [31, 39], "492": [31, 35], "492270": 32, "493": [28, 29, 31], "493544": 31, "493921": 32, "494": [30, 31, 34], "4943": 34, "49575": 35, "496": 39, "496213": 36, "496757": 38, "497386": 30, "497787": 36, "498": 35, "498133e": 36, "498562": 30, "499900": 31, "4f": [30, 32, 35, 43], "4m": 44, "4th": [35, 37, 38, 54], "4x": 57, "5": [4, 10, 27, 33, 34, 36, 37, 41, 42, 45, 47, 48, 49, 50, 57], "50": [10, 27, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 53, 54, 56, 57], "500": [27, 31, 35, 37, 38, 39, 54], "5000": [27, 28], "50000": [45, 56], "500000": [31, 32, 35, 36, 41, 45, 47, 56], "500000e": 34, "500001": 31, "5002": 36, "500625": 30, "50062e": 30, "500924": [31, 32], "501": [31, 47], "501071": 44, "501250": 30, "501304e": 36, "501875": 30, "5024752475247525": 34, "502500": 30, "502985": 35, "503000": 31, "503090": 35, "503125": 30, "503750": 30, "504": [30, 39], "504231": 46, "504375": 30, "504429": 32, "504644": 34, "50475372e": 38, "504fde4fcf8": 46, "505335": 35, "505592e": 36, "505625": 30, "5057": 36, "50596432e": 48, "506023": 37, "506035e": 36, "506079e": 36, "506084e": 36, "506211": [31, 34], "506410": 33, "506875": 30, "507130": 34, "507359": [31, 34], "507500": 30, "50774": 34, "507740": 31, "50775": 34, "507750": 34, "507752": [31, 34], "507995": 33, "508": [31, 36], "508125": 30, "508133": [31, 34], "508371": 34, "50884": 39, "50899": 34, "509000": 27, "509001": 36, "509317": [31, 34], "509930": [45, 56], "50k": [35, 37, 38, 54], "51": [30, 31, 32, 34, 35, 36, 38, 40, 45, 46, 52, 56], "510000": [28, 30, 34], "5106": 47, "510836": 34, "5109": 38, "511": 9, "5112": 28, "51137414e": 38, "51143": 39, "51150": 35, "511620e": 36, "5118": 38, "512": 44, "5120": 27, "512000": [30, 34], "51226051": 40, "512319": 31, "512408": [36, 38], "512897": 30, "512x640": 44, "513": 31, "513678": 46, "514155": [31, 32, 36], "514598e": 36, "5146": 33, "515000": 30, "51503393": 32, "515034": 32, "515351e": 36, "5156": [31, 39], "515848": 39, "516394": 39, "517346": 35, "519029": 35, "52": [30, 31, 33, 35, 36, 39, 45, 46, 47, 56], "52061": 45, "5208": 28, "520857": 35, "5209": 36, "5212": 36, "521284e": 36, "521567e": 36, "521578e": 36, "521743e": 36, "522": 36, "522563e": 36, "5238095238095238": 28, "52398": 39, "524": [28, 42], "524364": 46, "5253": 38, "525554": 39, "525757": 30, "526078": [31, 32], "526214": 38, "526596": 39, "526602": 36, "5274": 46, "527500": 31, "528": 36, "5282": 46, "528403": 30, "52881619": 30, "529210": 35, "529388e": 36, "5294": 37, "529412": 31, "53": [33, 36, 45], "530052": 34, "530978": 35, "531116e": 36, "531353": 44, "5315": 34, "532034": 36, "533454": 44, "533498": 30, "534": 47, "534114": 34, "534342": 39, "535": [31, 39], "535014": 31, "53520104": 30, "535604": 31, "535622": 39, "536362": 40, "53636249": 40, "537267": 31, "538000": 28, "538702": 30, "538816": 35, "5390": [35, 38], "5391": [31, 39], "539116": [45, 56], "539376": 46, "539459": 47, "54": [36, 45, 46, 55, 56], "540": 45, "540000": 31, "540359": 39, "541117": 36, "541488": 39, "54152": 35, "541667": 32, "541795": 35, "54240": 35, "542624": 38, "542873": [31, 32], "543297": 34, "543351": 38, "544": 34, "544462": 38, "545": [36, 47], "546": 31, "5461": 36, "546473": 33, "546610": 30, "54676006e": 38, "547": [34, 36, 38], "547993": 35, "548831": 38, "549": 47, "549682": 35, "5498": 30, "55": [28, 29, 30, 33, 35, 36, 37, 38, 45, 46, 50], "55000": 34, "550000": [31, 32, 34], "550004": 37, "550616": 35, "55101": 45, "5513": 34, "5514": [37, 38], "5515": 46, "551579e": 36, "551862e": 36, "551975": 36, "552": [31, 36], "552721": 37, "553965": 38, "553979": 35, "5540": 46, "5541306485809793": 37, "55413065": 37, "554180": [45, 56], "554621": 39, "5551": 33, "555740": 30, "5566": [31, 32, 52], "557197": 44, "557242": 35, "557739": 36, "558": [36, 38, 39], "558564": 35, "55862988e": 38, "55873324": 44, "5588": 27, "558824": 35, "558889": 36, "559": [34, 36, 38], "56": [30, 32, 35, 36, 45, 46, 55, 56], "560225": 31, "560768": 36, "561": [10, 30, 34, 38, 39], "561467": [31, 32], "561602": 38, "561645e": 36, "562112": 31, "563": 10, "5630224174651539": 33, "563314": [36, 38], "563467": 31, "5644": 36, "564483": 39, "56499": 43, "565": 39, "5650": 28, "565062": 46, "56521734": 8, "565679": 35, "565746": 46, "565888": 31, "566": 31, "566092": 31, "566222": 44, "5667": 35, "567724": 44, "567856e": 36, "568": 44, "568009": 30, "56804591": 36, "568663": 36, "5690201394302518": 38, "56902014": 38, "569375": 30, "5694": 39, "57": [30, 31, 32, 35, 36, 38, 45, 46, 52, 56], "57000": 46, "570015": 36, "570449": 35, "570473": 39, "5707": 46, "570739": 39, "571": [40, 48], "571500": 39, "571901e": 36, "571969": 39, "572": 10, "572105": 30, "572549": 31, "572962": 46, "573": 48, "573050": 35, "573129": [36, 38], "5732": 35, "573542": 39, "573818": 35, "57415": [45, 56], "574260": 39, "575000": 42, "57510": 39, "575907": 39, "576": 31, "57640869": 32, "576409": 32, "578523": 33, "578654": 35, "5789": 36, "579091": 39, "579432": 33, "579559e": 36, "579660": 37, "5798": 37, "57994": 35, "58": [28, 29, 30, 33, 36, 45, 46, 50], "580": 44, "580539e": 36, "581": 38, "58137177": 32, "581372": 32, "5814": 27, "581687": 39, "581787": 46, "582": [27, 37], "582090": 35, "582469": 36, "58387198": 40, "583872": 40, "584": 31, "584615": [31, 39], "585": 31, "585513": 33, "5857": 46, "586095": [31, 32], "587773": 35, "588": [30, 34], "588125": 30, "588235": 33, "588307": 31, "589286": 47, "59": [1, 30, 36, 45, 46], "59049": 35, "59050": 35, "590618": 39, "59082668": 32, "590827": 32, "5915": 32, "592": 47, "592401": 27, "59243876": 37, "59300": 39, "5931": 36, "593370": 36, "593508": 40, "5938": 31, "594": 31, "594595": 30, "594982": 35, "594995": 35, "5950": 31, "595427": 44, "595569e": 36, "596088e": 36, "596151": 39, "596810": 30, "596864": 36, "5970": 37, "59700": 35, "597015": 33, "59708": 35, "597326": 35, "597555": 27, "597924": [36, 38], "598": 31, "59810": 35, "598100": 33, "598149": [36, 38], "598750": 30, "599": 47, "599492": 33, "599860": 30, "599894": [45, 56], "5fin": 36, "5th": [35, 37, 38, 54], "5unf": 36, "6": [8, 10, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 57], "60": [8, 27, 31, 35, 36, 38, 39, 40, 42, 43, 45, 46], "600": [31, 33, 43], "60000": [45, 56], "600000": [29, 30, 34, 45, 56], "600193": 35, "60023631": 36, "600k": 36, "601": 34, "601042": 27, "601504": 33, "601712": 35, "601790": 33, "602": [31, 32, 52], "602000": 31, "602649": 30, "6028": 35, "602941": 35, "602954": 37, "60319915": 48, "603684e": 34, "603970": 46, "604": 30, "6040": [30, 34], "604000": 28, "604032": 35, "60429913": 36, "604320": 33, "60455": [45, 56], "604619": 33, "604797": 33, "6048": 45, "604807": 46, "60495488": 30, "605060": 35, "6051": [31, 32, 52], "605100": 33, "605101": 33, "605102": 33, "605263": 30, "605625": 30, "605696": 33, "606": 31, "606061": 33, "606557": 33, "606567": 33, "606811": 34, "606875": 30, "606902": 33, "607062": [45, 56], "608050": 33, "608125": 30, "6082": 31, "608468": 33, "608532": 44, "608565": 46, "60860": 31, "609": 31, "6092": 27, "609375": 30, "60943": 35, "60k": 36, "61": [30, 32, 33, 35, 36, 40, 45, 46], "61029914": 36, "610407": 35, "610931": 41, "611": 32, "611007": 44, "611178": [45, 56], "612349": 32, "61234944": 32, "6124": 46, "612546": 35, "612621": 33, "612755": 30, "613507": 33, "613738": 34, "613738418384": 34, "614": 31, "61420598": 32, "614206": 32, "614567": 39, "615": 31, "6154": 39, "615730": 37, "616": 34, "616099": 34, "6168": 28, "617342": 46, "617431": 41, "6176": 35, "617647": 35, "618": 31, "618012": 34, "619": 47, "61912405": 38, "62": [30, 34, 35, 36, 45, 46, 56], "622255": 31, "622454": 34, "622500": 30, "6226": 39, "622612": 35, "622709": 33, "623000": 31, "62320": 45, "62352928": 37, "624049": 36, "6241": 27, "624375": 30, "624450e": 36, "624615": 36, "6250": 31, "625387": 34, "6257": 46, "626206": 36, "62657": 45, "626875": 30, "62688064": 38, "627": 46, "6273": 34, "6275": [28, 29, 50], "627722": 38, "627966": 31, "628032": 39, "628139": 35, "62873917": 38, "629792e": 36, "63": [30, 34, 35, 36, 45, 46, 47, 56], "6303": [31, 32, 52], "6306": [31, 39], "631899": 46, "632": 47, "6320": 33, "6322": 39, "632353": 35, "632786": [45, 56], "63316788": 48, "63358": 43, "63362": 36, "634397": 33, "634490": 32, "634686": 35, "635": 31, "635200": 39, "635239": [31, 32], "635648": 33, "636": [27, 31, 32, 46, 52], "636364": 47, "636410": 37, "636849e": 36, "637": 44, "637982": 30, "638169": 38, "6389": [31, 39], "6391518364256": 46, "6392": 39, "639754": 36, "64": [11, 30, 33, 36, 44, 45, 46], "640": [34, 44, 47], "6400": 31, "640000": [35, 47], "640266": [31, 32], "640x480": 30, "641216": 45, "641538": 46, "641873": 36, "642676": 45, "642965": 35, "643": 34, "6431": 39, "643311e": 36, "644106": 35, "64417243": 44, "64454": 35, "644770": 41, "645519": 35, "6458": [28, 29, 50], "645963": 34, "646050": 38, "6464": 46, "647796": 39, "648": [30, 31, 34], "6480": 37, "648195": 35, "648550": 44, "649658": 38, "64994": [45, 56], "65": [28, 32, 36, 46], "650": 35, "65000": 34, "650000": 34, "65000e": 30, "65013704": 40, "65125032": 48, "6513": 38, "651446": 45, "65243": 36, "652487": 39, "6526853": 36, "652828": 34, "652986": 39, "653": 31, "653205": 34, "653205232272": 34, "654": 31, "65424895": 36, "656297e": 36, "656349": 30, "656827": 35, "657675": 39, "658047": 33, "658645": 33, "659056": 36, "66": [28, 29, 31, 33, 35, 36, 44, 45, 50, 56], "660171": 30, "6604": [31, 32, 52], "660714": 32, "66214339": 30, "66221": 45, "662450": 35, "662541e": 36, "662745": 31, "662879": 37, "66368": 38, "663680": [36, 38], "6637": 46, "6638": 46, "663822": 38, "6639": 46, "6641": 46, "6642": 46, "664207": 35, "6643": 46, "6644": 46, "6645": 46, "664707": 33, "66473": [45, 56], "665": 31, "665351e": 36, "665625": 30, "665882": 37, "666": [31, 32], "666166": [45, 56], "6666666666666666": 44, "666667": [29, 31, 42], "666754": 44, "667450": 45, "668787": 30, "6688": 27, "669614": 35, "669725": 35, "669805e": 36, "67": [28, 29, 32, 33, 35, 36, 45, 46], "670344": 30, "67186503136": 36, "673277": 34, "6744": 38, "674490": 34, "674721": 37, "675000": 27, "67501": 45, "67512181": 36, "67562658": 32, "675627": 32, "675676": 42, "675814": 30, "676250": 30, "676373": 35, "67672595": 36, "677": 31, "6772": 46, "677268": 46, "677579": 30, "677601": 34, "677629": 30, "678": [30, 34], "678689": 33, "679478": 31, "679877": [36, 38], "68": [28, 29, 30, 32, 35, 36, 38, 40, 41, 45, 46, 48, 56], "680000": 27, "680657": 31, "681223": 30, "683015": 37, "683171": 35, "68323": 34, "68339": [45, 56], "684211": 30, "684447": 31, "684960": [31, 32], "685103e": 36, "68523": 45, "685786": 37, "6858": 33, "686": 31, "686348e": 36, "687": 36, "687055": 35, "687307": 34, "687500": 29, "688": 34, "6880359361853475": 33, "688135": 34, "689338": [36, 38], "69": [28, 29, 30, 32, 36, 40, 45, 46, 56], "690": 47, "69027185e": 38, "690402": 34, "690778": 38, "691241": 35, "691640": 30, "691877": 34, "691924": 40, "69192445": 40, "692308": 31, "693": 31, "693498": 34, "693590": 32, "6938": [27, 45], "693890": 45, "693898": 45, "693936": 32, "69393613": 32, "69411": 39, "694155": 30, "694334": 37, "6950": 38, "695532": 31, "696034e": 36, "6962": 31, "6963": 38, "696373": 31, "696429": 35, "696712": 45, "696859": 34, "696875": 30, "696970": 33, "69698010e": 38, "697": [31, 39], "697248": 35, "6973": 31, "698": 31, "698167": [45, 56], "698206": 36, "698384608345687": 34, "698385": 34, "6984": 39, "698857": 34, "699224": 30, "699706": 44, "699901396097971": 41, "6th": [35, 37, 38, 54], "6x6": 53, "7": [10, 11, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 57], "70": [28, 29, 32, 35, 36, 40, 41, 45, 46, 56], "70000": [45, 56], "700000": [45, 56], "700855": 35, "701128": [45, 56], "701173": 34, "701186e": 36, "70162085e": 38, "7017": 46, "701863": 34, "702703": 30, "703406": 46, "704": [30, 31, 36], "704099": 32, "7042": 46, "7043": 46, "7046136400143138": 33, "70472": 39, "704969": 34, "705000": 31, "705511": 34, "70560276": 32, "705603": 32, "70568": 36, "705696": 30, "705882": [29, 34], "70588235": 29, "705898": 39, "706": 32, "706128": 30, "706444": 35, "706783": 32, "70678332": 32, "706966": 45, "707681": 30, "707712": 46, "707899": 40, "70789903": 40, "70799": 34, "708": [31, 32, 34, 37, 52], "708075": 34, "708527": 31, "708978": 34, "709185": 30, "70978": 39, "709874": 34, "709880": 34, "709893": 45, "7099": 39, "71": [27, 28, 29, 32, 33, 35, 36, 40, 45, 46, 56], "710000": 31, "710031": 38, "710526": 30, "710896": 35, "71096": 39, "711": [32, 34], "711077": 31, "711086": 34, "711717": 34, "711754": [31, 32], "711852": 39, "71199006": 36, "712": 31, "712074": 34, "71219761": 32, "712198": 32, "712324": 34, "712402": 37, "7129": 34, "713": 32, "71327467": 36, "714": 44, "714077": [31, 32], "714286": 34, "714402": 35, "715072": 44, "71517": 34, "7153": 46, "715424": 34, "715728": 35, "715992": 44, "716157": 35, "716655": 34, "716657": 34, "716792": 35, "716985": 30, "717289": 34, "717391": 34, "717829": 31, "718242": 34, "718266": 34, "718524": 45, "71866979": 36, "718750": 30, "7188": 32, "719": [27, 31, 39], "719056": 37, "719427e": 36, "719500": 30, "719747": 35, "72": [28, 29, 30, 35, 36, 45, 46, 50, 53], "720357": [45, 56], "72036": 45, "720497": 34, "720859": 31, "720893": 46, "720904": 45, "7210": 28, "721006": 34, "721008": 34, "7212512828409691": 33, "721616": 34, "721705": 31, "7218": [28, 29, 50], "721818": 39, "721921": 31, "722": 31, "722241": 34, "722249": 34, "723": 31, "72338": 43, "72345029": 36, "723602": 34, "723613": 30, "7242": 28, "724458": 34, "724539": [45, 56], "724891": 35, "725": [33, 34], "7250894": 48, "726": [31, 35, 39], "726412": [31, 32], "726474": 44, "726573": 34, "726583": 34, "726634": 35, "7266666666666667": 48, "726788": 36, "727014": 45, "727198": 34, "727273": 30, "727554": 34, "7277854625841886": 46, "727821": 34, "7278214718381631": 34, "727829": 34, "728": [31, 35], "728235": [31, 32], "7283": 35, "728324": 35, "728777": 30, "729": 34, "729109": 47, "729143": 35, "7292": 39, "729814": 34, "73": [28, 29, 32, 33, 34, 35, 36, 41, 45, 46], "730383": 35, "731498": 46, "7315": 33, "7315558717766282": 34, "731572": 33, "731583": 30, "7328": 31, "732919": 34, "733102": [31, 32], "733333": [29, 31, 32], "733746": 34, "734": [34, 36, 46], "734011": 34, "734385": 35, "734816": 45, "735": 36, "735043": 35, "735261": 34, "7352614272253524": 34, "735879": 34, "736285": 35, "736498": 34, "736900": 31, "7379": 28, "738": [31, 36], "738564": 45, "738701": [31, 32], "738715": 46, "738839": 33, "738977": 34, "739": 47, "739264": [31, 39], "7395977155164125": 34, "739598": 34, "739938": 34, "74": [28, 29, 31, 32, 33, 34, 35, 36, 41, 52], "740542": 27, "740844": 34, "741": 46, "741037": [45, 56], "741250": 30, "741463": 34, "7418": 38, "741935": 47, "742084": 34, "742088": 34, "742703": 34, "742981": 35, "743": [30, 31, 34, 46, 47], "743133": 30, "743135": 35, "743321": 34, "743323": 34, "743324": 34, "743391": 30, "743555": 38, "7436": [28, 29, 50], "743917": [31, 32], "7440": 27, "744201": 35, "744565": 34, "745": 37, "745178": 34, "746114": 37, "746328": 30, "747": 27, "74720920774": 36, "74798624e": 38, "748510": 35, "748725": 46, "748749e": 34, "748797": 33, "749118": 38, "75": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 45, 46, 52, 56], "750": 27, "7500": 36, "750000": 36, "7503": 28, "7504": 47, "751": 47, "7524": 45, "753286": [31, 32], "754": 31, "754165": 47, "754386": 35, "754874": 39, "755": 46, "755000": 36, "7551": 34, "755364": 30, "755418": 34, "755477": 30, "756": 46, "7562": 27, "75625": [45, 56], "757": 35, "7574257425742574": 34, "75745416": 40, "757545": 36, "757591": 45, "757932": 46, "757985": [37, 38], "758": [37, 38, 46], "758062e": 36, "75826": [37, 38], "758514": 34, "7588186": 44, "759561": 40, "75956122": 40, "7599": 33, "76": [29, 31, 33, 34, 35, 36, 38, 39, 46], "760": 46, "760262": 34, "760678": 45, "76161": 34, "761945e": 36, "762": [29, 46], "7620": 27, "762093e": 36, "76270194": 38, "763": 31, "7639": 28, "764052": 39, "76470588": 29, "764706": [29, 30, 34], "765": 35, "765591": 35, "765601": 36, "766317e": 36, "766423": 36, "766430": 30, "767": [36, 38], "767742": 33, "767802": 34, "767819": 45, "767852": 30, "768": [31, 32, 36, 38, 52], "768176": 46, "768512": 35, "76908228": 37, "769231": 31, "77": [28, 29, 32, 33, 35, 36, 41, 45, 46, 49, 55], "770": 28, "7706532429048965": 37, "770833": 42, "770898": 34, "771": 31, "771969": 30, "772532": 35, "773017": [36, 38], "7736": 34, "773851": 45, "774261": 45, "774844": 32, "77484447": 32, "7750553478074826": 45, "775270": 36, "7752884548630529": 33, "775311": 38, "77536150e": 38, "7758": 34, "776": 34, "7763": [31, 39], "776427": 46, "77694295": 37, "77709": 34, "777934": 30, "778": 47, "7781845435415525": 45, "779": [31, 39], "779271": 39, "78": [27, 28, 29, 31, 32, 35, 36, 39, 40, 45, 46, 49], "7800": 34, "780000": 37, "780296": 36, "780298": 36, "780316": 36, "780497": 36, "78058051e": 38, "780864": 35, "781": 31, "781004": 30, "781531": 35, "7816": 36, "782183": 36, "782219": 30, "7827": 35, "783282": 34, "783582": 30, "783784": 42, "783789": 30, "784424": 33, "784573": 39, "785": 32, "785105": 36, "785108": 36, "785134": 36, "785399": 36, "785483": [45, 56], "785714": 31, "786115": 39, "78617028": 37, "786555": 36, "787": 31, "787574": 36, "787879": [30, 33], "787933": 36, "788": 29, "788374": 44, "7887": 38, "7891381897690047": 33, "789436": 31, "789657": [45, 56], "79": [28, 29, 31, 32, 33, 35, 36, 45, 46, 50], "790": 35, "790000": 31, "79041": 36, "790731": 33, "791017": 46, "791467": 31, "792": 48, "792023": 38, "79250": 31, "792577": 36, "792603": 30, "792828": 36, "793": 39, "793243": 31, "79378": 35, "7938": 32, "794": 46, "794118": 30, "794236": 31, "794820": 31, "795": [30, 34], "79500e": 30, "7951": 34, "7951559890417761": 36, "795902": [45, 56], "796": 31, "7964215270662811": 33, "797": 31, "797355": [31, 32], "7978563117812038": 31, "798": 31, "7982": 30, "7986546": 36, "799983": 30, "79998417": 48, "7f688092391a": 44, "7pm": 39, "7th": [35, 37, 38, 54], "8": [9, 10, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 56], "80": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 45, 46, 49, 56], "800": [27, 29, 34, 43, 53], "800000": [34, 45, 56], "8001": 33, "800190": 30, "80062924": 30, "801219e": 36, "801666": 35, "801863": 30, "802502": 39, "802902": 36, "802987": 30, "803": [30, 31, 47], "803617": 35, "804": [30, 46, 47], "804818": [31, 32], "80482065": 32, "804821": 32, "805198": 36, "805342": 45, "805970": [30, 33], "806": 32, "8062": 28, "806899": 44, "8076": 36, "807684": 30, "807735": 35, "8078": 27, "808": 46, "8080": 28, "808208": 35, "808958": 30, "809": 31, "8098": 46, "81": [28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 45, 46, 56], "810073": [36, 38], "810098": 39, "810368": 30, "81071706": 34, "810811": 42, "8112": 27, "812272": 36, "812363": 36, "812500": 29, "812593": 44, "812875": 46, "813": 31, "813586": 35, "815669": 35, "816717791411044": 46, "817": 37, "817034": 47, "817558": [31, 32], "8180": 31, "818041": 46, "818868": 31, "819152": 30, "819213": 46, "8195": 33, "819549": 30, "819584": 30, "81970188": 32, "819702": 32, "82": [28, 32, 34, 35, 41, 45, 46, 56], "820": 30, "820033": 36, "820143": 33, "82025568e": 38, "820564": 36, "821040": 38, "821807": 36, "8219": 31, "8221": 32, "8225": 47, "82273995": 32, "822740": 32, "823511": 35, "823529": [29, 30, 33], "82352941": 29, "823543": 39, "824849": 35, "824884": 36, "825": 31, "825123": 39, "8253": 30, "825306": 34, "825470": 46, "825697": 36, "826142": 36, "826203": 33, "826216": 36, "826513": [45, 56], "826553": 36, "82670": [45, 56], "826739": 36, "826758": 36, "826760": 36, "827039": 33, "827068": 33, "827130": 35, "827261": 36, "827842": 33, "827907": 34, "8280229354283182": 36, "82804": 34, "828332": [36, 38], "828358": 30, "828405": 45, "828682": 34, "828891": 34, "828976": 34, "83": [28, 29, 32, 34, 35, 41, 42, 43, 45, 46, 49, 56], "830382": 35, "830712e": 36, "831135": 30, "831611": [36, 38], "831989": 34, "832": 31, "832320": 33, "832370": 35, "832866": 36, "833": [30, 34], "83320": 45, "8334": 38, "8340": 30, "834109": 34, "834356e": 36, "83437": 36, "834455": 30, "8356": 38, "835651": 34, "835749": [36, 38], "83603": [36, 38], "8361313": 36, "836189": 30, "836735": 35, "836878e": 36, "836880e": 36, "837022e": 36, "837838": 30, "837848": 30, "838": [30, 34], "83848729e": 44, "83876": 34, "8388866943476283": 33, "838951": 36, "8389756947416362": 33, "839225": 36, "84": [28, 29, 32, 45, 46, 47, 48, 49], "840": 31, "84002795": 32, "840028": 32, "840074": 29, "840183": 36, "840492": [36, 38], "84062193": 38, "841": 36, "841208": 34, "841886": 34, "841983": 34, "842": 31, "842028": 35, "842064": 46, "842105": 30, "843": 37, "843281": 38, "843284": [30, 33], "843842": [31, 32], "843992": [36, 38], "844409": 32, "84440919": 32, "844921": 40, "845": 34, "846154": [31, 47], "8462": 39, "846260e": 36, "846650": 36, "84679073": 30, "84698489": 44, "847178": 35, "847287": 34, "8475": 45, "84772": 35, "847799": 34, "847808": 35, "8478316682480326": 45, "848": [37, 38], "8481": 47, "84893192": 34, "849": [37, 38], "849102e": 36, "849438e": 36, "849612": 34, "85": [28, 29, 32, 35, 36, 37, 38, 39, 45, 46, 49, 56], "850": [27, 37, 38], "8502": 34, "850283": [45, 56], "850503": 34, "850746": 30, "851460": 36, "851852": 33, "852": [46, 47], "852053": 34, "852104": 36, "852941": 33, "853125": 30, "853399": 35, "854129": 36, "854167": 42, "854500": 46, "8546143543902771": 46, "854744525547446": 46, "854749": 45, "85545875": 30, "85597188": 32, "855972": 32, "856": 34, "856175": 31, "856589": 34, "857": 36, "857874": 34, "858": 33, "8580": [31, 32, 52], "858209": [30, 33], "858915": 34, "859": 37, "859318": 36, "859439": 40, "85943906": 40, "859455": 46, "85969": 34, "859799": 34, "86": [28, 30, 32, 33, 34, 35, 39, 45, 46], "860": [35, 38], "86000e": 30, "8601643854446082": 36, "860677": 35, "861": 31, "86102": [45, 56], "861348": 34, "862432": 36, "862552": 31, "8625888648969532": 46, "86267067": 32, "862671": 32, "862997": 39, "863014": 33, "863889": 45, "863941": 36, "864": 37, "86400": [45, 56], "8641864337292489": 46, "864205": 38, "865562": 46, "8661": 47, "866110": 33, "866667": [29, 35], "866980": 36, "867434": 44, "867558": 39, "868003": 36, "868281": 36, "868305": 36, "868308": 36, "869077": 32, "86907725": 32, "869094": 34, "8691": 32, "869531": 30, "869964": 34, "87": [28, 31, 32, 35, 45, 46], "870": [37, 38], "870503": 44, "871": [34, 37], "871094": 45, "8711": 35, "872": [37, 38], "872093": 34, "872603": 44, "872722908439952": 38, "8727229084399575": 38, "872961060": 36, "8729610607986": 36, "873": 37, "8731": [36, 38], "873103": 30, "873182": 45, "873356": 30, "873643": 34, "873704": 36, "874062": 32, "87406235": 32, "874305": 45, "874516": 34, "874532": 36, "874767e": 36, "875": 35, "8750": [31, 39], "875000": 29, "876065": 34, "876540": 46, "876574": [31, 32], "877046": 39, "877390": 38, "877519": 34, "877551": 35, "878183": 30, "87844893": 36, "87849316": 33, "879": 31, "87907": 34, "879938": 34, "88": [28, 29, 31, 32, 33, 35, 39, 46, 47, 52], "880": 39, "880348": 34, "880831": [45, 56], "881395": 34, "881720": 35, "883138": 34, "884586": 34, "885": [27, 32], "885044": [36, 38], "885968": 46, "886047": 34, "886759": 33, "887": 37, "887017": 35, "887159": [45, 56], "8873": 35, "887324": 35, "887343": 30, "887597": 34, "887701": 35, "8878117": 32, "887812": 32, "888": [34, 37, 38], "888066": 38, "888372": 34, "888513": 35, "888811": 34, "888889": [31, 33], "888961": 38, "889086": 36, "889147": 34, "889429": 45, "889921": 45, "89": [28, 29, 32, 35, 41, 45, 46, 49, 56], "890": 37, "890457": 36, "890933": 46, "891001": 35, "891557": 34, "892476": 35, "892477": 30, "892491": 31, "89270": 39, "892733": 45, "892961": 39, "893000": 31, "893260": 32, "8937442459553657": 38, "894": 31, "895": 37, "895349": 34, "895541": 36, "89572": [45, 56], "895833": 35, "895963": 33, "897010": [31, 32], "89706451e": 38, "897674": 34, "898": 38, "898016": 34, "898703e": 36, "899": [31, 32, 34, 37, 52], "8994": 38, "8997": 36, "899969": [45, 56], "8m": 44, "8th": [35, 37, 38, 54], "9": [4, 10, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 56, 57], "90": [8, 27, 28, 29, 30, 32, 35, 36, 41, 42, 45, 46, 49], "900": [32, 34, 35], "90000": [45, 56], "900000": [29, 45, 56], "900662": 29, "901085": 33, "9010852321946792": 33, "901262": 45, "90159483": 40, "901595": 40, "902401": 34, "903101": 34, "904": [30, 34], "90403853": 32, "904039": 32, "904226": 30, "9047619047619048": 28, "904902": 44, "905": [30, 31], "905327": 45, "906667": 29, "90669": 39, "906865": 29, "907": 46, "907143": 47, "907595": 45, "908": 31, "908140": [31, 32], "908215": 36, "909091": 31, "90982": 39, "91": [28, 29, 31, 32, 34, 35, 39, 40, 45, 49, 56], "910": 28, "9100": 45, "910018": 36, "910174": 36, "9103": 45, "910456e": 36, "91063776": 38, "910714": 47, "910843": 36, "911615": 36, "911846": 36, "912": 31, "912395": 38, "913333": 29, "913767": 36, "913849": 36, "914003": 38, "914451894267": 36, "914585": 38, "91515735": 36, "915714e": 36, "915952": 36, "916254": 30, "916722": 38, "917526": 35, "917837": 35, "918": 37, "918124": 35, "918191": 44, "9182": 45, "919198": 38, "9196": 27, "92": [28, 29, 32, 35, 41, 44, 45, 46, 49], "920000": 29, "9203": 34, "920305": 39, "920462": 38, "92120500e": 48, "921422": 46, "921438": 36, "921850": 36, "92195464": 38, "921955": 38, "922": 32, "923077": 35, "923283": [31, 32], "923432": 38, "924485": 39, "9245": [29, 33], "925272e": 36, "925288e": 36, "925593": 30, "925768": 35, "926657": 36, "926733e": 36, "926829": 35, "928": 34, "92809": 39, "92852376": 30, "929": 34, "9295": 34, "93": [28, 29, 32, 33, 34, 40, 45, 46, 49], "930000": 31, "930123": 30, "930561": 30, "931439e": 36, "931786": 33, "932": 31, "932070": 46, "932124": 30, "932143": 47, "93279": 45, "9336": 31, "934205": 30, "934269": [31, 32], "934783": 35, "9351": 39, "935512": 46, "935802": 30, "93665": [45, 56], "9375": 29, "937500": [29, 32], "93788": 43, "938": 35, "9383": [30, 33], "93869659": 32, "938697": 32, "939006": 35, "9391": 36, "939394": [30, 33], "94": [28, 29, 31, 32, 33, 34, 35, 36, 45, 49, 52], "9401": 45, "9406": [28, 29, 50], "941": 46, "941176": [29, 32], "94117647": 29, "943609": 39, "944": 27, "944092": 35, "944354": 32, "946783": 30, "947": [31, 34, 47], "9471": 34, "948482": 46, "94888": 35, "949": 31, "9490": 31, "9492": 36, "94933723": 36, "94959681": 32, "949597": 32, "95": [28, 29, 32, 35, 41, 45, 46], "950000": 31, "950088": 39, "9505": 38, "950564": 39, "9506": 38, "950696": 46, "950733": 30, "951294": 36, "951574": 39, "951644": 39, "951669": 39, "951696": 30, "953": 37, "95511263": 30, "955113": 30, "9558": 45, "956": 31, "956966": 39, "957075": 39, "9573": 45, "9576": 27, "957886": 44, "957919": 30, "957987": 30, "9583333333333334": 44, "958393": [31, 39], "95886206e": 44, "959": 31, "959139": 38, "959402e": 36, "959870": 35, "959873": 46, "96": [28, 32, 33, 34, 35, 39, 45], "960": 33, "961106": 35, "961109802000133": 41, "961404": [31, 32], "961498": [36, 38], "961771": 33, "961898": 33, "962776": 35, "96319": 45, "96320": 45, "96321": 45, "96322": 45, "96323": 45, "96325": 45, "963689": 39, "96554": 39, "9661": 36, "966131": [31, 32], "9664": [28, 29, 50], "966491": 35, "967102": 35, "967907": 35, "968": 31, "968233": 39, "96834506": 30, "968493": 46, "968514e": 36, "96875": 44, "969048e": 36, "9691": 36, "9692602666681306": 33, "96965253": 38, "969653": 38, "97": [28, 29, 32, 33, 34, 38, 41, 45, 46], "970518": 35, "970683": 39, "971": 32, "97203586": 32, "972036": 32, "97217": 45, "972198": 34, "97223953": 32, "972240": 32, "972440": 35, "97253": 45, "9730": 32, "973225": 35, "973280": 32, "97328024": 32, "973482e": 34, "973750": 30, "974": 31, "974480": 39, "9748": 33, "974801e": 36, "975895": 45, "976": [31, 35, 37], "977": [31, 45, 56], "977278": 39, "9773": [28, 29, 30, 50], "978": 33, "9781449369880": 45, "9781789957211": 44, "97823755": 33, "978738": 39, "979": [37, 38], "979562": 46, "98": [28, 31, 32, 33, 36, 38, 40, 43, 45, 46], "980": [45, 56], "98007": 27, "98028": 28, "98045": 27, "98052": 27, "98055": 27, "980634": 46, "98072": 27, "98074": 28, "98075": 27, "9808": 33, "98107": 27, "98112": 27, "98116": 27, "981195": 45, "98125": 28, "98136": 28, "981735": 33, "98178": 28, "982": 32, "982184": 34, "982570": 46, "983": 44, "9837": [29, 33], "984": 34, "984653": 33, "984664": 36, "985283": 34, "9854": [28, 29, 33, 50], "985457": 46, "985816": 29, "986047": 34, "9862": 47, "986207": 34, "987": [34, 44], "987062": 36, "987597": 34, "9876": [37, 38], "987681": 39, "988": 39, "9881": [28, 29, 50], "988381": 34, "988841": 34, "988901": 36, "989": 28, "989147": 34, "989156": 34, "989443": 46, "989922": 34, "989973": 33, "99": [28, 29, 31, 32, 34, 35, 45, 54, 56], "990631": [45, 56], "990754": 45, "9912": [30, 33], "9915": [45, 56], "991966": 46, "992": [29, 34], "992254": 34, "99240562": 38, "992406": 34, "9926": 32, "992857": 29, "992908": 29, "993023": 34, "993029": 34, "993065": 46, "9931": [28, 29, 50], "9934531067299874": 33, "993666": 38, "993969": [36, 38], "994": 27, "994266": 34, "994574": 34, "994764": 45, "995": [39, 44], "9950": 39, "9951": [28, 29, 50], "99515": 45, "995434": 36, "996588e": 36, "996765": 38, "996788": 46, "996820": 46, "996899": 34, "99744241e": 38, "9977957422135844": 38, "998": [35, 46, 47], "9983": 35, "998302": 35, "99845": 34, "998451": 34, "999": [33, 47], "99907": 34, "999122": 35, "999147": 35, "999172": 35, "999183": 35, "999185": 35, "999192": 35, "999210": 35, "999214": 35, "999221": 35, "999223": 35, "999225": 34, "999254": 35, "999298": 35, "999317": 35, "99931882": 36, "999335": 35, "999535": 34, "999577": 45, "999622": 31, "9am": 39, "9th": [35, 37, 38, 54], "A": [0, 8, 9, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 56, 57], "AND": [0, 36], "AS": 0, "And": [27, 28, 34, 36, 43, 45, 46, 50, 51], "As": [4, 29, 32, 34, 36, 37, 38, 42, 45, 46, 48, 51, 53, 55, 57], "At": [4, 27, 29, 33, 35, 37, 39, 40, 44, 45], "BE": [0, 43], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 30, 38, 49, 51], "Being": 44, "But": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 51, 53, 55, 56, 57], "By": [27, 29, 30, 32, 35, 37, 40, 43, 44, 46, 51, 53, 57], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 53, 54, 55, 56, 57], "IN": [0, 29, 33], "IT": 33, "If": [4, 5, 6, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57], "In": [6, 7, 8, 9, 10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57], "Ines": 47, "It": [2, 4, 7, 8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 55, 57], "Its": 46, "NEAR": [31, 32, 39, 52], "NO": 0, "NOT": [0, 8, 32, 33], "No": [0, 27, 28, 36, 37, 38, 39, 41, 45, 46, 49, 56], "Not": [35, 36, 37, 38, 39, 40, 42, 45, 46, 54], "OF": 0, "OR": [0, 8, 36], "Of": [9, 32, 34], "On": [4, 7, 27, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 46, 47], "One": [5, 8, 16, 28, 29, 32, 33, 34, 35, 38, 40, 41, 46, 49, 54, 56], "Or": [30, 32, 34, 51], "Such": [6, 42, 45], "THE": [0, 29], "TO": [0, 43], "That": [28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 54], "The": [0, 1, 2, 5, 7, 8, 10, 27, 28, 30, 31, 32, 35, 36, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57], "Their": 5, "Then": [28, 33, 37, 40, 45, 54], "There": [2, 5, 8, 9, 10, 11, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 57], "These": [4, 11, 28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 45, 55, 57], "To": [8, 11, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 41, 43, 44, 45, 47, 51, 53, 55, 56, 57], "WITH": 0, "Will": [35, 46, 47, 49, 54], "With": [0, 27, 28, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 44, 46, 48, 51, 57], "_": [37, 44, 46, 47], "__call__": 32, "__class__": [33, 45], "__finalize__": 46, "__getitem__": [29, 31], "__init__": 47, "__name__": [33, 45], "_arg": 47, "_array_api": 47, "_astype_nansaf": 46, "_c": 47, "_california_housing_dataset": 33, "_call_func_on_transform": 32, "_callback": 47, "_column_transform": 32, "_constructor_from_mgr": 46, "_context": 47, "_data": 34, "_distn_infrastructur": 34, "_encod": 32, "_get_default_devic": 47, "_get_sequential_output": 32, "_i": 44, "_logist": 48, "_mgr": 46, "_proba": 37, "_pseudo_sync_runn": 47, "_run": 47, "_run_cel": 47, "_run_cod": 47, "_run_module_as_main": 47, "_run_onc": 47, "_score": 32, "_scorer": 32, "_set_output": 32, "_temp": 47, "_time_fit_was_cal": 46, "_transform": 32, "_transform_on": 32, "_valid": 32, "ab": [33, 35, 36, 38], "abbrevi": 43, "abil": [27, 32, 34, 38, 43, 45, 51], "abl": [8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 51, 53, 57], "about": [2, 4, 7, 10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57], "abov": [0, 5, 8, 11, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 51, 53, 56, 57], "absenc": [32, 38, 42], "absolut": [33, 35, 36, 38, 40, 47, 57], "abspath": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56], "academ": [7, 39], "accept": [5, 8, 35, 36, 43], "accept_spars": 32, "access": [10, 11, 29, 31, 34, 37, 40, 42, 43, 45, 53], "accessori": 45, "accident": [30, 31], "accommod": 7, "accompani": [7, 27, 28], "accord": [33, 35, 36, 39, 42, 46, 53, 54, 55, 57], "account": [7, 10, 29, 35, 39, 42, 46, 49, 54], "accur": [27, 29, 37, 38, 39, 42, 46, 49, 50], "accuraci": [28, 29, 30, 31, 34, 35, 37, 38, 39, 41, 44, 46, 47, 49, 50, 54, 55, 57], "accuracy_scor": 35, "acdm": [35, 37, 38, 54], "acf": 45, "achiev": [8, 30, 35, 53, 55, 56], "acinonyx": [27, 44], "acoust": [30, 31, 34, 53], "acquir": 57, "acquisit": 42, "across": [27, 28, 29, 31, 35, 38, 44, 57], "act": [33, 57], "action": [0, 27, 37, 38, 40, 42, 43, 46, 57], "activ": [4, 11, 27, 34, 47, 49, 57], "actor": [42, 43], "actual": [7, 27, 33, 35, 37, 38, 40, 42, 43, 45, 46, 53, 55], "ad": [32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 46, 47, 53, 56], "adapt": [0, 31, 32, 35, 37, 43, 45, 47], "add": [7, 8, 11, 31, 32, 35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 52, 54, 55, 56], "add_pip": 47, "addit": [0, 4, 36, 42, 54, 57], "addition": [50, 51, 57], "address": [18, 41, 54], "adelaid": [45, 56], "adj": 47, "adject": 43, "adjust": [30, 34, 41, 45, 51], "adm": [35, 37, 38], "admin": 57, "administr": 1, "admit": 29, "adopt": [6, 42], "adp": [43, 47], "adult": [35, 37, 38, 54], "adult_df_larg": [37, 38], "adv": 43, "advanc": [32, 34, 40, 41, 42, 43, 44, 50, 57], "advantag": [31, 32, 33, 37, 41, 42, 43, 49, 57], "advic": 46, "advis": 27, "advisor": 57, "af": 38, "affect": [11, 30, 31, 33, 34, 35, 40, 45, 46, 47, 51], "affix": 43, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 32, 35, 36, 38, 40, 41, 44, 45, 46, 47, 49, 55, 56, 57], "ag": [27, 33, 35, 36, 37, 38, 39, 42, 54, 55], "again": [11, 28, 29, 31, 41, 42, 43, 44, 46, 51, 54, 55, 56], "against": [42, 45, 53], "agenc": 47, "agent": 10, "agglomerativeclust": 41, "aggress": 43, "agnost": 38, "ago": [44, 45], "agre": 51, "agreement": [46, 57], "ahead": 54, "ai": [7, 9, 35, 39, 44, 54], "aight": 27, "aim": 49, "airport": 35, "aka": [33, 46], "al": [37, 43], "alamine_aminotransferas": 27, "alan": 10, "alaska": 33, "album": 34, "albumin": 27, "albumin_and_globulin_ratio": 27, "alburi": [45, 56], "alexnet": 44, "algebra": [42, 43], "algorithm": [2, 15, 27, 29, 31, 32, 35, 36, 37, 38, 41, 43, 44, 50, 51, 52, 54, 57], "align": [8, 27, 28, 29], "align_kei": 46, "alkaline_phosphotas": 27, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 29, 30, 32, 34, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57], "all_cap": 47, "all_featur": [45, 56], "allei": [36, 38], "allen": 47, "alley_grvl": 36, "alley_miss": 36, "alley_pav": 36, "alloc": [8, 43, 44], "allow": [5, 7, 11, 29, 31, 34, 35, 39, 43, 45, 46, 50, 51, 53, 56, 57], "allpub": [36, 38], "almost": [33, 34, 36, 39, 41, 42, 43, 54], "along": [7, 28, 32, 35, 44, 45, 50], "alpha": [30, 31, 45, 51, 56], "alpha_": 36, "alphabet": 33, "alphago": [27, 40], "alq": [36, 38], "alreadi": [4, 8, 11, 35, 36, 38, 40, 45, 46, 47, 50, 53, 56, 57], "also": [2, 4, 5, 7, 8, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "altar": 44, "altern": [8, 34, 40, 53, 57], "although": [29, 37, 40, 42, 46], "alwai": [27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 47, 49, 50, 51, 53, 57], "am": [31, 40, 47], "amatriain": 42, "amazon": [27, 40, 42, 47], "ambigu": 43, "amer": 35, "america": 32, "american": 40, "aml": 31, "among": [27, 28, 34, 35, 37, 38, 42, 55], "amongst": 47, "amount": [4, 27, 29, 33, 34, 35, 36, 38, 40, 44, 45, 46, 53, 56], "amp": [37, 38], "amplifi": [35, 43, 54], "amuel": 31, "an": [0, 2, 4, 6, 7, 8, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 55, 56, 57], "anaconda": [11, 38, 47], "analogi": [15, 41, 43], "analysi": [2, 9, 10, 28, 35, 36, 40, 41, 43, 54, 57], "analyt": 45, "analyz": [35, 39, 45, 46, 56, 57], "anatinu": 44, "anca": 57, "ancestor": 39, "ancestr": 57, "ancuta": 57, "andrea": [9, 10], "andrew": [9, 10, 34, 39], "anemon": 44, "angel": [46, 47], "ani": [0, 11, 28, 29, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 57], "anim": [35, 44], "animal_fac": 44, "anneal": 39, "annot": [38, 40], "announc": 7, "annoyingli": 36, "annual": 47, "anomali": [35, 36, 40], "anonym": 45, "anoth": [8, 11, 28, 30, 33, 34, 35, 37, 38, 40, 41, 42, 44, 45, 46, 49, 50, 52, 55, 56], "answer": [4, 6, 7, 27, 28, 29, 34, 37, 40, 42, 43, 45, 48, 50, 51, 54, 55, 56, 57], "anteat": 44, "anti": 46, "anymor": [36, 40, 42, 51], "anyth": [0, 29, 32, 35, 42, 43, 46, 53], "anytim": 57, "anywher": 32, "ap": [49, 57], "ap_lr": 35, "ap_svc": 35, "apart": [30, 41], "apeendixa": 39, "api": [35, 43, 45, 49], "app": [28, 47, 49], "appeal": 43, "appear": [2, 7, 32, 37, 51, 55, 57], "append": [4, 8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 53, 54, 55], "appendix_b": 43, "appendixb": 44, "appli": [0, 2, 6, 9, 10, 27, 28, 29, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 57], "applic": [0, 5, 27, 32, 34, 35, 36, 38, 39, 43, 46, 47, 49, 54, 57], "appreci": [40, 57], "approach": [10, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 49, 51, 56, 57], "appropri": [0, 4, 11, 28, 29, 32, 35, 36, 40, 41, 45, 46, 49, 57], "approv": [35, 54, 57], "approx": [30, 38], "approxim": [28, 34, 39], "april": 45, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 34, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "arang": [8, 29, 30, 33, 34, 35, 36, 51, 53], "arbitrari": [38, 40, 41, 45], "architectur": 44, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "area": [34, 36, 37, 39, 40, 53], "aren": [7, 36, 39, 40, 44, 45, 47, 56], "arena": 39, "arg": [29, 32, 47], "argh": 46, "argmin": [29, 30, 35, 40], "argsort": [38, 43], "argu": [40, 43, 53], "argument": [8, 28, 32, 34, 35, 36, 38, 47, 49, 52], "arima": 45, "arima_model": 45, "aris": [0, 27, 43], "aristotl": 30, "arithmet": 8, "around": [7, 30, 32, 35, 36, 45, 46, 50], "aroundn": 27, "arr": 46, "arr1": 8, "arr2": 8, "arrai": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53], "array_equ": 8, "arriv": 39, "arthur": 27, "articl": [10, 28, 29, 31, 35, 40, 42, 43, 44], "articul": 49, "artifici": [10, 43], "artist": [30, 31, 34, 53], "as_fram": [30, 51], "ascend": [8, 32, 33, 34, 36, 37, 38, 39, 45, 46, 49, 55], "ased": 41, "asi": 47, "asia": 32, "asid": [4, 29, 37, 51], "ask": [3, 7, 11, 27, 28, 29, 30, 32, 35, 39, 40, 42, 43, 46, 47, 50, 57], "asleep": 33, "aspartate_aminotransferas": 27, "aspect": [33, 38, 39, 41, 42, 46, 49], "assault": 57, "assert": [7, 32, 35, 37, 38, 54], "assess": [6, 10, 27, 28, 29, 31, 35, 38, 40, 57], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 52, 54, 56], "assist": 27, "assoc": [35, 37, 38, 54], "associ": [0, 27, 29, 30, 35, 36, 38, 39, 40, 43, 44, 45, 46, 49, 55, 57], "assum": [27, 28, 32, 33, 35, 36, 41, 42, 43, 45, 49, 54], "assumpt": 46, "asterisk": 34, "astyp": [8, 45, 46, 56], "astype_arrai": 46, "astype_array_saf": 46, "async_": 47, "async_help": 47, "asyncio": 47, "asyncio_loop": 47, "atabak": 57, "atratu": 44, "attack": 28, "attempt": [29, 53, 54], "attend": 57, "attent": [6, 43], "attic": 36, "attract": 43, "attribut": [0, 1, 27, 28, 30, 31, 33, 34, 39, 40, 43, 44, 53, 55], "attrit": 46, "auc": [46, 49, 54, 57], "audienc": [54, 57], "audio": [44, 57], "audit": 57, "auditor": 57, "augment": 35, "august": 45, "australia": [45, 56], "authent": 40, "author": [0, 43, 57], "auto": [27, 34, 35, 39, 40], "autocorrel": 45, "autom": [28, 36, 43], "automat": [31, 32, 36, 39, 43, 45, 46, 56], "autoregress": 33, "autumn": 45, "autumn_month": 45, "aux": 47, "av": [36, 38], "avail": [0, 1, 7, 9, 10, 11, 29, 32, 34, 35, 36, 41, 42, 43, 44, 45, 46, 49, 54, 55, 56, 57], "avebedrm": 33, "aveoccup": 33, "averag": [29, 30, 32, 33, 34, 36, 38, 40, 41, 43, 46, 47, 49, 51, 57], "average_precis": 35, "average_precision_scor": 35, "average_word_length": 47, "averaging_model": [37, 55], "averaging_model_ndt": 37, "averoom": 33, "avg": [35, 42, 45], "avg_sent_emb": 43, "avoid": [7, 8, 28, 31, 35, 36, 41, 45, 46, 48, 49, 51, 54, 57], "awai": [4, 6, 28, 33, 40, 42, 44, 46, 49], "await": 47, "awar": [32, 46, 57], "award": 57, "awesom": 9, "ax": [29, 30, 33, 35, 40, 41, 44, 46, 51, 54], "axi": [7, 8, 27, 28, 29, 31, 32, 33, 38, 40, 41, 43, 44, 45, 56], "axvlin": 40, "az": 47, "b": [8, 10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46], "b3": [31, 38], "babe": 27, "babi": [39, 43], "bachelor": [35, 37, 38, 54], "back": [8, 31, 34, 43, 49], "backdrop": 45, "background": [28, 57], "bad": [8, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 44, 45], "badgeryscreek": 45, "bag": [39, 43, 44, 49, 53], "bai": [31, 32, 39], "baidu": 29, "bal_scor": 35, "balanc": [6, 30, 37, 40, 42, 48, 54, 55], "ballarat": [45, 56], "balust": 44, "balustrad": 44, "bambi": 42, "banist": 44, "bank": [35, 38, 45, 46, 54], "bannist": 44, "bar": [35, 36, 38, 44, 45, 46, 56], "baranski": 47, "barbu": 57, "barri": 33, "base": [5, 8, 11, 15, 28, 29, 31, 32, 33, 34, 35, 36, 38, 40, 41, 43, 46, 47, 49, 50, 53, 54, 55, 57], "base_ev": 47, "base_scor": 37, "base_valu": 38, "baseblockmanag": 46, "baselin": [14, 46, 49, 50, 52, 53, 56], "baseline_hazard_": 46, "bash": 5, "basi": [28, 30], "basic": [2, 8, 28, 34, 39, 42, 44, 46, 47, 55, 56], "batch": [43, 44], "batch_siz": 44, "batch_t": 44, "bath": 27, "bathroom": [27, 28, 33], "bayesian": 34, "bayesopt": 34, "beagl": [27, 44], "bear": 44, "beat": [37, 46], "beauti": [42, 43], "becam": 44, "becaus": [7, 8, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 56, 57], "becom": [4, 29, 30, 33, 34, 35, 38, 39, 40, 43], "bed": 35, "bedroom": [27, 28, 33], "bedroomabvgr": [36, 38], "bedrooms_per_household": [31, 32, 52], "beef": 43, "been": [4, 6, 10, 27, 28, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 57], "befor": [4, 10, 11, 27, 28, 29, 30, 32, 33, 36, 37, 40, 41, 42, 43, 44, 45, 46, 50, 51, 53, 54, 55, 56], "begin": [28, 33, 39, 42, 45, 46, 49], "beginn": 44, "behav": [34, 38], "behavior": [29, 31, 35, 42], "behaviour": [32, 54, 55], "behind": [27, 33, 57], "being": [4, 27, 29, 31, 35, 36, 37, 38, 41, 43, 46, 51, 57], "believ": [34, 38, 45], "bell": 44, "belong": [28, 33, 41, 50], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57], "bench": 44, "benchmark": 44, "bendigo": [45, 56], "benefici": 32, "benefit": [4, 30, 37, 41, 43, 49], "bengio": 34, "ber": 43, "bergstra": 34, "berri": 43, "bertop": 43, "best": [2, 28, 29, 30, 34, 35, 36, 37, 38, 40, 41, 42, 46, 50, 51, 53, 55], "best_alpha": 36, "best_depth": 29, "best_estimator_": [34, 36], "best_n_neighbour": 30, "best_param": 34, "best_paramet": 34, "best_params_": [34, 36, 53], "best_scor": 34, "best_score_": [34, 36, 53], "bestalpha_coeff": 36, "better": [6, 27, 28, 30, 31, 32, 33, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57], "between": [2, 8, 11, 27, 29, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 57], "bewar": 43, "beyond": [29, 34, 39], "bia": [33, 35, 38, 46, 49, 54], "bias": [35, 38, 43, 46, 54, 57], "bicycl": [28, 45], "big": [7, 30, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 51], "bigalpha_coeff": 36, "bigger": [30, 32, 33, 36, 38, 41, 43, 44, 45], "biggest": [36, 39, 56], "bike": 45, "bill": 44, "billboard": 45, "billion": 36, "billionth": 45, "bin": [31, 34, 36, 39, 45, 46, 47, 50], "binar": [28, 32], "binari": [28, 31, 32, 33, 44, 46, 48, 49, 54], "binary_feat": 32, "binary_featur": [35, 37, 38, 54, 55], "binary_transform": [35, 37, 38, 54, 55], "bincount": [35, 37, 54], "bind": [30, 51], "binomi": 34, "biolog": 39, "biologi": 32, "bit": [11, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 44, 45, 46, 53, 54, 56], "black": [30, 38, 40, 44, 45, 56], "bld": 47, "bldgtype": [36, 38], "bldgtype_1fam": 36, "bldgtype_2fmcon": 36, "bldgtype_duplex": 36, "bldgtype_twnh": 36, "bldgtype_twnhs": 36, "blei": 43, "blend": 43, "blindli": [35, 36], "blob": 48, "block": [33, 46], "blog": [43, 45], "bloomberg": [9, 10], "blq": [36, 38], "blue": [28, 30, 34, 35, 38, 39, 40, 45], "bmatrix": [39, 42], "board": 4, "boathous": 44, "bob_dylan": 43, "bodi": 47, "boggl": 37, "bond": 35, "bonu": 37, "book": [1, 9, 35, 36, 42, 43, 45, 57], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "bool": [36, 45], "boom": 47, "boost": [19, 20, 43, 49], "booster": 37, "bootstrap": 11, "border": [28, 33, 41, 43, 48, 50], "bore": 33, "boston": 33, "both": [2, 6, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 52, 53, 54, 57], "bother": 38, "bottom": 41, "bought": 42, "bound": [39, 46], "boundari": [29, 41, 43, 51], "bow_df": 32, "box": [9, 38, 49], "boxplot": 38, "boyc": 28, "br": 43, "bracket": 8, "brain": [39, 44], "branch": [28, 41, 43, 46], "break": [35, 49, 51], "breakwat": 44, "breath": 49, "breathtak": 43, "breed": 49, "breiman": 37, "brief": [4, 33, 37], "briefli": [27, 35, 37, 39], "bring": [6, 38, 41, 47, 49], "british": [1, 43], "british_columbia": 43, "broad": [30, 51], "broadcast": 43, "broader": [2, 37, 43], "broadli": [28, 30, 33, 35, 37, 40, 41, 43], "brownle": 39, "browser": 11, "brush": 44, "bsmtcond": [36, 38], "bsmtexposur": [36, 38], "bsmtfinsf1": [36, 38], "bsmtfinsf2": [36, 38], "bsmtfintype1": [36, 38], "bsmtfintype2": [36, 38], "bsmtfullbath": [36, 38], "bsmthalfbath": [36, 38], "bsmtqual": [36, 38], "bsmtunfsf": [36, 38], "btw": 38, "bubbl": [42, 44], "bucket": [39, 47], "budget": [34, 42], "bug": [4, 8], "bui": 42, "build": [0, 2, 11, 29, 31, 32, 37, 39, 40, 43, 45, 48, 51, 56, 57], "built": [8, 27, 28, 29, 33, 34, 38, 45, 56], "bullshit": [10, 46], "bulwark": 44, "bunch": [8, 11, 28, 36, 37, 44, 46, 51], "bundl": [7, 11], "bureau": 33, "busi": [35, 40, 46, 47], "bustl": 45, "butterfli": 41, "buzz": 27, "bypass": 57, "c": [0, 5, 8, 9, 10, 11, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 51, 53, 57], "c1": 41, "c2": 41, "c_1": 40, "c_2": 40, "c_3": 40, "c_log": [30, 51], "c_widget": [30, 51], "ca": [5, 9, 47, 57], "ca_transform": 32, "cal_hous": 33, "calcul": [7, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 49, 51, 54, 56], "california": [31, 39], "california_h": 39, "californian": 31, "call": [8, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 55, 56], "callback": 37, "calm": 49, "came": 45, "camera": 32, "campu": [39, 57], "can": [4, 6, 7, 10, 11, 27, 28, 30, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "canada": [5, 29, 30, 32, 33, 43, 47, 49], "canada_usa_c": [28, 29, 30, 33, 50], "canadian": 43, "canadien": 43, "canberra": [45, 56], "cancel": 57, "cancer": [27, 39], "candid": [34, 37, 43, 51], "cannot": [0, 8, 29, 30, 34, 35, 37, 38, 39, 41, 45, 46, 47, 57], "canva": [1, 7, 10], "capabl": 9, "capit": [35, 37, 38, 54], "caption": [7, 44], "captiv": 43, "captur": [29, 31, 33, 37, 39, 41, 42, 43, 45, 46, 49, 57], "car": [27, 43, 44], "card": [27, 28, 35, 46, 54], "care": [5, 7, 29, 31, 34, 35, 36, 38, 39, 40, 45, 46, 49, 53, 55, 56], "carefulli": [1, 35, 36, 54, 57], "carpentri": 5, "carri": [28, 29, 30, 32, 34, 35, 36, 37, 40, 42, 43, 45, 47, 51, 53, 56], "caruana": 38, "case": [6, 11, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 56, 57], "cash": 27, "cast": [34, 42, 47], "castl": 44, "cat": [27, 35, 37, 43, 44, 47, 49], "catamount": [27, 44], "catboost": [38, 49, 57], "catboostclassifi": 37, "catboostregressor": 37, "catch": [35, 57], "categor": [28, 34, 35, 36, 37, 39, 40, 42, 43, 46, 49, 51, 52, 54, 56], "categori": [30, 31, 35, 36, 37, 38, 39, 40, 44, 49, 54], "categorical_feat": [32, 34, 49, 53], "categorical_featur": [32, 35, 36, 37, 38, 45, 46, 54, 55, 56], "categorical_transform": [32, 35, 36, 37, 38, 45, 54, 55, 56], "categories_": [31, 32], "cater": 40, "caus": [35, 38, 39, 42, 46, 53], "causal": [38, 39], "caution": 45, "cbar": 33, "cbtf": [10, 57], "cc": [0, 1], "cc_df": [35, 54], "cconj": 43, "cell": [7, 8, 27, 31, 32, 34, 35, 36, 37, 38, 39, 42, 44, 46, 47, 50, 51, 53, 55], "cell_nam": 47, "censor": [10, 49, 57], "censu": [33, 35, 37, 38, 54], "census_df": [35, 54], "cent": 36, "center": [30, 40, 41, 44, 48], "centercrop": 44, "centers_idx": 40, "central": 5, "centralair": [36, 38], "centralair_i": 36, "centralair_n": 36, "centric": 57, "centroid": [40, 41], "centroids_idx": 40, "centroids_idx_init": 40, "centuri": 43, "certain": [11, 30, 33, 34, 35, 38, 39, 40, 43, 46, 54], "certainli": 50, "certainti": 35, "cezannec": 44, "chage": 53, "chain": 32, "challeng": [6, 29, 39, 40, 42, 44, 45, 49, 55, 57], "chanc": [28, 29, 34, 35, 36, 39, 40, 46, 54], "chang": [0, 5, 7, 8, 11, 28, 29, 30, 31, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 50, 51, 53, 54, 55, 56, 57], "channel": [1, 11, 44], "chapter": 10, "charact": [32, 35, 43], "characterist": [28, 29, 33, 53], "charg": [0, 27, 46], "charl": 33, "charm": 43, "chart": [38, 45, 46, 56], "chat": 57, "chatgpt": 43, "che210d": 9, "cheaper": 39, "cheat": 9, "check": [4, 7, 10, 11, 27, 28, 29, 31, 33, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 51, 54, 55, 56], "check_assumpt": 46, "check_invers": 32, "checklist": 49, "checkmark": 42, "checkout": 34, "cheetah": [27, 44], "chest": 29, "chestpaintyp": 55, "chetah": [27, 44], "chi": 46, "chicago": 47, "chicken": 40, "child": [35, 38], "children": 42, "chines": 43, "chn": 8, "choic": [2, 34, 36, 37, 38, 40, 41, 42, 45, 47, 51, 52, 53], "cholesterol": 55, "choos": [27, 34, 35, 37, 41, 49, 51], "chop": [34, 43], "choreograph": 47, "chosen": [29, 34, 35, 46, 49, 55], "chrbv": 46, "christin": 47, "christma": 47, "chunki": 40, "churn": 49, "ciml": 10, "cinematographi": 43, "cinereu": 44, "circl": [30, 35], "circumst": 7, "citat": 7, "cite": 46, "citi": [28, 29, 30, 45, 49, 50], "citibik": 45, "cities_df": [30, 33], "citizen": 46, "cityscap": 45, "civ": [35, 37, 38], "clai": 38, "claim": [0, 34, 35], "clarif": 40, "clarifi": 49, "clariti": 57, "class": [4, 5, 11, 27, 28, 29, 30, 31, 32, 33, 39, 40, 45, 46, 50, 51, 54, 55, 56], "class_attend": [28, 29, 49], "class_attendance_enc": 32, "class_attendance_level": 32, "class_label": 35, "class_labels_fil": 27, "class_nam": [28, 30, 37, 44], "class_sep": 35, "class_weight": [37, 54], "classes_": [33, 35, 37, 38, 44, 48], "classic": [30, 44, 48], "classif": [2, 10, 29, 30, 31, 32, 33, 36, 37, 38, 39, 42, 43, 45, 46, 48, 50, 51, 53, 54, 55, 57], "classifi": [29, 30, 31, 32, 34, 35, 38, 44, 48, 50, 52, 54, 55], "classification_df": [28, 29], "classification_report": [35, 44, 54], "classifiers_ndt": 37, "classify_imag": [27, 44], "classmat": [6, 51, 52, 53, 54, 55, 56, 57], "classroom": 10, "clean": [2, 27, 41, 56, 57], "clean_text": 43, "cleaned_hm": 35, "cleaner": [35, 38], "clear": [7, 35, 40, 51, 57], "clearli": [4, 6, 7, 34, 37, 38, 45], "cleric": [35, 37, 38], "clf": [27, 28, 30, 33, 44], "cli": 43, "click": [5, 7, 10, 35, 42], "client": 42, "clinic": 28, "clip": 27, "clone": [5, 7, 11], "close": [2, 29, 30, 33, 34, 35, 40, 41, 43, 45, 47, 48, 51, 57], "close_default_lr": 35, "close_zero_svm": 35, "closer": [30, 31, 33, 42, 50, 53, 57], "closest": [30, 31, 35, 40, 41, 43, 45], "cloth": 45, "cloud": [27, 28, 32, 33, 34, 36, 37, 47], "cloud3pm": [45, 56], "cloud9am": [45, 56], "clust_label": 40, "cluster": [2, 10, 42, 43, 45, 57], "cluster_cent": 40, "cluster_centers_": 40, "cluster_std": [41, 44], "clutter": 28, "cm": [30, 33, 35, 38, 42, 51, 54], "cmap": [31, 34, 35, 38, 44, 53], "cmn": 36, "cmp": 46, "cnn": [44, 45], "co": [32, 43], "coast": 44, "code": [4, 7, 8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56], "code_ast": 47, "code_obj": 47, "codecademi": 9, "coef": [45, 46, 47, 56], "coef_": [33, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 55], "coef_df": [33, 38], "coef_nonzero": 45, "coeff": 33, "coeff_df": 45, "coeffici": [36, 37, 39, 42, 44, 45, 46, 47, 48, 49, 55, 56], "coefs_df": 39, "coher": 40, "col": [28, 32, 33, 42, 45, 49], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 31, "colinear": 38, "collabor": [5, 42, 57], "collaps": 38, "colleagu": [8, 9], "collect": [27, 28, 31, 32, 35, 37, 38, 39, 42, 43, 44, 45, 46, 49, 55, 57], "colleg": [35, 37, 38, 54], "collinear": 39, "color": [19, 23, 24, 25, 26, 33, 38, 39, 40, 41, 45], "color_continuous_scal": 39, "color_threshold": 41, "colorbar": [31, 33], "colour": [32, 33, 34, 38, 40, 41, 44], "colsample_bylevel": 37, "colsample_bynod": 37, "colsample_bytre": 37, "columbia": [1, 9, 43], "column": [7, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "column_nam": 32, "column_stack": 39, "columntranform": 52, "columntransform": [10, 16, 17, 31, 34, 35, 36, 37, 38, 39, 45, 46, 47, 53, 54, 55, 56], "columntransformer__countvectorizer__max_featur": [34, 53], "columntransformercolumntransform": [32, 34, 36, 37, 39, 47], "columntransformerifittedcolumntransform": [32, 36], "columntransformerinot": [32, 37], "com": [0, 5, 8, 9, 11, 27, 28, 32, 33, 35, 36, 37, 44, 45, 46, 47, 54], "comat": 43, "combin": [28, 31, 32, 34, 35, 39, 42, 44, 45, 46, 50, 51, 53, 55], "come": [11, 27, 28, 31, 32, 35, 39, 42, 43, 44, 45, 46, 50], "comedi": 42, "comfort": 5, "command": [4, 11, 35, 43], "comment": [8, 9, 56], "commerci": 0, "commit": [7, 35, 57], "common": [1, 8, 28, 29, 30, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 51, 57], "commonli": [28, 31, 34, 35, 40, 46], "commun": [2, 10, 11, 32, 34, 36, 57], "commut": 8, "comp_dict": 35, "compact": [34, 39], "compani": [35, 40, 42, 43, 46, 47, 54], "compar": [8, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 49, 53, 54, 55, 56, 57], "comparison": [41, 44, 46, 49], "compassion": 57, "compat": [8, 38, 47], "compatibitl": 8, "compel": 45, "compet": 47, "competit": [37, 44, 48], "compil": 47, "complain": [6, 47], "complaint": [6, 57], "complement": 43, "complet": [1, 6, 7, 27, 31, 34, 37, 38, 39, 41, 43, 46, 50, 51, 54, 55, 57], "complex": [28, 30, 33, 34, 36, 37, 38, 39, 41, 43, 44, 45, 51, 57], "compli": 0, "complic": [4, 28, 29, 34, 36, 39], "compon": [32, 35, 42, 45, 57], "components_": 43, "compos": [30, 32, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 52, 53, 54, 55, 56], "composit": 32, "compound": [43, 44, 46, 47], "comprehend": 43, "comprehens": [40, 49, 57], "compress": [32, 40], "compris": [27, 28, 40], "comput": [7, 9, 10, 11, 27, 32, 34, 35, 37, 38, 39, 40, 41, 43, 45, 48, 54, 55, 57], "computation": 39, "compute_class_weight": 35, "computer_programm": 43, "coms4995": 31, "con": [40, 44], "concat": [27, 30, 31, 32, 33, 38], "concaten": [32, 43], "concav": 39, "concensu": 29, "concentr": [34, 49], "concept": [10, 28, 29, 38, 39, 40, 45, 49, 51, 57], "conceptu": 37, "concern": [4, 32, 37, 57], "concess": 7, "concis": 28, "concord": 46, "concordance_index": 46, "concordance_index_": 46, "concret": 27, "conda": [27, 35, 36, 37, 38, 40, 43, 46, 47], "condit": [0, 27, 28, 32, 39, 43, 46, 57], "condition1": [36, 38], "condition1_arteri": 36, "condition1_feedr": 36, "condition1_norm": 36, "condition1_posa": 36, "condition1_posn": 36, "condition1_rra": 36, "condition1_rran": 36, "condition1_rrn": 36, "condition1_rrnn": 36, "condition2": [36, 38], "condition2_arteri": 36, "condition2_feedr": 36, "condition2_norm": 36, "condition2_posa": 36, "condition2_posn": [36, 38], "condition2_rra": 36, "condition2_rran": 36, "condition2_rrnn": 36, "conditional_aft": 46, "confid": [27, 29, 38, 46, 49, 51, 54, 55], "confidenti": 35, "config": [11, 47], "configur": [34, 36, 37], "confirm": 11, "conflict": [11, 41, 57], "confound": 39, "confus": [8, 18, 30, 32, 36, 40, 51, 54], "confusion_matrix": [35, 44, 46], "confusionmatrixdisplai": [35, 54], "congrat": 32, "conjunct": 39, "connect": [0, 28, 41, 42], "connot": 43, "conort": 39, "consciou": 57, "consecut": 45, "consequ": [7, 27, 32, 35, 42, 54], "consid": [4, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 49, 51, 57], "consider": [2, 35, 37, 40, 42, 46, 57], "consist": [6, 7, 28, 29, 31, 40], "constant": [28, 35, 36, 37, 38, 45, 46, 54, 56], "constitu": 37, "constitut": [43, 57], "construct": 42, "constructor": [28, 31], "consult": [30, 51, 57], "consum": [27, 39, 40, 42, 49], "consumpt": 45, "contact": [27, 57], "contain": [8, 11, 19, 23, 24, 25, 26, 27, 28, 31, 32, 33, 36, 42, 43, 44, 47, 48, 57], "content": [1, 4, 11, 40, 43, 44, 49, 57], "contest": 6, "context": [28, 31, 33, 34, 35, 37, 38, 39, 41, 42, 44, 45, 49, 51, 57], "contextu": 57, "contin": 32, "conting": 41, "continu": [15, 32, 34, 36, 37, 39, 43, 45, 56], "contract": [0, 46], "contract_month": 46, "contract_on": 46, "contract_two": 46, "contrast": [49, 57], "contribut": [30, 33, 38, 44, 55, 57], "control": [5, 8, 28, 29, 30, 32, 33, 36, 37, 44, 57], "convei": 57, "conveni": [8, 34, 35, 40, 43, 45, 46], "converg": 40, "convers": [35, 36, 38, 43, 53], "convert": [27, 31, 32, 33, 37, 38, 39, 43, 45, 46, 56], "convinc": 32, "convolut": [39, 44], "convolutional_neural_network": 44, "cooccurrencematrix": 43, "cook": 40, "cool": 44, "coolwarm": 33, "coordin": 57, "copi": [0, 7, 8, 11, 28, 34, 37, 38, 40, 42, 44, 45, 46, 55, 56, 57], "copy_arrai": 47, "copyright": 0, "cor": 38, "coral": 44, "core": [9, 29, 31, 32, 34, 35, 36, 39, 41, 42, 45, 46, 47, 49, 56, 57], "corefer": 43, "corgi": [27, 44], "coro": 47, "corona_nlp_test": 47, "coronapocalyps": 47, "coronaviru": 47, "corpor": [5, 47], "corpora": [32, 43], "corpu": [32, 35, 43], "corr": 38, "corr_df": 38, "correct": [7, 27, 28, 29, 30, 35, 37, 38, 46, 50, 51, 55], "correctli": [10, 11, 28, 29, 35], "correl": [45, 49], "correspond": [10, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 42, 45, 51, 53], "cosin": 43, "cosine_similar": 43, "cost": [8, 27, 44, 57], "cost_rep": 8, "costli": 35, "cot": 44, "cote": 44, "could": [6, 8, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 42, 43, 45, 46, 51, 53, 54, 56, 57], "count": [8, 28, 31, 32, 35, 36, 39, 43, 44, 45, 46, 47, 48, 51, 53, 54, 56, 57], "counter": 35, "counti": 51, "countri": [29, 30, 32, 33, 35, 37, 38, 54, 57], "country_columbia": 38, "country_dominican": 38, "country_guatemala": 38, "country_hondura": 38, "country_hong": 38, "country_hungari": 38, "country_india": 38, "country_iran": 38, "country_miss": [37, 38], "country_puerto": 38, "country_scotland": 38, "country_south": 38, "country_taiwan": 38, "country_thailand": 38, "country_trinadad": [37, 38], "country_unit": [37, 38], "country_vietnam": [37, 38], "country_yugoslavia": [37, 38], "countvector": [27, 33, 34, 35, 43, 47, 49, 53], "countvectorizercountvector": [32, 34, 47], "countvectorizeroriginaltweet": 47, "countvectorizersong_titl": 34, "coupl": [4, 28, 34, 41, 47, 56], "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53], "coursera": [9, 10], "coursework": 57, "court": 43, "covari": [28, 46], "cover": [8, 35, 37, 40, 44, 45, 57], "coverag": 35, "covid": 47, "covid2019": 47, "cox": 57, "coxph_fitt": 46, "coxphfitt": 46, "cph": [46, 49], "cph_param": 46, "cpp": 47, "cpsc": [9, 10, 11, 27, 28, 37, 39, 43, 44, 45, 47, 57], "cpsc330": [0, 11, 27, 28, 29, 32, 34, 38, 43, 44, 46, 47, 57], "cpsc330env": 11, "cpu": [34, 44, 47], "craft": [30, 35, 37, 38, 40, 51], "crash": [10, 47], "crate": 44, "creat": [8, 9, 11, 27, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "create_lag_df": 45, "create_lag_featur": [45, 56], "create_y_from_r": 42, "creativ": 1, "credit": [0, 28, 35, 37, 43, 45, 46, 54], "creditcard": [35, 54], "crime": 33, "crimin": 38, "criteria": [28, 41], "criterion": 41, "critic": 57, "cross": [15, 28, 30, 32, 34, 36, 37, 38, 40, 42, 46, 47, 49, 52, 53, 54, 55, 56], "cross_val": 37, "cross_val_predict": [35, 37, 46], "cross_val_scor": [31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 52, 53, 54, 55, 56], "cross_valid": [30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56], "cross_validate_std": 29, "crowd": [37, 41], "crown": 57, "crucial": [27, 29, 33, 38, 40, 41, 42, 43], "crude": 43, "cs189": 9, "cs189_ch7": 9, "csrc": 47, "csv": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "ct": 32, "cuda": 44, "cui": 57, "cultiv": 57, "cultur": [44, 57], "cupi": 47, "curios": 27, "curiou": [27, 51], "current": [37, 43, 44, 45, 46, 47], "curriculum": 57, "curv": [7, 8, 40, 49, 51, 57], "custom": [5, 8, 27, 28, 32, 35, 36, 42, 47, 49], "custom_plot_tre": [28, 29, 37, 38], "customerid": 46, "customiz": 47, "cut": 41, "cv": [29, 32, 35, 36, 37, 38, 39, 45, 46, 49, 51, 53], "cv_feat": 47, "cv_results_": [34, 36, 53], "cv_score": [29, 36], "cv_train_scor": 51, "cv_valid_scor": 51, "cycl": 8, "cyclic": 45, "cycling_data": 8, "cygnu": 44, "d": [4, 8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 54, 55, 56], "d1b": 57, "d1c": 57, "d1e": 57, "d1f": 57, "d3": 40, "da": 27, "dabeaz": 9, "dad": 39, "dai": [4, 8, 10, 39, 44, 46, 49, 56, 57], "daili": [46, 49], "dall": 45, "damag": [0, 35], "dan": 43, "danceabl": [30, 31, 34, 53], "dark": 47, "darker": 34, "dashboard": [30, 51], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 41, 43, 46, 48, 49, 50, 52, 53, 54, 55, 57], "data_dict": 33, "data_dir": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56], "data_to_wrap": 32, "data_transform": 44, "data_transforms_bw": 44, "data_url": [35, 54], "datacamp": 9, "datafram": [27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56], "dataload": 44, "dataloaders_bw": 44, "datapoint": 33, "dataquest": 9, "dataset": [8, 18, 27, 29, 30, 37, 38, 39, 40, 41, 46, 47, 48, 49, 51, 53, 54, 57], "dataset2": 40, "dataset_s": 44, "date": [7, 11, 27, 28, 42, 46, 47, 49, 51, 56, 57], "date_rang": 45, "dates_rain": [45, 56], "datetim": 46, "datetime64": [45, 56], "datetimeindex": 45, "daughter": 35, "daum\u00e9": 10, "daunt": 42, "dave": 43, "david": [10, 43], "day_nam": [45, 56], "daylight": [45, 56], "dayofweek": 45, "days_sinc": 45, "dbscan": 57, "dc": [45, 46, 47], "dcc": 33, "dd": [45, 56], "de": [43, 45], "deactiv": 11, "deadlin": 57, "deal": [0, 29, 30, 31, 36, 43, 46, 49, 52], "death": 57, "debat": [8, 38], "debbi": 47, "debug": [4, 38], "decad": 44, "decemb": [45, 56], "decid": [8, 28, 30, 33, 37, 38, 39, 40, 41, 43, 45, 46, 49], "decis": [2, 6, 10, 14, 29, 31, 34, 35, 37, 39, 44, 48, 49, 50, 52, 55, 57], "decision_boundari": 48, "decision_funct": 35, "decisiontreeclassifi": [29, 30, 31, 32, 33, 34, 38, 50, 51, 52, 53, 55], "decisiontreeclassifierdecisiontreeclassifi": 37, "decisiontreeregressor": [28, 36, 50, 51], "deck": 9, "declar": 57, "decomposit": [41, 42, 43], "decor": 47, "decreas": [29, 33, 34, 37, 38, 40, 51], "deduct": 7, "deem": 6, "deep": [2, 9, 34, 38, 39, 43, 46], "deepen": [49, 57], "deeper": [2, 34, 35, 36, 38], "deepexplain": 38, "def": [29, 30, 31, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 51, 53, 56], "defalut": 53, "default": [5, 11, 28, 29, 32, 33, 34, 35, 36, 37, 40, 41, 44, 45, 46, 48, 53, 54, 57], "default_threshold": 35, "defaultdict": 42, "defin": [28, 30, 31, 32, 35, 37, 38, 40, 41, 42, 45, 56], "definit": [8, 30, 38, 40, 43, 45, 48, 49, 50], "degre": 35, "degrees_freedom": 46, "degrees_of_freedom": 46, "del": 37, "delai": [10, 11, 39], "deleg": 43, "delet": [4, 7, 31], "delgado": 37, "delight": 43, "deliver": 7, "delv": [43, 57], "demo": [10, 37, 57], "demograph": [28, 42], "demonstr": [28, 29, 31, 33, 34, 36, 37, 40, 42, 43, 44], "denomin": [36, 47], "denot": [28, 42], "dens": [41, 43], "densenet": 44, "densenet121": 44, "densenet121_weight": 44, "densiti": [38, 41, 49], "dep": 43, "department": 57, "departur": 39, "depend": [2, 8, 11, 28, 29, 30, 32, 34, 35, 36, 37, 38, 40, 41, 43, 45, 46, 55], "dependence_plot": 38, "dependents_no": 46, "dependents_y": 46, "deploi": [29, 35, 42, 49], "deploy": [38, 45, 57], "deprec": [29, 31, 35, 36, 46, 48], "deprecationwarn": [37, 46], "depth": [10, 28, 29, 34, 37, 41, 50, 51], "dequ": [37, 38, 55], "deriv": [0, 28, 33, 35, 42, 46, 49, 54], "descend": [8, 41, 44, 49], "descent": 45, "descr": 33, "describ": [8, 27, 28, 29, 30, 31, 33, 35, 36, 42, 43, 45, 51, 54, 56, 57], "descript": [36, 46, 47], "deserv": 6, "design": [28, 38, 41, 44, 53, 57], "desir": [35, 43, 46, 52], "desk": 57, "despit": [39, 43], "det": [43, 47], "detach": 44, "detail": [7, 30, 32, 37, 44, 57], "detect": [27, 28, 35, 36, 40, 41, 45, 54], "determin": [30, 40, 41, 43, 46, 51, 55, 57], "detriment": [35, 42, 54], "dev": [29, 48], "develop": [9, 10, 27, 29, 31, 32, 34, 35, 36, 37, 43, 44, 47, 49, 57], "devianc": 46, "deviat": [6, 29, 31, 37, 38], "devic": [37, 44, 47], "deviceprotect": 46, "deviceprotection_no": 46, "deviceprotection_y": 46, "df": [27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 44, 45, 46, 47, 50, 56], "df_concat": 27, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 45, "df_locat": [45, 56], "di": 46, "diagnos": [29, 38, 49], "diagnosi": 35, "diagnost": 46, "diagon": [30, 35, 38], "diagram": [32, 34, 37, 38], "dialogu": 43, "dict": [35, 42], "dict_kei": 37, "dictionari": [8, 31, 34, 35, 37, 38], "did": [6, 28, 30, 38, 40, 43, 45, 47, 51, 53, 54, 55, 57], "didn": [34, 37, 38, 41, 45, 46], "die": 47, "diet": 28, "diff": [45, 56], "differ": [2, 5, 7, 8, 10, 11, 27, 28, 29, 30, 32, 33, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57], "differenti": [27, 28, 57], "difficult": [4, 6, 7, 35, 39, 40], "difficulti": [40, 49], "dig": [35, 36], "digit": 45, "dilemma": 42, "dim": 44, "dimens": [8, 33, 39], "dimension": [2, 8, 33, 34, 35, 37, 39, 40, 43], "direct": [33, 38, 39, 41, 43, 47], "direct_bilirubin": 27, "directli": [8, 10, 32, 36, 44, 46, 57], "director": 42, "directori": [11, 28, 29, 31], "dirichlet": [43, 44], "disabl": 43, "disadvantag": [34, 37, 41, 42, 52], "disast": 27, "discard": [39, 43], "disciplin": [35, 39], "disclos": [47, 57], "discourag": 8, "discours": 42, "discov": [39, 40], "discoveri": 27, "discret": [28, 39, 57], "discrete_scatt": [28, 29, 30, 33, 40, 41, 44, 48, 50, 51], "discretization_feat": 39, "discrimin": 37, "discuss": [1, 4, 29, 30, 31, 33, 38, 39, 40, 41, 45, 49, 51, 52, 53, 55, 56, 57], "diseas": [28, 35, 46], "dispatch": 47, "dispatch_queu": 47, "dispatch_shel": 47, "displaci": [43, 47], "displai": [7, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 50, 51, 52, 53, 54, 56], "display_heatmap": [34, 53], "display_label": [35, 54], "disput": 43, "disrespect": 4, "dist": [30, 40, 41], "distanc": [8, 31, 39, 41, 42, 43], "distinct": [35, 39, 45], "distinguish": [28, 30, 32, 35, 51], "distract": 57, "distribut": [0, 11, 29, 35, 38, 39, 41, 43, 44, 45, 53, 56, 57], "district": [31, 33], "districtdatalab": 40, "disturb": 27, "dive": 38, "divers": [37, 40, 42, 45, 57], "divid": [33, 35, 37, 38, 45, 51], "divis": 38, "divorc": [37, 38], "dktal": 46, "dlwqn": 46, "dmp": 57, "do": [0, 4, 5, 6, 7, 8, 10, 11, 27, 28, 29, 30, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "do_execut": 47, "doc": [8, 9, 38, 43, 44, 47, 57], "doctor": [35, 37, 38, 54], "document": [0, 1, 7, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 49, 53, 54, 55, 57], "document_top": 43, "documentari": 42, "doe": [5, 8, 11, 27, 29, 30, 31, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 49, 51, 53, 55, 56, 57], "doesn": [7, 8, 29, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 49], "dog": [35, 44], "dollar": [4, 33, 36], "dolli": 47, "domain": [0, 27, 38, 40, 43], "domin": [31, 36, 44], "domingo": [10, 29, 39], "don": [4, 27, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48], "done": [5, 11, 29, 32, 34, 35, 44, 45, 49, 52, 54], "dont": 47, "door": 44, "dot": [30, 33, 35, 37, 38, 39, 41, 43], "dot_product": 43, "doubl": 34, "down": [29, 35, 38, 46, 51, 55, 57], "downfal": 42, "downgrad": 47, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 35, 36, 38, 43, 44, 47, 51, 55], "dpi": 39, "dr": [43, 57], "draft": 10, "drag": 7, "drama": 42, "drastic": 35, "draw": [33, 34, 43], "drawback": [38, 42, 57], "drawn": 37, "dream": 44, "drinker": 43, "drive": [27, 38], "driven": [11, 34, 35], "drop": [7, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57], "drop_dupl": [30, 34], "drop_feat": [32, 49], "drop_featur": [35, 36, 37, 38, 45, 46, 47, 54, 56], "dropdown": [19, 23, 24, 25, 26], "dropdrop": [32, 36, 37, 47], "drope": 31, "dropna": [35, 45, 56], "dropoff": 40, "drug": 27, "dsci": [9, 10, 38, 48], "dsl": 46, "dt": 51, "dt88trtd17lf726d55bq16c40000gr": 47, "dt_best": 51, "dt_pipe": 34, "dtype": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 55, 56], "dual": 35, "duan": 57, "duck": 44, "duckbil": 44, "due": [7, 33, 37, 39, 42, 57], "dummi": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 50, 52, 53, 54, 55, 56], "dummy_clf": [28, 50], "dummy_scor": 30, "dummy_valid_accuraci": 30, "dummyclassifi": [29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 44, 47, 50, 51, 52, 53, 54, 55, 56], "dummyregressor": [32, 37, 38, 39, 47, 52, 55], "dun": 27, "dunno": 27, "duplex": 36, "duplic": 8, "durat": [7, 39, 45, 46], "duration_col": 46, "duration_m": [30, 31, 34], "dure": [4, 8, 10, 27, 28, 30, 32, 33, 34, 37, 38, 39, 42, 49, 50, 51, 52, 53, 54, 55, 56, 57], "dwell": 36, "e": [6, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 56, 57], "e737c5242822": 46, "e_": 29, "each": [7, 8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57], "earli": [38, 46], "earlier": [31, 37, 39, 45, 46], "early_stopping_round": 37, "earn": 57, "earnest": 57, "easi": [7, 30, 31, 33, 37, 38, 39, 40, 41, 43, 47], "easier": [5, 7, 35, 38, 39, 42], "easiest": [38, 46, 47], "easili": [37, 39, 45, 50, 56], "echidna": 44, "econom": [32, 45], "ecosystem": 44, "ed": 1, "eda": [29, 43, 46, 49, 56], "edg": [28, 34], "edgecolor": [34, 45, 56], "edit": [34, 43], "edu": 9, "educ": [35, 37, 38, 42, 54], "education_level": [35, 37, 38, 54], "effect": [30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 49, 51, 54], "effici": 34, "effort": [4, 11, 34, 39, 40, 42, 44, 57], "egg": 40, "eghbal": 57, "either": [4, 28, 29, 30, 32, 35, 38, 40, 41, 43, 44, 45, 51, 53], "elast": 46, "elbow": 41, "elect": 43, "electr": [36, 38], "electrical_fusea": 36, "electrical_fusef": 36, "electrical_fusep": 36, "electrical_miss": 36, "electrical_mix": 36, "electrical_sbrkr": 36, "electron": [46, 57], "eleg": 31, "elegantli": 43, "element": [0, 9, 10, 29, 32, 43, 50], "eli5": 38, "elif": [28, 45, 46], "elimin": 57, "els": [28, 32, 35, 44, 45, 46, 47, 54], "email": [27, 29, 35, 57], "emb": [7, 30, 35, 40, 41], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 44, 49, 57], "emoji": 47, "emoticon": [39, 40], "emp": 38, "empathi": 43, "emphas": 57, "emphasi": 57, "emploi": [45, 46, 49], "employ": 42, "employe": 28, "empti": [33, 43, 44, 45, 56], "en": [45, 46, 47, 56], "en_core_web_lr": 43, "en_core_web_md": [43, 47], "enabl": [11, 42, 43, 45], "enable_categor": 37, "enable_halving_search_cv": 34, "enc": [31, 32, 45], "enclosedporch": [36, 38], "encod": [16, 17, 27, 29, 34, 35, 36, 38, 42, 46, 49, 52, 54, 56], "encompass": [46, 49], "encount": [32, 34], "encourag": [11, 57], "end": [4, 8, 27, 29, 30, 33, 34, 35, 39, 40, 41, 42, 43, 45, 46, 51, 57], "endors": 0, "endpoint": 46, "energi": [30, 31, 34, 45, 53], "engag": 57, "engin": [9, 10, 32, 35, 36, 40, 42, 43, 46, 56, 57], "england": 47, "english": [27, 31, 34, 35, 43, 44, 47, 53], "enhanc": 57, "enjoi": [10, 33], "enjoy_class": 32, "enjoy_cours": [32, 49], "enjoy_course_enc": 32, "enjoy_the_mo": 35, "enough": [7, 30, 32, 35, 36, 37, 40, 42, 49, 53, 54, 56], "ensembl": [10, 19, 20, 36, 38, 39, 41, 42, 45, 46, 47, 55, 56, 57], "ensiti": 41, "ensur": [7, 31, 37, 45, 56, 57], "ent": [43, 47], "enter": [32, 46, 53], "enterpris": 5, "entertain": 43, "enthusiast": 27, "entir": [4, 8, 29, 36, 44, 45, 47, 55, 57], "entiti": [39, 42, 43, 47], "entitl": 32, "entlebuch": [27, 44], "entri": [30, 31, 32, 33, 35, 36, 39, 42, 45, 46, 56], "entropi": 28, "enumer": 37, "env": [11, 28, 29, 32, 34, 38, 46, 47, 48], "environ": [3, 5, 8, 27, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 46, 47, 57], "environemnt": 11, "environment": 49, "ep": [28, 29, 30, 33, 41, 50], "epoch": 45, "epsilon": 41, "equal": [8, 30, 32, 35, 36, 37, 38, 41, 42, 45, 49, 56, 57], "equat": [4, 33], "equip": [30, 46, 57], "equival": [8, 35, 37, 54], "err": 43, "error": [4, 6, 7, 8, 11, 28, 30, 32, 33, 37, 38, 39, 43, 46, 47, 49, 51, 55, 57], "error_": 29, "erupt": 27, "erythrocebu": [27, 44], "es": [45, 56], "eskimo": 35, "esl": 10, "especi": [2, 28, 30, 34, 35, 37, 39, 42, 45], "essenti": [46, 49], "estat": 28, "estim": [29, 30, 32, 33, 34, 39, 40, 46, 49, 55], "estimators_": 37, "et": [37, 43], "etc": [2, 7, 8, 28, 39, 44, 45, 46, 47, 57], "ethic": [10, 57], "euclidean": [40, 41, 43], "euclidean_dist": [30, 31, 40, 41, 43], "ev": 47, "eva": 42, "eva_model": 42, "eval": 44, "eval_metr": [37, 38], "eval_on_featur": 45, "evalu": [8, 10, 28, 29, 34, 36, 38, 40, 45, 51, 55, 57], "evapor": [45, 56], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 39, 40, 41, 42, 45, 46, 47, 49, 51, 52, 54, 57], "event": [0, 35, 36, 47, 57], "event_col": 46, "event_observ": 46, "ever": [28, 48], "everi": [8, 28, 29, 37, 41, 45, 51], "everydai": [8, 43], "everyon": [6, 38, 49], "everyth": [32, 35, 42, 45, 55], "everywher": 45, "evict": 47, "evok": 43, "ex": [36, 38], "ex1_idx": 38, "ex2_idx": 38, "exact": [4, 46], "exactli": [7, 27, 29, 38, 51, 53], "exam": [6, 10], "examin": [29, 30, 31, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 54, 56], "exampl": [0, 4, 5, 6, 7, 8, 11, 36, 41, 42, 44, 45, 48, 49, 50, 51, 53, 54, 56, 57], "example1": 28, "example2": 28, "exceedingli": 51, "excel": [32, 33, 36, 38, 46, 49, 52], "except": [0, 7, 8, 29, 45, 46, 56, 57], "exception": 4, "exchang": [35, 49], "excit": 42, "exec": 47, "execut": [4, 7, 40], "execute_request": 47, "exercis": [7, 9, 10, 43, 47, 51, 52, 53, 54, 55, 56, 57], "exerciseangina": 55, "exhaust": 53, "exist": [8, 35, 39, 46, 54], "exp": [33, 46], "expand": [10, 28, 57], "expect": [1, 4, 7, 8, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 56, 57], "expected_valu": 38, "expenditur": 45, "expens": [27, 35, 36, 39, 40, 42], "experi": [27, 34, 42, 43, 57], "experienc": 57, "experiment": 34, "expert": [27, 28, 29, 34, 38, 39, 54], "explain": [4, 7, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 54, 55, 57], "explan": [4, 29, 30, 49, 54], "explanatori": 28, "explicit": [35, 46], "explicitli": [8, 27], "exploit": 6, "explor": [28, 29, 32, 34, 35, 38, 39, 42, 43, 44, 51, 53], "exploratori": [36, 46, 49], "explos": 47, "expm1": 36, "expon": 34, "exponenti": 34, "export_graphviz": [28, 50], "exposur": 42, "express": [0, 8, 32, 33, 39, 43], "extend": [43, 44, 48, 57], "extend_block": 46, "extens": [30, 35, 38, 40, 41, 43, 45, 51, 57], "extent": [40, 43], "extercond": [36, 38], "exterior": 38, "exterior1st": [36, 38], "exterior1st_asbshng": 36, "exterior1st_asphshn": 36, "exterior1st_brkcomm": 36, "exterior1st_brkfac": 36, "exterior1st_cblock": 36, "exterior1st_cemntbd": 36, "exterior1st_hdboard": 36, "exterior1st_imstucc": [36, 38], "exterior1st_metalsd": 36, "exterior1st_plywood": 36, "exterior1st_ston": 36, "exterior1st_stucco": 36, "exterior1st_vinylsd": 36, "exterior1st_wd": 36, "exterior1st_wdsh": 36, "exterior2nd": [36, 38], "exterior2nd_asbshng": 36, "exterior2nd_asphshn": 36, "exterior2nd_brk": 36, "exterior2nd_brkfac": 36, "exterior2nd_cblock": 36, "exterior2nd_cmentbd": 36, "exterior2nd_hdboard": 36, "exterior2nd_imstucc": 36, "exterior2nd_metalsd": 36, "exterior2nd_oth": 36, "exterior2nd_plywood": 36, "exterior2nd_ston": 36, "exterior2nd_stucco": 36, "exterior2nd_vinylsd": 36, "exterior2nd_wd": 36, "exterqu": [36, 38], "extra": [4, 40, 45, 56, 57], "extract": [39, 40, 42, 43, 44, 47, 56, 57], "extractor": 49, "extrapol": [45, 46], "extratreesclassifi": 37, "extrem": [6, 32, 35, 37, 38, 42, 46, 47], "ey": 47, "f": [8, 11, 27, 28, 29, 30, 31, 32, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 55, 56, 57], "f1": [18, 36, 49, 57], "f1_score": 35, "f403": 47, "fa": [36, 38], "face": [27, 28, 30, 42, 44], "facebook": [42, 43, 57], "facial": 30, "facil": 57, "facilit": [8, 57], "fact": [27, 34, 35, 37, 44, 45, 46, 56], "factor": [28, 34, 38, 39, 41, 42, 46], "fail": [7, 8, 10, 11, 29, 31, 32, 39, 41, 43, 46, 47], "failur": [7, 27, 46, 55, 57], "fair": [6, 29, 31, 36, 38, 40, 49, 57], "fairli": [29, 34, 35, 38, 54], "fake": 30, "fall": [30, 40, 43, 45], "fals": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 49, 54, 55, 56], "famili": [27, 34, 35, 36, 37, 38, 40, 57], "familiar": [8, 11, 28, 31, 51, 56, 57], "famou": [9, 10, 44], "fanci": [4, 27, 34], "fancier": 39, "far": [28, 30, 31, 32, 33, 35, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 51, 53, 55], "farm": 35, "farthest": 28, "fashion": [37, 43], "fast": [29, 30, 33, 37, 38, 43, 46, 57], "faster": [27, 34, 37, 39, 44], "fastest": 37, "fastingb": 55, "fasttext": 43, "favourit": 43, "fc": 33, "fcluster": 41, "feat": [34, 45, 47], "feat1": 40, "feat2": 40, "feat_nam": [45, 47], "feat_vec": 42, "featur": [10, 16, 17, 21, 22, 23, 24, 25, 26, 29, 35, 37, 40, 41, 43, 46, 48, 51, 52, 53, 54, 55, 57], "feature_extract": [27, 32, 33, 34, 35, 43, 47, 53], "feature_importances_": 39, "feature_nam": [28, 29, 33, 37, 38, 39, 43], "feature_names_out": 32, "feature_select": 39, "feature_typ": 37, "features_lag": 45, "features_nonzero": 45, "features_poli": 45, "februari": 45, "feder": [35, 38, 45], "feedback": [28, 49], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 40, 49], "feli": [27, 44], "fell": 33, "femal": [35, 37, 38, 46, 54], "female_cm": [35, 54], "female_pr": [35, 54], "fenc": [36, 38, 44], "fernandez": 37, "fetch_california_h": 33, "few": [8, 10, 27, 33, 36, 37, 39, 42, 44, 45, 46, 50, 55], "fewer": [11, 37, 39, 41], "fewest": 55, "fiber": 46, "fiction": 47, "field": [2, 4, 27, 32, 43, 44, 45, 57], "fig": [29, 30, 33, 35, 39, 40, 41, 44, 51, 54], "figsiz": [28, 29, 30, 31, 33, 35, 38, 39, 40, 41, 44, 45, 46, 51, 54], "figur": [4, 8, 11, 27, 28, 30, 34, 36, 38, 39, 40, 41, 44, 45, 46, 51], "file": [0, 1, 4, 5, 7, 8, 11, 19, 25, 28, 32, 35, 38, 44, 46, 47, 54, 56], "filenam": 44, "fill": [30, 33, 34, 42, 51, 55, 57], "fill_diagon": 30, "fill_valu": [35, 36, 37, 38, 45, 54, 56], "film": [43, 47], "filter": [4, 27, 29, 40, 45, 49, 56, 57], "filterwarn": [30, 46, 55], "final": [6, 7, 10, 29, 31, 37, 39, 50, 52, 55], "final_estim": 37, "final_estimator_": [37, 55], "financ": [44, 45], "find": [7, 8, 10, 27, 28, 31, 34, 36, 37, 38, 40, 41, 42, 43, 47, 48, 53, 54, 57], "fine": [7, 31, 32, 35, 42, 44, 45, 55], "finish": [25, 27, 36], "fira": [0, 1, 57], "firasm": [35, 54], "fireplac": [36, 38], "fireplacequ": [36, 38], "first": [4, 8, 10, 28, 30, 32, 33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 53, 54, 55, 57], "first_dai": 45, "first_day_retail": 45, "firth": 43, "fish": [35, 38], "fist": 45, "fit": [0, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56], "fit_intercept": 35, "fit_predict": 41, "fit_resampl": 35, "fit_tim": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47], "fit_transform": [31, 32, 35, 37, 38, 39, 41, 42, 43, 45, 49, 54], "fittedcolumntransform": [32, 37], "fittedpipelin": [32, 34, 36], "fittedvotingclassifi": 37, "fitter": 46, "five": 34, "fix": [31, 32, 37, 46, 48, 51, 57], "flag": 46, "flagstaff": 47, "flaki": 35, "flashcard": 49, "flat": 41, "flatten": [37, 38, 41, 45, 55], "flatten_train": 44, "flatten_transform": 44, "flatten_valid": 44, "flaw": [29, 31], "flawless": 33, "flexibl": [7, 27, 39, 44, 49, 57], "flibbertigibbet": 43, "flickr_cat_000002": 44, "flight": 39, "flip": [10, 29, 35, 36], "flip_i": 35, "float": [8, 36, 39, 46, 47], "float32": [43, 44], "float64": [28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 45, 46, 56], "floatlogslid": [30, 51], "floatslid": [30, 35, 40, 41, 51], "floor": [27, 28], "flower": [30, 35, 51], "fmt": 34, "fn": 35, "fnlwgt": [35, 37, 38, 54], "focu": [10, 27, 31, 32, 33, 38, 41, 42, 43, 45, 49, 51, 52, 53, 54, 55, 57], "focus": [27, 33, 40, 43, 49, 56], "fold": [29, 31, 32, 34, 35, 36, 37, 51], "folder": [5, 6, 29, 31, 38, 47], "folk": [46, 57], "follow": [0, 5, 6, 7, 8, 11, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 51, 57], "font": [27, 28, 29, 40, 41, 42, 45, 46], "font_scal": 38, "fontsiz": [28, 29, 30, 35, 37, 38, 40, 44, 50, 51], "food": [40, 43, 44, 57], "foot": [36, 38], "footag": 33, "footstal": 44, "forc": [35, 38, 51], "force_plot": 38, "forecast": [28, 46, 49, 56, 57], "forest": [35, 36, 44, 45, 46, 49, 55, 57], "forev": 45, "forg": [11, 35, 36, 37, 38, 43, 46, 47], "forget": [28, 32, 37, 55], "form": [10, 32, 35, 39, 41, 42, 43, 46, 49], "formal": 57, "format": [0, 10, 28, 35, 41, 43, 45, 46, 56], "former": 46, "formul": [4, 34], "formula": [33, 36, 44, 48], "forum": [6, 7], "forward": 46, "found": [7, 10, 29, 32, 34, 36, 40, 42, 43, 47, 49, 53, 55, 57], "foundat": [9, 10, 35, 36, 38, 57], "foundation_brktil": 36, "foundation_cblock": 36, "foundation_pconc": 36, "foundation_slab": 36, "foundation_ston": 36, "foundation_wood": 36, "fountain": 44, "four": [28, 29, 39, 41, 49], "fourth": 41, "foxhound": [27, 44], "foyer": 36, "fp": 35, "fpr": 35, "fpr_lr": 35, "fpr_svc": 35, "frac": [28, 33, 35, 36, 40, 43, 44], "fractal": 39, "fraction": [32, 35, 42], "fragment": 51, "frame": [31, 32, 35, 36, 39, 45, 46, 56], "framework": [28, 34], "fraud": [28, 35, 36, 40, 45, 54], "fraudul": [28, 35, 54], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 36, 43, 46], "freedom": [0, 47], "french": 31, "freq": [45, 56], "frequenc": [32, 43, 45, 46, 49, 56], "frequent": [28, 31, 42, 43, 46], "fresh": 42, "fri": [10, 45], "fridai": [10, 57], "friend": [28, 29, 35, 38, 41, 42, 49, 57], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "from_block": 46, "from_estim": [35, 54], "front": 57, "frozen": 47, "fruit": 43, "frustrat": [4, 6, 34], "full": [34, 37, 44, 45, 46, 57], "fullbath": [36, 38], "fulli": 41, "fun": [35, 43, 44], "func": [8, 32, 33, 36], "function": [2, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 56], "functiontransform": [32, 46], "fund": 47, "fundament": [2, 9, 10, 15, 31, 33, 34, 36, 39, 44, 46, 57], "funni": [27, 37, 47], "furnish": 0, "furnitur": 49, "further": [35, 37, 39, 40, 44, 46, 51, 53, 54], "futur": [29, 31, 34, 36, 46, 49, 53, 56, 57], "futurewarn": [29, 31, 36, 38, 48], "fyi": 46, "g": [6, 7, 8, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 56, 57], "g26r0dcx4b35vf3nk31216hc0000gr": [31, 38], "gain": [6, 28, 35, 37, 38, 54, 57], "game": [28, 38], "gamma": [33, 34, 37, 51, 53], "gamma_log": [30, 51], "gamma_widget": [30, 51], "gap": [29, 45, 46, 49, 51], "garagearea": [36, 38], "garagecar": [36, 38], "garagecond": [36, 38], "garagefinish": [36, 38], "garagefinish_fin": 36, "garagefinish_miss": 36, "garagefinish_rfn": 36, "garagefinish_unf": 36, "garagequ": [36, 38], "garagetyp": [36, 38], "garagetype_2typ": 36, "garagetype_attchd": 36, "garagetype_bas": 36, "garagetype_builtin": 36, "garagetype_carport": 36, "garagetype_detchd": 36, "garagetype_miss": 36, "garageyrblt": [36, 38], "garlic": 40, "gauss": 43, "gaussian": 41, "gaussianmixtur": 41, "gave": [42, 45], "gbr": 8, "gca": [40, 41, 46], "gd": [27, 36, 38], "gdprv": [36, 38], "gdwo": [36, 38], "gelbart": [0, 1, 28, 43, 53], "gender": [27, 32, 35, 43, 45, 46, 54], "gender_femal": 46, "gender_mal": 46, "gener": [7, 9, 15, 28, 31, 32, 34, 35, 36, 38, 41, 43, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57], "genet": 39, "genom": 39, "genr": 42, "gensim": 43, "gentl": 57, "geograph": 33, "geometr": 28, "georg": 43, "geq": 33, "ger": 8, "german": 43, "get": [4, 5, 6, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57], "get_avg_word_length": 47, "get_cmap": 31, "get_depth": 51, "get_dummi": 31, "get_featur": 44, "get_feature_names_out": [31, 32, 35, 36, 37, 38, 39, 43, 45, 46, 47, 54, 56], "get_length_in_word": 47, "get_lr_data_per_us": 42, "get_permutation_import": 38, "get_relative_length": 47, "get_season": 45, "get_senti": 47, "get_stat": 42, "get_user_profil": 42, "getattr": 46, "gif": [40, 41], "gift": 47, "gini": [28, 38], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 27, 31, 32, 34, 35, 36, 37, 38, 39, 44, 47, 53, 54], "githubusercont": 8, "gitlf": 35, "giulia": [0, 1], "give": [0, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 54], "given": [0, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 56], "gladwel": 40, "glob": [27, 44], "global": [31, 35, 37, 40, 43, 49], "glove": [43, 57], "glq": [36, 38], "gmail": [27, 40], "go": [5, 7, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56], "goal": [2, 30, 31, 34, 35, 40, 41, 42, 43, 47, 53, 55, 56, 57], "goe": [2, 29, 30, 32, 35, 37, 38, 41, 42, 44], "gold": 8, "goldcoast": 45, "golden": [30, 49, 51], "good": [9, 11, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56], "googl": [4, 10, 27, 28, 37, 38, 39, 40, 43, 47], "google_news_vector": 43, "got": [30, 33, 34, 35, 36, 44], "gotten": [46, 55], "gov": [35, 37, 38], "govern": [43, 57], "gpe": 43, "gpt": [42, 43], "gpu": [37, 43, 44], "grad": [35, 37, 38, 54], "grade": [3, 7, 10, 27, 29, 32, 34, 49, 51, 52, 53, 54, 55, 56], "grader": 6, "grades_df": 49, "gradescop": [1, 6, 10, 57], "gradient": [19, 20, 49], "gradientboostingclassifi": 37, "gradientboostingregressor": 37, "gradientexplain": 38, "grading_concern": 6, "graduat": 44, "grai": 44, "grain": [33, 38], "gram": 43, "grammat": 43, "grandma": 39, "grandmoth": 35, "grant": 0, "granular": 41, "graph": [10, 44, 45], "graphic": 44, "graphviz": [28, 50], "grasp": [49, 57], "grayscal": 44, "great": [27, 28, 30, 32, 33, 38, 39, 43, 44, 45, 47], "greater": [11, 39, 40], "greater_is_bett": 36, "greedili": 41, "green": [30, 34, 40, 48], "grei": 57, "grid": [33, 36, 45, 46, 49, 53, 56], "grid_search": [34, 53], "gridsearchcv": [30, 37, 38, 53, 55], "gridsearchcvifittedgridsearchcv": 34, "grip": 43, "grlivarea": [36, 38], "groak": 43, "groceri": [44, 47], "groin": 44, "ground": [29, 39, 41, 42, 57], "ground_truth_categori": 35, "group": [7, 28, 30, 32, 33, 37, 39, 49, 51, 52, 55, 57], "groupbi": [45, 56], "grow": [34, 37, 39], "grow_polici": 37, "growth": [45, 46], "groyn": 44, "grv": 36, "gt": [32, 33, 34, 35, 36, 37], "gtl": 38, "guarante": [34, 35, 37, 40, 44], "guenon": 44, "guess": [30, 31, 43, 47], "guid": [7, 9, 10, 39, 44, 57], "guidanc": 38, "guidelin": [38, 39], "guido": 10, "h": [35, 37, 38, 40, 43, 44, 46, 47, 54], "ha": [2, 5, 6, 10, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 54, 55, 56, 57], "habit": 32, "hacki": [44, 48], "had": [27, 31, 32, 33, 35, 42, 44, 45, 46], "hadn": 46, "hal": 10, "half": [6, 10, 28, 33, 39, 41], "halfbath": [36, 38], "halvingrandomsearchcv": 34, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 34, "ham": 27, "hand": [4, 9, 35, 42, 54, 57], "handi": 35, "handl": [37, 38, 41, 46, 47, 48, 49, 51, 57], "handle_unknow": 32, "handle_unknown": [31, 32, 34, 35, 36, 37, 38, 45, 46, 49, 53, 54, 55, 56], "handler": [35, 38], "handrail": 44, "handwritten": 35, "hang": 35, "happen": [4, 6, 27, 30, 32, 34, 37, 38, 39, 42, 45, 46, 49, 56, 57], "happi": [35, 40, 46], "happier": 57, "happydb": 35, "hard": [8, 27, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 49, 55], "hardli": 42, "hardwar": 44, "harmon": 35, "harri": 43, "has_cupi": 47, "has_emoji": 47, "has_rais": 47, "hasn": [4, 42, 46], "hassl": [8, 38, 45], "hat": [33, 36, 37], "have": [0, 4, 6, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57], "haven": [29, 46, 49], "haylei": 28, "hazard": 57, "hc_truncation_toy_demo": 41, "hdbscan": 41, "he": [29, 32, 57], "head": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56], "headlin": 43, "health": 43, "healthcar": 38, "healthi": 43, "heard": 29, "heart": [28, 47, 55], "heart_df": 55, "heartdiseas": 55, "heat": [34, 36, 38, 53], "heating_floor": 36, "heating_gasa": 36, "heating_gasw": 36, "heating_grav": 36, "heating_othw": [36, 38], "heating_wal": 36, "heatingqc": [36, 38], "heatmap": 38, "heavi": [37, 47], "heavili": [42, 44, 45, 54], "heeren": 43, "height": [28, 29, 35, 43, 47, 50], "hell": 47, "help": [3, 7, 11, 27, 29, 31, 32, 34, 35, 38, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 56, 57], "henc": [5, 35, 36, 38, 40], "her": [27, 42, 43], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57], "herebi": 0, "herself": 47, "herta": 30, "heurist": [28, 34], "hi": [43, 51], "hidden": [39, 44], "hide": [8, 44], "hier_label": 41, "hier_labels1": 41, "hier_labels2": 41, "hierarch": [49, 57], "hierarchi": [28, 41], "high": [6, 29, 30, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 57], "high_corr": 38, "higher": [28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 42, 46, 51, 53, 54], "highest": [37, 38, 42, 43, 44, 48, 51, 54], "highland": 47, "highli": [10, 11, 31, 38, 42], "highlight": [4, 44, 49], "highwai": 33, "hinder": 57, "hindi": 31, "hint": [38, 51], "hist": [31, 34, 36, 39, 46], "histgradientboostingclassifi": 37, "histgradientboostingregressor": 37, "histogram": 46, "histor": 49, "histori": [33, 42, 45, 57], "hit": [27, 34], "hitter": 47, "hl": [36, 38], "hmid": 35, "hmmm": 46, "hockei": 43, "hold": 53, "holder": 0, "holdout": 35, "holidai": [10, 42, 57], "home": [28, 33, 35, 44], "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 30, 33, 34, 43, 49, 57], "honour": 57, "hood": 29, "hope": 29, "hopefulli": 53, "hopeless": 39, "hopelessli": 30, "horizont": [28, 32], "host": [5, 46], "hot": [16, 29, 32, 38, 49, 56], "hound": [27, 44], "hour": [4, 11, 35, 37, 38, 39, 42, 45, 49, 54, 57], "hourli": [46, 49], "hous": [18, 36, 38, 39, 46, 51], "houseag": 33, "household": [31, 32, 33, 39, 52], "housestyl": [36, 38], "housestyle_1": 36, "housestyle_1stori": 36, "housestyle_2": 36, "housestyle_2stori": 36, "housestyle_sfoy": 36, "housestyle_slvl": 36, "housing_df": [28, 31, 32, 39, 51, 52], "housing_median_ag": [31, 32, 39, 52], "houston": 47, "how": [0, 3, 8, 11, 27, 32, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57], "howard": 40, "howev": [2, 8, 31, 32, 35, 36, 38, 40, 42, 45, 46, 48, 51, 54], "hsjcy": 46, "hstack": 45, "html": [7, 9, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 46, 47, 50, 52, 54], "http": [0, 5, 8, 9, 11, 27, 28, 29, 31, 32, 33, 35, 36, 37, 44, 45, 46, 47, 54, 57], "hug": 42, "huge": [32, 36, 43, 44, 45, 46, 56], "human": [0, 27, 30, 31, 32, 33, 34, 35, 38, 39, 40, 43, 44, 54], "humidity3pm": [45, 56], "humidity3pm_lag1": [45, 56], "humidity9am": [45, 56], "hummu": [40, 43], "humour": [10, 43], "hundr": 33, "hurrai": 55, "hurrican": 27, "husband": [35, 37, 38], "hussar": [27, 44], "hw": 27, "hw1": [4, 10, 50], "hw2": [10, 30, 31, 53], "hw3": 10, "hw4": 10, "hw5": [10, 57], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 42, "hyperband": 34, "hyperopt": 34, "hyperparamet": [10, 29, 35, 41, 42, 43, 44, 53], "hyperparamt": [29, 34, 46], "hyperparlan": 33, "hyperplan": 33, "hypothesi": [43, 46], "hypothet": [33, 40], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 33, 36, 41, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "i1": 37, "i2": 37, "ia": 47, "ibm": 47, "ic": 43, "icc": 57, "iclick": 10, "id": [27, 28, 36, 38, 42, 51], "idea": [8, 28, 29, 31, 34, 38, 40, 41, 42, 43, 44, 45, 46, 49, 51, 56], "ideal": [4, 35, 37, 39, 42, 46], "ident": [43, 44, 47], "identif": [27, 47], "identifi": [28, 29, 30, 31, 34, 35, 36, 40, 41, 43, 44, 45, 49, 54, 56, 57], "idf": 32, "idx": 44, "idxmax": 30, "if_binari": [32, 35, 37, 38, 49, 52, 54, 55], "ifram": [29, 35], "igloo": 43, "ignor": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 45, 46, 49, 53, 54, 55, 56], "ignore_index": 8, "ii": 35, "iii": 10, "ij": [33, 42], "ik": 37, "ill": 57, "illus": [35, 54], "illustr": [41, 45], "iloc": [8, 28, 29, 30, 31, 32, 37, 38, 43, 45, 47, 50, 55, 56], "im": 47, "imag": [7, 29, 35, 38, 39, 40, 41, 45, 49, 54, 57], "image_dataset": 44, "image_datasets_bw": 44, "image_s": 44, "imagefold": 44, "imagenet": 48, "imagenet1k_v1": 44, "imagenet_class": [27, 44], "imagin": [27, 28, 29, 31, 33, 35, 38, 39, 40, 43, 46, 49, 50, 54], "imaginari": [29, 43], "imbal": [18, 40, 46, 54], "imbalanc": [35, 36, 48], "imblearn": 35, "img": [27, 44], "img_classifi": 27, "img_path": 27, "img_t": 44, "immedi": [38, 42, 57], "imp": [31, 32, 45], "impact": [7, 32, 33, 37, 38, 41, 45, 51, 56, 57], "implement": [2, 4, 27, 31, 35, 36, 37, 39, 41, 42, 43, 46, 48], "impli": [0, 46], "implic": [31, 49, 57], "implicit": 43, "import": [8, 10, 21, 22, 23, 24, 25, 26, 48, 52, 53, 54, 55, 57], "importance_typ": 37, "importances_mean": 38, "impos": 31, "imposs": 40, "impress": 38, "improv": [34, 35, 36, 37, 39, 40, 41, 42, 45, 46, 49, 53, 57], "impur": [28, 37], "imput": [16, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 49, 52, 53, 54, 55, 56], "imread": 44, "imshow": [27, 44], "inbox": 29, "inc": [38, 43], "incept": [42, 44], "inception": 44, "incl": 36, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 28, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57], "include_bia": [39, 45], "incom": [29, 33, 35, 37, 38, 54], "incomplet": 46, "inconsist": 32, "incorpor": [34, 36, 39, 46, 49], "incorrect": 46, "incorrectli": [27, 35], "increas": [8, 29, 30, 32, 33, 37, 38, 39, 40, 41, 44, 51, 53], "increasingli": 27, "incred": 44, "inde": 38, "independ": [8, 9, 28, 34, 36, 37, 39, 45, 57], "index": [27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 51, 54, 55, 56], "index_col": [8, 30, 31, 34, 35, 42, 53], "india": 43, "indian": 35, "indian_liver_pati": 27, "indic": [0, 32, 40, 42, 43, 44, 45, 46], "individu": [37, 38, 40, 42, 43, 46, 55, 57], "industri": [37, 39, 43, 44], "inequ": [35, 54], "inertia_": 40, "inertia_valu": 40, "inf": [30, 46], "infeas": 34, "infer": [28, 43, 44, 45, 50], "infin": 30, "infinit": 34, "inflamm": 9, "inflat": 38, "inflect": [40, 43], "influenc": [28, 29, 34, 38, 40, 42, 46, 51], "info": [1, 3, 8, 31, 32, 35, 36, 39, 43, 45, 46, 51, 55, 56], "inform": [1, 4, 7, 11, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 51, 54, 55, 56, 57], "inhabit": 57, "inher": [35, 45, 46, 54], "initi": [41, 44, 47], "initj": 38, "inject": [39, 42, 49], "inland": [31, 32, 39, 52], "inlin": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 50, 51, 53, 54, 55], "inner": [32, 34, 43], "inplac": [8, 27, 28, 34], "input": [8, 28, 31, 33, 37, 38, 41, 43, 44, 45, 47, 49, 56], "input_img": 44, "inputs_bw": 44, "insid": [9, 32, 35], "insight": [2, 30, 35, 38, 40, 57], "inspct": 35, "inspect": [38, 41], "inspir": [28, 35, 37], "instal": [27, 30, 35, 36, 37, 38, 40, 43, 44, 46, 47], "instanc": [27, 28, 29, 32, 33, 35, 40, 41, 42, 43, 44, 45, 48], "instanti": [34, 51], "instead": [5, 8, 11, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 53, 54, 55], "institut": 47, "instruct": [3, 4, 5, 11, 30, 57], "instructor": [4, 6, 27, 57], "instrument": [30, 31, 34, 53], "int": [31, 32, 35, 37, 38, 43, 45, 47, 54, 55, 56], "int32": [30, 40, 41, 45], "int64": [28, 30, 32, 35, 36, 42, 45, 46, 47], "integ": [8, 29, 31, 34, 37, 38, 45], "integr": 57, "intellig": [10, 43], "intend": 0, "intens": 43, "inter": 47, "interact": [9, 30, 34, 35, 38, 40, 41, 42, 45, 47, 51], "interaction_constraint": 37, "interaction_onli": [39, 45], "interactive_plot": [30, 51], "interactiveshel": 47, "intercept": [38, 44, 48], "intercept_": [33, 37, 44, 48], "intercept_sc": 35, "interest": [2, 27, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 53, 55, 56], "interfac": 37, "intermedi": [41, 44], "intern": [0, 1, 28, 44, 45, 46, 47], "internet": 46, "internetservic": 46, "internetservice_dsl": 46, "internetservice_fib": 46, "internetservice_no": 46, "internship": 27, "interpret": [10, 11, 21, 22, 23, 24, 25, 26, 30, 31, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 54, 57], "interv": [45, 46, 49, 53, 57], "intrins": 45, "intro": [10, 19, 20, 43, 44], "introduc": [32, 35, 46], "introduct": [9, 10, 11, 13, 16, 45, 46, 51, 57], "intslid": [30, 51], "intuit": [30, 31, 32, 34, 36, 38, 40, 41, 46, 47, 57], "invalid": 34, "inventori": 49, "invers": [33, 36], "inverse_func": 36, "investig": [30, 38, 51], "involv": [2, 4, 34, 36, 37, 41, 43, 44], "io": [9, 31, 44, 46, 47], "io_loop": 47, "ipkernel": 47, "ipykernel": 47, "ipykernel_19402": 38, "ipykernel_32469": 31, "ipykernel_79734": 29, "ipykernel_86208": 47, "ipykernel_launch": 47, "ipynb": [7, 8], "ipython": [27, 28, 29, 30, 31, 32, 33, 35, 43, 47, 50, 52, 54], "ipywidget": [30, 51], "ir1": [36, 38], "ir2": [36, 38], "iri": [30, 51], "iris_df": [30, 51], "irregular": 57, "irregularli": 49, "irrelev": [30, 39, 43], "irrelevant_po": 43, "irrespect": [29, 33, 57], "is_avail": 44, "is_leap_year": [45, 56], "is_stop": 43, "is_year_end": [45, 56], "isinst": 46, "island": [31, 32], "isn": [29, 30, 35, 36, 37], "isnul": 31, "isol": [11, 35, 36, 38], "issu": [4, 6, 7, 37, 42, 46, 49, 53, 57], "issubclass": 46, "isupp": 47, "itali": 43, "item": [27, 37, 38, 40, 42, 43, 44, 46, 49, 55], "item_inverse_mapp": 42, "item_kei": 42, "item_mapp": 42, "iter": [34, 39, 40, 41, 44], "iterable_with_config": 32, "iterrow": 42, "its": [8, 27, 29, 30, 32, 33, 35, 38, 40, 41, 43, 44, 45, 46, 47, 48, 51, 53, 56, 57], "itself": [7, 35, 37, 41], "j": [8, 33, 38, 39, 40, 42, 44], "j6": 47, "jackin": 34, "jackpot": 32, "jaguar": [27, 44], "jam": 34, "jame": [43, 46, 47], "jan": 1, "januari": 45, "japan": 43, "jargon": 28, "jason": [10, 39], "javascript": 38, "jellyfish": 44, "jennif": 47, "jerri": 42, "jet": 31, "jetti": 44, "jieba": 43, "jim": 42, "jmlr": 34, "job": [32, 45, 46, 56], "joblib": 32, "john": 37, "join": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57], "jointli": 45, "joke": [27, 42], "jolen": 47, "joseph": 57, "journal": 43, "journei": [10, 41, 57], "jpg": 44, "ju": 27, "jubatu": [27, 44], "judg": 39, "juic": 43, "juli": 45, "jun": 57, "june": [10, 45], "junh": 57, "jupyt": [1, 7, 8, 9, 11, 27, 31, 32, 34, 35, 36, 37, 38, 39, 44, 47], "jupyter_notebook": 46, "jupyterlab": 38, "jurafski": 43, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 49, 51, 55, 56, 57], "justic": [38, 57], "justif": 55, "k": [7, 10, 15, 29, 33, 35, 36, 37, 39, 43, 44, 46, 47, 48, 51, 57], "k_neighbor": 35, "k_valu": 30, "kaggl": [28, 31, 35, 36, 37, 38, 39, 44, 54, 55], "kaggler": 39, "kangaroo": 44, "kaplan": 57, "kaplanmeierfitt": 46, "kb": [32, 36, 46], "kbinsdiscret": 39, "kbinsdiscretizer__latitude_0": 39, "kbinsdiscretizer__latitude_1": 39, "kbinsdiscretizer__latitude_2": 39, "kbinsdiscretizer__latitude_3": 39, "kbinsdiscretizer__latitude_4": 39, "kbinsdiscretizer__latitude_5": 39, "kbinsdiscretizer__latitude_6": 39, "kbinsdiscretizer__latitude_7": 39, "kbinsdiscretizer__latitude_8": 39, "kbinsdiscretizer__latitude_9": 39, "kbinsdiscretizer__longitude_11": 39, "kbinsdiscretizer__longitude_12": 39, "kbinsdiscretizer__longitude_13": 39, "kbinsdiscretizer__longitude_14": 39, "kbinsdiscretizer__longitude_15": 39, "kbinsdiscretizer__longitude_16": 39, "kbinsdiscretizer__longitude_17": 39, "kbinsdiscretizer__longitude_18": 39, "kbinsdiscretizer__longitude_19": 39, "kbinsdiscretizerkbinsdiscret": 39, "kc_house_data": [27, 28, 51], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 35, 37, 38, 39, 40, 42, 43, 46, 51, 52, 57], "keep_empty_featur": 42, "kei": [9, 28, 29, 30, 31, 34, 35, 36, 37, 42, 43, 46, 53, 55, 57], "kelbowvisu": 40, "kellei": 33, "kelli": 57, "kept": 29, "kera": 38, "kernel": [7, 10, 15, 31, 33, 34, 38, 39, 51], "kernelapp": 47, "kernelbas": 47, "kernelexplain": 38, "keyword": [4, 34, 47], "kfold": 35, "kick": 43, "kilian": 38, "kill": 46, "kimia": 57, "kind": [0, 27, 28, 29, 31, 32, 33, 35, 36, 38, 40, 41, 42, 44, 45, 46, 48, 56], "king": [42, 43, 51], "kitchenabvgr": [36, 38], "kitchenqu": [36, 38], "kk": 40, "km": [46, 49], "km_label": 40, "kmean": [40, 41, 49], "kmf": 46, "kmqfw": 46, "kneighborregressor": 31, "kneighborsclassifi": [31, 32, 33, 39, 51, 52], "kneighborsregressor": [31, 32, 33, 52], "kneighborsregressorkneighborsregressor": [31, 32], "knew": 40, "knn": [2, 15, 29, 30, 31, 32, 33, 38, 39, 42, 44, 48, 49, 55], "knn1": 30, "knn100": 30, "knn_pipe": 32, "knn_scale": 31, "knn_unscal": 31, "knn_valid_accuraci": 30, "knnimput": 42, "knob": 28, "know": [8, 10, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57], "knowledg": [8, 28, 32, 34, 39, 40, 43, 49], "knowleg": 49, "known": [42, 43, 46], "koala": 44, "kolhatkar": [0, 1, 43], "kr9rkqfj4w78h49djkz8yy9r0000gp": 29, "ksatr": 46, "kvarada": [11, 28, 29, 32, 34, 38, 44, 46, 48], "kvarada01": 11, "kwarg": [29, 31, 32, 46, 47], "l": 11, "l1": [10, 46], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 35, "l2": [10, 35, 43, 46], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "lab": [11, 28, 29, 40, 42], "lab1": [28, 29, 32, 49], "lab2": [28, 29, 32, 49], "lab3": [28, 29, 32, 49], "lab4": [28, 29, 32, 49], "label": [7, 8, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 52], "label_": [43, 47], "label_encod": [37, 38], "label_n_clust": 41, "labelencod": [37, 38], "labels": [35, 40], "labels_": [40, 41], "lack": [29, 42], "lag": [46, 49], "lag_df": 45, "lakeshor": 44, "lakesid": 44, "lambda": [8, 28, 33, 41, 44, 45, 46, 47], "land": 46, "landcontour": [36, 38], "landcontour_bnk": 36, "landcontour_hl": 36, "landcontour_low": 36, "landcontour_lvl": 36, "landmark": 49, "landown": 47, "landscap": [40, 43], "landslop": [36, 38], "landslope_gtl": [36, 38], "landslope_mod": [36, 38], "landslope_sev": [36, 38], "languag": [2, 9, 31, 32, 42, 44, 47], "language_enc": 31, "language_english": 31, "language_french": 31, "language_hindi": 31, "language_mandarin": 31, "language_spanish": 31, "language_vietnames": 31, "laptop": 27, "lar": 27, "larg": [27, 29, 30, 31, 33, 35, 36, 40, 41, 43, 44, 49, 51, 54], "larger": [28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 41, 46], "largest": 36, "larvatu": [27, 44], "last": [8, 25, 28, 29, 30, 31, 32, 35, 38, 42, 44, 45, 46, 47, 51, 53, 55, 56, 57], "last_row": 8, "lastp": 41, "lat": [27, 28], "late": [35, 57], "latent": [42, 43, 44], "latentdirichletalloc": 43, "later": [11, 28, 32, 35, 44, 45, 51], "latest": [32, 38, 46], "latex": [4, 7], "latin": [27, 35, 54], "latitud": [29, 30, 31, 32, 33, 39, 52], "latitude_0": 39, "latitude_1": 39, "latitude_10": 39, "latitude_11": 39, "latitude_12": 39, "latitude_13": 39, "latitude_14": 39, "latitude_15": 39, "latitude_16": 39, "latitude_17": 39, "latitude_18": 39, "latitude_19": 39, "latitude_2": 39, "latitude_3": 39, "latitude_4": 39, "latitude_5": 39, "latitude_6": 39, "latitude_7": 39, "latitude_8": 39, "latitude_9": 39, "latter": 36, "launch_inst": 47, "launch_new_inst": 47, "lauvagrand": 47, "law": 43, "lawsuit": 43, "layer": 44, "layout": [30, 51], "lazi": 30, "lbfg": 35, "lda": 44, "ldot": 34, "lead": [8, 10, 29, 33, 36, 41, 42, 43, 46], "leaf": [28, 41], "leak": [31, 46, 49], "leakag": 49, "leaner": 29, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "learner": [29, 30, 37], "learning_method": 43, "learning_r": 37, "learnxinyminut": 9, "least": [4, 10, 29, 30, 35, 36, 38, 39, 40, 41, 55, 56, 57], "least_confident_i": 33, "least_confident_x": 33, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 41, 44, 46, 48], "lec11": 19, "lec16": 25, "lec17": 25, "lectur": [5, 7, 8, 11, 19, 25, 49, 54], "lecun": 38, "lee": 38, "left": [7, 27, 34, 35, 36, 40, 41, 43, 45, 46, 57], "legal": [0, 43], "legend": [7, 8, 30, 33, 35, 36, 39, 40, 44, 45, 46, 48], "legendari": 47, "leisur": 35, "lemma": 43, "lemma_": 43, "lemmat": 43, "lemon": 40, "len": [29, 31, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47], "length": [28, 29, 30, 33, 36, 38, 40, 41, 43, 45, 46, 47, 51, 56], "leo": 37, "leopard": [27, 44], "leq": [39, 40], "less": [5, 6, 10, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 46, 49, 51, 54], "lesson": [9, 31, 47], "lesssim": 29, "let": [27, 28, 29, 33, 34, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "letter": [33, 47], "lev": 36, "level": [30, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 54, 57], "leverag": [38, 42], "lewi": 47, "lexic": 43, "lexicon": 47, "lg": [19, 23, 24, 25, 26], "lgbm": [37, 38, 49, 57], "lgbmclassifi": [27, 37, 38, 55], "lgbmclassifierifittedlgbmclassifi": [27, 38], "lgbmclassifierlgbmclassifi": 37, "lgbmregressor": [27, 37], "li": 33, "liabil": 0, "liabl": 0, "liao": 27, "lib": [28, 29, 32, 34, 38, 46, 47, 48], "librari": [4, 8, 11, 29, 35, 38, 39, 43, 44, 45, 47, 51], "licensor": 0, "life": [28, 33, 40, 42, 50, 57], "lifelin": [46, 57], "lifetim": 46, "lighter": 34, "lightgbm": [27, 38, 55], "lightweight": 43, "like": [2, 4, 7, 8, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57], "likelihood": 46, "likewis": 7, "lime": 38, "limit": [0, 27, 28, 29, 32, 37, 38, 47, 49, 50, 53, 57], "linalg": 43, "line": [4, 8, 11, 28, 32, 33, 34, 35, 36, 40, 43, 44, 45, 46, 47, 51, 53], "line2d": 8, "linear": [10, 17, 21, 22, 23, 24, 25, 26, 34, 35, 37, 39, 41, 42, 44, 45, 46, 48, 49], "linear_model": [27, 33, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 54, 55, 56], "linear_svc": 33, "linearli": [33, 39, 45], "linearregress": [33, 36, 39, 46, 47], "linestyl": [40, 45, 56], "linewidth": 45, "linger": 30, "lingual": 43, "linguist": 32, "link": [0, 4, 5, 7, 10, 27, 28, 32, 33, 36, 37, 41, 46], "linkag": 41, "linkage_arrai": 41, "linkage_typ": 41, "linkedin": 42, "linspac": [33, 34, 36, 39, 53], "lion": 42, "list": [4, 7, 8, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 46, 55, 57], "listedcolormap": 33, "liter": 47, "literatur": 37, "littl": [8, 35, 44], "live": [10, 11, 30, 31, 32, 34, 40, 46, 53], "liver": 28, "livestream": 57, "ll": [6, 7, 10, 11, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 51, 56, 57], "llazx": 46, "llm": 10, "lo": 47, "load": [8, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 47, 51, 52, 54], "load_breast_canc": 39, "load_citibik": 45, "load_iri": [30, 51], "loan": [35, 54], "loc": [8, 30, 33, 35, 38, 42, 45, 46, 56], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 35, 37, 38, 39, 44, 47], "locat": [8, 32, 40, 42, 43, 45, 47, 55, 56, 57], "location_katherin": 45, "location_mountginini": 45, "location_townsvil": 45, "location_witchcliff": 45, "location_wollongong": 45, "lock": 29, "log": [30, 36, 37, 46, 51, 55, 57], "log10": 36, "log1p": 36, "log2": 46, "log_likelihood_ratio_test": 46, "logarithm": [30, 51], "logic": 39, "logical_xor": 39, "login": 42, "logisit": 44, "logist": [17, 37, 38, 45, 46, 47, 48, 49, 54, 55, 56], "logisticregress": [27, 33, 36, 37, 38, 39, 43, 44, 47, 48, 54, 55, 56], "logisticregressionifittedlogisticregress": 44, "logisticregressionlogisticregress": [35, 37, 44, 47], "logloss": 38, "lognorm": 34, "logspac": [34, 53], "loguniform": [34, 53], "lol": 32, "london": 47, "lone": 41, "long": [0, 27, 28, 33, 35, 37, 41, 42, 46, 49, 57], "longer": [7, 34, 35, 44, 46], "longest": 28, "longitud": [29, 30, 31, 32, 33, 39, 52], "longitude_0": 39, "longitude_1": 39, "longitude_10": 39, "longitude_11": 39, "longitude_12": 39, "longitude_13": 39, "longitude_14": 39, "longitude_15": 39, "longitude_16": 39, "longitude_17": 39, "longitude_18": 39, "longitude_19": 39, "longitude_2": 39, "longitude_3": 39, "longitude_4": 39, "longitude_5": 39, "longitude_6": 39, "longitude_7": 39, "longitude_8": 39, "longitude_9": 39, "look": [1, 11, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55], "lookatm": 27, "loop": [34, 37, 45, 48, 49], "loos": 41, "lose": [6, 32], "loss": [2, 35, 36, 37, 38, 43, 46, 54], "lot": [5, 9, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 41, 44, 45, 46, 53, 57], "lotarea": [36, 38], "lotconfig": [36, 38], "lotconfig_corn": 36, "lotconfig_culdsac": 36, "lotconfig_fr2": 36, "lotconfig_fr3": 36, "lotconfig_insid": 36, "lotfrontag": [36, 38], "lotshap": [36, 38], "lotshape_ir1": 36, "lotshape_ir2": 36, "lotshape_ir3": 36, "lotshape_reg": 36, "loud": [30, 31, 34, 49, 53], "loui": 45, "lourenzutti": 34, "love": 47, "low": [6, 29, 30, 34, 35, 36, 38, 39, 40, 41, 46], "lower": [29, 30, 35, 36, 38, 40, 42, 43, 46, 53, 57], "lowercas": [31, 32], "lowest": [51, 57], "lowqualfinsf": [36, 38], "lr": [33, 35, 36, 38, 44, 45, 46, 47, 48], "lr_1": 39, "lr_2": 39, "lr_3": 39, "lr_coef": [38, 45, 46, 56], "lr_coefs_landslop": 38, "lr_flatten_pip": 44, "lr_item": 42, "lr_pipe": [36, 38, 45], "lr_pred": [35, 36], "lr_scale": 38, "lr_schedul": 44, "lr_x": 42, "lr_y": 42, "ls15hb": 27, "lstm": 45, "lt": [29, 31, 32, 34, 35, 36, 37, 38, 39, 46], "ltorgo": 33, "lucki": [30, 34], "luckili": [53, 55], "lundberg": 38, "luster": 41, "lvert": 43, "lvl": [36, 38], "lwq": [36, 38], "lynx": [27, 44], "l\u00e9cuyer": 43, "m": [11, 27, 29, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "m_neighbor": 35, "ma": 34, "macaqu": [27, 44], "macbook": 11, "machin": [2, 9, 10, 11, 13, 14, 15, 31, 32, 34, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 51, 56, 57], "mackworth": 10, "made": [0, 6, 7, 8, 27, 28, 35, 37, 38, 42, 43, 44, 45, 53], "magazin": 43, "magnitud": [34, 36, 38, 43, 45, 56], "maguir": 42, "mahsa": 57, "mai": [0, 7, 8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57], "mail": 46, "main": [8, 11, 28, 30, 32, 37, 40, 41, 49, 57], "mainland": 33, "maintain": [37, 42, 49], "mainten": 37, "maj1": [36, 38], "maj2": [36, 38], "major": [2, 29, 30, 31, 32, 43, 49, 50, 55], "major_biologi": 32, "major_comput": 32, "major_econom": 32, "major_linguist": 32, "major_mathemat": 32, "major_mechan": 32, "major_phys": 32, "major_psychologi": 32, "make": [2, 4, 5, 6, 7, 11, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57], "make_blob": [30, 40, 41, 44, 48], "make_circl": 41, "make_classif": [30, 35], "make_column_transform": [34, 35, 36, 37, 38, 39, 45, 46, 47, 52, 53, 54, 55, 56], "make_forg": 30, "make_grid": 44, "make_imb_pipelin": 35, "make_moon": 41, "make_num_tree_plot": 37, "make_pipelin": [27, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56], "make_scor": [36, 39, 47], "malcolm": [40, 42], "malcom": 40, "male": [35, 37, 38, 46, 54], "male_cm": [35, 54], "male_pr": [35, 54], "mall": 47, "man": [42, 43], "manag": [5, 45, 46, 49, 57], "mandarin": 31, "mango": 43, "mani": [2, 5, 8, 10, 27, 28, 29, 30, 31, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 53, 55, 56, 57], "manner": [0, 37], "manual": [11, 27, 32, 35, 39, 40, 41, 43, 53], "manufactur": 44, "map": [10, 28, 29, 32, 34, 42, 53], "mape": 49, "mape_scor": 36, "mapper": 42, "march": 45, "marit": [35, 37, 38, 54], "mark": [6, 7, 34, 35, 41, 57], "marker": [30, 33, 40], "markers": [33, 35], "market": [27, 40, 44, 45], "marri": [35, 37, 38], "martin": 43, "mask": 34, "massiv": [32, 34], "master": [8, 34, 35, 37, 38, 43, 54], "masvnrarea": [36, 38], "masvnrtyp": [36, 38], "masvnrtype_brkcmn": 36, "masvnrtype_brkfac": 36, "masvnrtype_miss": 36, "masvnrtype_ston": 36, "match": [32, 33, 35, 37, 38, 45, 55, 56], "materi": [8, 11, 19, 27, 28, 29, 30, 40, 43, 46, 49, 57], "matern": 39, "math": [2, 40, 42, 46], "mathcal": 30, "mathemat": [2, 32, 37, 49], "mathematician": 43, "mathia": 47, "matlab": 8, "matplotlib": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "matplotlibdeprecationwarn": 38, "matric": [30, 35, 42, 54], "matrix": [18, 32, 41, 43, 49, 54], "matter": [31, 32, 35, 37, 41, 49], "max": [8, 29, 31, 33, 34, 35, 36, 37, 40, 41, 45, 56], "max_bin": 37, "max_cat_threshold": 37, "max_cat_to_onehot": 37, "max_clust": 41, "max_colwidth": [27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 50, 51, 52, 53, 54], "max_delta_step": 37, "max_depth": [29, 30, 34, 37, 38, 50, 51], "max_depth_widget": [30, 51], "max_df": 32, "max_displai": 38, "max_featur": [27, 32, 34, 37, 53], "max_it": [27, 35, 37, 38, 39, 43, 44, 45, 46, 47, 48, 54], "max_leaf_nod": 28, "max_leav": 37, "max_opt": [30, 35, 40, 41], "max_row": 46, "maxclust": 41, "maxent": 48, "maxhr": 55, "maxim": [27, 35, 36, 40], "maximum": [28, 31, 36, 37, 40, 41, 51, 57], "maxosx": 11, "maxtemp": [45, 56], "may": 10, "mayb": [35, 38, 45, 57], "maybe_coerce_valu": 46, "mb": [31, 32, 35, 39, 45, 46, 56], "md": [11, 28, 43], "me": [8, 27, 34, 47], "mean": [5, 6, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57], "mean_absolute_percentage_error": 36, "mean_cv_error": 29, "mean_cv_scor": [30, 33, 34], "mean_fit_tim": [34, 36], "mean_scor": [29, 31, 34, 47], "mean_score_tim": [34, 36], "mean_squared_error": [36, 39, 47], "mean_std_cross_val_scor": [29, 31, 32, 37, 38, 46, 47], "mean_test_neg_mean_squared_error": 36, "mean_test_scor": [34, 36, 53], "mean_train_error": 29, "mean_train_neg_mean_squared_error": 36, "mean_train_scor": [30, 33, 34, 36], "meaning": [30, 32, 35, 38, 40, 43, 52, 57], "meaningless": 41, "measur": [0, 27, 28, 29, 30, 35, 36, 38, 40, 41, 42, 43, 45, 46, 49, 51, 55, 56], "mechan": [32, 49], "medal": 8, "median": [28, 31, 32, 33, 36, 38, 39, 45, 46, 56], "median_house_valu": [31, 32, 39, 52], "median_incom": [31, 32, 39, 52], "medic": [35, 40, 57], "medinc": 33, "medit": 35, "medium": [0, 30, 46, 49], "meet": 43, "meier": 57, "melbourneairport": [45, 56], "member": [33, 37, 57], "membership": [32, 40, 41], "memori": [8, 31, 32, 35, 36, 37, 39, 44, 45, 46, 49, 56], "mention": [0, 4, 33, 46], "menu": 11, "merchant": 0, "merg": [0, 5, 11, 41], "meshgrid": 39, "mess": [42, 46], "messag": [4, 6, 11, 29, 32], "messi": [39, 43], "met": 57, "meta": 37, "metacademi": 10, "method": [2, 28, 30, 31, 33, 35, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 55, 56, 57], "methodologi": [31, 45], "metric": [10, 30, 32, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 54, 55, 57], "mexico": 35, "mglearn": [28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 44, 45, 48, 50, 51, 53, 54], "mi": [27, 34, 35], "microsoft": 47, "midnight": 45, "midterm": [6, 10], "might": [6, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 51, 57], "mike": [0, 1, 9, 28, 53], "mikolov": 43, "milk": 43, "mill": 37, "millennia": 57, "million": 44, "min": [10, 33, 36, 41, 45, 56], "min1": [36, 38], "min2": [36, 38], "min_child_weight": 37, "min_df": 32, "min_sampl": 41, "min_samples_leaf": 28, "min_samples_split": 28, "min_token_len": 43, "min_token_length": 43, "mind": [29, 31, 32, 37, 38, 42, 46, 49, 57], "mine": 10, "minibatchkmean": 41, "miniconda": 11, "miniconda3": [11, 47], "miniforge3": [28, 29, 32, 34, 38, 46, 48], "minim": [5, 28, 36, 40, 41], "minimum": [8, 29, 31, 41, 43], "minmaxscal": [31, 32], "minor": [6, 46], "mintemp": [45, 56], "minut": [4, 28, 39, 46, 49], "miracl": 47, "miscalcul": 10, "miscfeatur": [36, 38], "miscfeature_gar2": 36, "miscfeature_miss": 36, "miscfeature_othr": 36, "miscfeature_sh": 36, "miscfeature_tenc": 36, "misclassifi": 54, "misconduct": 57, "miscval": [36, 38], "mislead": [29, 35], "miss": [11, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 46, 49, 51, 53, 54, 56, 57], "mistak": [31, 37, 46, 51], "mit": [0, 1], "mitig": [42, 57], "mitlp": 46, "mitt": 43, "mitten": 43, "mix": 36, "mixtur": [41, 43, 44], "ml": [2, 9, 10, 14, 15, 28, 31, 37, 41, 43, 44, 57], "ml_experi": [28, 29, 32, 49], "mlpclassifi": 44, "mlpregressor": 44, "mm": [45, 56], "mmsto": 27, "mn": [36, 38], "mnprv": [36, 38], "mnww": [36, 38], "mobil": [32, 44], "mobilenet": 44, "mod": [36, 38], "mode": [30, 31, 34, 53], "model": [2, 10, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 40, 41, 42, 45, 48, 50, 53, 56, 57], "model_nam": 42, "model_select": [27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56], "modern": [10, 30, 43], "modif": 46, "modifi": [0, 11, 35, 46, 57], "modul": [9, 10, 28, 29, 35, 47], "moe": 34, "mole": 44, "mom": 39, "moment": [35, 53, 55, 57], "mon": [10, 45], "mondai": [10, 45, 57], "monei": [8, 46], "monitor": 43, "monkei": [27, 44], "monotone_constraint": 37, "montani": 47, "month": [29, 32, 36, 46, 56], "month_nam": [45, 56], "monthli": 46, "monthlycharg": 46, "montreal": [43, 47], "moon": 41, "moosvi": [0, 1, 43, 57], "moral": [0, 40], "more": [1, 2, 5, 6, 8, 10, 11, 14, 29, 34, 37, 38, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57], "morn": 27, "morpholog": 43, "moskowitz": 40, "mosold": [36, 38], "mosold_1": 36, "mosold_10": 36, "mosold_11": 36, "mosold_12": 36, "mosold_2": 36, "mosold_3": 36, "mosold_4": 36, "mosold_5": 36, "mosold_6": 36, "mosold_7": 36, "mosold_8": 36, "mosold_9": 36, "most": [7, 8, 11, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 55, 57], "most_confident_i": 33, "most_confident_x": 33, "most_frequ": [28, 30, 31, 35, 36, 38, 50], "most_similar": 43, "mostli": [8, 32, 45], "motiv": [19, 20, 21, 22, 23, 24, 25, 26, 27, 32], "mountginini": 45, "move": [7, 12, 33, 38, 39, 50, 55, 57], "movi": [33, 43, 47], "movie_feats_df": 42, "movie_id": 42, "movie_nam": 42, "movies_rated_by_pat": 42, "movies_to_pr": 42, "movieto": 47, "mpimg": 44, "mri": 49, "mrtssm448usn": 45, "mse": [28, 42, 49], "msg": [32, 46], "mssubclass": [36, 38], "mssubclass_120": 36, "mssubclass_160": 36, "mssubclass_180": 36, "mssubclass_190": 36, "mssubclass_20": 36, "mssubclass_30": 36, "mssubclass_40": 36, "mssubclass_45": 36, "mssubclass_50": 36, "mssubclass_60": 36, "mssubclass_70": 36, "mssubclass_75": 36, "mssubclass_80": 36, "mssubclass_85": 36, "mssubclass_90": 36, "mszone": [36, 38], "mszoning_c": [36, 38], "mszoning_fv": 36, "mszoning_rh": 36, "mszoning_rl": 36, "mszoning_rm": 36, "much": [4, 5, 8, 28, 29, 30, 31, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 51, 53, 57], "mueller": 10, "multi": [36, 38, 40, 43, 45], "multi_class": [35, 48], "multi_strategi": 37, "multiclass": [44, 48], "multicoliniar": 38, "multicultur": 43, "multilevel": 36, "multimod": 40, "multinomi": 48, "multipl": [7, 8, 29, 33, 34, 37, 38, 43, 44, 45, 46, 56], "multiplelin": 46, "multiplelines_no": 46, "multiplelines_y": 46, "multipli": [33, 34, 35, 37, 39, 46], "music": [42, 47], "musqueam": 57, "must": [0, 6, 7, 8, 28, 29, 31, 38, 41, 43, 46, 47, 57], "mutual": 41, "mwf": 57, "my": [6, 11, 27, 34, 35, 40, 43, 47, 57], "my_heatmap": [34, 53], "my_map": 36, "mypreprocessor": 43, "myself": 28, "m\u00fcller": 9, "n": [10, 28, 30, 33, 34, 36, 37, 38, 39, 41, 42, 43, 45, 47, 48, 51, 56], "n_bin": 39, "n_class": [30, 35, 54], "n_cluster": [40, 41], "n_clusters_per_class": 35, "n_compon": 43, "n_constitu": 37, "n_estim": [39, 45, 46], "n_exampl": 40, "n_feat": 30, "n_featur": [30, 35, 40, 53], "n_features_to_select": 39, "n_inform": 35, "n_init": 40, "n_iter": 53, "n_job": [32, 35, 36, 37, 53], "n_neighbor": [42, 51], "n_neighbors_selector": 30, "n_neighbors_widget": [30, 51], "n_redund": 35, "n_rental": 45, "n_rentalsin3hour": 45, "n_rentalsin6hour": 45, "n_repeat": 38, "n_resourc": 34, "n_sampl": [30, 35, 40, 41, 44, 48, 54], "n_split": 45, "n_threshold": 35, "n_topic": 43, "n_train": 45, "n_word": [43, 47], "na": [36, 38], "nafter": 43, "nah": 32, "naiv": 41, "name": [4, 5, 6, 7, 8, 11, 28, 30, 31, 32, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 47, 51, 55, 56, 57], "named_estimators_": 37, "named_step": [33, 35, 36, 37, 38, 39, 45, 47, 56], "named_transformers_": [32, 35, 36, 37, 38, 39, 45, 46, 47, 54, 56], "nan": [31, 32, 35, 36, 37, 38, 39, 42, 45, 46, 47, 49, 54, 56], "nanmean": 42, "nanosecond": 45, "narr": 43, "narrow": 42, "nasali": [27, 44], "nation": 57, "nativ": [35, 37, 38, 44, 48, 54], "natur": [2, 27, 32, 35, 37, 39, 44, 48, 57], "navig": [7, 11], "nbsp": [27, 31, 32, 34, 36, 37, 38, 39, 44], "nbviewer": [27, 31, 32, 34, 35, 36, 37, 38, 39, 44, 47], "nc": 1, "ncol": 33, "ndarrai": [8, 32], "ndate": 47, "ndframe": [39, 46], "ndim": 8, "ne": [45, 56], "nearbi": [30, 40], "nearest": [15, 35, 41, 51], "necessari": [0, 7, 28, 34, 49, 52], "necessarili": [29, 36, 37, 42], "necvq": 46, "need": [5, 7, 8, 11, 27, 28, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 55, 56, 57], "neg": [28, 29, 30, 33, 36, 37, 38, 43, 45, 46, 47, 51, 54], "neg_mean_absolute_percentage_error": 36, "neg_mean_squared_error": 36, "neg_root_mean_square_error": 36, "neg_root_mean_squared_error": 36, "neigh": 30, "neighbor": [30, 31, 32, 33, 35, 39, 41, 51, 52], "neighborhood": [33, 36, 38], "neighborhood_blmngtn": 36, "neighborhood_bluest": 36, "neighborhood_brdal": 36, "neighborhood_brksid": 36, "neighborhood_clearcr": 36, "neighborhood_collgcr": 36, "neighborhood_crawfor": 36, "neighborhood_edward": 36, "neighborhood_gilbert": 36, "neighborhood_idotrr": 36, "neighborhood_meadowv": 36, "neighborhood_mitchel": 36, "neighborhood_nam": 36, "neighborhood_noridg": [36, 38], "neighborhood_npkvil": 36, "neighborhood_nridght": [36, 38], "neighborhood_nwam": 36, "neighborhood_oldtown": [36, 38], "neighborhood_sawy": [36, 38], "neighborhood_sawyerw": [36, 38], "neighborhood_somerst": [36, 38], "neighborhood_stonebr": [36, 38], "neighborhood_swisu": [36, 38], "neighborhood_timb": [36, 38], "neighborhood_veenk": [36, 38], "neighbour": [15, 29, 38, 40, 41, 43, 51], "neighbourhood": [33, 39, 41, 52], "neither": [29, 32, 42], "neq": [38, 42], "ner": 43, "nervou": 28, "nest": [34, 49], "net": [44, 46], "netflix": [42, 47], "network": [10, 27, 32, 37, 39, 40, 42, 45, 57], "neu": 47, "neural": [10, 39, 45, 57], "neutral": 47, "never": [35, 37, 38, 42, 44, 46], "new": [10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 55, 56], "new_cent": 40, "new_column": [36, 38, 45, 46, 56], "new_data": 46, "new_df": [45, 56], "new_exampl": [28, 40], "new_feature_nam": [45, 56], "new_valu": 46, "newaxi": 8, "newcastl": 47, "newer": 36, "newli": [31, 36, 39, 41], "newsgroup": 43, "newswir": 43, "next": [11, 28, 29, 30, 31, 32, 35, 36, 37, 43, 44, 45, 52, 53, 54, 55, 57], "nfeat": 30, "nfeats_accuraci": 30, "ng": [9, 10, 34, 39], "ngram": 39, "ngram_rang": 32, "nhqxu": 46, "nice": [4, 34, 35, 37, 38, 41, 44, 46], "nicki": 34, "night": [35, 45], "niki": 57, "nlemma": 43, "nlp": [32, 44, 47], "nltk": [43, 47], "nltk_data": 47, "nn": [10, 31, 44, 47, 51], "nne": [45, 56], "nnw": [45, 56], "nnz": 32, "no_grad": 44, "nobodi": 27, "node": [28, 37, 41, 44, 50], "nois": [41, 49, 51], "non": [1, 8, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 45, 46, 49, 54, 56, 57], "noncommerci": 1, "none": [10, 26, 29, 31, 32, 33, 34, 35, 37, 39, 41, 45, 46, 47, 55], "noninfring": 0, "nonzero": 32, "noqa": [34, 47], "nor": [7, 29, 32], "norg": [43, 47], "norm": [34, 43], "normal": [6, 35, 36, 37, 38, 40, 41, 43, 44, 45, 47, 54, 55], "norvig": 10, "notat": 30, "note": [0, 3, 7, 9, 10, 11, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 48, 49, 53, 54, 56, 57], "notebook": [5, 7, 9, 11, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 44, 47, 52, 56], "notic": [0, 32, 33, 35, 36, 39], "notion": [30, 34, 40, 42], "notna": [45, 56], "noun": [43, 47], "nov": 45, "novel": 49, "novemb": 45, "novic": 9, "now": [8, 11, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 50, 51, 52, 53, 54, 55], "np": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "nperson": 47, "npie": 8, "npo": 43, "npr": [39, 43, 47, 49], "ntest": [30, 34, 51], "ntoken": 43, "ntree": 37, "null": [31, 32, 35, 36, 39, 45, 46, 56], "null_distribut": 46, "num": [35, 37, 38, 54], "num_output_channel": 44, "num_parallel_tre": 37, "num_sent": 35, "num_work": 44, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 49, 51, 53, 56, 57], "number_test": 34, "numer": [2, 28, 31, 32, 33, 35, 36, 37, 42, 43, 45, 46, 51, 52, 54, 56], "numeric_feat": [32, 34, 39, 49, 53], "numeric_featur": [32, 35, 36, 37, 38, 45, 46, 47, 54, 55, 56], "numeric_looking_column": 36, "numeric_transform": [32, 35, 36, 37, 38, 45, 54, 55, 56], "numpi": [9, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "numpy_dtyp": 46, "nutrit": 43, "nw": [45, 56], "nwith": 30, "ny": 47, "o": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "obelisk": 44, "object": [29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 47, 49, 50, 51, 53, 54, 56], "observ": [27, 28, 29, 30, 37, 38, 40, 41, 45, 46, 51, 54, 55, 56], "obtain": [0, 33, 40, 41, 42, 46, 51, 53], "obviou": [41, 43], "occasion": 35, "occup": [35, 37, 38, 54], "occupation_farm": 38, "occupation_miss": 38, "occupation_priv": 38, "occupi": 57, "occur": [8, 28, 29, 32, 43, 46], "occurr": [43, 46], "ocean": [31, 32, 39, 52], "ocean_proxim": [31, 32, 39, 52], "ocean_proximity_": [31, 32], "ocean_proximity_inland": [31, 32], "ocean_proximity_island": [31, 32], "ocean_proximity_near": [31, 32], "oct": 33, "octob": 45, "oe": [32, 49], "oe_encod": 49, "off": [25, 33, 34, 35, 36, 39, 40, 43, 44, 46, 49, 53, 57], "off_shelf": 55, "offens": 4, "offer": [8, 37, 42, 43, 46, 57], "offic": [4, 11, 49, 57], "offici": [43, 57], "offlin": 42, "offset": 33, "often": [8, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51], "ogunrind": 27, "oh": [38, 39, 44, 45, 46, 49, 53, 56], "ohe_column": [36, 38], "ohe_enc": 32, "ohe_encod": 49, "ohe_feature_nam": [38, 45, 56], "ohehotencod": 32, "ois": 41, "ok": [27, 30, 36, 45, 46, 49, 56], "okai": 40, "ola": 43, "old": [9, 37, 38], "old_cent": 40, "older": 36, "oldpeak": 55, "olymp": 8, "omit": 38, "omw": 43, "onc": [6, 7, 8, 11, 28, 29, 31, 32, 34, 39, 41, 42, 43, 44, 53, 54, 55, 57], "onca": [27, 44], "one": [6, 8, 9, 11, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57], "one_c": 30, "one_ex_preprocess": 38, "one_ex_preprocessed_perturb": 38, "one_exampl": 38, "one_example_perturb": 38, "onehot": [32, 39], "onehotencod": [31, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 52, 53, 54, 55, 56], "onehotencoder__major_biologi": 32, "onehotencoder__major_comput": 32, "onehotencoder__major_econom": 32, "onehotencoder__major_linguist": 32, "onehotencoder__major_mathemat": 32, "onehotencoder__major_mechan": 32, "onehotencoder__major_phys": 32, "onehotencoder__major_psychologi": 32, "onehotencoderonehotencod": [32, 34, 36, 37], "ones": [8, 27, 30, 31, 37, 38, 40, 42, 43, 51, 55], "onevsoneclassifi": 48, "onevsrestclassifi": 48, "onli": [2, 4, 8, 11, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 54, 57], "onlin": [3, 5, 7, 11, 28, 43, 57], "onlinebackup": 46, "onlinebackup_no": 46, "onlinebackup_y": 46, "onlinesecur": 46, "onlinesecurity_no": 46, "onlinesecurity_y": 46, "ontonot": 43, "op": 35, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 44, 57], "openporchsf": [36, 38], "oper": [4, 8, 11, 32, 39, 43], "operand": 8, "opinion": 37, "opportun": 42, "oppos": [36, 37], "opposit": [8, 36, 37, 38, 56], "opt": [11, 37], "optic": 46, "optim": [2, 10, 28, 29, 30, 32, 35, 37, 38, 39, 40, 41, 44, 46, 53], "optimist": 34, "option": [7, 8, 10, 28, 36, 40, 43, 53, 55, 56], "oracl": 10, "orang": 33, "order": [5, 7, 8, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 49], "ordering_ordinal_oth": [36, 38], "ordering_ordinal_reg": [36, 38], "ordin": [36, 49, 52], "ordinal_feat": 32, "ordinal_featur": [35, 37, 38, 54], "ordinal_features_oth": [36, 38], "ordinal_features_reg": [36, 38], "ordinal_transform": [35, 37, 38, 54], "ordinal_transformer_oth": [36, 38], "ordinal_transformer_reg": [36, 38], "ordinalencod": [31, 32, 35, 36, 37, 38, 39, 45, 46, 47, 49, 52, 54, 55, 56], "ordinalencoderordinalencod": [32, 36, 37], "ordinari": 36, "oreilli": [44, 45], "org": [9, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 47], "organ": [27, 28, 31, 43], "orgin": 8, "orig_featur": [45, 56], "orig_pr": 38, "orig_scor": 35, "origin": [31, 32, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 51, 53, 56, 57], "original_hm": 35, "originaltweet": 47, "ornithorhynchu": 44, "oscar": 33, "ostblom": 43, "other": [0, 1, 4, 5, 6, 7, 11, 28, 29, 31, 32, 33, 34, 35, 37, 38, 41, 42, 44, 47, 48, 49, 51, 53, 54, 55, 56, 57], "otherwis": [0, 7, 32], "ounc": [27, 44], "our": [5, 6, 8, 11, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 57], "ourselv": [28, 35, 44, 45], "out": [0, 4, 7, 8, 11, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53, 55, 56, 57], "out_col": [29, 31, 47], "out_step": 35, "outcom": 12, "outer": 47, "outlier": [36, 41, 49], "outlook": 46, "output": [7, 8, 11, 27, 28, 29, 32, 33, 35, 37, 38, 43, 44, 45, 49, 55, 56, 57], "outsid": [7, 35, 37, 38, 42, 43, 45, 46], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 34, 36, 44, 45, 46, 49, 57], "over_confident_i": 33, "over_confident_x": 33, "over_sampl": 35, "overal": [11, 35, 38, 40, 43, 44, 49, 54, 55, 57], "overallcond": [36, 38], "overallqu": [36, 38], "overconfid": [38, 39], "overfit": [10, 30, 33, 36, 37, 39, 44, 51, 53, 55, 57], "overflow": 7, "overhead": 32, "overlap": [2, 29, 40], "overli": [30, 34, 51], "overload": [42, 46], "overpredict": 36, "oversample_pip": 35, "overshadow": 43, "overus": 37, "overview": [40, 41, 42, 43], "overwhelm": 40, "overzeal": 6, "own": [4, 5, 8, 29, 31, 35, 36, 38, 39, 40, 41, 43, 44, 45, 47, 48, 56], "p": [33, 34, 41, 43, 46], "p_i": 40, "p_value_threshold": 46, "pace": [33, 40, 43, 57], "packag": [5, 8, 28, 29, 32, 34, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 57], "pad": 44, "page": [1, 4, 10, 27, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 47, 55, 57], "pai": 38, "pain": [4, 44, 45, 56], "pair": [41, 43, 48], "pairwis": [30, 41], "panda": [9, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "pane": [30, 51], "panel": [30, 35, 38, 40, 41, 51], "panic": 47, "panther": [27, 44], "panthera": [27, 44], "paper": [7, 38, 39, 43, 44, 46, 47], "paperlessbil": 46, "paperlessbilling_no": 46, "paperlessbilling_y": 46, "paradigm": [27, 28, 40], "paradox": 42, "paragraph": 43, "parallel": [32, 34, 37], "param": [30, 32, 34, 36, 51], "param_columntransformer__countvectorizer__max_featur": 34, "param_dist": [34, 53], "param_distribut": [34, 53], "param_grid": [29, 30, 34, 36, 53], "param_grid1": [34, 53], "param_grid2": [34, 53], "param_grid3": 34, "param_grid4": 34, "param_ridge__alpha": 36, "param_svc__c": 34, "param_svc__gamma": 34, "paramet": [30, 31, 32, 36, 37, 38, 40, 41, 43, 45, 46, 47, 50, 51, 53, 54, 55, 56], "parametr": 41, "params_": 46, "params_str": 34, "paramter": 30, "pardu": [27, 44], "parent": [41, 47], "park": [39, 44, 47], "pars": 43, "parse_d": [8, 45, 56], "parser": 43, "part": [4, 9, 10, 11, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 45, 47, 55, 57], "part1": 42, "part2": 42, "parti": 43, "partial": [4, 46], "particip": 57, "particular": [0, 9, 11, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 54], "particularli": [37, 42, 57], "partit": [32, 40, 41], "partner": [46, 57], "partner_no": 46, "partner_y": 46, "parton": 47, "pass": [8, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 44, 51], "passthrough": [32, 34, 46, 47, 53, 55], "passthrough__ml_experi": 32, "passthrough_feat": [32, 34, 49, 53], "passthrough_featur": [46, 47, 55], "passthroughpassthrough": [32, 34, 47], "past": [28, 29, 37, 45, 46, 49], "pat": 42, "pat_i": 42, "pat_model": 42, "pat_x": 42, "pata": [27, 44], "path": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "patial": 41, "patient": [28, 55], "patio": 44, "patric": 38, "patrick": 57, "pattern": [27, 28, 29, 32, 34, 39, 40, 45, 51, 56], "pave": [36, 38], "paveddr": [36, 38], "paveddrive_i": 36, "paveddrive_n": 36, "paveddrive_p": 36, "paymentmethod": 46, "paymentmethod_bank": 46, "paymentmethod_credit": 46, "paymentmethod_electron": 46, "paymentmethod_mail": 46, "pca": [35, 41, 42], "pcarter": 9, "pd": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "pdf": [7, 9, 19, 25], "peac": 43, "pedest": 44, "pedro": [10, 29, 39], "peek": 56, "peer": [49, 57], "pembrok": [27, 44], "penal": [6, 46], "penalti": [35, 57], "peopl": [4, 28, 29, 31, 33, 35, 37, 40, 42, 43, 44, 45, 46, 47, 49, 51, 54, 57], "per": [8, 33, 35, 36, 37, 38, 42, 44, 45, 48, 49, 53, 54, 56], "perceiv": 6, "percent": 36, "percent_error": 36, "percentag": [28, 35, 42], "perfect": [6, 28, 29, 35, 36, 38, 42, 46, 47], "perfectli": [2, 42, 43], "perform": [28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 52, 53, 54, 55, 56, 57], "performac": 29, "perhap": [36, 45, 48], "perimet": 39, "period": [43, 45, 46, 47, 57], "perm_sorted_idx": 38, "perman": 8, "permiss": [0, 57], "permit": [0, 31, 35, 57], "permut": 38, "persist": 42, "person": [0, 4, 6, 10, 27, 35, 40, 43, 44, 45, 46, 47, 57], "perspect": [37, 42], "pertain": 5, "perthairport": [45, 56], "perturb": [38, 41], "perturbed_pr": 38, "peter": 10, "ph": 43, "phascolarcto": 44, "phase": 29, "phd": 43, "phdei": 46, "phenomenon": [42, 46, 51], "philippin": 47, "philosoph": 43, "phone": [27, 46, 57], "phoneservic": 46, "phoneservice_no": 46, "phoneservice_y": 46, "photo": [47, 49], "photograph": 57, "phrase": 43, "physic": [32, 45], "pi": 8, "pick": [28, 33, 35, 37, 38, 39, 40, 41, 44, 48, 50, 51, 53, 54, 55], "pictur": [37, 38, 41, 43, 45], "pie": 8, "piec": [33, 46], "pil": [27, 44], "pin": 44, "pineappl": 43, "pip": [11, 38, 43, 44, 47], "pipe": [31, 32, 33, 34, 35, 37, 43, 44, 47, 53, 54], "pipe_bestalpha": 36, "pipe_bigalpha": 36, "pipe_catboost": 37, "pipe_dt": [37, 38, 55], "pipe_forward": 39, "pipe_knn": 55, "pipe_lgbm": [37, 38, 55], "pipe_lr": [35, 37, 38, 54, 55], "pipe_lr_all_feat": 39, "pipe_lr_balanc": [35, 54], "pipe_lr_model_bas": 39, "pipe_lr_weight": [35, 54], "pipe_rf": [37, 38, 55], "pipe_rf_demo": 37, "pipe_ridg": [33, 36], "pipe_sklearn_gb": 37, "pipe_sklearn_histgb": 37, "pipe_smallalpha": 36, "pipe_svc": 35, "pipe_svm": [34, 53], "pipe_xgb": [37, 38], "pipe_xor": 39, "pipelin": [2, 10, 16, 27, 29, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57], "pipeline__lab1": 32, "pipeline__lab2": 32, "pipeline__lab3": 32, "pipeline__lab4": 32, "pipeline__quiz1": 32, "pipeline__rooms_per_household": 39, "pipeline__university_year": 32, "pipelineifittedpipelin": [31, 32, 34, 35, 39, 44, 47], "pipelineinot": [32, 34, 36], "pipelinepipelin": 34, "pitfal": 45, "pixel": 38, "pizza": 43, "pkg": 11, "place": [5, 43, 45, 57], "plagiar": 57, "plai": [28, 30, 34, 38, 41, 50, 51], "plain": 40, "plan": [11, 27, 36, 39, 46, 47, 52, 55, 57], "plane": 33, "plant": 49, "plastic": 43, "platform": [4, 47], "platypu": 44, "player": [38, 44], "pleas": [1, 4, 7, 11, 27, 31, 32, 34, 35, 36, 37, 38, 39, 44, 47, 53, 57], "plinth": 44, "plot": [7, 28, 29, 30, 31, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 51, 53, 54, 56], "plot_2d_scor": 33, "plot_2d_separ": [30, 33, 51], "plot_confusion_matrix": 35, "plot_confusion_matrix_exampl": 35, "plot_cross_valid": [29, 45], "plot_dbscan": 41, "plot_dbscan_with_label": 41, "plot_dendrogram_clust": 41, "plot_elbow": 40, "plot_example_dist": 40, "plot_fruit_tre": 28, "plot_grid_search_overview": 34, "plot_k_means_dbscan_comparison": 41, "plot_km_initi": 40, "plot_km_it": 40, "plot_km_iter": 40, "plot_kmean": 41, "plot_knn_clf": 30, "plot_knn_decision_boundari": 30, "plot_knn_regress": 30, "plot_lda_w_vector": 43, "plot_linkage_criteria": 41, "plot_logistic_regress": 33, "plot_logistic_regression_graph": 44, "plot_multiclass_lr_ovr": 48, "plot_original_clust": 41, "plot_partial_effects_on_outcom": 46, "plot_result": [30, 51], "plot_scal": 31, "plot_silhouette_dist": 40, "plot_single_hidden_layer_graph": 44, "plot_support_vector": 30, "plot_survival_funct": 46, "plot_svc_c": 30, "plot_svc_gamma": 30, "plot_time_spacing_distribut": [45, 56], "plot_train_test_point": 30, "plot_tree_decision_boundari": 29, "plot_tree_decision_boundary_and_tre": [28, 29, 50], "plot_two_hidden_layer_graph": 44, "plot_typ": 38, "plot_x_dendrogram": 41, "plotli": [39, 43], "plotting_funct": [28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 48, 50, 51, 52, 53, 54, 55], "plotting_functions_unsup": [40, 41, 42, 43], "plt": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "plu": [33, 44], "plural": 32, "pm": [1, 10, 45, 56, 57], "pmltt": 10, "pn": [30, 35, 40, 41, 51], "po": [29, 31, 33, 36, 38, 43, 47], "pobox": 27, "point": [4, 10, 27, 28, 29, 31, 32, 33, 34, 36, 39, 41, 46, 48, 49, 51, 54, 57], "point_ind": 40, "point_index": 40, "pointless": 53, "polarity_scor": 47, "pole": 44, "polici": [3, 4, 7, 57], "polit": [42, 43, 44], "poly_transform": 45, "polynomialfeatur": [39, 45], "pomegran": 44, "pool": 10, "poolarea": [36, 38], "poolqc": [36, 38], "poor": [32, 36, 39, 49, 52], "poorli": [30, 36, 41, 45], "pope": 43, "popul": [31, 32, 33, 39, 45, 52], "popular": [8, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 57], "population_per_household": [31, 32, 52], "porter": 43, "porterstemm": 43, "portion": [0, 29, 31, 34, 36, 38, 55, 56, 57], "portug": [35, 38], "pos_": [43, 47], "pos_label": 36, "posit": [28, 29, 30, 31, 33, 36, 37, 38, 43, 45, 46, 47, 54], "posix": 46, "possibl": [4, 5, 6, 8, 27, 28, 29, 31, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 49, 51, 52, 53, 54, 57], "possibli": [7, 43], "post": [4, 6, 8, 10, 43, 45, 57], "postprocess": 44, "potenti": [30, 31, 40, 43, 57], "potteri": 43, "powder": 43, "power": [8, 29, 37, 42, 43, 44], "pplicat": 41, "pr": 49, "practic": [0, 6, 9, 10, 29, 31, 39, 44, 49, 52, 53, 57], "prairielearn": [10, 57], "pre": [10, 11, 19, 23, 24, 25, 26, 27, 37, 39, 43, 47, 49], "precis": [18, 36, 49, 54, 57], "precision_lr": 35, "precision_recall_curv": 35, "precision_scor": 35, "precision_svc": 35, "precisionrecallcurvedisplai": 35, "precisionrecalldisplai": 35, "pred": [35, 36, 42, 45, 46], "pred_df": [27, 42], "pred_dict": 27, "pred_g": 42, "pred_lin_reg": 42, "pred_train": 36, "pred_x": 42, "prediciton": 46, "predict": [2, 17, 29, 30, 31, 34, 35, 36, 39, 40, 41, 43, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57], "predict_expect": 46, "predict_for_usr": 42, "predict_proba": [35, 37, 38, 44, 48, 55], "predict_survival_funct": 46, "predicted_categori": 35, "predicted_n_rent": 45, "predicted_quiz2": 28, "predicted_sal": 45, "predicted_target": 27, "predictor": [28, 49], "prefer": [27, 37, 40, 42, 53], "prefix": 8, "preliminari": [31, 39], "prepar": [31, 39, 44], "prepend": 11, "preprocess": [10, 16, 18, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 55, 57], "preprocess_featur": [45, 56], "preprocessing_fin": 46, "preprocessing_notenur": 46, "preprocessor": [32, 34, 35, 36, 37, 38, 45, 46, 47, 52, 53, 54, 55, 56], "preprocessor1": 39, "preprocessor2": 39, "preprocessor3": 39, "prerequisit": [2, 46, 57], "preschool": [35, 37, 38, 54], "presenc": [32, 38, 46], "present": [7, 29, 35, 42, 43, 44, 45, 46, 49, 51, 56], "preserv": [35, 40], "pressure3pm": [45, 56], "pressure9am": [45, 56], "pretend": [28, 29, 45], "pretrain": [43, 44, 47], "pretti": [28, 32, 33, 35, 37, 40, 43, 45, 46, 56], "prevent": [34, 43, 46, 57], "previou": [28, 36, 37, 40, 41, 45, 46, 49, 53, 54, 56], "previous": [42, 44, 45], "price": [8, 18, 31, 33, 36, 38, 39, 46, 51], "primari": [8, 19, 23, 24, 25, 26, 30], "primarili": [28, 38, 44], "prime": 27, "principl": [9, 28, 49, 57], "print": [7, 8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 56], "print_top": 43, "prior": [40, 45, 49], "priorit": [39, 49], "privaci": [0, 40, 57], "privat": [7, 35, 37, 38], "privileg": 6, "prize": 32, "pro": [40, 44], "prob": [33, 37], "proba": 44, "probabilist": 2, "probabl": [17, 27, 30, 31, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 49, 54, 55, 56], "problem": [4, 6, 10, 27, 32, 33, 35, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 51, 53, 54, 55, 56, 57], "problemat": [35, 38, 46], "probosci": [27, 44], "proce": 57, "procedur": 37, "proceed": [29, 56], "process": [2, 5, 7, 28, 30, 31, 32, 34, 39, 40, 41, 44, 47, 51, 53, 57], "process_on": 47, "prod": [32, 34], "produc": [2, 7, 36, 38, 41, 46, 49, 51], "product": [5, 34, 42, 43], "prof": [35, 37, 38, 54], "profession": 42, "profil": 36, "profile_df": 42, "profilereport": 36, "program": [0, 4, 9, 11, 27, 43, 57], "programm": 43, "progress": 40, "project": [11, 31, 37, 39, 44, 49, 57], "promin": 43, "promis": [27, 43, 45], "promot": 46, "prompt": [11, 57], "pron": [43, 47], "prone": 34, "proper": [44, 50], "properli": [7, 46], "properti": [28, 36, 38, 39], "prophet": 45, "propn": 47, "proport": [28, 29, 32, 33, 35, 36, 37, 38, 54, 57], "proportional_hazard_test": 46, "prostitut": 43, "prototyp": 49, "prove": 35, "provid": [0, 5, 7, 11, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 49, 53, 54, 55, 56, 57], "provinc": [32, 43], "proxi": 29, "proxim": [33, 43, 57], "prune": 39, "psychologi": [32, 49], "pt": [33, 34, 44], "public": [0, 4, 7, 43, 47], "publish": [0, 10, 33, 43], "pud": 36, "pull": [11, 33, 43], "punct": [43, 47], "punctuat": [32, 43], "punkt": 47, "punkt_tab": 47, "purchas": [27, 42], "pure": [28, 45], "purpos": [0, 28, 29, 31, 42, 43, 45, 49, 50, 51, 55, 57], "push": [7, 38], "put": [7, 8, 11, 28, 29, 31, 32, 39, 40, 41, 42, 53], "px": [39, 43], "py": [28, 29, 31, 32, 34, 37, 38, 40, 41, 46, 47, 48], "pybind11": 47, "pybo": 34, "pydata": 39, "pyplot": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "pysurviv": 46, "python": [3, 4, 10, 27, 34, 36, 42, 43, 44, 45, 46, 47, 57], "python3": [9, 28, 29, 32, 34, 38, 46, 47, 48], "pythonwarn": 36, "pytorch": [27, 44], "pytorch_1711403226120": 47, "pyviz": 35, "q": 10, "qualiti": [35, 38, 40, 41], "quantifi": [35, 54], "queri": [31, 35, 37, 40, 42, 43, 45, 46, 54, 56, 57], "query_point": 30, "quest": 39, "question": [6, 7, 57], "quick": [4, 43, 57], "quickli": [28, 30, 31, 34, 41, 46, 49, 57], "quickstart": 9, "quirk": 29, "quit": [6, 27, 28, 31, 34, 35, 36, 38, 39, 41, 43, 44, 45, 46, 47], "quiz": [1, 10, 43], "quiz1": [28, 29, 32, 49], "quiz2": [29, 32, 49], "quizz": 28, "r": [28, 32, 33, 35, 45, 55, 57], "r1": 37, "r2": [36, 37, 49, 51], "r2_score": [36, 39, 47], "r4": 37, "race": [32, 35, 37, 38, 54, 57], "radial": 30, "radiu": [39, 41], "rail": 44, "rain": [45, 56], "rain_df": [45, 56], "rain_df_modifi": [45, 56], "rainfal": [45, 56], "rainfall_lag1": [45, 56], "rainfall_lag2": [45, 56], "rainfall_lag3": [45, 56], "raintodai": [45, 56], "raintoday_miss": [45, 56], "raintoday_no": [45, 56], "raintoday_y": [45, 56], "raintomorrow": [45, 56], "rais": [6, 32, 35, 45, 46, 56], "rand": [8, 37], "randint": [34, 53], "randn": [33, 39], "random": [6, 8, 29, 30, 33, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 55, 57], "random_forest_data": 37, "random_search": [34, 53], "random_st": [27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55], "randomforestclassifi": [38, 39, 45, 55, 56], "randomforestclassifierrandomforestclassifi": 37, "randomforestregressor": [36, 37, 38, 39, 45, 46, 47, 55], "randomhorizontalflip": 44, "randomizedsearchcv": [30, 37, 38, 53, 55], "randomizedsearchcvifittedrandomizedsearchcv": 34, "randomli": [29, 33, 34, 35, 37, 46, 54], "randomoversampl": 35, "randomresizedcrop": 44, "randomst": [39, 41], "randomundersampl": 35, "rang": [4, 8, 29, 30, 31, 32, 33, 37, 40, 42, 43, 44, 45, 46, 47, 53, 57], "rangeindex": [32, 39, 45, 46, 56], "rank": [35, 39, 42, 43, 46, 54], "rank_test_mape_scor": 36, "rank_test_neg_mean_squared_error": 36, "rank_test_scor": [34, 36], "ranking_": 39, "rare": [32, 35, 36, 40, 43, 49], "rate": [27, 33, 35, 37, 40, 46, 49, 54], "rated_item": 42, "rather": [27, 32, 34, 35, 36, 37, 38, 40, 43, 44], "ratings_df": 42, "ratio": [35, 37, 43, 46], "ravel": [35, 49], "raw": [8, 32, 35, 38, 39, 43, 44, 48, 54], "raw_model_output": 33, "raw_scor": 38, "rbf": [10, 15, 29, 31, 33, 34, 37, 38, 39, 49, 51, 53], "rcparam": [27, 28, 29, 35, 40, 41, 42, 44, 45, 46, 50, 56], "re": [4, 7, 8, 11, 27, 28, 29, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 56], "reach": [6, 40, 57], "read": [1, 4, 7, 10, 30, 31, 32, 35, 36, 37, 38, 43, 45, 55, 56], "read_csv": [8, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 57, "readi": [7, 29, 30, 31, 33], "readlin": 44, "readm": 46, "readthedoc": 46, "real": [29, 30, 31, 32, 33, 35, 38, 40, 41, 42, 43, 44, 47, 49], "realdonaldtrump": 47, "realist": [31, 45, 56], "realiti": [29, 36, 46], "realli": [8, 29, 33, 34, 37, 39, 41, 42, 44, 45, 46], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 34, 35, 36, 38, 40, 42, 43, 45, 46, 49, 57], "rebuild": 47, "rec": [36, 38], "recal": [18, 28, 29, 30, 31, 32, 33, 36, 40, 45, 49, 54, 57], "recall_lr": 35, "recall_scor": 35, "recall_svc": 35, "receiv": [6, 7, 32, 41, 44, 45], "recent": [8, 11, 27, 32, 39, 42, 43, 45, 46, 47], "recip": 29, "recogn": [29, 41, 45, 57], "recognit": [27, 28, 30, 35, 43, 57], "recommend": [2, 4, 8, 10, 11, 27, 29, 30, 34, 35, 40, 43, 44, 55, 57], "record": [28, 46], "recreat": 56, "rectangular": 40, "recurr": 45, "recurs": 57, "red": [28, 30, 35, 38, 39, 40, 45], "redbon": 34, "redefin": 46, "redistribut": 0, "reduc": [7, 8, 27, 30, 34, 35, 36, 37, 38, 39, 42, 43, 44, 48, 51, 54, 57], "reduct": [2, 35, 37, 39, 40], "redund": [33, 38], "ref": [35, 46, 54], "refer": [8, 28, 29, 30, 31, 32, 33, 35, 38, 40, 42, 43, 44, 51, 57], "referenc": 57, "referenti": 43, "refin": [30, 51], "refit": 36, "reflect": [30, 36, 38, 43, 51, 53, 57], "reflection_period": 35, "reg": [28, 37, 55], "reg_model": 28, "regard": 57, "regardless": 7, "regex": 43, "region": [28, 35, 41, 45, 48, 53, 56], "region_data": [45, 56], "regist": 57, "registri": 47, "regrad": 6, "regress": [2, 10, 17, 27, 31, 32, 38, 39, 42, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57], "regression_df": 28, "regressor": [28, 31, 32, 36, 45, 55], "regular": [30, 32, 33, 37, 43, 45, 46, 49], "regulatori": 38, "reinforc": [27, 40], "reject": [35, 54], "rel": [33, 38, 41, 43, 47, 48, 54], "rel_char_len": 47, "relabel": 40, "relat": [2, 6, 11, 27, 33, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 55, 57], "relationship": [35, 37, 38, 39, 43, 45, 47, 49, 50, 51, 54, 56, 57], "relationship_husband": 38, "relationship_own": 38, "releas": [7, 10], "relev": [4, 8, 10, 28, 30, 31, 34, 38, 45, 57], "reli": [29, 30, 39, 41, 42, 45, 51], "reliabl": [27, 40], "religi": 43, "remain": [5, 36, 39, 42, 45], "remaind": 6, "rememb": [7, 30, 32, 34, 35, 38, 39, 41, 44, 45, 46, 50, 51, 53, 56], "remind": 50, "remix": 0, "remov": [7, 31, 35, 37, 38, 39, 43, 44, 46, 48, 53, 54, 56], "renam": [27, 35, 38, 45], "render": [4, 7, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 47], "rent": 45, "rental": 45, "rentals_df": 45, "rentals_lag5": 45, "rentals_lag5_i": 45, "rentals_lag5_x": 45, "rentals_model": 45, "repair": [35, 37, 38], "repeat": [8, 39, 40, 41, 44, 53, 54, 55], "repeatedli": 6, "replac": [27, 31, 35, 37, 38, 42, 46, 54], "reply_cont": 47, "repo": [10, 35], "report": [6, 28, 34, 36, 39, 45, 47, 54], "repositori": [0, 5, 10, 11, 33, 35, 57], "repres": [28, 29, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 55], "represent": [27, 28, 31, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 49], "reproduc": [4, 29, 34, 37, 57], "republ": 38, "request": [6, 43, 57], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 49, 51, 56], "rerun": [27, 31, 32, 34, 35, 36, 37, 38, 39, 44, 47], "res_mean": 29, "resampl": 35, "research": [27, 29, 34, 42, 43], "reserv": [45, 57], "reset_index": 27, "reshap": [8, 33, 34, 44, 45, 53], "resid": 33, "residu": 37, "resiz": 44, "resnet": 44, "resolut": 43, "resolv": 57, "resort": 33, "resourc": [3, 5, 10, 28, 37, 38, 43, 44, 49], "respect": [33, 34, 35, 37, 38, 53], "respons": [4, 7, 28, 40, 43, 57], "rest": [33, 34, 44, 46, 49, 56], "restart": [7, 11], "restaur": 42, "restingbp": 55, "restingecg": 55, "restrict": [0, 36, 37, 43], "result": [2, 7, 8, 10, 11, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 51, 53, 54, 55, 56, 57], "result_block": 46, "result_img": 44, "results_df": [29, 30, 33, 51], "results_dict": [29, 30, 31, 32, 34], "results_single_valid_df": 51, "retail": [47, 49], "retail_df": 45, "retail_df_test": 45, "retail_df_train": 45, "retail_lag_5": 45, "retail_model": 45, "retail_test_5": 45, "retail_test_5_pr": 45, "retail_train_5": 45, "retail_train_5_d": 45, "retail_train_5_i": 45, "retail_train_5_x": 45, "retent": 46, "retrain": [34, 53], "return": [5, 8, 11, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 53, 56], "return_gener": 32, "return_train_scor": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 51, 53, 55], "reus": [35, 57], "revenu": 42, "revers": [32, 36], "review": [4, 10, 25, 33, 40, 47, 49, 53, 54, 55, 57], "revisit": [35, 49], "revok": 0, "reward": [27, 32, 40], "rf": [45, 46], "rf_imp_df": 38, "rfe_cv": 39, "rfe_pip": 39, "rfecv": 39, "rgb": 27, "rich": [38, 43, 46, 49], "rico": 38, "rid": [11, 32, 37, 38, 43, 46], "ridg": [38, 39, 42, 45, 46, 47], "ridge__alpha": 36, "ridge_pr": 36, "ridge_tun": 36, "ridgecv": [39, 47], "ridgecv_pip": 36, "ridgeridg": [36, 39], "right": [0, 10, 27, 33, 34, 35, 36, 39, 40, 41, 42, 43, 49, 53, 54, 57], "rightarrow": [28, 30, 33, 35, 36, 37, 40, 41, 42, 43, 49], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 43, "rise": [39, 43], "risk": [10, 35, 39, 51, 55], "river": 33, "rl": [36, 38], "rmse": [42, 49], "rng": [39, 41], "rnn": 45, "ro": 35, "roast": 40, "robot": [42, 43], "robust": [27, 29, 30, 31, 34, 37, 41, 51, 53], "roc": [49, 57], "roc_auc": 35, "roc_auc_scor": 35, "roc_curv": 35, "roc_lr": 35, "roc_svc": 35, "roccurvedisplai": 35, "rodolfo": 34, "rodr\u00edguez": 43, "roger": 39, "role": [33, 34, 38, 44], "roman": 42, "romanc": 42, "romant": 42, "ronald": 33, "roof": 38, "roofmatl": [36, 38], "roofmatl_clytil": [36, 38], "roofmatl_compshg": [36, 38], "roofmatl_membran": 36, "roofmatl_met": 36, "roofmatl_rol": 36, "roofmatl_tar": 36, "roofmatl_wdshak": 36, "roofmatl_wdshngl": [36, 38], "roofstyl": [36, 38], "roofstyle_flat": 36, "roofstyle_g": 36, "roofstyle_gambrel": 36, "roofstyle_hip": 36, "roofstyle_mansard": 36, "roofstyle_sh": 36, "room": [27, 28, 33, 36, 39, 47, 57], "rooms_per_household": [31, 32, 39, 52], "rooms_per_household_0": 39, "rooms_per_household_1": 39, "rooms_per_household_10": 39, "rooms_per_household_11": 39, "rooms_per_household_12": 39, "rooms_per_household_13": 39, "rooms_per_household_14": 39, "rooms_per_household_15": 39, "rooms_per_household_16": 39, "rooms_per_household_17": 39, "rooms_per_household_18": 39, "rooms_per_household_19": 39, "rooms_per_household_2": 39, "rooms_per_household_3": 39, "rooms_per_household_4": 39, "rooms_per_household_5": 39, "rooms_per_household_6": 39, "rooms_per_household_7": 39, "rooms_per_household_8": 39, "rooms_per_household_9": 39, "root": [11, 28, 30, 42, 44, 49], "rose": 43, "rostin": 57, "rotat": [45, 56], "rough": 4, "roughli": [5, 29, 43, 49], "round": [8, 30, 31, 34, 35, 37, 41, 44, 51], "rout": [5, 28, 45], "row": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 50, 51, 55, 56, 57], "rry": 43, "rsh": 34, "ru": [8, 35], "rubric": 33, "rule": [1, 8, 27, 28, 30, 33, 35, 37, 43, 49, 51, 54], "run": [4, 5, 7, 10, 11, 27, 29, 30, 32, 34, 35, 36, 38, 40, 41, 43, 44, 47, 48, 50, 51, 53, 55], "run_ast_nod": 47, "run_cel": 47, "run_cell_async": 47, "run_cod": 47, "run_forev": 47, "runner": 47, "runpi": 47, "runtimewarn": 34, "rush": 39, "russel": 10, "rv": 34, "rv_continuous_frozen": 34, "rv_discrete_frozen": 34, "rvert_2": 43, "s1": [8, 43], "s19": 31, "s2": [8, 43], "s_lag": [45, 56], "sa": 1, "sabrina": 10, "sadli": 43, "safe": 31, "safeti": 44, "sai": [8, 28, 30, 31, 32, 35, 36, 37, 38, 43, 45, 49, 54], "said": [29, 31, 33, 38, 41, 42, 43], "sal": [36, 38], "sale": [8, 35, 36, 45, 51], "salecondit": [36, 38], "salecondition_abnorml": 36, "salecondition_adjland": 36, "salecondition_alloca": 36, "salecondition_famili": 36, "salecondition_norm": 36, "salecondition_parti": 36, "salepric": [36, 38], "sales_data": 45, "salesforc": 47, "saletyp": [36, 38], "saletype_cod": 36, "saletype_con": 36, "saletype_conld": 36, "saletype_conli": 36, "saletype_conlw": 36, "saletype_cwd": 36, "saletype_new": 36, "saletype_oth": 36, "saletype_wd": 36, "salt": [33, 38], "sam": 42, "same": [6, 7, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 54, 56], "sampl": [28, 30, 31, 33, 34, 38, 41, 44, 45, 46, 50, 51, 54, 55, 56], "sample_df": 35, "sample_text": 47, "sampling_strategi": 35, "samuel": 27, "sand": 44, "sandbar": 44, "saniti": [28, 46], "sarah": 10, "sat": 45, "satisfactori": 40, "satisfi": [40, 57], "saturdai": [10, 45], "save": [7, 8, 32, 34, 38, 43, 44, 45, 47, 52, 53, 56], "saw": [31, 33, 34, 35, 41, 49], "sb": 39, "scalabl": [27, 41], "scalar": 8, "scale": [16, 29, 30, 32, 34, 35, 36, 37, 39, 41, 44, 46, 49, 51, 52, 53], "scale_pos_weight": 37, "scaler": [31, 38, 39], "scan": 49, "scatter": [31, 36, 38, 39], "scatter_3d": 39, "scatterplot": 39, "scc": 43, "scenario": [29, 32, 37, 38, 39, 41, 45, 46, 49, 57], "schedul": [46, 49], "schmidt": 34, "school": [27, 35, 37, 38, 42, 54], "scienc": [2, 9, 10, 11, 32, 40, 45, 49, 51, 57], "scientif": [42, 43], "scientist": [9, 10, 41], "scikit": [9, 11, 16, 17, 28, 30, 33, 34, 35, 37, 40, 41, 44, 45, 47, 48, 53, 54, 57], "scipi": [11, 34, 41, 43, 53], "scm": 5, "scope": [43, 45], "score": [17, 18, 27, 30, 31, 32, 37, 38, 41, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57], "score_func": 36, "score_lr_print_coeff": [45, 56], "score_param": 32, "score_tim": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47], "scorer": [32, 36], "scores_averag": 55, "scores_dict": 33, "scores_imag": 33, "scores_stack": 55, "scoring_method": 46, "scoring_metr": [37, 38, 47], "scotland": 43, "scratch": [2, 44], "screen": 7, "screennam": 47, "screenplai": 43, "screenporch": [36, 38], "script": 11, "scroog": 47, "sd": [19, 23, 24, 25, 26], "sdng": 36, "se": [45, 46, 56], "sea": 44, "seaborn": [38, 39, 40, 41, 42], "seacoast": 44, "search": [4, 5, 11, 36, 43, 49, 53], "search_multi": 36, "seashor": 44, "season": 56, "season_autumn": 45, "season_fal": 45, "season_summ": 45, "season_wint": 45, "seat": [44, 57], "seattl": 47, "seawal": 44, "second": [4, 6, 28, 33, 37, 38, 41, 44, 45], "secondari": 27, "secpompeo": 47, "section": [7, 11, 28, 29, 39, 55, 57], "secur": [38, 57], "see": [1, 4, 6, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 57], "seed": [33, 34, 40, 41], "seem": [28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 45, 46, 47, 48, 51, 53, 54], "seemingli": [35, 54], "seen": [8, 27, 29, 30, 31, 32, 33, 39, 41, 42, 46, 49, 51, 53, 55], "sefa": 57, "segment": [35, 43, 44, 46, 49, 57], "select": [5, 6, 10, 11, 29, 30, 31, 32, 33, 34, 35, 36, 37, 44, 45, 46, 57], "select_dtyp": 36, "select_knn": 39, "select_rf": 39, "select_svc": 39, "selectfrommodel": 39, "self": [27, 32, 46, 47, 57], "sell": [0, 8, 28], "semant": [40, 41, 43, 57], "semest": 57, "semi": [10, 43], "semicolon": 8, "semilogx": 36, "send": [4, 27, 47], "senior": 46, "seniorcitizen": 46, "sens": [6, 29, 32, 33, 35, 36, 38, 39, 40, 42, 43, 45, 46, 48], "sensibl": 7, "sensit": [29, 31, 34, 35, 36, 40, 46], "sent": [27, 43], "sent_token": 43, "sentenc": 43, "sentiment": [28, 33, 43, 47], "sentimentintensityanalyz": 47, "sepal": [30, 51], "separ": [28, 29, 31, 32, 33, 35, 39, 40, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54], "septemb": 45, "sequenc": [29, 32, 44, 45], "sequenti": [28, 37, 45, 46, 49], "sequentialfeatureselector": 39, "ser": [29, 31, 46], "seri": [2, 10, 29, 31, 32, 35, 39, 44, 46, 47, 57], "serial": 37, "seriou": [6, 35, 42, 43, 46, 57], "serv": [5, 28, 38, 57], "server": 5, "servic": [37, 38, 42, 46, 47], "session": [40, 49, 57], "set": [7, 8, 9, 10, 27, 28, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56], "set_config": [34, 37], "set_index": [29, 30, 34, 35, 36], "set_opt": [27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 42, 50, 51, 52, 53, 54], "set_properti": 27, "set_titl": [30, 33, 35, 44, 51, 54], "set_xlabel": [30, 33, 40, 51], "set_ylabel": [30, 33, 40, 51], "settl": [53, 54], "setup": [3, 7, 11, 50], "setup_default_warn": 47, "sev": [36, 38], "sever": [11, 31, 33, 40, 41, 43, 44, 45, 48, 56, 57], "sex": [35, 37, 38, 39, 54, 55], "sexual": 57, "shadab": 57, "shadow": [19, 23, 24, 25, 26], "shaikh": 57, "shall": [0, 43], "shallow": 37, "shape": [28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 56], "shape_df": 29, "shape_dict": 29, "share": [0, 39, 57], "sharealik": 1, "sharex": 31, "shashwat": 57, "she": [27, 42, 47], "shed": [36, 38], "sheet": [9, 49], "shelf": [37, 43, 53], "shell": [5, 9, 47], "shelv": 47, "shift": [45, 56], "shit": 47, "shng": 36, "shop": 42, "short": [10, 11, 29, 34, 37, 43, 57], "shorter": 46, "shorthand": 31, "shot": 39, "should": [5, 7, 8, 11, 28, 29, 30, 31, 32, 33, 35, 38, 39, 40, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57], "shouldn": [35, 37, 51], "show": [4, 7, 11, 27, 29, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 53, 55, 56], "show_plot": 46, "showcas": 43, "shown": [7, 11, 27, 28, 30, 35, 37, 40, 41, 45], "shrink": [34, 39], "shuffl": [29, 44, 45, 56], "si": 27, "sibl": 39, "sick": [40, 47], "sid": 47, "side": [6, 44], "sift": 42, "sigma": 44, "sign": [4, 36, 38, 44, 51, 53, 55, 57], "signal": [29, 43], "signific": [31, 44, 57], "significantli": [32, 35, 42], "sigoptsearchcv": 34, "silhouett": 41, "silhouettevisu": [40, 41], "sim": 38, "sim_word": 43, "simard": 38, "similar": [10, 11, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 48], "similarity_": 43, "similarli": [38, 40, 46], "simp": 45, "simpl": [10, 28, 30, 31, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 49, 50, 54], "simplefilt": [37, 38], "simpleimput": [31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 52, 53, 54, 55, 56], "simpleimputersimpleimput": [31, 32, 36, 37, 39], "simpler": [33, 34, 51], "simplest": 32, "simpli": [31, 39, 40], "simplic": [28, 32, 42], "simplist": [30, 38, 51], "simul": 39, "sin": 8, "sinc": [5, 33, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 56], "singl": [8, 30, 31, 33, 34, 35, 37, 38, 41, 45, 46, 49, 50, 51, 53, 54], "sit": 57, "site": [5, 28, 29, 32, 34, 38, 46, 47, 48, 57], "situat": [6, 27, 35, 37, 40, 44, 46, 57], "six": [29, 37, 45], "size": [27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 55, 56, 57], "skew": 36, "skill": [37, 57], "skin": 47, "skip": 54, "skipna": 46, "sklearn": [10, 27, 29, 30, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "sklearn_gb": 37, "sklearn_histgb": 37, "sktime": 45, "skyblu": [45, 56], "skyscrap": 45, "slate": 56, "slice": 8, "slide": [9, 10, 19, 25, 31, 44, 57], "slightli": [32, 33, 35, 37, 46], "slope": 33, "sloppi": 31, "slot": 57, "slow": [30, 37, 39, 44], "slower": [37, 40], "slowest": 55, "sm": [27, 32], "smac": 34, "small": [11, 29, 30, 32, 34, 36, 37, 38, 39, 40, 42, 44, 46, 49, 51, 53, 55], "small_citi": 30, "small_train_df": 30, "smallalpha_coeff": 36, "smaller": [30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 45, 46, 51, 53], "smallest": [33, 36, 40, 41], "smart": [40, 47], "smile": 47, "smooth": [30, 51], "smoothli": 11, "smote_pip": 35, "sms_df": 27, "sn": [38, 40, 41], "snake": [33, 44], "snake_length": 33, "snakes_df": 33, "snbf": 37, "snippet": 7, "snow": [27, 44], "snp": 39, "so": [0, 4, 5, 7, 8, 10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57], "social": [40, 41, 42, 45], "societ": 57, "societi": [35, 43, 54], "sofist": 51, "soft": [33, 37, 55], "softmax": 49, "softwar": [1, 5, 11, 46], "solar": 42, "sold": [8, 36], "sole": [35, 41], "solidifi": 49, "solut": [27, 28, 29, 37, 40, 46, 47, 49, 57], "solv": [4, 27, 28, 30, 39, 43, 51, 57], "solver": 35, "some": [4, 6, 7, 8, 11, 27, 29, 30, 31, 32, 33, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57], "someon": [27, 28, 29, 39, 46], "someth": [4, 7, 11, 28, 32, 35, 36, 37, 38, 40, 45, 46, 49, 57], "sometim": [6, 28, 29, 32, 33, 34, 37, 38, 43], "somewhat": 36, "somewher": [27, 36], "song": [30, 31, 42, 47, 53], "song_titl": [30, 31, 34, 53], "soo": 57, "soon": [27, 30, 31, 45], "sopha": 27, "sophist": [34, 38, 43], "sort": [5, 10, 28, 29, 31, 38, 42, 43, 44, 45, 56], "sort_index": [8, 34, 36, 45, 56], "sort_valu": [31, 32, 33, 34, 36, 37, 38, 39, 45, 46, 47, 55, 56], "sound": [38, 39], "soundtrack": 43, "sourc": [11, 27, 28, 29, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 53, 57], "south": 32, "space": [30, 33, 34, 39, 40, 41, 43, 47, 56, 57], "spaci": 39, "spacy_download": 43, "spacymoji": 47, "spam": [29, 35, 40], "spam_predict": 27, "span": [43, 45], "spanish": 31, "spars": [30, 33, 37, 42, 43, 49], "sparse_output": [31, 32, 35, 36, 37, 38, 45, 46, 49, 54, 55, 56], "spatial": 33, "speak": 5, "spearmint": 34, "speci": [30, 49, 51], "special": [27, 32, 42, 43, 44, 45, 46, 51, 57], "specialti": [35, 37, 38], "specif": [8, 28, 29, 34, 35, 38, 40, 42, 43, 44, 45, 46, 49, 51, 53, 55, 57], "specifi": [8, 28, 29, 32, 34, 35, 40, 41, 44, 53, 55], "spectrogram": 39, "speech": [39, 43, 47], "speechi": [30, 31, 34, 53], "speed": [8, 28, 37, 44], "spell": 27, "spend": [27, 31, 39, 47, 57], "spent": [6, 31, 39], "spheric": [41, 49], "spici": 40, "spini": 44, "spit": 44, "split": [15, 28, 30, 32, 33, 34, 36, 37, 39, 42, 43, 46, 47, 49, 54, 55, 56, 57], "split0_test_r2": 36, "split0_test_scor": 34, "split0_train_neg_mean_squared_error": 36, "split0_train_scor": 34, "split1_test_r2": 36, "split1_test_scor": 34, "split1_train_neg_mean_squared_error": 36, "split1_train_scor": 34, "split2_test_r2": 36, "split2_test_scor": 34, "split2_train_neg_mean_squared_error": 36, "split2_train_scor": 34, "split3_test_r2": 36, "split3_test_scor": 34, "split3_train_neg_mean_squared_error": 36, "split3_train_scor": 34, "split4_test_scor": 34, "split4_train_neg_mean_squared_error": 36, "split4_train_scor": 34, "spoken": 32, "sport": [43, 44, 45], "spot": [35, 36, 51], "spotifi": [30, 42, 53], "spotify_df": [30, 31, 34, 53], "spotlight": [5, 11], "spous": [35, 37, 38], "spread": 41, "spring_month": 45, "sqft": 38, "sqft_abov": [27, 28], "sqft_basement": [27, 28], "sqft_live": [27, 28], "sqft_living15": [27, 28], "sqft_lot": [27, 28], "sqft_lot15": [27, 28], "sqrt": [30, 36, 38, 42, 43], "squar": [8, 28, 30, 33, 38, 42, 46, 47, 49, 57], "squash": [33, 44], "squeez": [8, 46], "src": [29, 35], "sse": [45, 56], "ssw": 45, "st": [45, 47], "st_slope": 55, "stabil": 11, "stabl": [29, 35, 37, 51], "stack": [7, 49, 57], "stack_method": 55, "stacking_model": [37, 55], "stacking_model_tre": 37, "stackingclassifi": [37, 55], "stackingregressor": 37, "staff": 6, "stai": [35, 46], "stakehold": 57, "stale": 40, "stand": [30, 34, 43], "standard": [4, 6, 29, 31, 34, 37, 38, 39, 43], "standardscal": [32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56], "standardscalerstandardscal": [31, 32, 34, 35, 36, 37, 39, 44, 47], "stanford": 43, "star": [30, 40, 42, 47], "start": [7, 8, 11, 28, 29, 30, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56], "startswith": 38, "starttim": 45, "stat": [34, 46, 53], "state": [6, 8, 29, 35, 37, 38, 42, 47, 54], "statement": [7, 29, 30, 31, 32, 33, 34, 35, 36, 39, 44, 46], "station": 45, "statist": [9, 10, 28, 33, 38, 42, 43, 46, 57], "statistician": 30, "statlib": 33, "statsmodel": [45, 46], "statu": [35, 37, 38, 54], "status_marri": 38, "status_nev": 38, "std": [29, 30, 31, 35, 36, 44, 45, 47, 48, 56], "std_cv_error": 29, "std_cv_score": 30, "std_fit_tim": [34, 36], "std_score": [29, 31, 47], "std_score_tim": [34, 36], "std_test_neg_mean_squared_error": 36, "std_test_scor": [29, 34], "std_train_error": 29, "std_train_neg_mean_squared_error": 36, "std_train_scor": [29, 30, 34], "stdki": 46, "stem": 43, "step": [7, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 55, 57], "stereotyp": 43, "stick": 45, "still": [4, 11, 34, 35, 36, 37, 39, 40, 45, 46, 47, 51, 52, 53, 54], "stochast": [39, 40], "stock": [27, 45], "stop": [8, 40, 43, 44, 46, 51], "stop_word": [34, 35, 43, 47, 53], "stopword": 43, "storag": 30, "store": [7, 8, 30, 31, 32, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47], "stori": [36, 37, 47], "storylin": 43, "str": [34, 38, 43, 45, 46, 47, 56], "straight": 46, "straightforward": 38, "strain": 7, "strang": [38, 46], "strata": 46, "strategi": [28, 30, 31, 32, 35, 36, 38, 40, 42, 45, 46, 49, 50, 54, 56], "stratif": 46, "stratifi": 46, "stratifiedkfold": [29, 35], "stream": [46, 47], "streamingmovi": 46, "streamingmovies_no": 46, "streamingmovies_y": 46, "streamingtv": 46, "streamingtv_no": 46, "streamingtv_y": 46, "street": [36, 38], "street_grvl": 36, "street_pav": 36, "strength": [43, 49], "stress": 40, "strftime": [45, 46], "string": [8, 11, 30, 35, 36, 37, 38, 43, 45, 46, 51, 55], "strip": [38, 44], "strong": [37, 46, 49], "stronger": 37, "strongli": 37, "structur": [8, 40, 43, 44], "struggl": [40, 45], "stuart": [10, 37], "stuck": [4, 8], "student": [4, 5, 6, 7, 27, 28, 33, 35, 36, 38, 39, 40, 41, 42, 44, 47, 57], "studi": [27, 32, 39, 43, 46], "stuff": [30, 44, 46], "stump": [28, 29, 30, 37, 50], "stupid": 47, "style": [27, 36, 39, 40, 42, 43, 44, 47], "sub": [34, 40, 43, 46, 49], "subdirectori": 38, "subgroup": 46, "subject": [0, 46, 57], "sublicens": 0, "submiss": [3, 57], "submit": [8, 10, 57], "subplot": [29, 30, 33, 35, 40, 44, 46, 51, 54], "subplot_kw": 29, "subprocess": 36, "subscrib": 46, "subscript": [45, 46], "subset": [28, 29, 34, 37, 44, 45, 48, 51], "substanti": 0, "substitut": 0, "subtl": 43, "subtleti": [29, 36], "subtract": [30, 35, 38], "suburb": 47, "subword": 43, "succe": [39, 57], "success": [5, 8, 11, 27, 35, 37, 42, 43, 44, 45], "successfulli": [11, 27, 47], "sudo": 5, "suei": 34, "suffer": 34, "suffici": [7, 43], "suggest": [0, 10, 28, 42, 46], "suicid": 43, "suit": 42, "suitabl": [11, 27, 40, 42, 49, 55, 57], "sum": [8, 30, 31, 32, 33, 37, 38, 40, 44, 47], "sum_": [30, 36, 40, 43, 44], "sum_i": [38, 43], "sum_prob_ex1_class_0": 37, "sum_prob_ex1_class_1": 37, "summar": [10, 27, 33, 35, 36, 40, 43], "summari": [0, 48, 49, 51], "summary_plot": 38, "summat": 37, "summer": [1, 42, 45], "summer_month": 45, "sun": [43, 45], "sundai": 45, "sundial": 44, "sunshin": [45, 56], "super": [32, 47, 49], "superfici": 30, "superior": 57, "supermarket": 47, "supervis": [31, 32, 34, 35, 36, 39, 41, 43, 45, 46, 49, 56, 57], "suppli": 57, "support": [11, 15, 28, 31, 35, 37, 38, 39, 41, 43, 47, 48, 51, 57], "support_": [30, 39], "suppos": [27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 49, 50], "suppress": 8, "suprem": 43, "sure": [4, 7, 8, 11, 29, 30, 32, 35, 36, 37, 38, 41, 44, 45, 51, 54, 55, 56, 57], "surgeri": 46, "suri": 57, "surpris": [38, 42], "surprisingli": [32, 33], "surround": [4, 57], "survei": 40, "surviv": [2, 10, 57], "survival_function_": 46, "suscept": 41, "suspect": 34, "svc": [30, 31, 32, 33, 34, 37, 38, 39, 44, 47, 51, 52, 53, 55], "svc__c": [34, 53], "svc__gamma": [34, 53], "svc_pipe": 34, "svc_pred": 35, "svcsvc": [32, 34, 35], "svm": [10, 29, 31, 32, 34, 37, 38, 39, 44, 45, 47, 48, 49, 51, 52, 53, 55], "svm_estim": 35, "svr": [30, 32, 38], "svr_c_pipe": 32, "svr_pipe": 32, "sw": [45, 56], "swai": 27, "swamp": 30, "swan": 44, "swcarpentri": 9, "sweep": 35, "sweet": 47, "switch": [38, 40, 45, 46, 56], "sy": [27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55], "sydnei": 45, "syllabu": [3, 7, 10, 12], "symbol": 28, "symmetri": 39, "sync": 5, "synonym": 43, "syntact": 43, "syntax": [4, 8, 27, 39, 46], "synthet": [39, 48], "system": [2, 4, 5, 6, 10, 11, 27, 29, 30, 32, 35, 38, 40, 45, 54, 57], "systemat": [28, 32, 34, 38, 43], "t": [4, 5, 7, 8, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 55, 56, 57], "ta": [7, 27, 36, 38, 50, 51, 52, 53, 54, 55, 56], "tabbi": [27, 44], "tabl": [7, 55], "tabular": [8, 27, 44, 45], "tackl": [29, 31, 35, 41, 51], "taco": 39, "tag": [4, 43, 47], "tail": [8, 45], "tailor": [40, 57], "take": [2, 4, 5, 6, 11, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57], "taken": [45, 48, 53, 57], "talk": [28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 57], "tall": 43, "target": [29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56], "target_column": [37, 38, 46, 55], "target_nam": 35, "target_names_toi": 35, "tariff": 43, "task": [31, 32, 33, 34, 38, 39, 40, 42, 44, 45, 46, 47, 49, 53, 56, 57], "tast": [40, 42], "taught": [32, 43, 57], "tba": 10, "tbd": [19, 57], "teach": [4, 27, 31, 43, 49], "team": [4, 8, 27, 37, 38, 43, 55], "tech": [30, 35, 38], "technic": 57, "techniqu": [10, 30, 34, 39, 42, 44, 46, 48, 49, 57], "technolog": 0, "technologi": 43, "techsupport": 46, "techsupport_no": 46, "techsupport_y": 46, "ted": 40, "tediou": 41, "telco": 46, "telecom": 46, "telephon": 43, "tell": [29, 30, 31, 33, 35, 38, 39, 42, 43, 45, 46, 51, 53, 56], "temp3pm": [45, 56], "temp9am": [45, 56], "temperatur": 28, "tempo": [30, 31, 34, 53], "tempor": [46, 49, 56], "tend": [29, 30, 33, 37, 39, 42, 45, 46, 57], "tendenc": 29, "tensor": 44, "tensor_numpi": 47, "tensorflow": [11, 38, 44], "tent": 57, "tenur": [46, 49], "tenure_lm": 46, "tenure_predict": 46, "term": [0, 2, 28, 30, 32, 33, 35, 38, 39, 42, 43, 46, 49], "termin": [5, 11, 28, 40], "terminologi": [14, 29, 35, 49, 50], "terrac": 44, "terribl": [36, 42], "territori": 57, "tesoro": 34, "test": [1, 7, 8, 11, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 41, 46, 48, 49, 51, 53, 54, 55, 56, 57], "test_accuraci": 35, "test_average_precis": 35, "test_df": [27, 31, 32, 33, 35, 36, 37, 38, 39, 45, 46, 47, 52, 54, 55, 56], "test_df_churn": 46, "test_df_nan": [35, 37, 38, 54], "test_df_sort": 45, "test_df_surv": 46, "test_exampl": 37, "test_f1": 35, "test_format": 30, "test_g50k": 37, "test_imag": [27, 44], "test_l50k": 37, "test_mape_scor": 36, "test_nam": 46, "test_neg_mean_squared_error": 36, "test_neg_root_mean_square_error": 36, "test_point": [30, 48], "test_precis": 35, "test_r2": 36, "test_recal": 35, "test_roc_auc": 35, "test_sampl": 55, "test_scor": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 51], "test_shap_valu": 38, "test_siz": [27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 47, 48, 51, 52, 53, 54, 55], "test_sklearn": 36, "test_statist": 46, "test_x": 46, "text": [7, 10, 16, 17, 27, 28, 33, 34, 35, 36, 37, 38, 39, 42, 44, 49, 53, 57], "text_feat": [34, 53], "text_featur": 47, "text_pp": 43, "textbook": [3, 9], "textrm": 29, "textual": 57, "textur": 39, "tf": 32, "tfidfvector": 33, "th": [33, 42, 57], "than": [6, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 48, 50, 51, 54, 55, 57], "thank": [27, 43, 51], "thankfulli": [45, 56], "thei": [7, 8, 10, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57], "theirs": 43, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 57], "theme": 43, "themselv": [40, 41, 43], "theoret": [31, 35, 37, 49], "theori": 38, "thepopbreak": 47, "therefor": 51, "thermostat": 28, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 25, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "thick": 40, "thinc": 47, "thing": [5, 7, 8, 10, 28, 29, 30, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 55, 56], "think": [4, 27, 28, 29, 30, 32, 33, 35, 36, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 53, 54, 56, 57], "third": 41, "thk": 27, "thorough": [11, 55], "thoroughli": 49, "those": [5, 8, 11, 31, 36, 37, 38, 42, 46, 57], "though": [29, 32, 33, 40, 41, 42, 47], "thought": [4, 30, 38, 46, 49], "thousand": [33, 41, 42], "threahold": 39, "threaten": 47, "three": [8, 28, 31, 33, 35, 37, 38, 39, 40, 41, 43, 44, 45, 48, 49, 54, 57], "thresh": 8, "threshold": [28, 33, 37, 39, 41, 43, 46], "thresholds_lr": 35, "thresholds_svc": 35, "through": [7, 11, 28, 35, 36, 39, 41, 42, 44, 57], "throughout": 29, "throw": [32, 44, 46, 49], "thu": [6, 34, 45, 46], "thumb": [28, 47], "thursdai": 57, "ti": 32, "tick": 45, "tick_label": 38, "tick_param": 40, "tiger": [27, 44], "tight": [30, 41, 51], "tight_layout": 44, "tightrop": [30, 51], "tile": 38, "till": [30, 43, 46], "timber": 43, "time": [2, 4, 8, 10, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 53, 54, 55, 57], "time_diff": [45, 56], "time_signatur": [30, 31, 34, 53], "timedelta": [45, 56], "timeit": [8, 48], "timeseri": [44, 45], "timeseriessplit": [45, 46, 49, 56], "timestamp": [45, 56], "timezon": [10, 46], "tinder": 42, "tini": [7, 29, 35, 41], "tip": 43, "tire": 47, "titan": 42, "titi": 27, "titl": [7, 29, 30, 33, 36, 39, 41, 44, 45, 46, 51, 56], "tn": 35, "to_datetim": [45, 56], "to_html": [27, 28, 29], "to_notebook_ifram": 36, "to_numpi": [30, 42, 45], "to_str": [27, 44], "toarrai": [32, 38, 45], "tobago": [37, 38], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 42, 44, 45, 46, 49, 55, 56], "todens": [38, 39], "togeth": [5, 8, 28, 30, 31, 32, 40, 43, 51, 57], "toi": [8, 29, 30, 39, 40, 41, 42, 45, 49], "toilet": [44, 47], "token": [7, 47, 57], "token_pattern": 32, "tol": [35, 39], "told": [5, 57], "tolist": [27, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 56], "tomasbeuzen": 8, "tomorrow": [28, 45, 46, 49, 56], "ton": 34, "tone": 47, "too": [6, 7, 29, 30, 32, 34, 36, 37, 38, 45, 46, 51, 53, 56, 57], "took": 45, "tool": [7, 8, 10, 11, 32, 33, 35, 36, 38, 41, 42, 44, 45, 46, 49, 57], "toolbox": [30, 37, 43], "toolkit": 43, "top": [28, 32, 34, 35, 41, 45, 56], "topic": [2, 8, 10, 28, 35, 36, 40, 42, 44, 49, 57], "topic2vec": 43, "topics_per_chunk": 43, "topn": [27, 44], "torch": [44, 47], "torchvis": [27, 44], "tornado": 47, "toronto": [43, 47], "tort": 0, "total": [8, 10, 28, 31, 32, 35, 36, 37, 38, 39, 43, 45, 46, 56], "total_bedroom": [31, 32, 39, 52], "total_bilirubin": 27, "total_protien": 27, "total_room": [31, 32, 39, 52], "total_second": [45, 56], "totalbsmtsf": [36, 38], "totalcharg": 46, "totem": 44, "totensor": 44, "toti": [0, 1, 43], "totrmsabvgrd": [36, 38], "toward": [33, 38, 43, 54, 57], "towardsdatasci": [44, 46], "town": 47, "townsvil": 45, "toy_clust": 43, "toy_clust_df": 40, "toy_df": [32, 43], "toy_lda_data": 43, "toy_movie_feat": 42, "toy_rat": 42, "toy_spam": 32, "toy_x": 43, "tp": 35, "tpot": 34, "tpr": 35, "tpr_lr": 35, "tpr_svc": 35, "tr_score": 51, "traceback": [4, 8, 32, 46, 47], "track": [32, 57], "trade": [33, 35, 39, 40, 49, 57], "tradeoff": [15, 30, 31, 33, 36, 39, 40, 44], "tradit": [27, 42, 44, 46, 57], "tradition": 57, "trail": 8, "train": [7, 30, 31, 34, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56], "train_accuraci": 35, "train_dataload": 44, "train_df": [27, 31, 32, 33, 35, 36, 37, 38, 39, 45, 46, 47, 52, 54, 55, 56], "train_df_churn": 46, "train_df_nan": [35, 37, 38, 54], "train_df_ord": [45, 56], "train_df_sort": 45, "train_df_surv": 46, "train_df_surv_not_churn": 46, "train_f1": 35, "train_flatten": 44, "train_for_usr": 42, "train_load": 44, "train_mape_scor": 36, "train_mat": 42, "train_mat_imp": 42, "train_neg_mean_squared_error": 36, "train_neg_root_mean_square_error": 36, "train_precis": 35, "train_r2": 36, "train_recal": 35, "train_scor": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 45, 46, 47, 51], "train_shap_valu": 38, "train_sklearn": 36, "train_test_split": [27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56], "train_x": 42, "traitlet": 47, "transact": [28, 35, 45, 54], "transfer": 46, "transfer_learning_tutori": 44, "transform": [0, 30, 34, 35, 37, 38, 41, 43, 44, 45, 46, 47, 49, 51, 52, 56], "transformed_exampl": 37, "transformed_oh": 31, "transformedtargetregressor": [36, 39, 47, 49], "transformedtargetregressortransformedtargetregressor": 36, "transformerdecod": 47, "transformerencod": 47, "translat": [9, 10, 27], "transpar": [35, 49], "transpos": [39, 44], "trasform": 31, "trash": 50, "traumat": 57, "treat": [8, 29, 31, 32, 35, 36, 42, 45, 46, 49, 54, 56], "treati": 57, "treatment": 32, "tree": [2, 10, 14, 19, 20, 29, 30, 31, 32, 33, 34, 36, 39, 41, 44, 45, 46, 48, 49, 50, 52, 53, 55], "tree1": 37, "tree2": 37, "tree3": 37, "tree_numeric_transform": 38, "treeexplain": 38, "trend": [46, 49, 57], "tri": [37, 38, 48, 53, 54, 55], "trial": [34, 46], "triangl": [30, 40], "trick": [5, 36], "tricki": [32, 34, 38, 42], "trigger": [30, 47], "trigram": 43, "trivial": 41, "troubl": 11, "true": [8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56], "truli": [36, 43], "truncat": 41, "truncate_mod": 41, "truncation_mod": 41, "trust": [27, 31, 32, 34, 35, 36, 37, 38, 39, 42, 44, 47], "trustworthi": [41, 55], "truth": [37, 39, 40, 41, 42, 45], "try": [4, 5, 8, 10, 11, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57], "tsa": 45, "tscv": 45, "tslearn": 45, "tsunami": 27, "ttr": 36, "ttr_pipe": 36, "tue": 45, "tuesdai": [10, 39, 45, 56, 57], "tuggeranong": 45, "tumor": 49, "tune": [29, 34, 37, 41, 42, 44, 53, 55], "turn": [4, 29, 43, 44, 46, 52, 53, 57], "tusker": 44, "tutori": [4, 5, 9, 10, 11, 42, 44, 49, 57], "tweak": [30, 51], "tweet": [43, 47], "tweetat": 47, "twice": [8, 29, 32, 33], "twist": 43, "twitter_allowed_char": 47, "two": [4, 6, 7, 8, 9, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 54, 57], "two_citi": 30, "two_song": 31, "two_songs_subset": 31, "tx": [33, 47], "txt": [27, 44], "typ": [36, 38], "type": [4, 8, 11, 28, 30, 31, 32, 34, 37, 39, 41, 42, 43, 44, 47, 49, 51, 52, 53, 56, 57], "typeerror": 46, "typic": [2, 7, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 42, 45, 53], "u": [4, 11, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56], "u6": 28, "u_1": 30, "u_2": 30, "u_i": 30, "u_n": 30, "ubc": [0, 4, 5, 8, 9, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57], "ubc_img": 44, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 36, "ultim": [4, 29], "ultralyt": 44, "uluru": [45, 56], "umbrella": 42, "un": [36, 46], "unabl": [27, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 46, 47, 57], "unambigu": 43, "unassign": [40, 41], "unbalanc": 54, "unbias": [35, 54], "unced": 57, "uncertain": [33, 55], "uncertain_indic": 55, "uncertainti": [33, 35], "unchang": 38, "uncia": [27, 44], "uncomfort": 42, "uncorrel": 38, "under": [0, 1, 7, 28, 29, 36, 44, 46], "under_sampl": 35, "underestim": 46, "underfit": [30, 33, 34, 44, 51, 53], "underli": [2, 38, 39, 40], "underneath": 7, "underpredict": 36, "undersample_pip": 35, "understand": [0, 1, 4, 7, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 54, 57], "understood": 35, "unemploi": 46, "unexpect": [32, 33, 34, 43], "unexplain": 36, "unf": [36, 38], "unfinish": 36, "unfortun": [6, 34, 38, 40, 41, 53], "uniform": [34, 35, 41, 53], "unimport": [34, 38], "uninstal": 11, "uninterpret": 38, "unintuit": 8, "union": 8, "uniqu": [31, 32, 35, 36, 37, 38, 42, 43, 45, 46, 54, 56], "unit": [33, 35, 36, 37, 38, 43, 44, 46, 47], "unitless": 36, "univers": [1, 9, 43], "university_year": [32, 49], "unix": [5, 45], "unknown": [6, 43, 49], "unlabel": [27, 29, 41], "unless": [7, 57], "unlik": [8, 29, 30, 32, 36, 38, 40, 41], "unlimit": 45, "unlucki": 29, "unmarri": [37, 38], "unnam": 27, "unoffici": 57, "unqualifi": [35, 54], "unreason": [6, 36], "unreli": 29, "unscal": 31, "unseen": [28, 39, 40, 44, 51], "unsqueez": 44, "unstructur": 43, "unsupervis": [27, 42, 43, 44, 57], "unsur": 7, "until": [4, 28, 29, 34, 39, 40, 41, 46], "unus": 51, "unwieldi": [28, 31], "unzip": 38, "uoft": 43, "up": [7, 8, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 53, 57], "uparrow": 41, "upcom": 40, "updat": [10, 11, 30, 31, 32, 37, 40, 51], "update_cent": 40, "update_plot": [30, 51], "update_z": 40, "upgrad": [43, 47], "upload": 7, "upon": [0, 28, 29, 32, 35, 37, 38, 39, 40, 41, 43], "upper": [35, 46], "uppercas": 47, "upto": 45, "ur": 27, "urgent": [32, 43], "url": [4, 29, 35, 46, 54], "us": [0, 2, 4, 5, 10, 11, 33, 34, 38, 41, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56], "usa": [8, 29, 30, 33, 43], "usag": [31, 32, 35, 36, 39, 43, 45, 46, 56], "usec_": 46, "useless": [34, 38, 39], "user": [11, 27, 28, 29, 31, 32, 34, 37, 38, 40, 41, 44, 46, 47, 48, 49, 53], "user_global_n": 47, "user_id": 42, "user_inverse_mapp": 42, "user_kei": 42, "user_mapp": 42, "user_n": 47, "user_nam": 42, "usernam": 47, "userwarn": [28, 29, 32, 37, 38, 47], "usf": 32, "using_copy_on_writ": 46, "using_cow": 46, "usual": [10, 11, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 56, 57], "utc": [45, 46], "utcnow": 46, "util": [5, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 46, 47, 49, 50, 51, 52, 53, 55], "utilities_allpub": 36, "utilities_nosewa": 36, "utility_mat": 42, "v": [3, 7, 10, 32, 33, 41, 43, 45, 46, 49], "v1": [27, 35], "v10": 35, "v11": 35, "v12": 35, "v13": 35, "v14": 35, "v15": 35, "v16": 35, "v17": 35, "v18": 35, "v19": 35, "v2": [27, 35], "v20": 35, "v21": 35, "v22": 35, "v23": 35, "v24": 35, "v25": 35, "v26": 35, "v27": 35, "v28": 35, "v3": 35, "v4": 35, "v5": 35, "v6": 35, "v7": 35, "v8": 35, "v9": 35, "v_1": 30, "v_2": 30, "v_i": 30, "v_n": 30, "vacat": 33, "vaccin": 47, "vader": 47, "vader_lexicon": 47, "vader_senti": 47, "vain": 34, "val": [42, 46], "valenc": [30, 31, 34, 47, 53], "valid": [10, 15, 28, 30, 32, 36, 37, 38, 39, 40, 42, 44, 46, 47, 49, 52, 53, 54, 55, 56], "valid_dataload": 44, "valid_flatten": 44, "valid_load": 44, "valid_mat": 42, "valid_sample_df": 37, "valid_sample_i": 37, "valid_sample_x": 37, "valid_scor": 51, "valid_x": 42, "valu": [7, 8, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56], "valuabl": [39, 41, 57], "value_count": [28, 32, 35, 37, 38, 45, 46, 47, 54, 55, 56], "value_throttl": [30, 51], "valueerror": [8, 31, 32, 46], "values_format": [35, 54], "vancouv": 43, "vanilla": 33, "var": [29, 31, 38, 47, 53], "var_": 38, "varada": [0, 1], "vari": [28, 34, 37, 41, 46, 51, 57], "variabl": [7, 8, 28, 31, 32, 33, 34, 36, 38, 39, 45, 46, 51, 56], "varianc": [36, 38, 41, 45, 51], "variant": [38, 41], "variat": [29, 33, 35, 36, 39], "varieti": [27, 37, 43], "variou": [27, 30, 36, 38, 44, 45, 46, 49, 51, 53, 57], "vault": 29, "ve": [7, 8, 27, 29, 30, 35, 36, 38, 42, 44, 45, 48, 56], "vec": [32, 43, 44], "vec1": 43, "vec1_i": 43, "vec2": 43, "vec2_i": 43, "vec8": 32, "vec8_binari": 32, "vec_binari": 32, "vecom": 34, "vector": [15, 28, 33, 35, 42, 44, 51, 55], "verb": [43, 47], "verbos": [27, 35, 37, 38], "veri": [2, 4, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 56, 57], "verifi": 54, "versa": [36, 51, 54], "version": [4, 5, 7, 8, 11, 29, 31, 33, 34, 36, 38, 41, 43, 45, 46, 47, 48, 54, 56, 57], "versu": 9, "vert": 38, "vertic": [28, 35, 45], "vgg": 44, "vgg16": 44, "vgg16_weight": 44, "via": [1, 4, 7, 11, 35, 39, 57], "vice": [36, 51, 54], "video": [1, 7, 8, 9, 10, 11, 19, 23, 24, 25, 26, 42, 44, 46, 51, 54, 57], "vietnames": 31, "view": [6, 7, 11, 27, 28, 38, 41, 44, 45, 46], "viewpoint": 42, "vif": 38, "vikski": 43, "violat": [31, 32, 46, 57], "virginia": 44, "viridi": [34, 53], "visibl": 53, "vision": [10, 48], "visit": [8, 57], "visual": [10, 28, 29, 30, 32, 33, 35, 36, 37, 38, 40, 41, 44, 45, 46, 47, 49, 52, 53, 57], "voc": [35, 37, 38, 54], "vocab": 43, "vocabulari": [32, 33, 43], "vocabulary_": 32, "voic": 27, "volcano": 27, "vote": [30, 31, 37, 48, 55], "voting_ndt": 37, "votingclassifi": [37, 55], "votingclassifierinot": 37, "votingregressor": 37, "w": [11, 32, 33, 36, 40, 43, 45, 56, 57], "w_0": 33, "w_1": 33, "w_1x_1": 33, "w_2x_2": 33, "w_3x_3": 33, "w_4x_4": 33, "w_d": 33, "w_dx_d": 33, "w_j": 33, "wa": [4, 5, 11, 25, 28, 29, 31, 33, 35, 37, 38, 42, 43, 44, 46, 47, 48, 50, 51, 53, 56, 57], "wa_fn": 46, "wai": [0, 2, 6, 8, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 53, 54, 56, 57], "wait": [4, 27, 28, 30, 32, 46, 57], "waitlist": 57, "waiv": 57, "walk": [30, 35, 51], "walker": [27, 44], "wallabi": 44, "want": [4, 6, 7, 8, 11, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 52, 53, 54, 56, 57], "war": 42, "ward": 41, "warm": 31, "warm_start": 35, "warn": [6, 29, 30, 32, 36, 37, 38, 46, 48, 55], "warranti": 0, "washington": 47, "washroom": 57, "wast": [4, 32], "watch": [10, 11, 30, 33, 42, 43, 49], "waterfal": 38, "waterfront": [27, 28], "wavelet": 39, "wd": [36, 38], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "weak": 49, "weather": [28, 45], "weatherau": [45, 56], "web": [5, 43, 49], "weblog": 43, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "wed": [10, 45], "wednesdai": [10, 45, 57], "week": [6, 13, 14, 29, 30, 31, 32, 35, 36, 37, 38, 42, 43, 45, 54, 57], "weekdai": 45, "weekend": [8, 45], "weekli": 47, "weight": [30, 37, 39, 42, 43, 44, 54, 57], "weighted_averag": 35, "weinberg": 38, "weird": 36, "welcom": [50, 57], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 49, 53, 56, 57], "welsh": [27, 44], "went": [36, 47, 53, 55], "were": [0, 6, 32, 33, 35, 36, 44, 45, 46, 53, 55, 57], "what": [7, 8, 9, 28, 30, 34, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "whatev": 39, "when": [4, 6, 7, 11, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54, 55, 56, 57], "wher": 47, "where": [0, 7, 10, 11, 28, 29, 30, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 49, 51, 54, 56], "wherea": [2, 28, 33, 34, 36, 38, 41], "whether": [0, 4, 7, 8, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 50, 55, 56, 57], "which": [4, 6, 8, 11, 29, 30, 31, 32, 33, 34, 36, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57], "whichev": 37, "while": [28, 29, 33, 34, 35, 37, 38, 40, 42, 43, 46, 47, 53], "white": [35, 37, 38, 41, 43], "whitespac": [43, 46], "who": [4, 5, 6, 27, 35, 38, 40, 41, 45, 46, 47, 49, 57], "whole": [29, 34, 36, 38, 42, 53], "whom": [0, 47], "whose": 4, "why": [8, 29, 30, 35, 36, 37, 40, 41, 43, 45, 46, 49, 50, 51, 52, 53], "wid": 35, "wide": [11, 33, 34, 37, 39, 42, 44], "wider": [30, 51], "widespread": 43, "widget": [30, 35, 40, 41, 51], "width": [28, 29, 30, 35, 43, 50, 51], "wife": [27, 35, 37, 38], "wiki": 43, "wiki_df": 43, "wiki_dict": 43, "wikipedia": [43, 44], "wikipedia2vec": 43, "wild": [27, 29, 44], "willing": 35, "win": [30, 32, 37, 38, 39, 42, 48], "wind": 28, "winddir3pm": [45, 56], "winddir3pm_miss": [45, 56], "winddir3pm_ss": [45, 56], "winddir3pm_ssw": [45, 56], "winddir3pm_sw": [45, 56], "winddir3pm_w": [45, 56], "winddir3pm_wnw": [45, 56], "winddir3pm_wsw": [45, 56], "winddir9am": [45, 56], "windgustdir": [45, 56], "windgustspe": [45, 56], "window": [10, 46], "windsor": 47, "windspeed3pm": [45, 56], "windspeed9am": [45, 56], "wine_1": 8, "winter": 45, "winter_month": 45, "wire": 42, "wisdom": 37, "wish": [27, 28, 40, 57], "within": [28, 31, 33, 37, 39, 40, 41, 46, 49, 53], "without": [0, 7, 27, 28, 35, 37, 38, 39, 42, 44, 45, 46, 53, 57], "wnw": [45, 56], "wolv": 41, "woman": 43, "wombat": 44, "won": [5, 11, 28, 29, 30, 32, 33, 39, 42, 43, 44, 45, 46, 47], "wonder": [27, 29], "wooddecksf": [36, 38], "word": [27, 33, 34, 35, 39, 40, 41, 42, 44, 45, 46, 49, 53, 57], "word1": 43, "word2": 43, "word2vec": [43, 44, 57], "word3": 43, "word_pair": 43, "word_token": [43, 47], "wordnet": 43, "wordnetlemmat": 43, "work": [0, 4, 5, 7, 8, 11, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 53, 55, 56, 57], "work_of_art": 47, "workclass": [35, 37, 38, 54], "workclass_feder": [37, 38], "workclass_loc": [37, 38], "workclass_miss": 38, "workclass_nev": [37, 38], "workclass_priv": [37, 38], "workclass_self": 38, "workclass_st": 38, "workclass_without": 38, "workflow": [28, 57], "world": [30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 49], "worm": 44, "worri": [27, 40, 41, 42, 55], "wors": [28, 34, 36, 37, 46, 50, 53, 54], "worst": [35, 39, 40], "worth": [28, 30, 35, 36, 54], "worthi": 33, "would": [4, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57], "wouldn": [32, 34, 46], "wow": 38, "wrap": 32, "wrapper": 39, "write": [4, 7, 27, 34, 38, 39, 40, 43, 47, 51, 55, 57], "written": [7, 32, 38, 45, 56], "wrong": [11, 29, 33, 36, 39, 40, 46, 53], "wrote": [43, 45, 56], "wsw": [45, 56], "www": [9, 33], "x": [4, 8, 11, 29, 30, 31, 32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "x0": 39, "x0_male": 35, "x1": [39, 42], "x139": 57, "x1x2": 39, "x2": [39, 41, 42], "x27": [31, 32, 34, 35, 36, 37, 39, 44, 47], "x_": 33, "x_1": [33, 39, 40], "x_1x_2": 39, "x_2": [33, 39, 40], "x_binari": 28, "x_citi": 30, "x_count": 32, "x_d": 33, "x_femal": [35, 54], "x_hour": 45, "x_hour_week": 45, "x_hour_week_onehot": 45, "x_hour_week_onehot_poli": 45, "x_hour_week_onehot_poly_lag": 45, "x_i": [33, 42], "x_imp_ohe_train": 31, "x_init": 40, "x_int": 32, "x_label": [28, 29, 30, 50], "x_lag_featur": 45, "x_lag_features_imp": 45, "x_male": [35, 54], "x_mask": 32, "x_multi": 48, "x_n": 39, "x_orig": 41, "x_re": 35, "x_small_citi": 30, "x_spotifi": [30, 34, 53], "x_subset": [28, 29], "x_test": [27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55], "x_test_big": 34, "x_test_enc": [38, 45, 46, 56], "x_test_happi": 35, "x_test_imp": 31, "x_test_multi": 48, "x_test_pr": 45, "x_test_predict": 31, "x_test_scal": 31, "x_test_transform": 31, "x_toi": [30, 31, 32, 45], "x_toy_oh": 31, "x_toy_ord": [31, 32], "x_tr": 51, "x_train": [27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55], "x_train_big": [35, 54], "x_train_enc": [35, 36, 38, 45, 46, 54, 56], "x_train_happi": 35, "x_train_hous": 39, "x_train_imp": 31, "x_train_imp_sc": 31, "x_train_multi": 48, "x_train_oversampl": 35, "x_train_perm": 38, "x_train_pp": 32, "x_train_predict": 31, "x_train_scal": [31, 39], "x_train_subsampl": 35, "x_train_tini": 34, "x_train_transform": 31, "x_train_usr": 42, "x_transform": 32, "x_valid": [35, 42, 51, 54], "x_vari": 41, "x_xor": 39, "xanni": 34, "xavier": [39, 42], "xcode": 5, "xgbclassifi": [37, 38], "xgbclassifierxgbclassifi": 37, "xgboost": 38, "xgbregressor": [27, 37], "xia": 57, "xlabel": [8, 28, 29, 30, 33, 34, 35, 36, 38, 41, 44, 45, 46, 48, 50, 53, 56], "xlim": 46, "xor": [33, 39], "xt": 32, "xtick": [29, 35, 45, 56], "xticklabel": [34, 53], "xticks_rot": 35, "xwm\u0259\u03b8kw\u0259y": 57, "xx": [39, 40], "y": [8, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 54, 56], "y_": 42, "y_citi": 30, "y_femal": [35, 54], "y_hat": [33, 37], "y_i": [36, 37, 39, 42], "y_init": 40, "y_label": [28, 29, 30, 50], "y_male": [35, 54], "y_mat": 42, "y_multi": 48, "y_pred": [35, 45], "y_pred_lower_threshold": 35, "y_pred_toi": 35, "y_pred_train": 45, "y_re": 35, "y_small_citi": 30, "y_spotifi": [34, 53], "y_test": [27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56], "y_test_big": 34, "y_test_happi": 35, "y_test_multi": 48, "y_test_num": [37, 38], "y_toi": [30, 45], "y_tr": 51, "y_train": [27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56], "y_train_big": [35, 54], "y_train_happi": 35, "y_train_hous": 39, "y_train_multi": 48, "y_train_num": [37, 38], "y_train_ord": [45, 56], "y_train_oversampl": 35, "y_train_subsampl": 35, "y_train_tini": 34, "y_train_usr": 42, "y_true_toi": 35, "y_valid": [35, 42, 44, 51, 54], "y_vari": 41, "y_xor": 39, "yale": 43, "yann": 38, "ycxmx": 46, "ye": [4, 27, 28, 31, 32, 38, 40, 41, 42, 44, 45, 47, 49, 56], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 42, 43, 44, 45, 46], "yearbuilt": [36, 38], "yearremodadd": [36, 38], "yellow": 34, "yellowbrick": [40, 41], "yesterdai": [45, 56], "yet": [10, 11, 33, 38, 42, 45, 46, 51, 57], "yield": 53, "yifei": 57, "yjh": [27, 28, 32, 33, 36, 37], "ylabel": [8, 28, 29, 30, 33, 34, 35, 36, 41, 44, 45, 46, 48, 50, 51, 53, 56], "ylim": 46, "yml": 11, "yolo": 44, "yolo8": 44, "yolo_input": 44, "yolo_result": 44, "yolo_test": 44, "yolov8n": 44, "york": [45, 47], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 38, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "your": [0, 2, 4, 6, 7, 8, 10, 11, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "your_miniconda_path": 47, "your_nam": 11, "yourself": [4, 32, 35, 42, 57], "youtub": [1, 10, 42, 43, 57], "yr_built": [27, 28], "yr_renov": [27, 28], "yrpxn": 46, "yrsold": [36, 38], "ytick": [29, 35], "yticklabel": [34, 53], "yy": [39, 45, 56], "yyyi": [45, 56], "z": [8, 33, 39, 40, 41, 42, 44, 46], "z_i": 44, "z_j": 44, "z_km": 40, "z_train": 44, "z_valid": 44, "zachari": 46, "zarei": 57, "zero": [8, 29, 32, 34, 42, 43], "zero_divis": 35, "zhu": 57, "zip": [30, 33, 42, 51], "zipcod": [27, 28, 51], "zmqshell": 47, "zone": [45, 56], "zoom": [7, 53, 57], "\u0259m": 57, "\u03bc": 48}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Class Meeting 4B", "Class Meeting 4C", "Class Meeting 5A", "Class Meeting 5B", "Class Meeting 5C", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [27, 29, 30, 31, 32, 35, 36, 38, 45], "0": 37, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56], "10": [18, 36, 55], "11": [20, 37], "12": [21, 37, 38], "13": [22, 39], "14": [23, 39, 40], "15": [23, 40, 41], "16": [24, 41, 42], "17": [24, 42, 43], "18": [26, 44], "19": [26, 44, 45], "1a": 13, "1b": 14, "1c": 15, "2": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 46, 49, 50, 51, 52, 53, 54, 55, 56], "20": 46, "2025s1": 1, "21": 46, "2a": 16, "2b": 17, "3": [15, 27, 28, 29, 31, 39, 40, 41, 46, 50, 51, 52, 53, 54, 55, 56], "330": [1, 2, 3, 6, 8], "340": 2, "3a": 18, "3b": 19, "3c": 20, "4": [15, 28, 29, 30, 50, 51, 52, 53, 54, 55, 56], "4a": 21, "4b": 22, "4c": 23, "5": [8, 16, 28, 29, 30, 31, 32, 35, 38, 39, 40, 43, 44, 46, 51, 52, 53, 54, 55, 56], "5a": 24, "5b": 25, "5c": 26, "6": [16, 32, 51, 53, 54, 55, 56], "7": [17, 33, 53, 55, 56], "8": [17, 34, 53, 55], "9": [18, 35, 55], "A": [4, 35, 41, 45, 47], "No": 8, "Not": 49, "One": [31, 45, 48], "The": [29, 33, 34, 37, 39, 40, 55], "__": 34, "about": [8, 39, 42], "academ": 57, "access": [7, 33, 57], "accommod": 57, "acknowledg": 57, "activ": [35, 38, 39, 40, 43, 54], "actual": 32, "ad": 8, "addit": [7, 38], "address": 35, "advantag": 34, "advic": 39, "ai": 57, "algorithm": [28, 30, 39, 40], "all": [27, 28, 31, 33, 35, 40, 41, 42], "alpha": [33, 36], "altern": [28, 31], "an": [37, 47], "analogi": 30, "analysi": [45, 46, 49, 51, 56], "announc": [28, 30, 32, 33, 37], "answer": 46, "ap": 35, "api": 31, "appendix": [47, 48], "appli": [1, 8, 31, 32, 36], "applic": 40, "applymap": 8, "approach": [42, 45, 46, 48], "approxim": 29, "ar": [5, 27, 28, 31, 33, 35, 40, 41, 42], "area": 35, "argument": [29, 30], "arrai": 8, "articl": 9, "ask": 4, "assign": [7, 57], "associ": 33, "assum": 46, "attent": [28, 30], "attribut": 38, "auc": 35, "autom": 34, "averag": [35, 37, 42, 55], "avoid": 29, "b": [40, 48], "backward": 39, "bad": 34, "bag": [32, 47], "balanc": 35, "base": [30, 37, 39, 42, 45, 56], "baselin": [28, 31, 35, 37, 38, 42, 51], "basic": 43, "befor": 31, "best": 39, "better": [29, 34, 35, 39], "between": [28, 30, 50], "beyond": [38, 42], "bia": [29, 34], "big": [28, 29, 31], "binari": 35, "book": 10, "boost": 37, "bootstrap": 37, "boundari": [28, 30, 33, 50], "bow": 32, "box": 44, "break": [8, 28, 29, 30, 31, 32, 39, 43, 44, 46], "broadcast": 8, "build": [27, 28, 36, 42], "c": [30, 34], "calcul": 33, "california": [32, 33, 52], "can": [8, 29, 31, 37, 38, 39, 40], "canada": [28, 50], "care": 42, "carri": [31, 39], "case": [32, 33, 41], "catboost": 37, "categor": [31, 32, 38, 45], "categori": 32, "censor": 46, "centr": 57, "certain": 32, "cfa": 57, "chang": 35, "charact": 27, "characterist": 35, "cheatsheet": 8, "choos": [30, 40], "churn": 46, "cite": 7, "citi": 33, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36, 37, 38, 42, 44, 48, 57], "class_attend": 32, "class_weight": 35, "classif": [28, 35, 44, 49], "classifi": [28, 33, 37, 47], "clearli": 39, "cluster": [40, 41, 49], "co": 57, "code": [11, 57], "coeffici": [33, 38], "color": [50, 51, 52, 53, 54, 55, 56], "column": [8, 31, 32, 45], "columntransform": [32, 52], "combin": 37, "come": [29, 30], "command": 5, "comment": [28, 34, 35, 36, 40, 41, 42], "common": [31, 40], "commonli": 43, "commun": 49, "compact": 31, "companion": 9, "complet": 42, "complex": 29, "complic": [45, 56], "compon": 33, "comprehens": 52, "comput": [44, 49], "con": [30, 41, 49], "concern": 6, "concess": 57, "conda": 11, "conduct": 57, "confid": 33, "confus": 35, "consid": 46, "construct": 37, "content": 42, "context": 43, "continu": 28, "conveni": 32, "correct": 40, "correl": 38, "countri": [28, 50], "countvector": 32, "cours": [9, 10, 27, 57], "cover": [42, 46], "cox": 46, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 28, 29, 32, 42], "credit": [11, 57], "cross": [29, 31, 35, 39, 45, 51], "cross_val_scor": 29, "cross_valid": [29, 36], "csv": 8, "curs": 30, "curv": [35, 46], "custom": [40, 46], "cv": 34, "dai": 45, "data": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 51, 56], "datafram": [8, 32], "dataset": [7, 28, 31, 32, 33, 34, 35, 36, 44, 45, 52, 55, 56], "date": [10, 45], "datetim": [45, 56], "dbscan": 41, "deal": [32, 35], "debug": 11, "decis": [28, 30, 33, 38, 51], "decisiontreeclassifi": [28, 37], "decreas": 35, "deep": [44, 45], "defin": 39, "definit": 27, "deliver": 10, "demo": [39, 45, 47], "demonstr": 35, "dendrogram": 41, "depend": 39, "deploy": [29, 49], "descript": 57, "desktop": 5, "detail": [35, 36, 41], "detect": 44, "df": 8, "did": [29, 31, 32, 35, 36, 42, 46], "differ": [31, 34, 35, 36, 38, 49], "dimens": 30, "dimension": 30, "discuss": [34, 35, 42, 43, 54], "diseas": 27, "distanc": [30, 40], "distribut": 34, "do": [31, 32, 34, 35, 37, 38, 39], "document": [3, 8, 40], "doe": [28, 33, 41], "domain": 39, "drop": 8, "due": 10, "dummi": 47, "dummyclassifi": [28, 37, 45, 46], "dummyregressor": [28, 31, 36], "eda": [31, 35, 36, 51], "effect": 37, "elbow": 40, "element": 8, "elimin": 39, "embed": 43, "encod": [31, 32, 39, 45], "engin": [39, 45, 47, 49], "ensembl": [37, 49], "environ": 11, "error": [29, 34, 35, 36, 42], "estim": [31, 37], "ethic": 49, "euclidean": 30, "eva": [27, 29], "evalu": [35, 41, 42, 46, 49, 54], "evalut": 35, "event": 46, "everyon": 46, "exactli": 33, "exam": [49, 57], "examin": [32, 36, 49], "exampl": [27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 43, 46, 47], "exercis": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 42, 44, 46, 50], "exhaust": 34, "explain": 38, "explan": 38, "explor": [30, 40], "exploratori": [45, 51, 56], "extract": [32, 45], "extractor": 44, "f1": 35, "failur": 41, "fair": [35, 54], "fancier": 34, "faster": 8, "fastest": 8, "featur": [27, 28, 30, 31, 32, 33, 36, 38, 39, 42, 44, 45, 47, 49, 56], "feature_importances_": 38, "few": [35, 41], "fictiti": 27, "figur": 7, "filter": [8, 42], "final": [28, 34, 40, 41, 42, 45, 49, 51, 57], "find": [30, 39], "first": 31, "fit": [28, 31, 37], "flatten": 44, "follow": [27, 28, 29, 40, 41, 42], "font": [50, 51, 52, 53, 54, 55, 56], "forecast": 45, "forest": [37, 38], "format": [7, 8], "formul": 42, "forum": 4, "forward": 39, "from": [8, 47], "function": [8, 33, 36], "fundament": [29, 30, 37, 49], "further": [45, 47], "futur": 45, "gamma": 30, "garbag": 39, "gener": [4, 6, 29, 30, 33, 37, 39], "geometr": 30, "get": 38, "git": [5, 11], "github": 5, "given": [27, 28], "global": 42, "goal": 29, "golden": [29, 31, 32], "good": 35, "grade": [4, 6, 28, 57], "gradescop": 7, "gradient": 37, "grid": 34, "gridsearchcv": [34, 36], "group": [35, 40, 54], "guid": 49, "guidelin": [4, 6, 7], "ha": 27, "halv": 34, "handl": 35, "have": [37, 38], "hazard": 46, "heatmap": 34, "help": [4, 39], "here": 29, "hierarch": 41, "home": 41, "homework": 7, "hot": [31, 39, 45], "hous": [27, 28, 31, 32, 33, 52], "how": [4, 7, 28, 29, 30, 31, 33, 37, 38, 39, 41], "hyper": 34, "hyperparamet": [28, 30, 32, 33, 34, 36, 37, 40, 49, 51], "i": [27, 29, 31, 32, 34, 35, 37, 38, 39, 40, 42, 43, 47], "iclick": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 57], "idea": [30, 35, 37, 39], "identifi": [32, 38], "imag": [27, 44], "imagenet": 44, "imbal": [35, 36, 37, 38], "import": [1, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 56], "improv": 47, "imput": [31, 42], "incorpor": 32, "increas": 35, "index": 8, "inertia": 40, "info": 7, "inform": [38, 45], "initi": 40, "inject": 37, "input": [27, 40], "instal": [5, 11], "instruct": [0, 7], "interact": 39, "intercept": 33, "interim": [35, 38, 39, 45], "interpret": [33, 38], "intra": 40, "intro": 42, "introduct": [8, 27, 38, 39, 40, 41, 43, 44, 49], "intuit": 33, "involv": 45, "jupyterlab": 11, "k": [30, 31, 40, 41, 42], "kaplan": 46, "kei": 38, "kernel": 30, "kind": 37, "kneighborsclassifi": 30, "label": [27, 40], "lag": [45, 56], "land": 57, "languag": 43, "larg": 34, "late": 7, "latitud": [28, 50], "lda": 43, "learn": [1, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 57], "least": 33, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 57], "lecture03": 15, "let": [30, 31, 32, 35, 36, 38], "licens": [0, 1], "lightgbm": 37, "limit": [6, 33, 41], "line": 5, "linear": [33, 36, 38], "link": 1, "list": 9, "liver": 27, "ll": 29, "lo": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 44, 45], "logist": [33, 35, 44], "logisticregress": [35, 45, 46], "longitud": [28, 50], "look": [35, 40], "loop": 8, "lower": 34, "mac": 5, "machin": [1, 27, 28, 29, 30, 35, 40], "maco": 11, "macro": 35, "magnitud": 33, "mai": 39, "main": [33, 42], "make": [8, 33], "make_column_transform": 32, "make_pipelin": 31, "mani": [32, 34], "manual": 34, "mape": 36, "materi": [0, 9, 10], "matplotlib": 8, "matric": 32, "matrix": [35, 42], "max_depth": 28, "mean": [36, 40, 41, 43], "measur": 39, "media": 43, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 57], "meier": 46, "messag": [27, 41], "meta": 48, "method": [8, 34, 39, 40], "metric": [35, 36, 49], "midterm": [40, 57], "might": 46, "min": [8, 28, 29, 30, 31, 32, 35, 38, 39, 40, 43, 44, 46], "minor": 35, "misc": [9, 10], "miscellan": 42, "ml": [27, 29, 30, 35, 38, 49, 54], "model": [27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 43, 44, 46, 47, 49, 51, 54], "model_select": 34, "month": 45, "more": [28, 30, 31, 32, 33, 35, 36, 39, 41, 45, 56], "most": 33, "motiv": [29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45], "movi": 42, "mse": 36, "much": 34, "multi": [35, 44, 48], "multiclass": 49, "multipl": [30, 32, 36], "multipli": 8, "n_estim": 37, "n_iter": 34, "n_job": 34, "n_neighbor": 30, "name": [29, 36, 42], "natur": 43, "nearest": [30, 31, 40, 42], "need": [31, 34], "neg": 35, "neighbour": [30, 31, 42], "nest": 8, "netflix": 37, "network": 44, "neural": 44, "nlp": [43, 49], "nn": 30, "non": [30, 32, 38], "notat": 8, "note": [8, 29, 45, 51], "now": 46, "number": [37, 40, 45], "numer": [38, 39], "numpi": 8, "object": [28, 37, 43, 44, 45, 46, 57], "observ": 35, "occasion": 31, "off": [29, 30, 37], "oh": [31, 32], "ok": [31, 32], "onc": 35, "one": [32, 39], "onehotencod": 32, "onli": [32, 46], "onlin": [9, 10], "oper": 35, "optim": [34, 49], "option": [11, 30, 31, 34, 35, 37, 39, 46], "ordin": [31, 32, 38, 57], "other": [8, 30, 36, 39, 40, 43, 45, 46], "our": [7, 29, 31, 47], "out": [31, 39, 44], "outcom": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42], "outlin": [50, 51, 52, 53, 54, 55, 56], "output": 40, "over": [8, 30, 33, 35], "overfit": [29, 34], "oversampl": 35, "overview": [30, 35], "ovo": 48, "ovr": 48, "packag": [11, 45], "panda": 8, "pandas_profil": 36, "paper": [35, 37], "paradigm": 31, "paramet": [28, 33, 34, 35, 49], "parametr": 30, "pars": [45, 56], "part": 49, "pass": [34, 57], "patient": 27, "perfect": 40, "permutation_import": 38, "persona": 27, "pick": [29, 34], "pictur": [28, 29, 31], "pipelin": [31, 43], "plan": 41, "playground": [30, 51], "plot": [8, 38, 40, 46], "point": [30, 35, 38, 40, 45], "polici": 6, "poll": 40, "popular": 27, "posit": 35, "posix": 45, "possibl": [32, 36, 40, 47], "post": 9, "pr": 35, "practic": [28, 30], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 22, 44], "precis": 35, "predict": [27, 28, 32, 33, 37, 38, 42, 44, 46, 48, 50], "predict_proba": 33, "prepar": [7, 49], "preprocess": [31, 32, 36, 43, 45, 49, 54, 56], "preval": 27, "price": [27, 28], "prize": 37, "pro": [30, 41, 49], "probabl": [33, 34], "problem": [28, 29, 30, 31, 34, 39, 42, 45, 47], "procedur": 35, "process": 43, "product": 27, "profil": 42, "program": 28, "project": 47, "proport": 46, "python": [8, 9, 11], "q": 4, "qualiti": 39, "queri": [8, 30], "question": [4, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56], "quick": 30, "quiz": 28, "quiz2": 28, "quot": 39, "r": 36, "random": [34, 37, 38], "random_st": 29, "randomforestclassifi": [37, 46], "randomizedsearchcv": [34, 36], "rang": 34, "rate": 42, "raw": 33, "rbf": 30, "read": [8, 28, 34, 44], "real": [28, 50], "realist": 32, "reason": 6, "recal": 35, "recap": [28, 30, 41, 46, 50, 52], "receiv": 35, "recommend": [31, 42, 49], "record": 57, "recurs": 39, "red": [50, 51, 52, 53, 54, 55, 56], "refer": [9, 10, 46], "reflect": [28, 29, 40, 41], "registr": 57, "regress": [28, 30, 33, 35, 36, 37, 44], "regressor": 30, "relat": [4, 28, 30], "relev": [9, 35, 37, 39], "remark": 45, "rememb": 40, "remind": [28, 42], "remov": 8, "renam": 8, "report": [7, 35], "repositori": 7, "represent": [32, 44], "requir": 57, "rescu": 29, "resourc": [9, 34, 35, 39, 40, 41, 42], "rest": 48, "result": 34, "retail": 45, "review": 19, "rfe": 39, "ridg": [33, 36], "ridgecv": 36, "right": 46, "rmse": 36, "roc": 35, "root": 36, "row": 8, "rule": [29, 31, 32], "run": 31, "same": 8, "sampl": [35, 37, 40], "sauc": 40, "save": 27, "scale": [27, 31, 33, 38], "schedul": [10, 57], "scheme": 57, "scikit": [29, 31, 32, 36], "score": [28, 29, 33, 34, 35, 36, 39, 40, 47], "search": [30, 34, 39], "season": 45, "segment": 40, "select": [27, 28, 39, 40, 41, 42, 49], "separ": [36, 38], "seri": [8, 45, 49, 56], "set": [5, 11, 29, 34, 35], "set_config": 32, "shap": 38, "shape": [8, 41], "shaplei": 38, "short": 9, "should": [37, 42], "show": 38, "sigmoid": [33, 44], "sign": 33, "silhouett": 40, "similar": 30, "simpl": [29, 47], "simplefeatur": 38, "simul": 55, "singl": 29, "size": 8, "sklearn": [28, 31, 32, 34, 35, 37, 38], "slide": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26], "slowest": 8, "smote": 35, "social": 43, "softmax": 44, "softwar": [0, 44, 45], "solv": 34, "some": [28, 34, 35, 37, 39], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 45, "spaci": [43, 47], "spaghetti": 40, "spam": [27, 32], "spars": 32, "specif": [4, 39], "split": [29, 31, 35, 45, 51], "spotifi": [31, 34], "squar": 36, "stack": [37, 55], "standardscal": 31, "statement": [27, 28, 40, 41, 42], "step": [28, 43, 52], "strategi": [37, 48], "stratifi": 35, "strength": [33, 37], "studi": 49, "submiss": 7, "submit": 7, "success": 34, "summari": [8, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "summer": 10, "supervis": [27, 28, 29, 30, 40, 42], "support": 30, "surviv": [46, 49], "svc": 35, "svm": [30, 33], "syllabu": [1, 57], "syntax": [31, 32, 34], "synthet": 35, "system": [42, 49], "ta": 57, "tabular": [28, 30], "tackl": 36, "take": 41, "target": [27, 28, 32, 36, 40], "task": 43, "teach": [10, 57], "team": 57, "techniqu": [31, 35], "templat": 7, "tempor": 45, "ten": 10, "tent": 10, "terminologi": [28, 44], "test": [5, 29, 34, 45], "test_df": 29, "test_siz": 29, "text": [32, 43, 47], "than": [32, 34, 39], "thei": 37, "them": 8, "thi": [8, 27, 31, 32, 38], "thing": 31, "threshold": 35, "time": [6, 27, 45, 46, 49, 56], "tip": 49, "todai": [29, 31, 32, 35, 36], "toi": [28, 32, 35, 43], "token": 43, "tool": 43, "topic": 43, "trade": [29, 30, 37], "tradeoff": [29, 35, 37], "tradit": [28, 45], "train": [27, 28, 29, 32, 33, 35, 44, 45, 54], "train_df": 29, "train_siz": 29, "transfer": 44, "transform": [31, 32, 36, 39], "transpar": 38, "tree": [28, 37, 38, 51], "trend": 45, "true": [27, 40, 41, 42], "try": [31, 36], "tune": [36, 40, 51], "tutori": [50, 51, 52, 53, 54, 55, 56], "two": 32, "type": [27, 29, 35, 36, 38, 40, 45, 46], "typic": [29, 43], "ubc": 1, "ubuntu": 5, "under": 35, "underfit": 29, "undersampl": 35, "unequ": 45, "unknown": 32, "unlabel": 40, "unseen": [27, 29], "unsupervis": [28, 40], "up": [5, 11, 29, 30], "updat": 7, "url": 8, "us": [7, 8, 27, 28, 29, 30, 31, 32, 35, 36, 37, 39, 40, 43, 44, 48, 50, 57], "usa": [28, 50], "user": [5, 42], "usual": 39, "util": 42, "v": [2, 28, 29, 30, 35, 38, 40, 44, 48], "valid": [29, 31, 34, 35, 45, 51], "varianc": 29, "vector": [8, 30, 43], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 27, 28, 29, 30, 31, 33, 35, 36, 37, 40, 41, 43], "view": [30, 32], "violat": 29, "virtual": 11, "vision": [44, 49], "visual": [9, 34], "wai": [34, 39], "want": [32, 38, 46], "warn": [28, 39], "we": [8, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 46], "weak": 37, "weight": [33, 35], "what": [5, 11, 27, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 46], "when": [8, 31, 34], "where": [32, 46], "whether": 27, "which": [27, 28, 35, 37, 40, 41, 42], "why": [11, 27, 32, 34, 38, 39, 42, 44], "window": [5, 11], "wise": 8, "without": 40, "word": [32, 43, 47], "work": [28, 37, 41], "workflow": [27, 29, 35], "would": 29, "wrapper": 48, "write": 28, "x": [27, 28, 36, 38], "xgboost": 37, "y": [27, 28, 36, 38], "ye": 46, "yield": 34, "you": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 46], "your": [5, 28]}})