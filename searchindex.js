Search.setIndex({"alltitles": {"(Optional) Changing the data": [[33, "optional-changing-the-data"]], "(Optional) Evaluation": [[44, "optional-evaluation"]], "(Optional) Evaluation metrics for multi-class classification": [[33, "optional-evaluation-metrics-for-multi-class-classification"]], "(Optional) Example 1: Optimization bias": [[32, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[32, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[32, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[35, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[37, "optional-forward-or-backward-selection"]], "(Optional) Macro average and weighted average": [[33, "optional-macro-average-and-weighted-average"]], "(Optional) Parametric vs non parametric": [[28, "optional-parametric-vs-non-parametric"]], "(Optional) Passing probability distributions to random search": [[32, "optional-passing-probability-distributions-to-random-search"]], "(Optional) Prediction in boosted regression trees": [[35, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[37, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[37, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[32, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Some more details": [[33, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[25, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[37, "id1"]], "(iClicker) Exercise 21.1": [[44, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[44, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[28, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[28, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[29, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[29, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[29, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[30, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[30, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[31, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[31, "iclicker-exercise-7-2"]], "(iClicker) Exercise 8.1": [[32, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[38, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[38, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[38, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[38, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[39, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[39, "id2"]], "16.3 Select all of the following statements which are True": [[39, "select-all-of-the-following-statements-which-are-true"]], "<font color='red'>Question 10</font>": [[53, "question-10"]], "<font color='red'>Question 1</font>": [[48, "question-1"], [49, "question-1"], [51, "question-1"], [52, "question-1"], [53, "question-1"], [54, "question-1"]], "<font color='red'>Question 2: Baseline model</font>": [[49, "question-2-baseline-model"]], "<font color='red'>Question 2</font>": [[48, "question-2"], [51, "question-2"], [52, "question-2"], [53, "question-2"], [54, "question-2"]], "<font color='red'>Question 3: Decision tree</font>": [[49, "question-3-decision-tree"]], "<font color='red'>Question 3</font>": [[48, "question-3"], [51, "question-3"], [52, "question-3"], [53, "question-3"], [54, "question-3"]], "<font color='red'>Question 4: Hyperparameter tuning</font>": [[49, "question-4-hyperparameter-tuning"]], "<font color='red'>Question 4</font>": [[48, "question-4"], [51, "question-4"], [52, "question-4"], [53, "question-4"], [54, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[49, "question-5-cross-validation"]], "<font color='red'>Question 5</font>": [[51, "question-5"], [52, "question-5"], [53, "question-5"], [54, "question-5"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[49, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[51, "question-6"], [52, "question-6"], [53, "question-6"], [54, "question-6"]], "<font color='red'>Question 7</font>": [[51, "question-7"], [53, "question-7"]], "<font color='red'>Question 8</font>": [[51, "question-8"], [53, "question-8"]], "<font color='red'>Question 9</font>": [[53, "question-9"]], "<font color='red'>Recap Questions</font>": [[48, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[50, "recap-comprehension-questions"]], "A few comments on PR curve": [[33, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[39, "a-few-comments-on-clustering-evaluation"]], "AP score": [[33, "ap-score"]], "AP vs. F1-score": [[33, "ap-vs-f1-score"]], "About this document": [[8, "about-this-document"]], "Academic concessions": [[55, "academic-concessions"]], "Accessing homework assignments": [[7, "accessing-homework-assignments"]], "Accessing learned parameters": [[31, "accessing-learned-parameters"]], "Activity (~5 mins)": [[36, "activity-5-mins"], [36, "id3"]], "Activity: Context and word meaning": [[41, "activity-context-and-word-meaning"]], "Activity: How can you measure quality of the data? (~3 mins)": [[37, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Adding/removing columns with [] and drop()": [[8, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[8, "adding-removing-rows-with-and-drop"]], "Additional submission instructions": [[7, "additional-submission-instructions"]], "Addressing class imbalance": [[33, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[32, "advantages-of-randomizedsearchcv"], [32, "id1"]], "Alternative and more compact syntax: make_pipeline": [[29, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative terminology for examples, features, targets, and training": [[26, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[35, "an-effective-strategy"]], "An example from a project": [[45, "an-example-from-a-project"]], "An example of a bootstrap samples": [[35, "an-example-of-a-bootstrap-samples"]], "Analogy-based algorithms in practice": [[28, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[28, "analogy-based-models"]], "Announcements": [[31, "announcements"]], "Appendix A: Demo of feature engineering for text data": [[45, null]], "Appendix B: Multi-class, meta-strategies": [[46, null]], "Applying feature transformations": [[34, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[8, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[44, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[44, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[44, "approach-3-survival-analysis"]], "Are we doing better with class_weight=\"balanced\"?": [[33, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[33, "area-under-the-curve-auc"]], "Assignments": [[55, "assignments"]], "Attention": [[26, null], [26, null], [26, null], [28, null]], "Automated hyperparameter optimization": [[32, "automated-hyperparameter-optimization"], [32, "id3"]], "Averaging": [[35, "averaging"]], "Averaging simulation": [[53, "averaging-simulation"]], "Bad range for hyperparameters": [[32, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[30, "bag-of-words-bow-representation"]], "Bag-of-words model": [[45, "bag-of-words-model"]], "Baseline": [[33, "baseline"], [36, "baseline"]], "Baseline Approaches": [[40, "baseline-approaches"]], "Baselines": [[26, "baselines"], [35, "baselines"]], "Baselines [video]": [[26, "baselines-video"]], "Basic text preprocessing [video]": [[41, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[37, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[40, "beyond-error-rate-in-recommendation-systems"]], "Bias vs variance tradeoff": [[27, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[26, "big-picture-and-datasets"]], "Big picture and motivation": [[27, "big-picture-and-motivation"]], "Books": [[10, "books"]], "Break (5 min)": [[8, "break-5-min"], [26, "break-5-min"], [27, "break-5-min"], [28, "break-5-min"], [29, "break-5-min"], [30, "break-5-min"], [37, "break-5-min"], [41, "break-5-min"], [42, "break-5-min"], [44, "break-5-min"]], "Broadcasting in numpy": [[8, "broadcasting-in-numpy"]], "Building a supervise machine learning model": [[25, "building-a-supervise-machine-learning-model"]], "Building decision trees with sklearn": [[26, "building-decision-trees-with-sklearn"]], "Building user profiles": [[40, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[8, null]], "CPSC 330 grading policies": [[6, null]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can we learn without targets?": [[38, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[29, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[30, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[35, "catboost"]], "Categorical features": [[36, "categorical-features"]], "Categorical features [video]": [[29, "categorical-features-video"]], "Categorical features with only two possible categories": [[30, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[44, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[55, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[33, "changing-the-training-procedure"]], "Characters in this course?": [[25, "characters-in-this-course"]], "Choosing K [video]": [[38, "choosing-k-video"]], "Choosing n_neighbors": [[28, "choosing-n-neighbors"]], "Citing sources": [[7, "citing-sources"]], "Class Meeting 1A": [[13, null]], "Class Meeting 1B": [[14, null]], "Class Meeting 1C": [[15, null]], "Class Meeting 2A": [[16, null]], "Class Meeting 2B": [[17, null]], "Class Meeting 3A": [[18, null]], "Class Meeting 3B - Review": [[19, null]], "Class Meeting 3C": [[20, null]], "Class Meeting 4A": [[21, null]], "Class Meeting 4B": [[22, null]], "Class Meeting 4C": [[23, null]], "Class Meeting 5A": [[24, null]], "Class Slides": [[13, "class-slides"], [14, "class-slides"], [15, "class-slides"], [16, "class-slides"], [17, "class-slides"], [18, "class-slides"], [20, "class-slides"], [21, "class-slides"], [22, "class-slides"], [23, "class-slides"], [24, "class-slides"]], "Class imbalance in training sets": [[33, "class-imbalance-in-training-sets"]], "Class meetings": [[55, "class-meetings"]], "Classification report": [[33, "classification-report"]], "Classification vs. Regression": [[26, "classification-vs-regression"]], "Clustering": [[47, "clustering"]], "Clustering Activity (~5 mins)": [[38, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[38, "clustering-motivation-video"]], "Clustering: Input and (possible) output": [[38, "clustering-input-and-possible-output"]], "Code of conduct": [[55, "code-of-conduct"]], "Coefficients and intercept": [[31, "coefficients-and-intercept"]], "ColumnTransformer example": [[30, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[30, "columntransformer-on-the-california-housing-dataset"], [50, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[30, "columntransformer-transformed-data"]], "Coming up \u2026": [[27, "coming-up"]], "Coming up:": [[28, "coming-up"]], "Command-line git": [[5, "command-line-git"]], "Common applications": [[38, "common-applications"]], "Common preprocessing techniques": [[29, "common-preprocessing-techniques"]], "Communication": [[47, "communication"]], "Completing the utility matrix with content-based filtering": [[40, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[31, "components-of-a-linear-classifier"]], "Confusion matrix (video)": [[33, "confusion-matrix-video"]], "Confusion matrix with cross-validation": [[33, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[28, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[40, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[30, "convenient-make-column-transformer-syntax"]], "Course Learning Objectives": [[55, "course-learning-objectives"]], "Course co-ordinator": [[55, "course-co-ordinator"]], "Course description": [[55, "course-description"]], "Cox proportional hazards model": [[44, "cox-proportional-hazards-model"]], "Create X and y": [[26, "create-x-and-y"]], "Create a classifier object": [[26, "create-a-classifier-object"]], "Create a column transformer": [[30, "create-a-column-transformer"]], "Creating train_df and test_df": [[27, "creating-train-df-and-test-df"]], "Creating utility matrix": [[40, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[33, "cross-validation-with-different-metrics"]], "Cross-validation": [[43, "cross-validation"], [43, "id4"]], "Cross-validation [video]": [[27, "cross-validation-video"]], "Cross-validation to the rescue!!": [[27, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[27, "cross-validation-using-scikit-learn"]], "Curse of dimensionality": [[28, "curse-of-dimensionality"]], "Customer churn": [[44, "customer-churn"]], "Customer segmentation": [[38, "customer-segmentation"]], "DBSCAN [video]": [[39, "dbscan-video"]], "DBSCAN introduction": [[39, "dbscan-introduction"]], "DBSCAN: failure cases": [[39, "dbscan-failure-cases"], [39, "id1"]], "Data": [[30, "data"], [31, "data"], [35, "data"], [36, "data"], [36, "id1"]], "Data Splitting [video]": [[27, "data-splitting-video"]], "Data and main approaches": [[40, "data-and-main-approaches"]], "Data exploration": [[38, "data-exploration"]], "Data splitting": [[49, "data-splitting"]], "Dataframe summaries": [[8, "dataframe-summaries"]], "Dataset": [[42, "dataset"]], "Dataset [video]": [[34, "dataset-video"]], "Dataset for demonstration": [[33, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[29, "dataset-splitting-and-baseline"]], "Datasets": [[7, "datasets"]], "Dealing with class imbalance (video)": [[33, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[30, "dealing-with-unknown-categories"]], "Debugging": [[11, "debugging"]], "Decision boundary": [[26, "decision-boundary"]], "Decision boundary for max_depth=1": [[26, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[26, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[26, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[28, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[31, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[26, "decision-tree-algorithm"]], "Decision tree feature importances": [[36, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[26, "decision-tree-for-regression-problems"]], "Decision tree with max_depth=1": [[26, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[26, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[26, "decision-trees-video"]], "Decision trees with continuous features": [[26, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[35, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[26, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decreasing the threshold": [[33, "decreasing-the-threshold"]], "Deep learning": [[43, "deep-learning"]], "Deep learning software": [[42, "deep-learning-software"]], "Deliverable due dates (tentative)": [[10, "deliverable-due-dates-tentative"]], "Demo of feature engineering with numeric features": [[37, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[43, "demo-a-more-complicated-dataset"]], "Dendrogram": [[39, "dendrogram"]], "Deployment (Not examinable)": [[47, "deployment-not-examinable"]], "Different models": [[36, "different-models"]], "Different range for hyperparameters yields better results!": [[32, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[34, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[28, "dimensions-in-ml-problems"]], "Discussion question": [[41, "discussion-question"]], "Distance between feature vectors": [[28, "distance-between-feature-vectors"]], "Do we actually want to use certain features for prediction?": [[30, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[35, "do-we-have-class-imbalance"], [36, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[36, "do-we-have-correlated-features"]], "Document clustering": [[38, "document-clustering"]], "Domain-specific transformations": [[37, "domain-specific-transformations"]], "Dummy classifier": [[45, "dummy-classifier"]], "DummyClassifier": [[26, "dummyclassifier"], [43, "dummyclassifier"], [44, "dummyclassifier"]], "DummyClassifier baseline": [[35, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[26, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[26, "dummyregressor"], [34, "dummyregressor"]], "EDA": [[29, "eda"], [33, "eda"], [34, "eda"]], "EDA: Exploratory Data Analysis": [[49, "eda-exploratory-data-analysis"]], "Encoding text data": [[30, "encoding-text-data"]], "Encoding time as a number": [[43, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[43, "encoding-time-of-day-as-a-categorical-feature"]], "Ensembles": [[47, "ensembles"]], "Ethics": [[47, "ethics"]], "Euclidean distance": [[28, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[39, "evaluating-dbscan-clusters"]], "Evaluation": [[40, "evaluation"], [40, "id3"]], "Evaluation metrics": [[47, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[33, "evaluation-metrics-for-binary-classification-motivation"]], "Evalution metrics overview": [[33, "evalution-metrics-overview"]], "Examining the preprocessed data": [[34, "examining-the-preprocessed-data"]], "Example": [[31, "example"], [35, "example"]], "Example 1: Predicting whether a patient has a liver disease or not": [[25, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[38, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[26, "example-1-quiz-2-grade-prediction"]], "Example 2: Predicting country using the longitude and latitude": [[26, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[25, "example-2-predicting-the-label-of-a-given-image"]], "Example 3: Predicting housing prices": [[25, "example-3-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[36, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[37, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[25, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Supervised vs unsupervised learning": [[38, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[26, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[26, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[33, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[29, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[25, "examples"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[40, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[40, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[26, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[26, "exercise-2-4"]], "Exercise 8.2": [[32, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[48, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[32, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[36, "explaining-a-prediction"]], "Exploratory data analysis": [[43, "exploratory-data-analysis"], [54, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[30, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[43, "extracting-date-and-time-information"]], "F1-score": [[33, "f1-score"]], "Faster method: vectorize the loop over rows": [[8, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[8, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[37, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[43, "feature-engineering"]], "Feature engineering and selection": [[47, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[43, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[43, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[37, "feature-engineering-motivation"]], "Feature importances": [[36, "feature-importances"], [47, "feature-importances"]], "Feature importances in linear models": [[36, "feature-importances-in-linear-models"], [36, "id2"]], "Feature interactions and feature crosses": [[37, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[34, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[37, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[29, "feature-transformations-and-the-golden-rule"]], "Feature types": [[34, "feature-types"], [34, "id1"]], "Feature vectors": [[28, "feature-vectors"]], "Figures": [[7, "figures"]], "Filtering a dataframe with [] and df.query()": [[8, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[32, "final-comments-and-summary"], [40, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[26, "final-comments-summary-and-reflection"], [38, "final-comments-summary-and-reflection"], [39, "final-comments-summary-and-reflection"]], "Final exam": [[55, "final-exam"]], "Final exam preparation: guiding questions": [[47, null]], "Final note": [[49, "final-note"]], "Final remarks": [[43, "final-remarks"]], "Finding the distances to a query point": [[28, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[28, "finding-the-nearest-neighbour"]], "Forecasting further into the future": [[43, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[43, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[40, "formulating-the-problem-of-recommender-systems"]], "Forum-specific Q&A guidelines": [[4, "forum-specific-q-a-guidelines"]], "Garbage in, garbage out.": [[37, "garbage-in-garbage-out"]], "General advice on finding relevant features": [[37, "general-advice-on-finding-relevant-features"]], "General guidelines": [[6, "general-guidelines"]], "General idea": [[35, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[28, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[37, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[27, "generalization-video"]], "Generalization: Fundamental goal of ML": [[27, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[31, "generalizing-to-more-features"]], "Generalizing to unseen data": [[27, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[28, "geometric-view-of-tabular-data-and-dimensions"]], "Git": [[11, "git"]], "GitHub Desktop": [[5, "github-desktop"]], "Global average baseline": [[40, "global-average-baseline"]], "Golden rule violation: Example 1": [[27, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[27, "golden-rule-violation-example-2"]], "Gradient boosted trees [video]": [[35, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[35, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[6, "grading-concerns-time-limit"]], "Grading scheme": [[55, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling imbalance": [[33, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[27, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering [video]": [[39, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[7, null]], "How are we making predictions?": [[31, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[27, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[36, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do they work?": [[35, "how-do-they-work"]], "How do we carry out feature selection?": [[37, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[26, "how-does-fit-work"], [26, "id2"]], "How does it work?": [[39, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[31, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[26, "how-does-predict-work"]], "How to approximate generalization error?": [[27, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[29, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[28, "how-to-choose-n-neighbors"]], "How to pick a model that would generalize better?": [[27, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[7, "how-to-submit"]], "Hyperparameter alpha of Ridge": [[31, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[47, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[32, "hyperparameter-optimization-motivation"]], "Hyperparameter tuning for the number of clusters": [[38, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[28, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[32, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[30, "identify-the-transformations-we-want-to-apply"]], "ImageNet": [[42, "imagenet"]], "Import": [[45, "import"]], "Importance of scaling": [[31, "importance-of-scaling"]], "Important hyperparameters": [[35, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[30, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[38, "important-points-to-remember"]], "Imports": [[25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [47, "imports"], [48, "imports"], [49, "imports"], [54, "imports"]], "Imports and LO": [[32, "imports-and-lo"], [34, "imports-and-lo"], [42, "imports-and-lo"], [43, "imports-and-lo"]], "Imports and LOs": [[33, "imports-and-los"]], "Imports and learning outcomes": [[38, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[26, "imports-announcements-los"]], "Imports, Announcements, and LO": [[30, "imports-announcements-and-lo"], [31, "imports-announcements-and-lo"]], "Imports, LOs": [[27, "imports-los"], [29, "imports-los"], [36, "imports-los"]], "Imports, announcements, LOs": [[35, "imports-announcements-los"]], "Imports, announcements, and LOs": [[28, "imports-announcements-and-los"]], "Imputation": [[29, "imputation"]], "Imputation and scaling [video]": [[29, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[30, "incorporating-ordinal-feature-class-attendance"]], "Increasing the threshold": [[33, "increasing-the-threshold"]], "Indexing Dataframes": [[8, "indexing-dataframes"]], "Indexing cheatsheet": [[8, "indexing-cheatsheet"]], "Inertia": [[38, "inertia"]], "Initialization of K-Means": [[38, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[35, "inject-randomness-in-the-classifier-construction"]], "Input data": [[25, "input-data"]], "Input features X and target y": [[25, "input-features-x-and-target-y"]], "Installing Python packages": [[11, "installing-python-packages"]], "Instructional Material": [[0, "instructional-material"]], "Interim summary": [[33, "interim-summary"], [36, "interim-summary"], [37, "interim-summary"], [43, "interim-summary"]], "Interpretation of coefficients": [[31, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[31, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[36, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[39, "introduction"], [47, "introduction"]], "Introduction to NLP": [[47, "introduction-to-nlp"]], "Introduction to computer vision": [[42, "introduction-to-computer-vision"]], "Introduction to neural networks": [[42, "introduction-to-neural-networks"]], "Introduction to pandas": [[8, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[38, "introduction-to-unsupervised-learning"]], "Is it possible to further improve the scores?": [[45, "is-it-possible-to-further-improve-the-scores"]], "Is stratifying a good idea?": [[33, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[30, "is-this-a-realistic-representation-of-text-data"]], "Is \u201cRelevance\u201d clearly defined?": [[37, "is-relevance-clearly-defined"], [37, "id2"], [37, "id3"], [37, "id4"], [37, "id5"], [37, "id6"], [37, "id7"]], "K-Means algorithm": [[38, "k-means-algorithm"]], "K-Means clustering [video]": [[38, "k-means-clustering-video"]], "K-Means example": [[38, "k-means-example"]], "K-Means limitations": [[39, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[39, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[39, "k-means-recap"]], "K-Means: failure case 1": [[39, "k-means-failure-case-1"]], "K-Means: failure case 2": [[39, "k-means-failure-case-2"]], "K-Means: failure case 3": [[39, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[44, "kaplan-meier-survival-curve"]], "Key point": [[36, "key-point"]], "LDA topics in social media": [[41, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[38, "labeled-vs-unlabeled-data"]], "Lag-based features": [[43, "lag-based-features"], [43, "id5"], [54, "lag-based-features"]], "Land acknowledgement": [[55, "land-acknowledgement"]], "Large datasets solve many of these problems": [[32, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[7, "late-submissions"]], "Learned coefficients associated with all features": [[31, "learned-coefficients-associated-with-all-features"]], "Learning git": [[5, "learning-git"]], "Learning objectives": [[41, "learning-objectives"], [42, "learning-objectives"], [43, "learning-objectives"], [44, "learning-objectives"]], "Learning outcomes": [[25, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [30, "learning-outcomes"], [31, "learning-outcomes"], [32, "learning-outcomes"], [33, "learning-outcomes"], [34, "learning-outcomes"], [36, "learning-outcomes"], [37, "learning-outcomes"], [38, "learning-outcomes"], [39, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[40, "learning-outcomes"]], "Least confident cases": [[31, "least-confident-cases"]], "Lecture 04": [[15, "lecture-04"]], "Lecture 05": [[16, "lecture-05"]], "Lecture 06": [[16, "lecture-06"]], "Lecture 07": [[17, "lecture-07"]], "Lecture 08": [[17, "lecture-08"]], "Lecture 09": [[18, "lecture-09"]], "Lecture 10": [[18, "lecture-10"]], "Lecture 10: Regression metrics": [[34, null]], "Lecture 11": [[20, "lecture-11"]], "Lecture 11: Ensembles": [[35, null]], "Lecture 12": [[21, "lecture-12"]], "Lecture 12: Feature importances and model transparency": [[36, null]], "Lecture 13": [[22, "lecture-13"]], "Lecture 13: Feature engineering and feature selection": [[37, null]], "Lecture 14": [[23, "lecture-14"]], "Lecture 14: K-Means Clustering": [[38, null]], "Lecture 15": [[23, "lecture-15"]], "Lecture 15: More Clustering": [[39, null]], "Lecture 16": [[24, "lecture-16"]], "Lecture 16: Recommender Systems": [[40, null]], "Lecture 17": [[24, "lecture-17"]], "Lecture 17: Introduction to natural language processing": [[41, null]], "Lecture 18: Multi-class classification and introduction to computer vision": [[42, null]], "Lecture 19: Time series": [[43, null]], "Lecture 1: Course Introduction": [[25, null]], "Lecture 20: Survival analysis": [[44, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[26, null]], "Lecture 3: Machine Learning Fundamentals": [[27, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[28, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[29, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[30, null]], "Lecture 7: Linear Models": [[31, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[32, null]], "Lecture 9: Classification metrics": [[33, null]], "Lecture learning objectives": [[35, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[39, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[55, "lecture-recordings"]], "Lecture schedule (tentative)": [[10, "lecture-schedule-tentative"]], "Lecture03": [[15, "lecture03"]], "Let\u2019s do it on our housing data": [[29, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[30, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[28, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[29, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[36, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[33, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[34, "let-s-separate-x-and-y"], [36, "let-s-separate-x-and-y"]], "Let\u2019s try a linear model: Ridge": [[34, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[29, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[35, "lightgbm"]], "Limitations of linear models": [[31, "limitations-of-linear-models"]], "Linear SVM": [[31, "linear-svm"]], "Linear models [video]": [[31, "linear-models-video"]], "Linear regression": [[31, "linear-regression"]], "Lists of resources": [[9, "lists-of-resources"]], "Logistic regression [video]": [[31, "logistic-regression-video"]], "Logistic regression intuition": [[31, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[31, "logistic-regression-on-the-cities-data"]], "Logistic regression with flattened representation of images": [[42, "logistic-regression-with-flattened-representation-of-images"]], "LogisticRegression": [[43, "logisticregression"], [44, "logisticregression"]], "MAPE": [[34, "mape"]], "ML fairness activity": [[52, "ml-fairness-activity"]], "ML fairness activity (~5 mins)": [[33, "ml-fairness-activity-5-mins"]], "ML fundamentals": [[47, "ml-fundamentals"]], "Mac Users": [[5, "mac-users"]], "Machine learning workflow": [[25, "machine-learning-workflow"], [33, "machine-learning-workflow"]], "Magnitude of the coefficients": [[31, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[31, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[31, "main-hyperparameters"]], "Manual hyperparameter optimization": [[32, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[38, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[38, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[34, "mean-squared-error-mse"]], "Meet Eva (a fictitious persona)!": [[25, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[38, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[38, "method-2-the-silhouette-method"]], "Midterms": [[55, "midterms"]], "Misc": [[9, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[40, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[34, "model-building"]], "Model complexity and training error": [[27, "model-complexity-and-training-error"]], "Model interpretability beyond linear models": [[36, "model-interpretability-beyond-linear-models"]], "Model predictions on unseen data": [[25, "model-predictions-on-unseen-data"]], "Model training and evaluation": [[52, "model-training-and-evaluation"]], "Model-based selection": [[37, "model-based-selection"]], "More comments on tackling class imbalance": [[34, "more-comments-on-tackling-class-imbalance"]], "More details on DBSCAN": [[39, "more-details-on-dbscan"]], "More on feature transformations": [[30, "more-on-feature-transformations"]], "More on k-NNs [video]": [[28, "more-on-k-nns-video"]], "More terminology [video]": [[26, "more-terminology-video"]], "More than one ordinal columns?": [[30, "more-than-one-ordinal-columns"]], "Most confident cases": [[31, "most-confident-cases"]], "Motivating example": [[31, "motivating-example"]], "Motivation": [[32, "motivation"], [43, "motivation"]], "Motivation [video]": [[35, "motivation-video"]], "Motivation and big picture [video]": [[29, "motivation-and-big-picture-video"]], "Motivation and context": [[41, "motivation-and-context"]], "Motivation and distances [video]": [[28, "motivation-and-distances-video"]], "Movie features": [[40, "movie-features"]], "Multi-class classification": [[42, "multi-class-classification"]], "Multiclass classification and computer vision": [[47, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[30, "multiple-transformations-in-a-transformer"]], "NOTE:": [[8, "note"]], "No-loop method: make them the same size, and multiply element-wise": [[8, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[27, null], [27, null], [43, null]], "Number of trees and fundamental trade-off": [[35, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[8, "numpy-array-shapes"]], "Numpy arrays": [[8, "numpy-arrays"]], "OHE with many categories": [[30, "ohe-with-many-categories"]], "Object detection": [[42, "object-detection"]], "Observations": [[33, "observations"]], "One Vs. One approach": [[46, "one-vs-one-approach"]], "One Vs. One prediction": [[46, "one-vs-one-prediction"]], "One vs. Rest": [[46, "one-vs-rest"]], "One-hot encoding (OHE)": [[29, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[43, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[43, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[30, "onehotencoder-and-sparse-features"]], "Online courses": [[9, "online-courses"], [10, "online-courses"]], "Operating point": [[33, "operating-point"]], "Optimization bias of hyper-parameter learning": [[32, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[32, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[32, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[32, "optimization-bias-overfitting-of-the-validation-set"]], "Optional readings and resources": [[32, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[29, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[36, "ordinal-features"]], "Other applications": [[38, "other-applications"]], "Other approaches / what did we not cover?": [[44, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[41, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[34, "other-possible-preprocessing"]], "Other software package": [[43, "other-software-package"]], "Other tools for preprocessing": [[41, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[41, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[28, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[37, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[27, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[48, "outline"], [49, "outline"], [50, "outline"], [51, "outline"], [52, "outline"], [53, "outline"], [54, "outline"]], "Over confident cases": [[31, "over-confident-cases"]], "Overfitting": [[27, "overfitting"]], "Overfitting of the validation data": [[32, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[32, "overfitting-of-the-validation-error"]], "Oversampling": [[33, "oversampling"]], "Overview": [[28, "overview"]], "POSIX time feature": [[43, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[33, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[8, "pandas-dataframes"]], "Pandas Series": [[8, "pandas-series"]], "Parameters": [[26, "parameters"]], "Parameters and hyperparameters: Summary": [[26, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[43, "parsing-datetimes"], [54, "parsing-datetimes"]], "Part 1": [[47, "part-1"]], "Part 2": [[47, "part-2"]], "Passing Requirements": [[55, "passing-requirements"]], "Pipelines": [[29, "pipelines"]], "Playground": [[28, "playground"]], "Plotting with matplotlib": [[8, "plotting-with-matplotlib"]], "Practice exercises": [[26, "practice-exercises"]], "Pre-lecture 10 Videos": [[18, "pre-lecture-10-videos"]], "Pre-lecture 11 Videos": [[20, "pre-lecture-11-videos"]], "Pre-lecture 12 Videos": [[21, "pre-lecture-12-videos"]], "Pre-lecture 13 Videos": [[22, "pre-lecture-13-videos"]], "Pre-lecture 3 Videos": [[15, "pre-lecture-3-videos"]], "Pre-lecture 4 Videos": [[15, "pre-lecture-4-videos"]], "Pre-lecture 5 Videos": [[16, "pre-lecture-5-videos"]], "Pre-lecture 6 Videos": [[16, "pre-lecture-6-videos"]], "Pre-lecture 7 Videos": [[17, "pre-lecture-7-videos"]], "Pre-lecture 8 Videos": [[17, "pre-lecture-8-videos"]], "Pre-lecture 9 Videos": [[18, "pre-lecture-9-videos"]], "Pre-lecture Videos": [[13, "pre-lecture-videos"], [14, "pre-lecture-videos"]], "Precision": [[33, "precision"]], "Precision and recall: toy example": [[33, "precision-and-recall-toy-example"]], "Precision, recall, f1 score (video)": [[33, "precision-recall-f1-score-video"]], "Precision-recall curve": [[33, "precision-recall-curve"], [33, "id1"]], "Precision/Recall tradeoff": [[33, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[25, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[31, "predicting-probability-scores-video"]], "Predicting with learned weights": [[31, "predicting-with-learned-weights"]], "Prediction": [[44, "prediction"]], "Prediction of linear regression": [[31, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[31, "prediction-with-learned-parameters"]], "Predictions": [[42, "predictions"]], "Preparation": [[7, "preparation"]], "Preprocessing": [[30, "preprocessing"], [43, "preprocessing"], [47, "preprocessing"], [52, "preprocessing"], [54, "preprocessing"]], "Preprocessing the targets?": [[30, "preprocessing-the-targets"]], "Prevalence of ML": [[25, "prevalence-of-ml"]], "Problem formulation": [[40, "problem-formulation"]], "Problem: Different transformations on different columns": [[29, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[32, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[27, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[28, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[47, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python and Conda": [[11, "python-and-conda"]], "Python resources": [[9, "python-resources"]], "Question": [[28, "question"]], "Question for you": [[39, "question-for-you"]], "Questions for class discussion": [[40, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[32, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[28, "quick-recap"]], "RFE algorithm": [[37, "rfe-algorithm"]], "R^2 (not in detail)": [[34, "r-2-not-in-detail"]], "Random forest feature importances": [[36, "random-forest-feature-importances"]], "Random forests": [[35, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[35, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[35, "randomforestclassifier"], [44, "randomforestclassifier"]], "Randomized hyperparameter search": [[32, "randomized-hyperparameter-search"]], "Range of C": [[32, "range-of-c"]], "Raw scores": [[31, "raw-scores"]], "Reading from .csv": [[8, "reading-from-csv"]], "Reading from other formats": [[8, "reading-from-other-formats"]], "Reading from url": [[8, "reading-from-url"]], "Reading the data": [[26, "reading-the-data"], [42, "reading-the-data"]], "Real boundary between Canada and USA": [[26, "real-boundary-between-canada-and-usa"], [48, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[6, "reasonable-grading-concerns"]], "Recall": [[33, "recall"]], "Recap": [[44, "recap"]], "Recap and motivation [video]": [[39, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[26, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[33, "receiver-operating-characteristic-roc-curve"]], "Recommender systems": [[47, "recommender-systems"]], "Recommender systems intro and motivation": [[40, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[40, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[37, "recursive-feature-elimination-rfe"]], "Reference Material": [[10, "reference-material"]], "Reference material": [[9, null]], "References": [[44, "references"]], "Registration": [[55, "registration"]], "Regression scoring functions": [[34, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[28, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[28, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[28, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[9, "relevant-companion-materials"]], "Relevant papers": [[35, "relevant-papers"]], "Relevant papers and resources": [[33, "relevant-papers-and-resources"]], "Relevant resources": [[37, "relevant-resources"]], "Reminder": [[40, "reminder"]], "Renaming columns with df.rename()": [[8, "renaming-columns-with-df-rename"]], "Report format": [[7, "report-format"]], "Resources": [[38, "resources"], [39, "resources"], [40, "resources"]], "Ridge": [[31, "ridge"]], "Ridge on the California housing dataset": [[31, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[34, "ridgecv"]], "Root mean squared error or RMSE": [[34, "root-mean-squared-error-or-rmse"]], "SHAP  (SHapley Additive exPlanations) introduction": [[36, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[36, "shap-plots"]], "SMOTE idea": [[33, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[33, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[28, "svm-regressor"]], "Saving time and scaling products": [[25, "saving-time-and-scaling-products"]], "Scaling": [[29, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[29, "scaling-using-scikit-learn-s-standardscaler"]], "Schedule": [[55, "schedule"]], "Schedule and Deliverables": [[10, null]], "Search over multiple hyperparameters": [[28, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[43, "seasonality-and-trends"]], "Select all of the following statements which are True (iClicker)": [[25, "select-all-of-the-following-statements-which-are-true-iclicker"]], "Setting up": [[5, "setting-up"]], "Setting up a virtual environment: Conda environments": [[11, "setting-up-a-virtual-environment-conda-environments"]], "Setting up coding environment": [[11, null]], "Short posts/articles": [[9, "short-posts-articles"]], "Sigmoid vs. Softmax": [[42, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[31, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[38, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[28, "similarity-between-examples"]], "Simple feature engineering for our problem.": [[45, "simple-feature-engineering-for-our-problem"]], "Simple train/test split": [[27, "simple-train-test-split"]], "SimpleFeature correlations": [[36, "simplefeature-correlations"]], "Slowest method: nested loop": [[8, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Some important hyperparameters:": [[35, "some-important-hyperparameters"]], "Some quotes on feature engineering": [[37, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[26, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[32, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[8, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[30, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[35, "stacking"], [53, "stacking"]], "Step 1": [[50, "step-1"]], "Step 2": [[50, "step-2"]], "Step 3": [[50, "step-3"]], "Step 4": [[50, "step-4"]], "Step 5": [[50, "step-5"]], "Steps to train a classifier using sklearn": [[26, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[33, "stratified-splits"]], "Strengths and weaknesses": [[35, "strengths-and-weaknesses"]], "Strengths of linear models": [[31, "strengths-of-linear-models"]], "Study tips": [[47, "study-tips"]], "Submitting on Gradescope": [[7, "submitting-on-gradescope"]], "Summary": [[25, "summary"], [28, "summary"], [35, "summary"], [41, "summary"], [42, "summary"], [44, "summary"]], "Summary and reflection": [[27, "summary-and-reflection"]], "Summary of linear models": [[31, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[27, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[39, "summary-pros-and-cons"]], "Summer Teaching Schedule (tenative)": [[10, "summer-teaching-schedule-tenative"]], "Supervised approach to rating prediction": [[40, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[38, "supervised-learning"]], "Supervised learning (Reminder)": [[26, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[26, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[25, "supervised-machine-learning"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[28, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[28, "support-vectors"]], "Survival analysis": [[47, "survival-analysis"]], "Survival plots": [[44, "survival-plots"]], "Syllabus": [[1, "syllabus"], [55, null]], "TAs": [[55, "tas"]], "Tabular data": [[26, "tabular-data"]], "Take-home message": [[39, "take-home-message"]], "Teaching Team": [[55, "teaching-team"]], "Terminology": [[42, "terminology"]], "Terminology [video]": [[26, "terminology-video"]], "Testing your git installation": [[5, "testing-your-git-installation"]], "The Netflix prize": [[35, "the-netflix-prize"]], "The __ syntax": [[32, "the-syntax"]], "The best features may be dependent on the model you use.": [[37, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[53, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[27, "the-golden-rule"]], "The random forests classifier": [[35, "the-random-forests-classifier"]], "The sigmoid function": [[31, "the-sigmoid-function"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[27, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[38, "the-perfect-spaghetti-sauce"]], "Time series": [[47, "time-series"]], "Time series analysis on a more complicated dataset": [[54, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[44, "time-to-event-and-censoring"]], "Tokenization": [[41, "tokenization"]], "Topic modeling": [[41, "topic-modeling"]], "Topic modeling motivation": [[41, "topic-modeling-motivation"]], "Topic modeling pipeline": [[41, "topic-modeling-pipeline"]], "Topic modeling toy example": [[41, "topic-modeling-toy-example"]], "Toy datasets": [[26, "toy-datasets"]], "Traditional time series approaches": [[43, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[43, "train-test-split-for-temporal-data"]], "Train/test splits": [[43, "train-test-splits"]], "Train/validation/test split": [[27, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[25, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[31, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[27, "training-error-vs-generalization-error"]], "Training models with transformed data": [[30, "training-models-with-transformed-data"]], "Transfer learning": [[42, "transfer-learning"]], "Transformations on the toy data": [[30, "transformations-on-the-toy-data"]], "Transforming the targets": [[34, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[36, "transparency-and-explainability-of-ml-models-motivation"]], "Tree-based ensemble models": [[35, "tree-based-ensemble-models"]], "Tree-based models": [[35, "tree-based-models"]], "Tuning alpha hyperparameter of Ridge": [[34, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[48, null]], "Tutorial 2": [[49, null]], "Tutorial 3": [[50, null]], "Tutorial 4": [[51, null]], "Tutorial 5": [[52, null]], "Tutorial 6": [[53, null]], "Tutorial 7": [[54, null]], "Types of censoring": [[44, "types-of-censoring"]], "Types of errors": [[27, "types-of-errors"]], "Types of machine learning": [[25, "types-of-machine-learning"], [38, "types-of-machine-learning"]], "Types of problems involving time series": [[43, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[44, "types-of-questions-we-might-want-to-answer"]], "UBC CPSC 330: Applied Machine Learning (2025S1)": [[1, null]], "Ubuntu Users": [[5, "ubuntu-users"]], "Underfitting": [[27, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[27, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[33, "undersampling"]], "Unequally spaced time points": [[43, "unequally-spaced-time-points"]], "Unsupervised learning": [[38, "unsupervised-learning"]], "Updates to assignments": [[7, "updates-to-assignments"]], "Use of AI in the course": [[55, "use-of-ai-in-the-course"]], "Use our template to create a repository": [[7, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[46, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[33, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[38, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[34, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[42, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[42, "using-pre-trained-models-out-of-the-box"]], "Using regression metrics with scikit-learn": [[34, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[30, "viewing-the-transformed-data-as-a-dataframe"]], "Virtual environment": [[11, "virtual-environment"]], "Visualization": [[9, "visualization"]], "Visualizing the parameter grid as a heatmap": [[32, "visualizing-the-parameter-grid-as-a-heatmap"]], "Warning": [[26, null]], "Warnings about feature selection": [[37, "warnings-about-feature-selection"], [37, "id8"]], "Weaknesses": [[35, "weaknesses"]], "What all transformations we need to apply on the dataset?": [[29, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What and Why": [[11, "what-and-why"]], "What are git and GitHub?": [[5, null]], "What are the options?": [[29, "what-are-the-options"]], "What are we exactly learning?": [[31, "what-are-we-exactly-learning"]], "What did we cover?": [[40, "what-did-we-cover"]], "What did we learn today?": [[27, "what-did-we-learn-today"], [29, "what-did-we-learn-today"], [30, "what-did-we-learn-today"], [33, "what-did-we-learn-today"], [34, "what-did-we-learn-today"]], "What if we apply OHE?": [[30, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[41, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[40, "what-is-a-recommender-system"]], "What is clustering?": [[38, "what-is-clustering"]], "What is feature engineering?": [[37, "what-is-feature-engineering"]], "What is feature selection?": [[37, "what-is-feature-selection"]], "What is model interpretability?": [[36, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[25, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[33, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[35, "what-kind-of-estimators-can-we-combine"]], "What to look for in these plots?": [[38, "what-to-look-for-in-these-plots"]], "What\u2019s the problem?": [[29, "what-s-the-problem"]], "When can we use broadcasting?": [[8, "when-can-we-use-broadcasting"]], "When is it OK to do things before splitting?": [[29, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[32, "when-test-score-is-much-lower-than-cv-score"]], "Which model should I use?": [[35, "which-model-should-i-use"]], "Which type of error is more important?": [[33, "which-type-of-error-is-more-important"]], "Why do we need a test set?": [[32, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[36, "why-do-we-want-this-information"]], "Why feature selection?": [[37, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[25, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[36, "why-model-transparency-interpretability"]], "Why neural networks?": [[42, "why-neural-networks"], [42, "id1"]], "Why not neural networks?": [[42, "why-not-neural-networks"], [42, "id2"]], "Why should we care about recommendation systems?": [[40, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[30, "why-sparse-matrices"]], "Windows": [[11, "windows"]], "Windows Users": [[5, "windows-users"]], "Word embeddings": [[41, "word-embeddings"]], "Word vectors with spaCy": [[41, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[26, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[35, "xgboost"]], "[Optional] Jupyterlab and Python": [[11, "optional-jupyterlab-and-python"]], "[] notation": [[8, "notation"]], "class_weight=\"balanced\"": [[33, "class-weight-balanced"]], "cross_val_score": [[27, "cross-val-score"]], "cross_validate": [[27, "cross-validate"]], "fit and transform paradigm for transformers": [[29, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[26, "fit-the-classifier"]], "fit, predict , and score summary": [[26, "fit-predict-and-score-summary"]], "iClicker (not for course credit)": [[55, "iclicker-not-for-course-credit"]], "iClicker Exercise 10.1": [[34, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[34, "iclicker-exercise-10-2"]], "iClicker Exercise 12.0": [[35, "iclicker-exercise-12-0"]], "iClicker Exercise 12.1": [[35, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[37, "iclicker-exercise-14-1"]], "iClicker Exercise 19.1": [[42, "iclicker-exercise-19-1"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[26, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 Classification vs regression": [[26, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.5: Baselines and decision trees": [[26, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[27, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[27, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[33, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[33, "iclicker-exercise-9-2"]], "k-Nearest Neighbours (k-NNs) [video]": [[28, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[40, "k-nearest-neighbours-imputation"]], "macOS": [[11, "macos"]], "n_iter": [[32, "n-iter"]], "n_jobs=-1": [[32, "n-jobs-1"]], "pandas_profiler": [[34, "pandas-profiler"]], "predict the target of given examples": [[26, "predict-the-target-of-given-examples"]], "predict_proba": [[31, "predict-proba"]], "random_state argument": [[27, "random-state-argument"]], "score your model": [[26, "score-your-model"]], "sklearn API summary: estimators": [[29, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[29, "sklearn-api-summary-transformers"]], "sklearn set_config": [[30, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[30, "sklearn-s-columntransformer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[36, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[36, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "spaCy": [[45, "spacy"]], "test score vs. cross-validation score": [[27, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[27, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[27, "deployment-data"]], "\u2753\u2753 Questions for group discussion": [[33, "questions-for-group-discussion"], [52, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[25, "questions-for-you"], [26, "questions-for-you"], [26, "id1"], [26, "id3"], [27, "questions-for-you"], [27, "id1"], [28, "questions-for-you"], [28, "id1"], [29, "questions-for-you"], [29, "id1"], [29, "id2"], [30, "questions-for-you"], [30, "id1"], [31, "questions-for-you"], [31, "id1"], [31, "id2"], [32, "questions-for-you"], [32, "id2"], [33, "questions-for-you"], [33, "id2"], [34, "questions-for-you"], [34, "id2"], [35, "questions-for-you"], [35, "id1"], [35, "id2"], [37, "questions-for-you"], [38, "questions-for-you"], [38, "id2"], [39, "questions-for-you"], [39, "id3"], [40, "questions-for-you"], [40, "id1"], [40, "id2"], [42, "questions-for-you"], [43, "questions-for-you"], [43, "id1"], [43, "id2"], [43, "id3"], [44, "questions-for-you"], [44, "id1"], [44, "id2"], [44, "id3"], [44, "id4"]], "\ud83e\udd14 Eva\u2019s questions": [[25, "eva-s-questions"], [27, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/schedule", "docs/setup", "learning-objectives", "lectures/classes/class1A", "lectures/classes/class1B", "lectures/classes/class1C", "lectures/classes/class2A", "lectures/classes/class2B", "lectures/classes/class3A", "lectures/classes/class3B", "lectures/classes/class3C", "lectures/classes/class4A", "lectures/classes/class4B", "lectures/classes/class4C", "lectures/classes/class5A", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/appendixA_feature-engineering-text-data", "lectures/notes/appendixB_multiclass-strategies", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/04_Hyperparameter_optimization", "lectures/tutorials/05_Classification_metrics", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_Time_series", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/schedule.md", "docs/setup.md", "learning-objectives.md", "lectures/classes/class1A.md", "lectures/classes/class1B.md", "lectures/classes/class1C.md", "lectures/classes/class2A.md", "lectures/classes/class2B.md", "lectures/classes/class3A.md", "lectures/classes/class3B.md", "lectures/classes/class3C.md", "lectures/classes/class4A.md", "lectures/classes/class4B.md", "lectures/classes/class4C.md", "lectures/classes/class5A.md", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/appendixA_feature-engineering-text-data.ipynb", "lectures/notes/appendixB_multiclass-strategies.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/04_Hyperparameter_optimization.ipynb", "lectures/tutorials/05_Classification_metrics.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_Time_series.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 32, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "0": [0, 1, 7, 8, 10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "00": [10, 25, 26, 28, 30, 31, 32, 33, 36, 39, 40, 43, 44, 54, 55], "000": [25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 41, 42, 44, 45], "0000": [29, 31, 33, 45], "00000": [32, 43, 54], "000000": [26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 43, 44, 54], "00000000e": 36, "000000e": 32, "000001": 34, "00000e": 28, "000010": 34, "000011": 33, "000021": 29, "000036": 33, "000057": 29, "000065": 32, "000067": 32, "000077": 32, "000087": 31, "000089": 31, "0001": [31, 33, 34, 44], "000100": [29, 34], "000108": 31, "000113": 33, "000114": 32, "000117": 34, "000130": 31, "000136": 42, "000137": 32, "000145": 32, "000146": 31, "000147": 32, "000149": 29, "000150": 31, "000151": 32, "000155": [29, 33], "000159": 32, "000163": 32, "000166": [31, 32], "000177": [29, 43], "000180": 29, "000181": 32, "000182": 31, "000183": 31, "000187": 31, "000188": 29, "000190": 43, "000192": 43, "000194": 31, "000195": 29, "000198": 33, "000201": 32, "000206": 32, "000208": 29, "000210": 32, "000212": 37, "000213": 31, "000218": 31, "000221": 34, "000226": 34, "000227": 33, "000231": 29, "000232": 42, "000234": [28, 32], "000235": [29, 33], "000240": 29, "000245": 32, "000247": 42, "000255": 31, "000256": 43, "000259": 29, "000260": 29, "000271": 43, "000273": 42, "000274": 42, "000281": 31, "000283": 31, "000285": 31, "000286": 32, "000289": 29, "000294": 32, "000312": 33, "000332": 34, "000336": 42, "000339": 32, "000348": 32, "000353": 32, "000354": 32, "000363": 42, "000366": 33, "000370": 32, "000371": 31, "000373": 34, "000378": 31, "00038": 32, "000397": 34, "000399": 42, "000433": 34, "000435": 42, "000437": 42, "000452": 29, "000459": 31, "000471": 43, "000472": 42, "000489": 32, "000492": 33, "000498": 43, "000503": 32, "000508": 32, "000520": 34, "000575": 43, "00058": 32, "000580": 28, "000630": 33, "000633": 28, "000637": 42, "000647": 28, "000650": 28, "000651": 28, "000652": 34, "000655": 28, "000661": 28, "000671": 28, "000678": 32, "000713": 34, "000726": 33, "000737": 43, "000747": 32, "000748": 29, "000752": 28, "000758": 42, "000765": 29, "000774": 29, "000786": 33, "000787": 28, "00079": 32, "000794": 28, "000795": 28, "000797": 28, "000803": 34, "000829": 28, "000831": 28, "000832": 34, "000867": 29, "000869": 43, "000873": 28, "000889": 28, "000891": 33, "000917": 32, "000927": 33, "000936": 28, "000945": 37, "000960": 42, "000964": 37, "000976": 32, "000977": 28, "000982": 32, "001": [25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 42, 44, 45], "0010": 31, "00100": 32, "001000": [32, 34], "001002": 27, "001006": 27, "001010": 27, "001011": [28, 34], "001014": 27, "001016": 27, "001017": 27, "001026": 27, "001027": 27, "001029": 27, "001038": 27, "001040": 33, "001043": 29, "001057": [27, 32], "001060": 29, "001063": 27, "001064": 42, "001068": 36, "001071": 27, "001078": 27, "001086": 27, "001087": 37, "001103": 27, "001111": 27, "001139": 28, "001149": 27, "001155": 37, "001162": [32, 37], "001174": 27, "001205": 33, "001220": 31, "001224": 28, "001226": 42, "001236": 32, "001239": 33, "001266": 34, "001279": 37, "001286": 33, "001294": 27, "001299": 27, "001305": 27, "001307": 27, "001315": 27, "001317": 27, "001322": 27, "001323": 27, "001325": 28, "001329": 27, "001337": 27, "001338": 31, "001347": 32, "001352": 27, "001361": 31, "001362": 31, "001365": 28, "001371": 30, "001390": 27, "001391": 27, "001392": 28, "001400": 30, "001406": 34, "001407": 27, "001412": 32, "001414": 28, "001422": 34, "001423": 32, "001429": 27, "001433": 34, "001441": 27, "001448": 30, "001453": 27, "00146": 32, "001466": 30, "001467": 32, "001492": 32, "001495": 28, "001563": 30, "001566": 34, "001585": 32, "001586": 28, "001591": 30, "001594": 32, "001595": 28, "001600": 28, "001604": 30, "001606": 30, "001608": 32, "001616": 32, "001620": 32, "001629": 32, "001641": 42, "001645": 31, "001647": 30, "001679": 32, "001682": 32, "001693": 37, "001699": 27, "0017": 33, "001700": 33, "001710": 31, "001715": 30, "001740": 34, "001769": 32, "001773": 28, "001776": 27, "001790": 34, "001792": 32, "001847": 37, "001850": 31, "001877": 28, "001894": 34, "001900": 28, "001920": 30, "001922": 30, "001933": 34, "001949": 37, "001952": 28, "001968": 27, "001994": 37, "002": [27, 31, 35, 36, 44], "002003": 32, "002022": 30, "002030": 28, "002045": 32, "002057": [29, 30], "002083": 28, "002096": 42, "002105": 32, "002116": 30, "002118": 28, "002123": 32, "002143": 27, "002146": 32, "002158": 37, "002159": 32, "002197": 32, "002221": 34, "002321": 31, "00234": 32, "002355": 37, "002385": 34, "002441": 37, "002460": 42, "002525": 42, "002561": 32, "002646": 37, "002664": 37, "002675": 32, "002682": 42, "002690": 29, "002692": 32, "002704": 32, "002711": 42, "002746": 34, "002783": 32, "002788": 30, "002789": 30, "002807": 30, "002835": 32, "002858": 30, "002867": 37, "002889": 33, "0029": 44, "002910": 30, "002934": 31, "002940": 42, "002948": 28, "002962": 42, "002986": 42, "002999": 32, "003": [32, 35], "003013": 30, "003014": 32, "003015": 32, "003027": 32, "003038": 32, "003083": 32, "003086": 30, "003115": 30, "003124": 34, "003133": 34, "003146": 30, "003148": 31, "003166": [29, 37], "003181": 29, "003183": 37, "003185": 44, "003186": 30, "003188": [29, 30], "003194": 31, "003212": 29, "003242": 42, "003257": 42, "003273": 27, "003283": 42, "003288": 34, "003300": 29, "00332": 32, "003324": 29, "003365": 30, "003401": 37, "003421": 32, "003423": 37, "003427": 37, "003472": 32, "003477": 42, "003479": 32, "003483": 32, "003493": 37, "003528": 32, "003529": 32, "003547": 34, "003563": 32, "003633": 32, "003647": 42, "00369": 32, "003748": 32, "003757": 32, "003785": 34, "003885": 32, "003919": 32, "003919287722401839": 32, "00392157": 42, "003923": 30, "003924": 37, "003933": 32, "003998": 32, "004": [28, 32, 35, 36, 42], "004057": 32, "004065": 43, "004082": 43, "004121": 34, "004143": 34, "004264": 27, "004293": 32, "004305": 32, "004337": 32, "00435173": 38, "004352": 38, "004398": 36, "004402": 32, "004466": 32, "004496": 32, "004521": 34, "004529": 36, "004556": 32, "004574": 34, "004602": 34, "00461": 32, "004714": 32, "004723": 36, "004761": 36, "004770": 29, "004801": [29, 30], "004807": 30, "004826": 34, "004829": 34, "004854": 34, "004884": 42, "004919": 32, "004934": 33, "004952": 32, "004959": 32, "00496": 32, "005": [25, 35, 36, 44], "005067": 29, "005074": 42, "005093": 29, "005098": 34, "005114": 34, "005126": 32, "005151": 32, "005157": 29, "005167": 34, "005196": 32, "005241": 34, "00525962": 29, "005269": 34, "005288": 30, "005335": 32, "005336": 34, "005387": 33, "005423": 32, "005426": 32, "00543825": 29, "005440": 42, "005478": 36, "00548": 32, "005538": 34, "005579": 34, "005641": 34, "005674": 34, "005699": 27, "005708": 32, "00573": 32, "005734": 32, "005735": 32, "005767": 32, "005809": 43, "005834": 32, "005836": 29, "005888": 29, "006": [35, 36, 44], "006012": 32, "006046": 34, "006055": 32, "006067": 34, "006106": 32, "006110": [28, 32, 34], "006236": 34, "006244": 32, "006435": 32, "006452": 31, "006476": 34, "006505": 42, "006531": 27, "006545": 32, "006546893270012566": 31, "006557": 31, "006578": [29, 30], "006652": 32, "006667": 32, "00667": 32, "006744": 34, "006805": 27, "006861": 32, "006904": 32, "00691": 32, "006973": 29, "007": [29, 35, 36, 44, 45], "007068": 37, "00715": 32, "00720988e": 36, "007228": 34, "007291": 30, "007316": 27, "007361": 33, "007362": 32, "007434": 36, "007458": [29, 30], "007517": 34, "007544": 32, "007563": 32, "007588": 38, "00758803": 38, "00759438": 36, "007655": 32, "007666": 33, "00767": 32, "007737": 34, "007776": 34, "007818": 32, "007938": 27, "007986": 34, "008": [35, 36, 45], "008040": 43, "008120": 34, "008153": 32, "008167": [29, 30], "00830586": 30, "008306": 30, "008322e": 44, "008333": 30, "008346": 34, "008377": 32, "008472": 34, "008577": 42, "008581": 34, "008606": 34, "008617": 34, "008667": 32, "00871": 32, "008735": 28, "008785": 34, "009": [30, 35, 44], "009059": 27, "009063": 32, "009082": 32, "009090": 34, "009132": 32, "009140": 34, "009297": 32, "009305": 32, "009339": 34, "009422": 27, "009512": 32, "009514e": 34, "009664": 34, "009692": 42, "009724": 37, "01": [28, 29, 31, 32, 33, 34, 36, 42, 43, 44, 46, 54], "010": [25, 31, 32, 44, 45], "0100": 31, "01000": 32, "010000": [29, 32, 34], "010027": 31, "010183": [29, 30], "0102": [28, 32], "010208": 37, "010294": 27, "010650": 27, "010679": 27, "010688": 37, "010715": 32, "010750": 37, "011": [25, 30, 42, 44], "011210": 37, "011234": 33, "011248": 34, "011252": 37, "011269e": 34, "011287": 37, "011332": 44, "011336": 28, "011440": 34, "011617": 32, "011678": 33, "011767": 34, "011773": 35, "012": [29, 30, 35, 36, 42, 44, 45], "012019": 27, "012030": 37, "012232": 34, "012240": 37, "012252": 32, "012616": 32, "012624": 34, "012707": 33, "012758": 34, "013031": 34, "01311996071": 34, "013120": 36, "013157": 32, "013161": 32, "013433": 28, "013629": 32, "013706928443177698": 32, "013707": 32, "013863": 32, "013888": 32, "014": [27, 29, 35, 36, 44], "014030": 34, "014081e": 34, "014305": 34, "01432486e": 36, "014481": 32, "014503": 32, "014650": 44, "014730": 30, "01473536": 28, "014758": 44, "015": [25, 29, 30, 35, 44, 45], "015003": 32, "015039": 33, "015056": 32, "015165": 34, "015372": 32, "015724": 37, "015755": 32, "015819": 32, "016263": 32, "016372": 32, "01647": 32, "016525": [34, 36], "016555": 31, "016587": 33, "016598": 32, "016602": 32, "016607": 32, "016676": 38, "016688": [29, 37], "016693": 34, "016807": 31, "016815": 32, "016918": 33, "016944": 28, "017": [30, 42], "017185": 32, "017226": 34, "017308": 32, "017427": 32, "017610": 36, "017696": 36, "017737": 36, "017741": 36, "017829": [43, 54], "017837": 32, "01784": 32, "017927": 32, "017959e": 34, "017972": 29, "018": 35, "018014": 36, "018046": 33, "018077": 32, "018178": 28, "018243": 32, "018310": 28, "018434": [43, 54], "018459e": 34, "018487": 31, "0185": 31, "018505": 32, "018507e": 34, "018558": 32, "018581": 34, "018653": 32, "018745": 25, "018789": 32, "018846": 32, "018854": 33, "019": 35, "019012": 32, "019163": 32, "019381838999846482": 32, "019382": 32, "019396": 32, "019444": 30, "019446": 32, "019531": 33, "019556": 44, "0195598": 31, "019574": 32, "019839": 32, "02": [28, 29, 30, 31, 32, 34, 36, 37, 43, 44, 50, 54], "02000e": 28, "020123": 34, "020403": 32, "020414": 32, "020641": 36, "020648": 34, "020653": 27, "020833": 40, "020862": 34, "020873": 29, "021": [35, 45], "021043": 33, "021100": 29, "021281": 32, "021305": 28, "021345": 32, "021523": 33, "021603": 42, "021721": 32, "021746": 32, "021813": 33, "021862": 32, "021900": [28, 32], "022039": 33, "022331": 36, "022433": 32, "022629": 32, "022686": 32, "022848": 27, "022866": 33, "023": [35, 42], "023086": 44, "023105": [43, 54], "023305": 34, "023366": 37, "023367": 33, "023511": 32, "023554": 34, "023636": 33, "023666": 32, "023810": 45, "024": 35, "024028": 32, "024122": 32, "024291": 43, "024351e": 34, "024390": 37, "02446630e": 36, "024540": 29, "025": [29, 33], "025381": 36, "025391": [29, 30], "025396": 32, "025489": 36, "025689": 32, "025910": 28, "025998": [29, 30], "026": 44, "0261": [28, 32], "026620": 32, "026777": 32, "02677733855112973": 32, "026793": [34, 36], "026972": 34, "027070": 34, "027112": [43, 54], "027321": 37, "027484": 34, "027578": 34, "028023": 33, "028337": 32, "028351": 32, "028420": 34, "028672": 37, "028772": 34, "029137": 33, "029146": 33, "029164": [43, 54], "029198": 32, "029264": 34, "029409": 34, "029475": 34, "029909": 27, "029950e": 34, "02d": 43, "03": [31, 32, 34, 36, 42, 43, 44, 45, 54], "030": 36, "03017665e": 36, "030200": 29, "030343": 34, "030349": 34, "030408": 28, "03049217": 28, "0305": 28, "030739733331869412": 31, "030786": 34, "030805": 34, "031": 30, "031070": 34, "031385": 28, "031483": 34, "031564": 29, "031794": 34, "031863": 34, "031994": 34, "032140": 34, "032280": 33, "032324": 32, "032404": 32, "032566": 30, "03256625": 30, "032656": 28, "032874": 28, "033165": 34, "033222": 44, "033267": 43, "033279": 36, "033305": 42, "033322": 34, "033459": 28, "0335": 32, "033723": 34, "033739": 34, "033780": 44, "033833": 33, "0339": 29, "034071": 33, "03411038e": 36, "034132": 34, "0344": [28, 32], "034894": 36, "034977": 34, "034979e": 34, "035": 42, "0351": 29, "03516073": 36, "035161": 36, "035223": 34, "035230": [43, 54], "035722": 34, "036": [29, 35, 42], "036136": 37, "0362": 29, "036646": 34, "036749": 33, "036764": 33, "036886": 35, "0370": 29, "0373": 29, "037414": [43, 54], "037785": 33, "0378": [29, 44], "038102": 31, "038609": 34, "038707": 36, "038948": 34, "039": 42, "039498": 31, "039741": 28, "0399": 29, "04": [29, 30, 32, 34, 36, 43, 44, 50, 54], "040": 35, "040129": 44, "040497": 33, "040698e": 34, "040954": 44, "040984": 43, "041": [35, 42], "041031": 33, "04108378": 31, "041084": 31, "041129": 28, "041201": 33, "041488": 34, "041704": 36, "041769": 34, "042081": 36, "042382": 37, "042743": 34, "042957": [29, 30], "043": 32, "043257": 30, "043319": 36, "043509": 32, "0437": [26, 27, 28, 48], "043890": 28, "044": [28, 32], "044029": [29, 30], "044166": 31, "044253": 36, "044313": 29, "044409": 34, "044614": 32, "044873": 27, "045": [26, 42], "045267": 43, "045280": 33, "045304": 28, "045415": 29, "045481": [43, 54], "046": 42, "04600e": 28, "046020": 28, "046116": 32, "046193e": 34, "046216": 32, "046638": 30, "0468": 44, "0469": 29, "046945": 32, "04709519e": 36, "0474": 31, "047567": 34, "04774884": 38, "047749": 38, "048": [27, 30], "048378": 27, "04861878": 38, "048630": 43, "048860": 29, "048889": 34, "049": [30, 42], "05": [28, 29, 32, 33, 34, 39, 43, 44, 54], "050": [25, 42], "050110e": 34, "050132": [29, 30], "051": 42, "051269": [29, 30], "05137470e": 36, "051392": 42, "051472": 28, "051620": 29, "051824": 34, "051925": 32, "052": 29, "052349": 29, "052607": 33, "052790": 33, "052819": 33, "05290827e": 36, "053156": 38, "05350962": 46, "0537": 32, "053763": 27, "053918": 32, "054054": 33, "054461": 33, "054653": 30, "05465323": 30, "054669": [34, 36], "054784": 30, "05478443": 30, "055": [27, 29, 30], "055100": 32, "055915e": 34, "05598498": 30, "055985": 30, "056": 42, "056478": [29, 30], "056703": 33, "057": [29, 42], "057003": 28, "057082": 34, "057254": 44, "057296": 33, "057331": 34, "057646": 28, "057729": 33, "057732e": 44, "057793": [29, 30], "057910": [29, 30], "058": 35, "0580": [27, 31], "058298": 34, "058311": 33, "059": [25, 29], "059077": 33, "0591": 29, "059242": [29, 30], "059360": 42, "059588": 32, "059863": 28, "06": [29, 32, 34, 39, 42, 43, 44, 46, 54], "060": 42, "060477": 34, "060543": 37, "061100": 29, "061206": 33, "061241": 28, "061312": 34, "061313": 42, "061937": 28, "062": [25, 28, 32], "062043": 32, "062449": 44, "062658e": 34, "062723": 27, "062792": 28, "063004": 37, "063110": [29, 30], "063173": 36, "064": [32, 36], "06405": 32, "064050": 32, "064200": 28, "064307": 37, "064452": 28, "065": 42, "065169": 32, "065199": 33, "065449": 34, "065463": 33, "066166": 44, "066251": 27, "066605": 32, "066667": 29, "0667579112160865": 31, "066810": 44, "066944": 32, "067119": 29, "067120": 27, "06797961": 34, "067991": 29, "068": 25, "068214": [31, 32], "068291": 42, "068498": 32, "068775": 32, "068891": 32, "069150": 36, "06915047": 36, "069188": 44, "0694": [28, 32], "069530": 28, "07": [32, 34, 37, 43, 44, 54], "070081": 32, "070195": 32, "070850": 33, "070898": 32, "070907": 27, "070929": 33, "071": 42, "071330": [43, 54], "071541": [29, 30], "071654": 37, "07174469222": 34, "071745": 36, "071975": 37, "072": 35, "072043": 32, "072243": 36, "0723": 29, "072396": 32, "07245741": 34, "072595": 32, "072707": 27, "073058": 29, "073233": 31, "073366": 29, "074": [29, 35], "0741": 28, "074141": 28, "07418": 32, "074327": 35, "074418": 42, "074475": 29, "074719": 30, "07471942": 30, "075000": 40, "075170": 43, "075453": 44, "075467": 44, "075747": 32, "076104": 34, "0762": 29, "076284": 38, "07639": 32, "076533": 34, "076798": 28, "077": [35, 42], "077204": 36, "077761": 44, "077803": 32, "078": [31, 35], "0780": [26, 27, 48], "078052": 33, "07808506982896266": 34, "078243": 32, "078387": 44, "078552": 32, "078740": 32, "07877994e": 46, "078880": 30, "079": 32, "079282": 32, "079377": 44, "0794": [28, 32], "079471e": 34, "079852e": 34, "08": [29, 32, 34, 37, 39, 42, 43, 44, 54], "080": 42, "08002986030": 30, "080084": 32, "080165": 32, "080319": 30, "08031924": 30, "080694": 36, "080734": 27, "0808": 32, "081": 25, "08116": 32, "081167": 44, "081292": 43, "08151507e": 36, "081837": 44, "082": 29, "082100": 32, "082251": 31, "082265e": 44, "082749": 28, "082835": 36, "082949": 28, "083": [28, 32, 35], "083123": [29, 30], "083338": 27, "083545": 33, "083615": 32, "083813": [29, 30], "084288": 32, "084746": [29, 30], "085150": 43, "085415": 36, "085477": 33, "085508": 34, "085546": 34, "085550": 34, "085551": 34, "085693": 32, "085698": 34, "08613": 32, "086461": 37, "086932": 27, "087": 30, "087128": 32, "087668": 32, "087996e": 32, "088": 42, "0880": 29, "088543": 32, "088948": 28, "089294": 32, "089313": 32, "089485": 27, "09": [27, 30, 32, 34, 43, 44, 54], "090000": 33, "09009799": 34, "090231": 36, "090376e": 34, "090453": 33, "090473": 32, "09058097218": 25, "090785": 34, "091": 42, "091243": 32, "091625": 37, "091819": 27, "092": 35, "092072": 32, "092123": 32, "0922": [28, 32], "092204": 27, "09245358900622544": 32, "092454": 32, "092604": 27, "092660": 44, "092670": 32, "092729": 32, "092930": 30, "093051": 32, "0931": 32, "093228": 37, "093390": 28, "09345386": 30, "093454": 30, "093624": 27, "093787": 32, "093893": 32, "094": 25, "094290": 44, "09430199": 30, "094302": 30, "094581": 30, "094586": 33, "094725": 32, "094863": 32, "095018": 32, "09503409246217484": 34, "095177": 32, "095345": 32, "09573445": 32, "096462": 34, "096692": 29, "096722": 32, "096858": 32, "096927": 33, "096960": 34, "096990": 27, "096997": 42, "097": 42, "09706504": 42, "097088": 44, "097184": 32, "097293": [29, 30], "097516": 29, "097707": 32, "097763": 32, "098": [31, 42], "098152": 32, "098307": 34, "098326": [28, 42], "098559": 32, "098629e": 32, "098663": 32, "0989147678053208": 31, "098915": 31, "098950": 32, "098966": 29, "099": 35, "099230": 36, "099240": [29, 30], "099454": 32, "099558": [29, 30], "099685": 34, "099723": 29, "099729": 32, "099749": [43, 54], "099802": 32, "099869": 32, "0x1227a36e0": 8, "0x1577111f0": 32, "0x16888d4c0": 32, "0x168921100": 32, "1": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 36, 41, 43, 45, 46, 55], "10": [4, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55], "100": [26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 51, 54], "1000": [27, 28, 30, 31, 32, 33, 34, 36, 37, 42, 43, 44, 45, 46, 51, 52], "10000": [26, 30, 31, 32, 34, 43, 54], "100000": [28, 30, 31, 32, 34, 43, 54], "1000000": 32, "100103": 43, "100105": 32, "100139": 30, "100146": 43, "100248": 28, "100275": 37, "1004": 28, "1005": [43, 54], "1006": [43, 54], "1007": [43, 54], "1008": [43, 54], "100882": 33, "1009": [43, 54], "10092665203438746": 34, "101": [9, 10, 38, 42, 44], "1010": [43, 54], "1012": [43, 54], "101259": 34, "1014": [32, 42], "1015": [42, 43, 54], "1016": [42, 43], "101688": 32, "1017": [42, 43, 54], "101796": 34, "1018": [42, 43, 54], "101810": 27, "101832": 32, "101894": 33, "1019": [42, 43, 54], "102": [33, 34, 53], "1020": [32, 37, 42, 43, 54], "102044": 37, "1021": [42, 43, 54], "102135": 33, "1022": [42, 43, 54], "1023": [42, 43, 54], "1024": [30, 42, 43], "102435": [28, 34], "102474": 30, "10247431": 30, "1025": [43, 54], "10254": 43, "1026": [31, 43], "1027": [43, 54], "10273": 34, "10274": 33, "1028": [43, 54], "1029": [43, 54], "103": 44, "103023": 32, "1031": 43, "103219": 37, "103222": 42, "1034": 37, "103439": 30, "1039": [43, 54], "104": [28, 29, 35, 38, 42], "1040": 29, "104070": 34, "1041": [34, 36, 43, 45, 54], "10416666666666667": 40, "1042": 32, "1044": 25, "104596": 32, "104643": 34, "105": 35, "1050": 26, "105080": 37, "105089": 30, "10513": 43, "1053": 45, "105314": 43, "10556679": 38, "105656": 36, "10584063": 42, "106000": 29, "106023": 34, "106112": 43, "106180": 43, "106319": 43, "106322": 43, "106424": 43, "106452": 28, "10645223": 28, "10653": [43, 54], "106705": 43, "106764": 32, "1068": 45, "106816": 43, "1069": 45, "106996": 32, "107": 35, "1070": 37, "107050": 43, "107292": 43, "1075": 45, "107502": [43, 54], "1076": 30, "107718": 32, "10781": [35, 36], "107917": [43, 54], "10793260e": 42, "107947": 34, "107985": 34, "107991": 33, "108": 25, "1080": 25, "10800": 25, "1085": 31, "10868": 43, "108681": 28, "1089": 34, "10910": 43, "10931": 30, "109526": 33, "1099": 34, "10_000": 44, "10th": [32, 33, 35, 36, 52], "10x": 33, "11": [1, 10, 11, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 47, 49, 54, 55], "110": [31, 42], "110316": [43, 54], "110319": [43, 54], "1104": 28, "11057": 43, "1106": 37, "110645": 34, "110915e": 34, "111": [29, 32, 33, 34, 44, 52], "11121453": 38, "111215": 38, "111220": 43, "111438": 37, "111543": 34, "112": 28, "1122": [34, 36, 45], "1123": [32, 45], "112441": 32, "112490": 32, "112527": 36, "112848": 34, "11331": 45, "11336331e": 36, "113600": [29, 30, 50], "1138": 37, "113837": 34, "1139": [34, 36], "113949e": 44, "114": 29, "1140": [25, 34, 36], "114000": [29, 37], "114079": 32, "114214": 32, "114507": 42, "11457": [34, 36], "114766": 36, "114836": 37, "114966": 36, "115": 30, "1150": 25, "115083": 29, "115089": 43, "11509": 34, "115090": 43, "115091": 43, "115092": 43, "115183": 32, "115276": 44, "115401": 34, "115406": 28, "115428": [43, 54], "115956": 31, "116": 29, "116145": 37, "116167": 31, "116443": 37, "116497": 34, "11664": 45, "11693": 34, "117": [29, 30, 31, 37, 50], "117058": 31, "117379": 32, "117380": 29, "117412": 34, "117528": 37, "11758": [43, 54], "117612": 42, "117712": 43, "117816": 29, "117899e": 34, "1179": 29, "118": [29, 30, 31, 34, 36, 37], "1180": 26, "118182": [29, 30], "118347": 34, "118450": 33, "118563": 37, "11886432": 32, "118874": 34, "118934": 33, "11898": 33, "119": [29, 30, 31, 37, 43, 50, 54], "1190": 29, "119049": [43, 54], "11909976": 38, "119100": 38, "119400": 29, "119570": 37, "119911": [43, 54], "11th": [33, 35, 36, 52], "12": [10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55], "120": [28, 29, 31, 34, 35, 42, 43, 46], "1204": 28, "120769e": 34, "121": [25, 29, 30, 31, 32, 35, 37, 43], "1210": 32, "121056e": 34, "121084e": 34, "121351": 36, "12138": 29, "1214": 34, "121438": 44, "12150684": 31, "121531": 33, "121599": 36, "121628": 28, "1217": 44, "12178": 37, "121846": 36, "121985": 34, "122": [25, 26, 27, 29, 30, 37, 42, 48, 53], "1220": [25, 29, 32], "1222": 32, "122307": [29, 30], "122331": 34, "12266": 41, "122668": 32, "123": [4, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "123367": 34, "1235387316046016": 32, "123539": 32, "124": 29, "1240": 25, "1241": [34, 37], "1243": 29, "12436984": 30, "124370": 30, "1247": 32, "12498": 36, "124982": 37, "125": [8, 34], "1250": [29, 30, 50], "12508": [34, 36], "125440e": 34, "125476": 28, "125523": [43, 54], "1256": 46, "125617": [43, 54], "125644": 34, "1258": 44, "126": 37, "126238": 37, "126398": [29, 30], "126488": 38, "12649": 29, "126500": 29, "126563": 32, "126808": [29, 30], "127": [27, 29, 31, 32], "127086": 29, "127087": 44, "1271": 35, "127107": 36, "127226": 30, "127242": 34, "1273": 36, "127326": 34, "1274": 37, "127418": 34, "127439": 34, "127441": 34, "127614": 34, "12761659": 34, "127878": 28, "1279": 34, "128": 45, "1280": [29, 32, 34], "1281": 34, "128188": [29, 30], "128384": 34, "128528": 34, "128820": 43, "128828": 43, "128829": 43, "128830": 43, "128984": 34, "129": [28, 31, 37, 44, 53], "1290": [29, 30], "12906": 25, "129257": 34, "12927": 25, "129300": [29, 30, 50], "129459": 37, "129600": 34, "129900": 33, "129904": 34, "129985": 29, "12th": [33, 35, 36, 52], "13": [8, 10, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 43, 44, 45, 47, 50, 54], "130": [25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 48, 50], "1300": [34, 36], "1302": 33, "130395": [43, 54], "1304": [28, 44], "130432": [43, 54], "130690e": 34, "1307": 34, "131": [29, 35, 43, 44], "131000": 34, "13107": 43, "131275": 33, "1313": 34, "1314": [34, 36], "131607": [34, 36], "131773": 44, "1319796954314723": 35, "132": 44, "1320": 37, "1321": 25, "132158": 34, "132292": 37, "13229595e": 36, "13255": 43, "132875": [29, 30], "132886": 43, "133": [32, 44], "133000": 34, "133210": 32, "133270": 34, "133337": 34, "133562": 44, "13392236": 42, "134": [26, 27, 30, 31, 48], "1340": 26, "134061": 37, "13407": 36, "134287": 33, "1346": [29, 34, 36, 37, 44, 45], "134615": 31, "134658": 29, "1347": 45, "134894": [43, 54], "135": [43, 44, 54], "135134": [43, 54], "135197": [43, 54], "13521135": 36, "135299": 37, "135305": [29, 30], "135384": 34, "135422": 34, "1357": 25, "136": [29, 30], "1360": 26, "13665": [29, 30, 50], "136714": 33, "1370": [25, 28, 32, 44], "13704": [34, 36], "137410": 38, "137500": [29, 30, 50], "1378": 34, "138": 45, "1380": 25, "138103": 42, "1383": 32, "138503": 37, "138528": 31, "138876": 44, "1389": [29, 34, 36], "139": [29, 45], "1390": 25, "139297": 33, "139317": 33, "139322": 33, "139349": 33, "13941": 33, "139554": 33, "1396": 32, "1397": 32, "14": [10, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 39, 40, 42, 43, 44, 47, 54], "140": 29, "140185": 37, "1404": [28, 44], "1405": 37, "1406": [29, 34, 36], "140641": [43, 54], "140953": [43, 54], "141": [29, 31], "141232": [43, 54], "14159265358979323": 8, "14160": 33, "141851": [43, 54], "142": 35, "142193": [43, 54], "142199": [43, 54], "1423": 33, "142398": [43, 54], "142467": 27, "142806": [43, 54], "142857": 30, "14289": [29, 30, 50], "143": [32, 33], "143693": [43, 54], "143803": 37, "1438387200": 43, "1438398000": 43, "1438408800": 43, "1438419600": 43, "1438430400": 43, "1438441200": 43, "1438452000": 43, "1438462800": 43, "1438473600": 43, "1438484400": 43, "143975": [43, 54], "144": [25, 32], "144000": [34, 36], "1441": 45, "144199": [43, 54], "144686": 36, "14471": [29, 30, 50], "144729": 43, "144730": 43, "144731": 43, "144732": 43, "144733": [43, 54], "144750": 28, "14485": 34, "145": [43, 54], "1452": 37, "145425": 34, "145454": [43, 54], "145455": [43, 54], "145456": [43, 54], "145457": [43, 54], "145458": [43, 54], "145459": [43, 54], "145460": [43, 54], "1457": [29, 30, 44, 50], "14579": 37, "1458": [29, 30, 50], "145833": 40, "146": [25, 35], "1460": [34, 44], "1465": [29, 30, 50], "146656": [43, 54], "1467": 37, "146767": [33, 36], "146809": 33, "146830": 33, "14690": 30, "147": 36, "147166": [35, 36], "14716638": 36, "147641": 34, "1477": 45, "147737": 42, "147893": 29, "147898": 33, "148": [28, 32, 36, 46], "14813": 43, "148141": 35, "148343": 34, "148349": 44, "14841": 33, "149": 44, "14970": 29, "149788": 36, "149822": [29, 30], "14999": 29, "15": [8, 10, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 43, 44, 45, 47, 48, 52, 54], "150": [28, 32, 34, 42], "150000": [33, 40], "150115": 32, "15026771": 34, "150395": 28, "1504": 28, "1505": 29, "150mb": 33, "150p": 25, "151357": 37, "152": 43, "1520": 32, "152401": 33, "152859": 33, "1530": 25, "1534": 29, "15377": [29, 37], "1540": 25, "154076": [33, 36], "154105": 37, "15429": 43, "154386": [29, 30], "1545": 37, "154795": [34, 36], "154842": 44, "155": [25, 32], "15500": 34, "155178e": 34, "15559528e": 36, "155624": 34, "156": [29, 32, 33], "1562": 32, "156311e": 34, "1564": 32, "15661": 43, "157": [25, 32, 42], "157008": 34, "157157": 45, "157234": 37, "15725": [29, 37], "15775": 43, "1578": 36, "15795": [33, 36], "158": 32, "1580": 25, "1582": 36, "158867": [43, 54], "158982": 34, "159": 32, "1590": [28, 32], "15915": 43, "15992": 36, "16": [10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 43, 44, 45, 47, 48, 54], "160": [27, 28, 31, 32, 34, 36], "160000": [34, 36], "160258": 27, "160282": 37, "1604": 28, "160506": 33, "160634": 42, "16063983": 30, "160640": 30, "160727": 36, "160729": [43, 54], "161": 29, "1610243052583638": 31, "16111330565237164": 31, "1613": 29, "16153": 43, "16157": 43, "16160": 43, "161606": [29, 30], "161782": 33, "1619": 32, "161931": [34, 36], "162": 25, "162000": 34, "162007": 45, "162330": 33, "162667": [33, 36], "1627": 37, "162904": 44, "1631": 32, "163195": [29, 30], "163397": [29, 30], "1634": [29, 30, 32, 50], "16358": 43, "164": [37, 42], "1645": 31, "16460": 37, "164679": 33, "165": [31, 34], "1650": [28, 32], "16507": [31, 37], "16508": [31, 37], "16509": [31, 37], "16510": [31, 37], "16511": [31, 37], "16512": [31, 37], "165198e": 34, "1652": [27, 31], "16533": 43, "165485": 36, "165617": 43, "165811": 32, "16630": 37, "166631": [29, 30], "167": 27, "167214": 28, "167241": 45, "16736": 41, "167600": 37, "167620": 42, "168": 34, "1680": 26, "168151": 42, "168196": [29, 30], "168244": 36, "1687": 32, "169": [27, 31, 37], "1690": [25, 26], "169269e": 44, "169421": 32, "169693": 28, "169748": 31, "16991815": 8, "1699181533555938": 8, "17": [4, 8, 10, 26, 28, 29, 30, 31, 32, 33, 34, 37, 43, 44, 47, 50, 54], "170": [29, 39], "170100": [29, 30, 50], "170277": [35, 36], "1704": 28, "17054987": 42, "170670": 34, "170931": 42, "171": [25, 42], "17144": 43, "171468": [34, 36], "1715": 32, "171657": 27, "171899": 44, "1720": 29, "17205": 43, "172792": 33, "173": [28, 32], "173025": 32, "17393037": 8, "1739787032867638": 32, "173979": 32, "174": [25, 28, 32], "174590": 33, "174766": 37, "1750": 29, "175000": [34, 36], "17518": 43, "176": 29, "1766": 34, "176924": 44, "177": 37, "17730": [29, 37], "177709": 44, "178": [25, 34], "178494": 34, "17896": 43, "179": [35, 44], "179080": 33, "179123": 28, "179300": 29, "179730": 32, "17973005068132514": 32, "179802": 34, "18": [10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 43, 44, 45, 47, 50, 54], "180": [32, 34, 42], "1800": [25, 26, 28, 32], "18000": 43, "180000": 26, "180279e": 34, "180388": 28, "1804": 28, "180900": 37, "18096": 43, "181": 44, "18113": 43, "18116": 43, "1813": 32, "182": [43, 44], "18201414": 36, "18245": 43, "182639": 34, "182648": 34, "18311": 43, "18313": 43, "18317085": 8, "183179": 44, "183423": 28, "183471e": 34, "18365": 30, "18391": [29, 30], "184": [43, 44], "1840": 25, "184405": 36, "1847": 30, "185": 44, "185155": 36, "185175": 44, "18533": 43, "1854": 32, "185707": [28, 32], "18571": [29, 30], "18572": [29, 30], "18573": [29, 30], "18574": [29, 30], "18575": [29, 30], "18576": [29, 30], "1858": 37, "185868": 37, "185975": 36, "18597545": 36, "186024": 25, "186814": 33, "186899": 33, "187": [27, 31, 35], "1870": 32, "187000": 29, "1872": 34, "1875": 31, "187503": 43, "187663": 28, "187700": 29, "188": [25, 27, 31], "1880": 32, "1886": 31, "1887": [33, 36], "18955": 43, "189981": 34, "19": [8, 10, 25, 26, 27, 28, 30, 32, 33, 34, 37, 40, 44, 45, 47, 54], "190": [27, 34, 37], "19000e": 28, "1901": 25, "190319": 37, "19032": 43, "1904": 28, "190617": [29, 30], "191": [27, 29], "1911": 37, "191169": [34, 36], "191204": 37, "191250": 27, "191396": 28, "191700": 37, "1918": 30, "191k": 36, "1920": 25, "19213263": 30, "192133": 30, "19266": 43, "1927": 45, "1928": 45, "193": 42, "1930": 25, "193021": 33, "193122": 33, "193247": 37, "1933": 26, "193346": 36, "193427": 32, "19365": 43, "193704": [43, 54], "19380": 43, "1940": 30, "194002": 28, "194034": [43, 54], "194040": 29, "19422": 36, "1945": 34, "1946": [25, 34], "194710": 34, "19485": 29, "194985": 34, "195": 29, "1950": 34, "1951": 26, "195228": 30, "1953": [32, 34], "19536": 33, "1954": 41, "1955": 26, "195564": 37, "1957": 41, "1959": 25, "19591": 37, "1960": 26, "1963": 32, "196385": 36, "1965": 26, "196599": 34, "1966": 34, "196717": 42, "196739": 43, "1968": 25, "1970": [31, 34, 43], "1972": 34, "197649": 37, "1977": [25, 44], "19777": [35, 36], "19781": 43, "198": [42, 45], "198127": 34, "1984": 34, "1985": 34, "198629": 42, "198645": 44, "1987": [25, 26], "1989": 25, "198924": [29, 30], "199": [25, 28, 33], "1990": [28, 31, 32], "1991": [26, 35], "1992": [43, 45], "1993": 34, "199364": 33, "1994": 25, "199412": 44, "199413": [28, 32], "19966": [29, 30, 37], "1997": [31, 32], "199771": 36, "1_000_000_000": 32, "1d": 42, "1e": [32, 34, 51], "1e3": [32, 51], "1e4": 32, "1h": [29, 30, 37], "1st": [8, 33, 35, 36, 43, 52], "1stflrsf": [34, 36], "1v": 46, "1v2": 46, "1v3": 46, "2": [4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 35, 36, 37, 41, 42, 43, 45, 46, 55], "20": [4, 8, 10, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 43, 45, 46, 47, 49, 50, 54, 55], "200": [25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 42, 48, 49, 50, 51, 52], "2000": [28, 32, 33, 34, 35, 36, 37, 42, 46, 51], "200000": [32, 43, 54], "200326e": 34, "2004": 34, "200475": 33, "2006": [34, 36], "2007": [34, 36, 43, 54], "2008": [34, 36, 43, 54], "200876": 30, "20087625": 30, "2009": [34, 36, 43], "200978": 28, "200k": 52, "201": [28, 55], "2010": [34, 36, 43], "20113": [29, 30, 50], "2012": [8, 29, 32], "2013": [41, 43, 54], "201332": 39, "2014": [25, 35, 43], "2015": [42, 43, 54], "20150630": [43, 54], "2016": [8, 42, 43], "20160101": 43, "2017": [36, 43, 54], "201810": 33, "201862": 37, "202": [28, 30], "2020": 45, "2022": 43, "2023": [10, 43], "2024": [0, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54], "20248": 29, "2024w1": 42, "2025": 1, "2025s1": [0, 11], "20274": 43, "202839": 33, "203": 28, "20310": 43, "20311": 37, "20319": 43, "203265": 36, "20334": 43, "203421": 34, "203500": 29, "20357847293371892": 31, "204": [26, 27, 28, 32, 48], "204167": 27, "2043": 44, "204302": [43, 54], "20433": 37, "204583": 27, "2046": 30, "204600": [28, 32], "204692": 34, "204734": 33, "20485": 43, "205": [26, 27, 28, 45, 48], "205000": [29, 30, 34, 36, 50], "205059": 37, "20509": 43, "20514": 43, "205144": 37, "205323": [43, 54], "205479": 31, "205597": 34, "20564": 43, "206": [26, 27, 28, 32, 33, 48], "206041": 36, "206073": 33, "206099": 32, "20620": 43, "206292": 29, "20639": 37, "2064": 29, "20640": [31, 37], "206724": 44, "20683258": 31, "20694": 43, "207": [26, 27, 28, 29, 32, 42, 48], "207039e": 34, "2071": 37, "207814e": 34, "20794": 43, "208": [26, 27, 28, 31, 32, 48], "209": [25, 26, 27, 28, 32, 48], "209583": 27, "209746": 33, "209903": 37, "20analysi": 44, "20assumpt": 44, "20hazard": 44, "20intro": 44, "20learn": 42, "20lifelin": 44, "20with": 44, "21": [10, 25, 26, 28, 29, 30, 33, 34, 37, 38, 40, 43, 45, 54], "210": 32, "210001": 33, "210240": 32, "210272": 37, "210591": [29, 30], "210779": 43, "21086181023099526": 31, "211": 32, "2110": 29, "211250": 27, "211343": 37, "211544": 33, "211892": [29, 30], "212": [27, 32], "212385": 36, "212581": 37, "21274": 43, "212870": 34, "212975": 34, "213": [32, 42, 43], "2130": 25, "21353": 43, "21382972": 35, "21389": 43, "2139": [29, 30, 50], "214": [25, 30, 32], "21405": 43, "2144": 32, "214740": 29, "214769": 42, "214821": 43, "214852": 33, "215": 32, "215245": 34, "21530": 43, "215412": 34, "21549": 43, "21571": 43, "21581": 43, "215865": 36, "21596": 43, "216": 32, "21603": 43, "21605": 43, "216123": 44, "21613": 26, "21616484": 46, "21617": 43, "216346": 36, "21634631": 36, "216585": 29, "216596": [43, 54], "21668": 43, "21670": 43, "216718": 33, "216728": 29, "21694": 43, "21697": 43, "2170": 26, "217334": 30, "21733442": 30, "21767954": 36, "21768": [36, 43], "217680": [35, 36], "21774": 43, "218207": [29, 30], "21847": 43, "21872": [34, 36], "218760": 36, "218830": 29, "219": 37, "2190": 29, "2192": 32, "219512": 37, "219700": 37, "219845e": 34, "22": [10, 28, 29, 30, 32, 33, 34, 35, 36, 37, 43, 44, 45, 46, 50, 54, 55], "220": 27, "22001": 36, "220392": 44, "22057": 43, "2206": 44, "22078": 43, "2210": 25, "22114": 43, "221329": 34, "221348": [43, 54], "2214": 45, "22154": 43, "221622": [29, 30], "22168237": 46, "221900": 26, "22219": 43, "22221894": 34, "222222": 29, "22225": 43, "222307": 29, "222500": 27, "22260": 43, "222647": [34, 36], "2229": 31, "222963e": 34, "22305705": 35, "22320": 43, "223333": 27, "223460": 44, "223750": 27, "223804": 36, "224": [32, 42], "22452": 43, "2246468746": 27, "224662": 34, "22471154513694713": 31, "224865": [34, 36], "225": 42, "225301e": 34, "2254": 29, "22550": 43, "226": 32, "226415": 29, "226789": 44, "2268": 35, "22697768": 30, "226978": 30, "2270": 32, "227143": 29, "2272": 33, "227304": 43, "22741": 37, "227559": [34, 36], "227836": 33, "22788": 43, "22811601": 31, "22826": 43, "228329": 33, "2285": 43, "228603": 34, "228750": 27, "229": 42, "229000": 29, "22910": 43, "229102": 36, "2293467570951035": 35, "2295": 43, "229583": 27, "229718": 36, "22974": 41, "23": [10, 28, 29, 30, 31, 32, 33, 34, 37, 43, 44, 50, 54], "230": [28, 32], "2300": 25, "23011": 36, "2305": 36, "2307": [27, 31], "2309": 43, "23091772": 35, "2310": 43, "2311": 43, "2312": 43, "2313": 43, "23175": 43, "231815": 36, "232143": 30, "232751": 44, "23290": 43, "233": 26, "234": 44, "234040": 33, "234436": 44, "235": 37, "235096": [29, 30], "235152": 28, "235417": 27, "235706": 37, "236": [28, 32, 44], "236096": 42, "236174": 37, "236210": 38, "23621041": 38, "23640124": 31, "236456": 29, "23654": [33, 36], "236960": 32, "237": [33, 44], "237895": 33, "237935": 36, "238": [33, 44], "238192": [33, 36], "2389": 30, "239": 44, "23902": 43, "23941": 43, "239944e": 34, "24": [1, 11, 25, 28, 29, 33, 34, 35, 36, 37, 42, 43, 44, 54], "240": 44, "2401": 37, "240893": 37, "241": 44, "241489": 44, "241620": 33, "24182": 43, "242015": [35, 36], "242083": 27, "242169": 33, "242381": 43, "24295676": 30, "242957": 30, "242996": [29, 30], "243": 43, "243243": 34, "2435": 37, "2436": 37, "24395": [35, 36], "24397122221206388": 43, "244": 43, "244592": 28, "2447": 35, "244814": 44, "245": 43, "2451": 32, "245329": 34, "245521": 33, "245686": 33, "246": 43, "246332": 34, "246646": 32, "246646103936": 32, "246653": 32, "247": 43, "247119": 43, "247439": 38, "24743939": 38, "247690828913": 32, "247691": 32, "248": 43, "248328": 35, "248333": 27, "2484": 25, "248457": [34, 36], "248609": 34, "248664": 37, "2488": 28, "248999": 44, "249": 45, "2496": [27, 31], "249601e": 34, "249618e": 34, "249720": 28, "24h": 33, "25": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55], "2500": [8, 45], "250000": [29, 33, 34], "25031": 43, "25037": 43, "2506": [26, 27, 48], "250900": 34, "251093": 32, "251158e": 34, "2516": 35, "25176": 43, "251769": 42, "252042": 37, "25214": 43, "252160": 28, "252859": 36, "2530": 25, "2533": [27, 31], "253312": [29, 30], "253432": 36, "253724": 28, "253914": 34, "254380": 44, "254443": 33, "255": 29, "2551": 45, "255134": 42, "2556": 35, "255751": 37, "255889": [43, 54], "256": [25, 42], "25622": 43, "256263": [35, 36], "256333": 29, "256437": 37, "25658": 37, "256813": 28, "257": 26, "2570": [25, 26], "257024": 32, "257103": 33, "2574": 37, "2580": 25, "258225": 43, "25823": 33, "258387": 36, "258427": 28, "258886": 33, "259": [34, 37], "25904": 43, "2590575478171884": 31, "259286": 28, "259500": 29, "26": [8, 10, 25, 28, 29, 32, 33, 34, 35, 36, 37, 38, 43, 44, 54], "2600": [29, 30, 50], "260258": 37, "26048": 36, "260572": 34, "26063": 43, "260890": [34, 36], "261035": 34, "261953": [43, 54], "262": [34, 36, 44], "262079e": 34, "262156e": 34, "262269e": 34, "2623": 34, "262361": 37, "262500": 34, "263": 34, "2630": 29, "26307": 41, "263541": 44, "263600": 29, "26370005": 31, "263736": 44, "263742e": 34, "26376": 43, "264195": 44, "264283e": 34, "26447953": 30, "264480": 30, "265": 35, "265273": 31, "266120": [43, 54], "266135": [29, 30], "2670": 32, "267612e": 34, "268": 32, "2683": 33, "26831": 43, "2691": [26, 27, 48], "26919": 37, "269689": 33, "269880": 28, "269972": [34, 36], "27": [8, 28, 30, 32, 33, 34, 43, 44, 54], "270093": 32, "270093376167": 32, "27021": 43, "270270": 40, "27048": 33, "2705": 32, "271037": 37, "271287": 43, "271500": 37, "271738e": 34, "2720": 26, "27206": 43, "27263": 36, "272667": [29, 30], "2730": 29, "273382": [29, 30], "273606": [29, 30], "273890": 42, "273962": 37, "274": [29, 30, 43, 50], "274404": 29, "275008": [43, 54], "27502379069": 34, "275290": 33, "275352": 28, "275410": 31, "2759": 36, "276": 29, "27638": 43, "27652": 33, "276687": 34, "27676": 33, "27678": 33, "276943e": 34, "27697": 33, "2770": 32, "27705": 33, "27715": 33, "277381": 28, "2777": 44, "278441": [43, 54], "278634": 33, "27874871715903093": 31, "278755": 30, "27875502": 30, "2788": [27, 31], "2794": 31, "28": [10, 28, 29, 30, 31, 32, 33, 34, 37, 38, 43, 44, 54], "280": [29, 37, 45], "2800": 8, "280028": 37, "280310": [29, 30], "2806": 32, "280618": 33, "2807": 44, "280801": 44, "281": 29, "28122025543": 34, "281583": 34, "2817": 36, "2820": 32, "282021e": 34, "2822": 36, "282600": 44, "283119e": 34, "28327": 43, "283421": 34, "2836": 36, "28362": 43, "283857": 28, "283921": 29, "284": [37, 43], "2845": 44, "2846": 45, "2847": 45, "285": [29, 30, 43, 50], "285263": 36, "28526302": 36, "285467": [34, 36], "28571429": 26, "286": [27, 28, 32, 43], "286000": 32, "286200": 37, "286416": 30, "2865025": 46, "286821": 28, "287": 43, "287031": [43, 54], "287079e": 34, "287344": [29, 30], "287500": 37, "288": 43, "288002": [43, 54], "288462": 31, "28854": 43, "28868": 33, "289": 43, "2890": [28, 32], "28953": 43, "289541": [34, 36], "289799": 28, "29": [8, 28, 29, 33, 34, 43, 44, 45, 54], "290": 43, "290002": 33, "290424": 34, "29045704": 34, "290961e": 34, "291": [31, 43], "291667": 40, "292": 43, "292587": 44, "293": 43, "29324459": 42, "293663": 33, "294": [29, 41], "294251": 30, "2948": [29, 30, 50], "294855": 36, "2953863599856862": 31, "295397": 33, "29545": 34, "296": [29, 45], "296601": 37, "29691": 43, "297": 31, "29802": [33, 36], "298561": 44, "298612": [43, 54], "29881": 43, "298813": 33, "299": 42, "299164": 37, "2d": 42, "2d454e5fd9a5": 44, "2e": 10, "2f": [27, 32, 40, 43], "2nd": 31, "2ndflrsf": [34, 36], "2v": 46, "2v3": 46, "3": [7, 8, 10, 11, 14, 16, 17, 18, 28, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 55], "30": [4, 10, 25, 27, 28, 31, 33, 34, 35, 36, 37, 43, 44, 45, 54, 55], "300": [28, 39, 41, 46], "3000": 42, "300000": [29, 30, 43, 54], "300464": 37, "300837": 33, "301": 44, "3010": 37, "301200": 32, "3014": 37, "30146": 43, "301563": 34, "30167": 43, "301784": 44, "3019": [26, 27, 31, 48], "301952": 37, "302": [34, 36], "302131": 34, "30279": 43, "302801": 44, "302844": 44, "303": [34, 36], "303000": 29, "303004": 37, "303030": 31, "303109": 30, "303790": 32, "3038": 45, "3038344082": 36, "303916": 28, "304": 28, "3040": 43, "3041": 43, "3042": 43, "3043": 43, "3044": 43, "304784": 34, "305": 25, "30504657": 38, "305047": 38, "30530902": 28, "305346": 28, "305674": 37, "3057": [27, 31], "30573": 37, "306": 45, "306500": 28, "306564": 42, "307": 29, "3075": 45, "307516": 42, "307521": 31, "308120": 29, "30815": 34, "308216": 42, "308220": 33, "308448": 28, "3089": 32, "309": 37, "3092": [26, 27, 48], "309249": 42, "309859": 31, "31": [10, 25, 28, 29, 30, 31, 33, 34, 35, 36, 38, 43, 44, 45, 50, 54], "310": 55, "310000": 29, "31000e": 28, "310284": 36, "310405": 33, "311": 29, "3110": 29, "311151": 44, "31127015": 36, "311310": 25, "311769": 37, "31196406381465247": 31, "3120": 29, "3125": 29, "312500": 40, "312501": [34, 36], "312696": 45, "3129": 45, "31297381": 30, "312974": 30, "31298589e": 42, "313": [30, 34], "3130": 45, "31384": 33, "314": 29, "3140": 29, "314000": 32, "31449687e": 36, "31454": 37, "314582": 36, "314840": 37, "314929": [43, 54], "315134": [43, 54], "315630": 33, "316164": 37, "316230": 37, "316363": 28, "316395e": 34, "316426": 37, "316552": 30, "31655231": 30, "316798": 37, "317": [29, 36], "317277": 37, "317761": 33, "318": 29, "3180": 32, "3180174485124284": 29, "318937": [29, 30], "319": [26, 29], "31908384": 42, "319630": 44, "31984311": 34, "31st": 43, "32": [8, 28, 29, 30, 31, 32, 34, 38, 43, 44, 50, 54], "320": 29, "320155": 33, "320430": 34, "32064171": 35, "321": 36, "32127053": 34, "322": 37, "32240": [35, 36], "32247597e": 36, "322755": 28, "323045": [29, 30], "32323": 25, "32397724e": 36, "3245": 25, "3252": 37, "325319": 37, "32561": 33, "326": [29, 37], "326730": 33, "326741e": 44, "326933": [28, 32], "327188": 33, "3272": 44, "327283": 34, "32734": 37, "3274": 44, "327408": 33, "328": 37, "328077e": 34, "328799": 33, "328953": 28, "3298721": 42, "3299": 45, "33": [8, 25, 28, 29, 30, 31, 32, 33, 34, 37, 43, 44, 54], "330": [9, 10, 11, 25, 26, 42, 43, 45, 55], "33000e": 28, "330346": 44, "3310": 29, "332125": 33, "332130": 34, "332671": 36, "3327": 43, "332710": 34, "332746": 44, "332791": 44, "332824": 34, "3330": 29, "33308783": 30, "333088": 30, "333139": 33, "333333": [26, 29, 32, 40], "3333333333333333": [40, 42], "333340": 28, "3334": 45, "334": 37, "334411": 28, "334576": 34, "335": 35, "335309": 34, "3355": [29, 30, 50], "3356700488_183566145b": 42, "33590": 43, "336389": 36, "33641142": 36, "3364114233677307": 36, "336411423367732": 36, "336735": 32, "336826": 30, "33682642": 30, "33683087": 31, "336831": 31, "337034": 37, "33726089": 34, "338": [28, 32], "33888659": 8, "339": 33, "339368": 44, "339889": 44, "34": [25, 28, 29, 30, 31, 33, 34, 37, 43, 44, 50], "340": [3, 10, 26, 35, 37, 42, 43, 44], "34000e": 28, "340988": 33, "341109": 34, "341300": 37, "341571": 44, "34161762": [34, 36], "341712": [43, 54], "34182": 36, "3420": 29, "342200": 37, "342605e": 34, "3436": [43, 54], "3437": 45, "3438": 45, "344": 29, "3442": 44, "34426571": 34, "34441": 34, "345": 36, "345136": 28, "345386e": 34, "3454": [44, 45], "3455": 45, "345831": 25, "346": [29, 30, 50], "346850": 33, "34691": 43, "347523": 32, "348": [29, 37], "34806": 34, "34900": 34, "35": [28, 29, 31, 33, 34, 35, 36, 43, 44, 45, 49, 53, 54], "350": 25, "3500": 49, "350000": 29, "351351": 40, "351366": 33, "3515": 44, "3517": 45, "351821": 44, "3520": 44, "3521": 25, "352100": 37, "352930": [29, 30], "353": 42, "35375221": 46, "353961": 32, "354114": [34, 36], "354604": 33, "3547": 37, "354759e": 34, "356689": [35, 36], "35671794": 36, "357": 29, "357500": [29, 30], "3576": 25, "3577": 45, "357823": 25, "358": [25, 32], "358032": 36, "3582": [44, 45], "358264": [34, 36], "3583": 45, "358333": 28, "358500": 37, "358913": 30, "3589134": 30, "359": [28, 32], "3590": 32, "359784": 32, "359887": 38, "359992": 28, "35p": 25, "36": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 54], "360": 30, "360172": 33, "360918": [43, 54], "361": 44, "361718": 33, "362": [44, 45], "362009": 43, "362185e": 34, "362553": 37, "36269995": 30, "362700": 30, "363": 44, "363192": 28, "363913": 33, "364": [43, 44], "364352": 31, "365": 43, "36525": 36, "365420": 45, "365603": 31, "365623": 28, "366": [30, 43, 44], "366005": 33, "3663": 44, "366626": 28, "367": 43, "367329e": 44, "367423": 32, "368": [43, 45], "3681": 36, "368304": 31, "3684": 44, "368922": 39, "369": 34, "369875": 28, "369896": 42, "37": [29, 30, 31, 34, 37, 43, 44, 45, 50, 54], "37050406": 8, "370643": 33, "371": [37, 43, 54], "3717": 36, "371722": 36, "372": 29, "372706": [43, 54], "372763": [34, 36], "373031": 28, "373275": [43, 54], "373656": 43, "374": 29, "374584": 42, "37546": 36, "376": [29, 34], "376089": 34, "37647072": 35, "3768": 45, "3769": 45, "377032": 34, "377619": 32, "377619120792": 32, "37797291": 30, "377973": 30, "378159": 34, "378764": 28, "378971e": 34, "37906": 33, "379416e": 34, "379875e": 34, "38": [8, 28, 29, 31, 33, 34, 37, 43, 44, 54], "3803": 44, "380436": 30, "38043616": 30, "380495": 28, "380504": [29, 30], "380643": 28, "381190": 37, "3814": 30, "381416e": 44, "381428": [34, 36], "381676": 28, "38192364": 38, "381924": 38, "382558": 33, "383": [29, 37], "384111": 45, "384127": 28, "384613e": 32, "3851": 33, "3856": 28, "385639": 38, "386": 32, "386071e": 34, "386530": 36, "387": 32, "388023": 33, "388169": 37, "38853": 34, "3889": 30, "389": [32, 37], "389065": 36, "389349": 37, "389736": [29, 30], "39": [28, 32, 33, 34, 38, 43, 53, 54], "390428669205": 32, "390429": 32, "390725": 34, "39095422e": 36, "391": 29, "3912": 44, "39163": 33, "391996": 42, "392": [25, 44], "392082": 36, "392221": 31, "392385": 44, "392612": 34, "392893": [28, 32], "393": [26, 30], "3932": 44, "39375": 43, "394113e": 34, "394920": 29, "395282e": 34, "395686e": 34, "395688": 44, "395697e": 34, "396": [29, 44], "396266": 42, "396752e": 34, "396991": [29, 30], "397": 44, "398": 37, "398495": [43, 54], "39896994": 30, "398970": 30, "399": 29, "3990": [26, 27, 48], "3991": 34, "39931": 36, "399827": 33, "3blue1brown": 42, "3d": [37, 42], "3f": [26, 27, 28, 29, 33, 34, 40, 41, 45], "3h": 43, "3m": 42, "3rd": 41, "3ssnporch": [34, 36], "3v": 46, "4": [0, 1, 8, 9, 10, 14, 16, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 55], "40": [8, 25, 28, 31, 32, 33, 34, 35, 36, 37, 39, 43, 44, 49, 54, 55], "400": [26, 29, 32, 51], "40000": [42, 43, 54], "400000": [32, 43, 54], "400047": 44, "400157": 37, "400164": 42, "400649628005": 32, "400650": 32, "401": [28, 32], "401102": 43, "401541": 33, "401623": 34, "401830": 36, "401895": 32, "402": 25, "402808": 36, "404": [28, 37], "405": 35, "405227e": 34, "405415": 28, "405650": 34, "406": 42, "406202": 32, "40689": 37, "407": 33, "407234": 42, "40725012": 42, "407510": 33, "40756124": 35, "407862": 44, "4084": 44, "40_000": 42, "40b5a809b05a": 44, "41": [28, 29, 33, 34, 36, 37, 38, 40, 43, 44, 54], "410": 29, "410240": [33, 36], "410599": 37, "411412": 34, "41150573": 34, "412": [25, 28, 32], "412500": 37, "413050": 42, "413718": 44, "413796": 34, "413958": 33, "414": 45, "4143": 44, "4151": 35, "4153": 37, "4158382658": 29, "416": 36, "4165": 35, "4169": 44, "418031": 28, "418069": 32, "41901484361": 32, "419015": 32, "419355": 31, "4195": 36, "4197": [26, 27, 31, 48], "419973": 33, "42": [25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 52, 53], "420": 32, "420000": 25, "4203": 41, "42060": 37, "421": 42, "42104086": 36, "421215": 38, "42121526": 38, "421875": 31, "422": 34, "4234": 36, "4236": 36, "4238": 33, "423852": 33, "424222": 34, "424337e": 34, "425": 35, "425365": 44, "42541681": 46, "425419": 34, "426067": 29, "426410": 28, "427": 44, "428": 44, "429": [34, 36], "429217": 33, "429634": 44, "43": [28, 31, 32, 33, 34, 43, 44], "430": [32, 34, 36, 44], "430323": 29, "430571": 33, "430704": 38, "4307043": 38, "430868": 31, "431": [27, 44], "4310": [28, 29, 32], "431137": 31, "4314": 33, "432": 44, "433": 44, "433514": [43, 54], "433814": 44, "434": [28, 31, 32, 44], "43445": 37, "435": 44, "435186": 28, "435489": 33, "435792": 32, "436": 44, "436492": 34, "43697758253484614": 31, "437": 45, "4372": 38, "437367": [29, 30], "4375": [37, 40], "437500": 40, "437684": 43, "438": 40, "438231": 42, "438275": 30, "43827545": 30, "43833466": 34, "438592": 36, "438906": 36, "439": 29, "4390": [28, 32], "439209": 33, "439360": 29, "439779": 33, "44": [27, 28, 29, 31, 33, 34, 37, 41, 43, 44, 45, 54], "440": [32, 43], "441": 34, "441404": 42, "441445": 37, "442377e": 34, "442806": 28, "4430": 44, "44311": 37, "4432": 37, "443317": 28, "443419": [34, 36], "444297": 37, "444444": 29, "4448": 37, "445": 32, "445111e": 34, "445124e": 34, "44586935": 35, "44586935141902073": 35, "446216": 37, "446284e": 34, "446869": 37, "447": [29, 36], "447461": [43, 54], "447517": 36, "4482": 25, "4484": 28, "448757": 44, "449": 45, "449666": 28, "44966612": 28, "45": [8, 26, 27, 28, 31, 33, 34, 41, 43, 44, 48, 54, 55], "450000": 40, "450132": [43, 54], "450739": 34, "450822": 37, "451888": 33, "452600": 37, "453367": 37, "4537": 44, "454427": [29, 30], "454677": 38, "45467725": 38, "454788": 36, "454966": 33, "455": 30, "4552": 36, "45555535": 36, "45587": [43, 54], "45588": [43, 54], "45589": [43, 54], "45590": [43, 54], "45591": [43, 54], "456": 42, "456419": 37, "45653693": 30, "456537": 30, "456904786": 45, "457435": [43, 54], "45756": 45, "458": 29, "458333": 40, "458524": 44, "459": 34, "4591": 29, "459214e": 34, "459873": 44, "45a": [43, 54], "45am": [43, 54], "46": [8, 26, 27, 28, 29, 30, 31, 33, 34, 43, 44, 45, 48, 50, 54], "460047": 44, "46019608e": 36, "46021": 45, "46075": 45, "4608": [26, 27, 48], "460950": 38, "461": [29, 32], "462060": 44, "462545": 36, "462963": 31, "46299": 45, "463": 33, "463582": 35, "464104e": 34, "465279e": 34, "46530779": 30, "465308": 30, "466246": 42, "4664": 25, "46729488": 34, "467379": 36, "467628": 37, "468": [28, 32, 36], "468232": [43, 54], "4687": 37, "46880": 45, "469": [29, 33], "469383": 33, "4695": 33, "469571": 37, "47": [10, 25, 26, 27, 28, 29, 31, 32, 34, 37], "470": [29, 45], "4700": 32, "470060": 34, "470666": 34, "471032": 36, "472": 45, "47232": 41, "47242662": 46, "4726": 44, "472603": 34, "472790": 33, "473691": 28, "474": 33, "474552": 28, "47491": 33, "475099": 36, "476": 26, "4760": 32, "47606": 37, "476092": [34, 36], "476406": 36, "476412": 38, "47641249": 38, "477": 32, "477291": 37, "47799": 45, "478060": [43, 54], "479109": 28, "479132": 37, "48": [26, 27, 28, 31, 33, 34, 40, 43, 44, 48, 54], "480": 34, "4800": 25, "480249": 28, "48073598": 38, "4809": 32, "481": 29, "4813": [27, 31], "481514": 34, "481793": 29, "481893": 33, "481960": 33, "4822": 44, "483751": 28, "48390": 45, "48407": 45, "484937": 31, "485": 42, "48535": 45, "4854": 36, "486": 36, "4861": [29, 30, 50], "486266": 29, "487": 29, "48721": 45, "4879": 45, "488": 29, "488753": [43, 54], "489130": 31, "49": [28, 31, 33, 34, 37, 43, 44, 53, 54], "490": [37, 46], "490000": 29, "490033": 34, "490568": 32, "491217": 33, "491366": 36, "491379": [29, 37], "492": [29, 33], "492270": 30, "493": [26, 27, 29], "493544": 29, "493921": 30, "494": [28, 29, 32], "4943": 32, "49575": 33, "496": 37, "496213": 34, "496757": 36, "497386": 28, "497787": 34, "498": 33, "498133e": 34, "498562": 28, "499900": 29, "4f": [28, 30, 33, 41], "4m": 42, "4th": [33, 35, 36, 52], "4x": 55, "5": [4, 10, 25, 31, 32, 34, 35, 39, 40, 43, 45, 46, 47, 48, 55], "50": [10, 25, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 51, 52, 54, 55], "500": [25, 29, 33, 35, 36, 37, 52], "5000": [25, 26], "50000": [43, 54], "500000": [29, 30, 33, 34, 39, 43, 45, 54], "500000e": 32, "500001": 29, "5002": 34, "500625": 28, "50062e": 28, "500924": [29, 30], "501": [29, 45], "501071": 42, "501250": 28, "501304e": 34, "501875": 28, "5024752475247525": 32, "502500": 28, "502985": 33, "503000": 29, "503090": 33, "503125": 28, "503750": 28, "504": [28, 37], "504231": 44, "504375": 28, "504429": 30, "504644": 32, "50475372e": 36, "504fde4fcf8": 44, "505335": 33, "505592e": 34, "505625": 28, "5057": 34, "50596432e": 46, "506023": 35, "506035e": 34, "506079e": 34, "506084e": 34, "506211": [29, 32], "506410": 31, "506875": 28, "507130": 32, "507359": [29, 32], "507500": 28, "50774": 32, "507740": 29, "50775": 32, "507750": 32, "507752": [29, 32], "507995": 31, "508": [29, 34], "508125": 28, "508133": [29, 32], "508371": 32, "50884": 37, "50899": 32, "509000": 25, "509001": 34, "509317": [29, 32], "509930": [43, 54], "50k": [33, 35, 36, 52], "51": [28, 29, 30, 32, 33, 34, 36, 38, 43, 44, 50, 54], "510000": [26, 28, 32], "5106": 45, "510836": 32, "5109": 36, "511": 9, "5112": 26, "51137414e": 36, "51143": 37, "51150": 33, "511620e": 34, "5118": 36, "512": 42, "5120": 25, "512000": [28, 32], "51226051": 38, "512319": 29, "512408": [34, 36], "512897": 28, "512x640": 42, "513": 29, "513678": 44, "514155": [29, 30, 34], "514598e": 34, "5146": 31, "515000": 28, "51503393": 30, "515034": 30, "515351e": 34, "5156": [29, 37], "515848": 37, "516394": 37, "517346": 33, "519029": 33, "52": [28, 29, 31, 33, 34, 37, 43, 44, 45, 54], "52061": 43, "5208": 26, "520857": 33, "5209": 34, "5212": 34, "521284e": 34, "521567e": 34, "521578e": 34, "521743e": 34, "522": 34, "522563e": 34, "5238095238095238": 26, "52398": 37, "524": [26, 40], "524364": 44, "5253": 36, "525554": 37, "525757": 28, "526078": [29, 30], "526214": 36, "526596": 37, "526602": 34, "5274": 44, "527500": 29, "528": 34, "5282": 44, "528403": 28, "52881619": 28, "529210": 33, "529388e": 34, "5294": 35, "529412": 29, "53": [31, 34, 43], "530052": 32, "530978": 33, "531116e": 34, "531353": 42, "5315": 32, "532034": 34, "533454": 42, "533498": 28, "534": 45, "534114": 32, "534342": 37, "535": [29, 37], "535014": 29, "53520104": 28, "535604": 29, "535622": 37, "536362": 38, "53636249": 38, "537267": 29, "538000": 26, "538702": 28, "538816": 33, "5390": [33, 36], "5391": [29, 37], "539116": [43, 54], "539376": 44, "539459": 45, "54": [34, 43, 44, 53, 54], "540": 43, "540000": 29, "540359": 37, "541117": 34, "541488": 37, "54152": 33, "541667": 30, "541795": 33, "54240": 33, "542624": 36, "542873": [29, 30], "543297": 32, "543351": 36, "544": 32, "544462": 36, "545": [34, 45], "546": 29, "5461": 34, "546473": 31, "546610": 28, "54676006e": 36, "547": [32, 34, 36], "547993": 33, "548831": 36, "549": 45, "549682": 33, "5498": 28, "55": [26, 27, 28, 31, 33, 34, 35, 36, 43, 44, 48], "55000": 32, "550000": [29, 30, 32], "550004": 35, "550616": 33, "55101": 43, "5513": 32, "5514": [35, 36], "5515": 44, "551579e": 34, "551862e": 34, "551975": 34, "552": [29, 34], "552721": 35, "553965": 36, "553979": 33, "5540": 44, "5541306485809793": 35, "55413065": 35, "554180": [43, 54], "554621": 37, "5551": 31, "555740": 28, "5566": [29, 30, 50], "557197": 42, "557242": 33, "557739": 34, "558": [34, 36, 37], "558564": 33, "55862988e": 36, "55873324": 42, "5588": 25, "558824": 33, "558889": 34, "559": [32, 34, 36], "56": [28, 30, 33, 34, 43, 44, 53, 54], "560225": 29, "560768": 34, "561": [10, 28, 32, 36, 37], "561467": [29, 30], "561602": 36, "561645e": 34, "562112": 29, "563": 10, "5630224174651539": 31, "563314": [34, 36], "563467": 29, "5644": 34, "564483": 37, "56499": 41, "565": 37, "5650": 26, "565062": 44, "56521734": 8, "565679": 33, "565746": 44, "565888": 29, "566": 29, "566092": 29, "566222": 42, "5667": 33, "567724": 42, "567856e": 34, "568": 42, "568009": 28, "56804591": 34, "568663": 34, "5690201394302518": 36, "56902014": 36, "569375": 28, "5694": 37, "57": [28, 29, 30, 33, 34, 36, 43, 44, 50, 54], "57000": 44, "570015": 34, "570449": 33, "570473": 37, "5707": 44, "570739": 37, "571": [38, 46], "571500": 37, "571901e": 34, "571969": 37, "572": 10, "572105": 28, "572549": 29, "572962": 44, "573": 46, "573050": 33, "573129": [34, 36], "5732": 33, "573542": 37, "573818": 33, "57415": [43, 54], "574260": 37, "575000": 40, "57510": 37, "575907": 37, "576": 29, "57640869": 30, "576409": 30, "578523": 31, "578654": 33, "5789": 34, "579091": 37, "579432": 31, "579559e": 34, "579660": 35, "5798": 35, "57994": 33, "58": [26, 27, 28, 31, 34, 43, 44, 48], "580": 42, "580539e": 34, "581": 36, "58137177": 30, "581372": 30, "5814": 25, "581687": 37, "581787": 44, "582": [25, 35], "582090": 33, "582469": 34, "58387198": 38, "583872": 38, "584": 29, "584615": [29, 37], "585": 29, "585513": 31, "5857": 44, "586095": [29, 30], "587773": 33, "588": [28, 32], "588125": 28, "588235": 31, "588307": 29, "589286": 45, "59": [1, 28, 34, 43, 44], "59049": 33, "59050": 33, "590618": 37, "59082668": 30, "590827": 30, "5915": 30, "592": 45, "592401": 25, "59243876": 35, "59300": 37, "5931": 34, "593370": 34, "593508": 38, "5938": 29, "594": 29, "594595": 28, "594982": 33, "594995": 33, "5950": 29, "595427": 42, "595569e": 34, "596088e": 34, "596151": 37, "596810": 28, "596864": 34, "5970": 35, "59700": 33, "597015": 31, "59708": 33, "597326": 33, "597555": 25, "597924": [34, 36], "598": 29, "59810": 33, "598100": 31, "598149": [34, 36], "598750": 28, "599": 45, "599492": 31, "599860": 28, "599894": [43, 54], "5fin": 34, "5th": [33, 35, 36, 52], "5unf": 34, "6": [8, 10, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 55], "60": [8, 25, 29, 33, 34, 36, 37, 38, 40, 41, 43, 44], "600": [29, 31, 41], "60000": [43, 54], "600000": [27, 28, 32, 43, 54], "600193": 33, "60023631": 34, "600k": 34, "601": 32, "601042": 25, "601504": 31, "601712": 33, "601790": 31, "602": [29, 30, 50], "602000": 29, "602649": 28, "6028": 33, "602941": 33, "602954": 35, "60319915": 46, "603684e": 32, "603970": 44, "604": 28, "6040": [28, 32], "604000": 26, "604032": 33, "60429913": 34, "604320": 31, "60455": [43, 54], "604619": 31, "604797": 31, "6048": 43, "604807": 44, "60495488": 28, "605060": 33, "6051": [29, 30, 50], "605100": 31, "605101": 31, "605102": 31, "605263": 28, "605625": 28, "605696": 31, "606": 29, "606061": 31, "606557": 31, "606567": 31, "606811": 32, "606875": 28, "606902": 31, "607062": [43, 54], "608050": 31, "608125": 28, "6082": 29, "608468": 31, "608532": 42, "608565": 44, "60860": 29, "609": 29, "6092": 25, "609375": 28, "60943": 33, "60k": 34, "61": [28, 30, 31, 33, 34, 38, 43, 44], "61029914": 34, "610407": 33, "610931": 39, "611": 30, "611007": 42, "611178": [43, 54], "612349": 30, "61234944": 30, "6124": 44, "612546": 33, "612621": 31, "612755": 28, "613507": 31, "613738": 32, "613738418384": 32, "614": 29, "61420598": 30, "614206": 30, "614567": 37, "615": 29, "6154": 37, "615730": 35, "616": 32, "616099": 32, "6168": 26, "617342": 44, "617431": 39, "6176": 33, "617647": 33, "618": 29, "618012": 32, "619": 45, "61912405": 36, "62": [28, 32, 33, 34, 43, 44, 54], "622255": 29, "622454": 32, "622500": 28, "6226": 37, "622612": 33, "622709": 31, "623000": 29, "62320": 43, "62352928": 35, "624049": 34, "6241": 25, "624375": 28, "624450e": 34, "624615": 34, "6250": 29, "625387": 32, "6257": 44, "626206": 34, "62657": 43, "626875": 28, "62688064": 36, "627": 44, "6273": 32, "6275": [26, 27, 48], "627722": 36, "627966": 29, "628032": 37, "628139": 33, "62873917": 36, "629792e": 34, "63": [28, 32, 33, 34, 43, 44, 45, 54], "6303": [29, 30, 50], "6306": [29, 37], "631899": 44, "632": 45, "6320": 31, "6322": 37, "632353": 33, "632786": [43, 54], "63316788": 46, "63358": 41, "63362": 34, "634397": 31, "634490": 30, "634686": 33, "635": 29, "635200": 37, "635239": [29, 30], "635648": 31, "636": [25, 29, 30, 44, 50], "636364": 45, "636410": 35, "636849e": 34, "637": 42, "637982": 28, "638169": 36, "6389": [29, 37], "6391518364256": 44, "6392": 37, "639754": 34, "64": [11, 28, 31, 34, 42, 43, 44], "640": [32, 42, 45], "6400": 29, "640000": [33, 45], "640266": [29, 30], "640x480": 28, "641216": 43, "641538": 44, "641873": 34, "642676": 43, "642965": 33, "643": 32, "6431": 37, "643311e": 34, "644106": 33, "64417243": 42, "64454": 33, "644770": 39, "645519": 33, "6458": [26, 27, 48], "645963": 32, "646050": 36, "6464": 44, "647796": 37, "648": [28, 29, 32], "6480": 35, "648195": 33, "648550": 42, "649658": 36, "64994": [43, 54], "65": [26, 30, 34, 44], "650": 33, "65000": 32, "650000": 32, "65000e": 28, "65013704": 38, "65125032": 46, "6513": 36, "651446": 43, "65243": 34, "652487": 37, "6526853": 34, "652828": 32, "652986": 37, "653": 29, "653205": 32, "653205232272": 32, "654": 29, "65424895": 34, "656297e": 34, "656349": 28, "656827": 33, "657675": 37, "658047": 31, "658645": 31, "659056": 34, "66": [26, 27, 29, 31, 33, 34, 42, 43, 48, 54], "660171": 28, "6604": [29, 30, 50], "660714": 30, "66214339": 28, "66221": 43, "662450": 33, "662541e": 34, "662745": 29, "662879": 35, "66368": 36, "663680": [34, 36], "6637": 44, "6638": 44, "663822": 36, "6639": 44, "6641": 44, "6642": 44, "664207": 33, "6643": 44, "6644": 44, "6645": 44, "664707": 31, "66473": [43, 54], "665": 29, "665351e": 34, "665625": 28, "665882": 35, "666": [29, 30], "666166": [43, 54], "6666666666666666": 42, "666667": [27, 29, 40], "666754": 42, "667450": 43, "668787": 28, "6688": 25, "669614": 33, "669725": 33, "669805e": 34, "67": [26, 27, 30, 31, 33, 34, 43, 44], "670344": 28, "67186503136": 34, "673277": 32, "6744": 36, "674490": 32, "674721": 35, "675000": 25, "67501": 43, "67512181": 34, "67562658": 30, "675627": 30, "675676": 40, "675814": 28, "676250": 28, "676373": 33, "67672595": 34, "677": 29, "6772": 44, "677268": 44, "677579": 28, "677601": 32, "677629": 28, "678": [28, 32], "678689": 31, "679478": 29, "679877": [34, 36], "68": [26, 27, 28, 30, 33, 34, 36, 38, 39, 43, 44, 46, 54], "680000": 25, "680657": 29, "681223": 28, "683015": 35, "683171": 33, "68323": 32, "68339": [43, 54], "684211": 28, "684447": 29, "684960": [29, 30], "685103e": 34, "68523": 43, "685786": 35, "6858": 31, "686": 29, "686348e": 34, "687": 34, "687055": 33, "687307": 32, "687500": 27, "688": 32, "6880359361853475": 31, "688135": 32, "689338": [34, 36], "69": [26, 27, 28, 30, 34, 38, 43, 44, 54], "690": 45, "69027185e": 36, "690402": 32, "690778": 36, "691241": 33, "691640": 28, "691877": 32, "691924": 38, "69192445": 38, "692308": 29, "693": 29, "693498": 32, "693590": 30, "6938": [25, 43], "693890": 43, "693898": 43, "693936": 30, "69393613": 30, "69411": 37, "694155": 28, "694334": 35, "6950": 36, "695532": 29, "696034e": 34, "6962": 29, "6963": 36, "696373": 29, "696429": 33, "696712": 43, "696859": 32, "696875": 28, "696970": 31, "69698010e": 36, "697": [29, 37], "697248": 33, "6973": 29, "698": 29, "698167": [43, 54], "698206": 34, "698384608345687": 32, "698385": 32, "6984": 37, "698857": 32, "699224": 28, "699706": 42, "699901396097971": 39, "6th": [33, 35, 36, 52], "6x6": 51, "7": [10, 11, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 55], "70": [26, 27, 30, 33, 34, 38, 39, 43, 44, 54], "70000": [43, 54], "700000": [43, 54], "700855": 33, "701128": [43, 54], "701173": 32, "701186e": 34, "70162085e": 36, "7017": 44, "701863": 32, "702703": 28, "703406": 44, "704": [28, 29, 34], "704099": 30, "7042": 44, "7043": 44, "7046136400143138": 31, "70472": 37, "704969": 32, "705000": 29, "705511": 32, "70560276": 30, "705603": 30, "70568": 34, "705696": 28, "705882": [27, 32], "70588235": 27, "705898": 37, "706": 30, "706128": 28, "706444": 33, "706783": 30, "70678332": 30, "706966": 43, "707681": 28, "707712": 44, "707899": 38, "70789903": 38, "70799": 32, "708": [29, 30, 32, 35, 50], "708075": 32, "708527": 29, "708978": 32, "709185": 28, "70978": 37, "709874": 32, "709880": 32, "709893": 43, "7099": 37, "71": [25, 26, 27, 30, 31, 33, 34, 38, 43, 44, 54], "710000": 29, "710031": 36, "710526": 28, "710896": 33, "71096": 37, "711": [30, 32], "711077": 29, "711086": 32, "711717": 32, "711754": [29, 30], "711852": 37, "71199006": 34, "712": 29, "712074": 32, "71219761": 30, "712198": 30, "712324": 32, "712402": 35, "7129": 32, "713": 30, "71327467": 34, "714": 42, "714077": [29, 30], "714286": 32, "714402": 33, "715072": 42, "71517": 32, "7153": 44, "715424": 32, "715728": 33, "715992": 42, "716157": 33, "716655": 32, "716657": 32, "716792": 33, "716985": 28, "717289": 32, "717391": 32, "717829": 29, "718242": 32, "718266": 32, "718524": 43, "71866979": 34, "718750": 28, "7188": 30, "719": [25, 29, 37], "719056": 35, "719427e": 34, "719500": 28, "719747": 33, "72": [26, 27, 28, 33, 34, 43, 44, 48, 51], "720357": [43, 54], "72036": 43, "720497": 32, "720859": 29, "720893": 44, "720904": 43, "7210": 26, "721006": 32, "721008": 32, "7212512828409691": 31, "721616": 32, "721705": 29, "7218": [26, 27, 48], "721818": 37, "721921": 29, "722": 29, "722241": 32, "722249": 32, "723": 29, "72338": 41, "72345029": 34, "723602": 32, "723613": 28, "7242": 26, "724458": 32, "724539": [43, 54], "724891": 33, "725": [31, 32], "7250894": 46, "726": [29, 33, 37], "726412": [29, 30], "726474": 42, "726573": 32, "726583": 32, "726634": 33, "7266666666666667": 46, "726788": 34, "727014": 43, "727198": 32, "727273": 28, "727554": 32, "7277854625841886": 44, "727821": 32, "7278214718381631": 32, "727829": 32, "728": [29, 33], "728235": [29, 30], "7283": 33, "728324": 33, "728777": 28, "729": 32, "729109": 45, "729143": 33, "7292": 37, "729814": 32, "73": [26, 27, 30, 31, 32, 33, 34, 39, 43, 44], "730383": 33, "731498": 44, "7315": 31, "7315558717766282": 32, "731572": 31, "731583": 28, "7328": 29, "732919": 32, "733102": [29, 30], "733333": [27, 29, 30], "733746": 32, "734": [32, 34, 44], "734011": 32, "734385": 33, "734816": 43, "735": 34, "735043": 33, "735261": 32, "7352614272253524": 32, "735879": 32, "736285": 33, "736498": 32, "736900": 29, "7379": 26, "738": [29, 34], "738564": 43, "738701": [29, 30], "738715": 44, "738839": 31, "738977": 32, "739": 45, "739264": [29, 37], "7395977155164125": 32, "739598": 32, "739938": 32, "74": [26, 27, 29, 30, 31, 32, 33, 34, 39, 50], "740542": 25, "740844": 32, "741": 44, "741037": [43, 54], "741250": 28, "741463": 32, "7418": 36, "741935": 45, "742084": 32, "742088": 32, "742703": 32, "742981": 33, "743": [28, 29, 32, 44, 45], "743133": 28, "743135": 33, "743321": 32, "743323": 32, "743324": 32, "743391": 28, "743555": 36, "7436": [26, 27, 48], "743917": [29, 30], "7440": 25, "744201": 33, "744565": 32, "745": 35, "745178": 32, "746114": 35, "746328": 28, "747": 25, "74720920774": 34, "74798624e": 36, "748510": 33, "748725": 44, "748749e": 32, "748797": 31, "749118": 36, "75": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 43, 44, 50, 54], "750": 25, "7500": 34, "750000": 34, "7503": 26, "7504": 45, "751": 45, "7524": 43, "753286": [29, 30], "754": 29, "754165": 45, "754386": 33, "754874": 37, "755": 44, "755000": 34, "7551": 32, "755364": 28, "755418": 32, "755477": 28, "756": 44, "7562": 25, "75625": [43, 54], "757": 33, "7574257425742574": 32, "75745416": 38, "757545": 34, "757591": 43, "757932": 44, "757985": [35, 36], "758": [35, 36, 44], "758062e": 34, "75826": [35, 36], "758514": 32, "7588186": 42, "759561": 38, "75956122": 38, "7599": 31, "76": [27, 29, 31, 32, 33, 34, 36, 37, 44], "760": 44, "760262": 32, "760678": 43, "76161": 32, "761945e": 34, "762": [27, 44], "7620": 25, "762093e": 34, "76270194": 36, "763": 29, "7639": 26, "764052": 37, "76470588": 27, "764706": [27, 28, 32], "765": 33, "765591": 33, "765601": 34, "766317e": 34, "766423": 34, "766430": 28, "767": [34, 36], "767742": 31, "767802": 32, "767819": 43, "767852": 28, "768": [29, 30, 34, 36, 50], "768176": 44, "768512": 33, "76908228": 35, "769231": 29, "77": [26, 27, 30, 31, 33, 34, 39, 43, 44, 47, 53], "770": 26, "7706532429048965": 35, "770833": 40, "770898": 32, "771": 29, "771969": 28, "772532": 33, "773017": [34, 36], "7736": 32, "773851": 43, "774261": 43, "774844": 30, "77484447": 30, "7750553478074826": 43, "775270": 34, "7752884548630529": 31, "775311": 36, "77536150e": 36, "7758": 32, "776": 32, "7763": [29, 37], "776427": 44, "77694295": 35, "77709": 32, "777934": 28, "778": 45, "7781845435415525": 43, "779": [29, 37], "779271": 37, "78": [25, 26, 27, 29, 30, 33, 34, 37, 38, 43, 44, 47], "7800": 32, "780000": 35, "780296": 34, "780298": 34, "780316": 34, "780497": 34, "78058051e": 36, "780864": 33, "781": 29, "781004": 28, "781531": 33, "7816": 34, "782183": 34, "782219": 28, "7827": 33, "783282": 32, "783582": 28, "783784": 40, "783789": 28, "784424": 31, "784573": 37, "785": 30, "785105": 34, "785108": 34, "785134": 34, "785399": 34, "785483": [43, 54], "785714": 29, "786115": 37, "78617028": 35, "786555": 34, "787": 29, "787574": 34, "787879": [28, 31], "787933": 34, "788": 27, "788374": 42, "7887": 36, "7891381897690047": 31, "789436": 29, "789657": [43, 54], "79": [26, 27, 29, 30, 31, 33, 34, 43, 44, 48], "790": 33, "790000": 29, "79041": 34, "790731": 31, "791017": 44, "791467": 29, "792": 46, "792023": 36, "79250": 29, "792577": 34, "792603": 28, "792828": 34, "793": 37, "793243": 29, "79378": 33, "7938": 30, "794": 44, "794118": 28, "794236": 29, "794820": 29, "795": [28, 32], "79500e": 28, "7951": 32, "7951559890417761": 34, "795902": [43, 54], "796": 29, "7964215270662811": 31, "797": 29, "797355": [29, 30], "7978563117812038": 29, "798": 29, "7982": 28, "7986546": 34, "799983": 28, "79998417": 46, "7f688092391a": 42, "7pm": 37, "7th": [33, 35, 36, 52], "8": [9, 10, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 54], "80": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 43, 44, 47, 54], "800": [25, 27, 32, 41, 51], "800000": [32, 43, 54], "8001": 31, "800190": 28, "80062924": 28, "801219e": 34, "801666": 33, "801863": 28, "802502": 37, "802902": 34, "802987": 28, "803": [28, 29, 45], "803617": 33, "804": [28, 44, 45], "804818": [29, 30], "80482065": 30, "804821": 30, "805198": 34, "805342": 43, "805970": [28, 31], "806": 30, "8062": 26, "806899": 42, "8076": 34, "807684": 28, "807735": 33, "8078": 25, "808": 44, "8080": 26, "808208": 33, "808958": 28, "809": 29, "8098": 44, "81": [26, 27, 28, 30, 31, 32, 33, 34, 36, 38, 43, 44, 54], "810073": [34, 36], "810098": 37, "810368": 28, "81071706": 32, "810811": 40, "8112": 25, "812272": 34, "812363": 34, "812500": 27, "812593": 42, "812875": 44, "813": 29, "813586": 33, "815669": 33, "816717791411044": 44, "817": 35, "817034": 45, "817558": [29, 30], "8180": 29, "818041": 44, "818868": 29, "819152": 28, "819213": 44, "8195": 31, "819549": 28, "819584": 28, "81970188": 30, "819702": 30, "82": [26, 30, 32, 33, 39, 43, 44, 54], "820": 28, "820033": 34, "820143": 31, "82025568e": 36, "820564": 34, "821040": 36, "821807": 34, "8219": 29, "8221": 30, "8225": 45, "82273995": 30, "822740": 30, "823511": 33, "823529": [27, 28, 31], "82352941": 27, "823543": 37, "824849": 33, "824884": 34, "825": 29, "825123": 37, "8253": 28, "825306": 32, "825470": 44, "825697": 34, "826142": 34, "826203": 31, "826216": 34, "826513": [43, 54], "826553": 34, "82670": [43, 54], "826739": 34, "826758": 34, "826760": 34, "827039": 31, "827068": 31, "827130": 33, "827261": 34, "827842": 31, "827907": 32, "8280229354283182": 34, "82804": 32, "828332": [34, 36], "828358": 28, "828405": 43, "828682": 32, "828891": 32, "828976": 32, "83": [26, 27, 30, 32, 33, 39, 40, 41, 43, 44, 47, 54], "830382": 33, "830712e": 34, "831135": 28, "831611": [34, 36], "831989": 32, "832": 29, "832320": 31, "832370": 33, "832866": 34, "833": [28, 32], "83320": 43, "8334": 36, "8340": 28, "834109": 32, "834356e": 34, "83437": 34, "834455": 28, "8356": 36, "835651": 32, "835749": [34, 36], "83603": [34, 36], "8361313": 34, "836189": 28, "836735": 33, "836878e": 34, "836880e": 34, "837022e": 34, "837838": 28, "837848": 28, "838": [28, 32], "83848729e": 42, "83876": 32, "8388866943476283": 31, "838951": 34, "8389756947416362": 31, "839225": 34, "84": [26, 27, 30, 43, 44, 45, 46, 47], "840": 29, "84002795": 30, "840028": 30, "840074": 27, "840183": 34, "840492": [34, 36], "84062193": 36, "841": 34, "841208": 32, "841886": 32, "841983": 32, "842": 29, "842028": 33, "842064": 44, "842105": 28, "843": 35, "843281": 36, "843284": [28, 31], "843842": [29, 30], "843992": [34, 36], "844409": 30, "84440919": 30, "844921": 38, "845": 32, "846154": [29, 45], "8462": 37, "846260e": 34, "846650": 34, "84679073": 28, "84698489": 42, "847178": 33, "847287": 32, "8475": 43, "84772": 33, "847799": 32, "847808": 33, "8478316682480326": 43, "848": [35, 36], "8481": 45, "84893192": 32, "849": [35, 36], "849102e": 34, "849438e": 34, "849612": 32, "85": [26, 27, 30, 33, 34, 35, 36, 37, 43, 44, 47, 54], "850": [25, 35, 36], "8502": 32, "850283": [43, 54], "850503": 32, "850746": 28, "851460": 34, "851852": 31, "852": [44, 45], "852053": 32, "852104": 34, "852941": 31, "853125": 28, "853399": 33, "854129": 34, "854167": 40, "854500": 44, "8546143543902771": 44, "854744525547446": 44, "854749": 43, "85545875": 28, "85597188": 30, "855972": 30, "856": 32, "856175": 29, "856589": 32, "857": 34, "857874": 32, "858": 31, "8580": [29, 30, 50], "858209": [28, 31], "858915": 32, "859": 35, "859318": 34, "859439": 38, "85943906": 38, "859455": 44, "85969": 32, "859799": 32, "86": [26, 28, 30, 31, 32, 33, 37, 43, 44], "860": [33, 36], "86000e": 28, "8601643854446082": 34, "860677": 33, "861": 29, "86102": [43, 54], "861348": 32, "862432": 34, "862552": 29, "8625888648969532": 44, "86267067": 30, "862671": 30, "862997": 37, "863014": 31, "863889": 43, "863941": 34, "864": 35, "86400": [43, 54], "8641864337292489": 44, "864205": 36, "865562": 44, "8661": 45, "866110": 31, "866667": [27, 33], "866980": 34, "867434": 42, "867558": 37, "868003": 34, "868281": 34, "868305": 34, "868308": 34, "869077": 30, "86907725": 30, "869094": 32, "8691": 30, "869531": 28, "869964": 32, "87": [26, 29, 30, 33, 43, 44], "870": [35, 36], "870503": 42, "871": [32, 35], "871094": 43, "8711": 33, "872": [35, 36], "872093": 32, "872603": 42, "872722908439952": 36, "8727229084399575": 36, "872961060": 34, "8729610607986": 34, "873": 35, "8731": [34, 36], "873103": 28, "873182": 43, "873356": 28, "873643": 32, "873704": 34, "874062": 30, "87406235": 30, "874305": 43, "874516": 32, "874532": 34, "874767e": 34, "875": 33, "8750": [29, 37], "875000": 27, "876065": 32, "876540": 44, "876574": [29, 30], "877046": 37, "877390": 36, "877519": 32, "877551": 33, "878183": 28, "87844893": 34, "87849316": 31, "879": 29, "87907": 32, "879938": 32, "88": [26, 27, 29, 30, 31, 33, 37, 44, 45, 50], "880": 37, "880348": 32, "880831": [43, 54], "881395": 32, "881720": 33, "883138": 32, "884586": 32, "885": [25, 30], "885044": [34, 36], "885968": 44, "886047": 32, "886759": 31, "887": 35, "887017": 33, "887159": [43, 54], "8873": 33, "887324": 33, "887343": 28, "887597": 32, "887701": 33, "8878117": 30, "887812": 30, "888": [32, 35, 36], "888066": 36, "888372": 32, "888513": 33, "888811": 32, "888889": [29, 31], "888961": 36, "889086": 34, "889147": 32, "889429": 43, "889921": 43, "89": [26, 27, 30, 33, 39, 43, 44, 47, 54], "890": 35, "890457": 34, "890933": 44, "891001": 33, "891557": 32, "892476": 33, "892477": 28, "892491": 29, "89270": 37, "892733": 43, "892961": 37, "893000": 29, "893260": 30, "8937442459553657": 36, "894": 29, "895": 35, "895349": 32, "895541": 34, "89572": [43, 54], "895833": 33, "895963": 31, "897010": [29, 30], "89706451e": 36, "897674": 32, "898": 36, "898016": 32, "898703e": 34, "899": [29, 30, 32, 35, 50], "8994": 36, "8997": 34, "899969": [43, 54], "8m": 42, "8th": [33, 35, 36, 52], "9": [4, 10, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 54, 55], "90": [8, 25, 26, 27, 28, 30, 33, 34, 39, 40, 43, 44, 47], "900": [30, 32, 33], "90000": [43, 54], "900000": [27, 43, 54], "900662": 27, "901085": 31, "9010852321946792": 31, "901262": 43, "90159483": 38, "901595": 38, "902401": 32, "903101": 32, "904": [28, 32], "90403853": 30, "904039": 30, "904226": 28, "9047619047619048": 26, "904902": 42, "905": [28, 29], "905327": 43, "906667": 27, "90669": 37, "906865": 27, "907": 44, "907143": 45, "907595": 43, "908": 29, "908140": [29, 30], "908215": 34, "909091": 29, "90982": 37, "91": [26, 27, 29, 30, 32, 33, 37, 38, 43, 47, 54], "910": 26, "9100": 43, "910018": 34, "910174": 34, "9103": 43, "910456e": 34, "91063776": 36, "910714": 45, "910843": 34, "911615": 34, "911846": 34, "912": 29, "912395": 36, "913333": 27, "913767": 34, "913849": 34, "914003": 36, "914451894267": 34, "914585": 36, "91515735": 34, "915714e": 34, "915952": 34, "916254": 28, "916722": 36, "917526": 33, "917837": 33, "918": 35, "918124": 33, "918191": 42, "9182": 43, "919198": 36, "9196": 25, "92": [26, 27, 30, 33, 39, 42, 43, 44, 47], "920000": 27, "9203": 32, "920305": 37, "920462": 36, "92120500e": 46, "921422": 44, "921438": 34, "921850": 34, "92195464": 36, "921955": 36, "922": 30, "923077": 33, "923283": [29, 30], "923432": 36, "924485": 37, "9245": [27, 31], "925272e": 34, "925288e": 34, "925593": 28, "925768": 33, "926657": 34, "926733e": 34, "926829": 33, "928": 32, "92809": 37, "92852376": 28, "929": 32, "9295": 32, "93": [26, 27, 30, 31, 32, 38, 43, 44, 47], "930000": 29, "930123": 28, "930561": 28, "931439e": 34, "931786": 31, "932": 29, "932070": 44, "932124": 28, "932143": 45, "93279": 43, "9336": 29, "934205": 28, "934269": [29, 30], "934783": 33, "9351": 37, "935512": 44, "935802": 28, "93665": [43, 54], "9375": 27, "937500": [27, 30], "93788": 41, "938": 33, "9383": [28, 31], "93869659": 30, "938697": 30, "939006": 33, "9391": 34, "939394": [28, 31], "94": [26, 27, 29, 30, 31, 32, 33, 34, 43, 47, 50], "9401": 43, "9406": [26, 27, 48], "941": 44, "941176": [27, 30], "94117647": 27, "943609": 37, "944": 25, "944092": 33, "944354": 30, "946783": 28, "947": [29, 32, 45], "9471": 32, "948482": 44, "94888": 33, "949": 29, "9490": 29, "9492": 34, "94933723": 34, "94959681": 30, "949597": 30, "95": [26, 27, 30, 33, 39, 43, 44], "950000": 29, "950088": 37, "9505": 36, "950564": 37, "9506": 36, "950696": 44, "950733": 28, "951294": 34, "951574": 37, "951644": 37, "951669": 37, "951696": 28, "953": 35, "95511263": 28, "955113": 28, "9558": 43, "956": 29, "956966": 37, "957075": 37, "9573": 43, "9576": 25, "957886": 42, "957919": 28, "957987": 28, "9583333333333334": 42, "958393": [29, 37], "95886206e": 42, "959": 29, "959139": 36, "959402e": 34, "959870": 33, "959873": 44, "96": [26, 30, 31, 32, 33, 37, 43], "960": 31, "961106": 33, "961109802000133": 39, "961404": [29, 30], "961498": [34, 36], "961771": 31, "961898": 31, "962776": 33, "96319": 43, "96320": 43, "96321": 43, "96322": 43, "96323": 43, "96325": 43, "963689": 37, "96554": 37, "9661": 34, "966131": [29, 30], "9664": [26, 27, 48], "966491": 33, "967102": 33, "967907": 33, "968": 29, "968233": 37, "96834506": 28, "968493": 44, "968514e": 34, "96875": 42, "969048e": 34, "9691": 34, "9692602666681306": 31, "96965253": 36, "969653": 36, "97": [26, 27, 30, 31, 32, 36, 39, 43, 44], "970518": 33, "970683": 37, "971": 30, "97203586": 30, "972036": 30, "97217": 43, "972198": 32, "97223953": 30, "972240": 30, "972440": 33, "97253": 43, "9730": 30, "973225": 33, "973280": 30, "97328024": 30, "973482e": 32, "973750": 28, "974": 29, "974480": 37, "9748": 31, "974801e": 34, "975895": 43, "976": [29, 33, 35], "977": [29, 43, 54], "977278": 37, "9773": [26, 27, 28, 48], "978": 31, "9781449369880": 43, "9781789957211": 42, "97823755": 31, "978738": 37, "979": [35, 36], "979562": 44, "98": [26, 29, 30, 31, 34, 36, 38, 41, 43, 44], "980": [43, 54], "98007": 25, "98028": 26, "98045": 25, "98052": 25, "98055": 25, "980634": 44, "98072": 25, "98074": 26, "98075": 25, "9808": 31, "98107": 25, "98112": 25, "98116": 25, "981195": 43, "98125": 26, "98136": 26, "981735": 31, "98178": 26, "982": 30, "982184": 32, "982570": 44, "983": 42, "9837": [27, 31], "984": 32, "984653": 31, "984664": 34, "985283": 32, "9854": [26, 27, 31, 48], "985457": 44, "985816": 27, "986047": 32, "9862": 45, "986207": 32, "987": [32, 42], "987062": 34, "987597": 32, "9876": [35, 36], "987681": 37, "988": 37, "9881": [26, 27, 48], "988381": 32, "988841": 32, "988901": 34, "989": 26, "989147": 32, "989156": 32, "989443": 44, "989922": 32, "989973": 31, "99": [26, 27, 29, 30, 32, 33, 43, 52, 54], "990631": [43, 54], "990754": 43, "9912": [28, 31], "9915": [43, 54], "991966": 44, "992": [27, 32], "992254": 32, "99240562": 36, "992406": 32, "9926": 30, "992857": 27, "992908": 27, "993023": 32, "993029": 32, "993065": 44, "9931": [26, 27, 48], "9934531067299874": 31, "993666": 36, "993969": [34, 36], "994": 25, "994266": 32, "994574": 32, "994764": 43, "995": [37, 42], "9950": 37, "9951": [26, 27, 48], "99515": 43, "995434": 34, "996588e": 34, "996765": 36, "996788": 44, "996820": 44, "996899": 32, "99744241e": 36, "9977957422135844": 36, "998": [33, 44, 45], "9983": 33, "998302": 33, "99845": 32, "998451": 32, "999": [31, 45], "99907": 32, "999122": 33, "999147": 33, "999172": 33, "999183": 33, "999185": 33, "999192": 33, "999210": 33, "999214": 33, "999221": 33, "999223": 33, "999225": 32, "999254": 33, "999298": 33, "999317": 33, "99931882": 34, "999335": 33, "999535": 32, "999577": 43, "999622": 29, "9am": 37, "9th": [33, 35, 36, 52], "A": [0, 8, 9, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 47, 54, 55], "AND": [0, 34], "AS": 0, "And": [25, 26, 32, 34, 41, 43, 44, 48, 49], "As": [4, 27, 30, 32, 34, 35, 36, 40, 43, 44, 46, 49, 51, 53, 55], "At": [4, 25, 27, 31, 33, 35, 37, 38, 42, 43], "BE": [0, 41], "BUT": [0, 8], "BY": [0, 1], "Be": [7, 28, 36, 47, 49], "Being": 42, "But": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 49, 51, 53, 54, 55], "By": [25, 27, 28, 30, 33, 35, 38, 41, 42, 44, 49, 51, 55], "FOR": 0, "For": [0, 4, 5, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 52, 53, 54, 55], "IN": [0, 27, 31], "IT": 31, "If": [4, 5, 6, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "In": [6, 7, 8, 9, 10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55], "Ines": 45, "It": [2, 4, 7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 49, 51, 53, 55], "Its": 44, "NEAR": [29, 30, 37, 50], "NO": 0, "NOT": [0, 8, 30, 31], "No": [0, 25, 26, 34, 35, 36, 37, 39, 43, 44, 47, 54], "Not": [33, 34, 35, 36, 37, 38, 40, 43, 44, 52], "OF": 0, "OR": [0, 8, 34], "Of": [9, 30, 32], "On": [4, 7, 25, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 44, 45], "One": [5, 8, 16, 26, 27, 30, 31, 32, 33, 36, 38, 39, 44, 47, 52, 54], "Or": [28, 30, 32, 49], "Such": [6, 40, 43], "THE": [0, 27], "TO": [0, 41], "That": [26, 27, 29, 31, 32, 34, 35, 36, 38, 39, 40, 41, 43, 44, 52], "The": [0, 1, 2, 5, 7, 8, 10, 25, 26, 28, 29, 30, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55], "Their": 5, "Then": [26, 31, 35, 38, 43, 52], "There": [2, 5, 8, 9, 10, 11, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 55], "These": [4, 11, 26, 27, 28, 31, 33, 34, 35, 36, 37, 38, 40, 43, 53, 55], "To": [8, 11, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 39, 41, 42, 43, 45, 49, 51, 53, 54, 55], "WITH": 0, "Will": [33, 44, 45, 47, 52], "With": [0, 25, 26, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 42, 44, 46, 49, 55], "_": [35, 42, 44, 45], "__call__": 30, "__class__": [31, 43], "__finalize__": 44, "__getitem__": [27, 29], "__init__": 45, "__name__": [31, 43], "_arg": 45, "_array_api": 45, "_astype_nansaf": 44, "_c": 45, "_california_housing_dataset": 31, "_call_func_on_transform": 30, "_callback": 45, "_column_transform": 30, "_constructor_from_mgr": 44, "_context": 45, "_data": 32, "_distn_infrastructur": 32, "_encod": 30, "_get_default_devic": 45, "_get_sequential_output": 30, "_i": 42, "_logist": 46, "_mgr": 44, "_proba": 35, "_pseudo_sync_runn": 45, "_run": 45, "_run_cel": 45, "_run_cod": 45, "_run_module_as_main": 45, "_run_onc": 45, "_score": 30, "_scorer": 30, "_set_output": 30, "_temp": 45, "_time_fit_was_cal": 44, "_transform": 30, "_transform_on": 30, "_valid": 30, "ab": [31, 33, 34, 36], "abbrevi": 41, "abil": [25, 30, 32, 36, 41, 43, 49], "abl": [8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 49, 51, 55], "about": [2, 4, 7, 10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55], "abov": [0, 5, 8, 11, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 46, 49, 51, 54, 55], "absenc": [30, 36, 40], "absolut": [31, 33, 34, 36, 38, 45, 55], "abspath": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54], "academ": [7, 37], "accept": [5, 8, 33, 34, 41], "accept_spars": 30, "access": [10, 11, 27, 29, 32, 35, 38, 40, 41, 43, 51], "accessori": 43, "accident": [28, 29], "accommod": 7, "accompani": [7, 25, 26], "accord": [31, 33, 34, 37, 40, 44, 51, 52, 53, 55], "account": [7, 10, 27, 33, 37, 40, 44, 47, 52], "accur": [25, 27, 35, 36, 37, 40, 44, 47, 48], "accuraci": [26, 27, 28, 29, 32, 33, 35, 36, 37, 39, 42, 44, 45, 47, 48, 52, 53, 55], "accuracy_scor": 33, "acdm": [33, 35, 36, 52], "acf": 43, "achiev": [8, 28, 33, 51, 53, 54], "acinonyx": [25, 42], "acoust": [28, 29, 32, 51], "acquir": 55, "acquisit": 40, "across": [25, 26, 27, 29, 33, 36, 42, 55], "act": [31, 55], "action": [0, 25, 35, 36, 38, 40, 41, 44, 55], "activ": [4, 11, 25, 32, 45, 47, 55], "actor": [40, 41], "actual": [7, 25, 31, 33, 35, 36, 38, 40, 41, 43, 44, 51, 53], "ad": [30, 31, 32, 33, 35, 36, 37, 39, 41, 42, 44, 45, 51, 54], "adapt": [0, 29, 30, 33, 35, 41, 43, 45], "add": [7, 8, 11, 29, 30, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 50, 52, 53, 54], "add_pip": 45, "addit": [0, 4, 34, 40, 52, 55], "addition": [48, 49, 55], "address": [18, 39, 52], "adelaid": [43, 54], "adj": 45, "adject": 41, "adjust": [28, 32, 39, 43, 49], "adm": [33, 35, 36], "admin": 55, "administr": 1, "admit": 27, "adopt": [6, 40], "adp": [41, 45], "adult": [33, 35, 36, 52], "adult_df_larg": [35, 36], "adv": 41, "advanc": [30, 32, 38, 39, 40, 41, 42, 48, 55], "advantag": [29, 30, 31, 35, 39, 40, 41, 47, 55], "advic": 44, "advis": 25, "advisor": 55, "af": 36, "affect": [11, 28, 29, 31, 32, 33, 38, 43, 44, 45, 49], "affix": 41, "after": [4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 33, 34, 36, 38, 39, 42, 43, 44, 45, 47, 53, 54, 55], "ag": [25, 31, 33, 34, 35, 36, 37, 40, 52, 53], "again": [11, 26, 27, 29, 39, 40, 41, 42, 44, 49, 52, 53, 54], "against": [40, 43, 51], "agenc": 45, "agent": 10, "agglomerativeclust": 39, "aggress": 41, "agnost": 36, "ago": [42, 43], "agre": 49, "agreement": [44, 55], "ahead": 52, "ai": [7, 9, 33, 37, 42, 52], "aight": 25, "aim": 47, "airport": 33, "aka": [31, 44], "al": [35, 41], "alamine_aminotransferas": 25, "alan": 10, "alaska": 31, "album": 32, "albumin": 25, "albumin_and_globulin_ratio": 25, "alburi": [43, 54], "alexnet": 42, "algebra": [40, 41], "algorithm": [2, 15, 25, 27, 29, 30, 33, 34, 35, 36, 39, 41, 42, 48, 49, 50, 52, 55], "align": [8, 25, 26, 27], "align_kei": 44, "alkaline_phosphotas": 25, "all": [0, 1, 4, 5, 6, 7, 8, 10, 11, 27, 28, 30, 32, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55], "all_cap": 45, "all_featur": [43, 54], "allei": [34, 36], "allen": 45, "alley_grvl": 34, "alley_miss": 34, "alley_pav": 34, "alloc": [8, 41, 42], "allow": [5, 7, 11, 27, 29, 32, 33, 37, 41, 43, 44, 48, 49, 51, 54, 55], "allpub": [34, 36], "almost": [31, 32, 34, 37, 39, 40, 41, 52], "along": [7, 26, 30, 33, 42, 43, 48], "alpha": [28, 29, 43, 49, 54], "alpha_": 34, "alphabet": 31, "alphago": [25, 38], "alq": [34, 36], "alreadi": [4, 8, 11, 33, 34, 36, 38, 43, 44, 45, 48, 51, 54, 55], "also": [2, 4, 5, 7, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "altar": 42, "altern": [8, 32, 38, 51, 55], "although": [27, 35, 38, 40, 44], "alwai": [25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 45, 47, 48, 49, 51, 55], "am": [29, 38, 45], "amatriain": 40, "amazon": [25, 38, 40, 45], "ambigu": 41, "amer": 33, "america": 30, "american": 38, "aml": 29, "among": [25, 26, 32, 33, 35, 36, 40, 53], "amongst": 45, "amount": [4, 25, 27, 31, 32, 33, 34, 36, 38, 42, 43, 44, 51, 54], "amp": [35, 36], "amplifi": [33, 41, 52], "amuel": 29, "an": [0, 2, 4, 6, 7, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 53, 54, 55], "anaconda": [11, 36, 45], "analogi": [15, 39, 41], "analysi": [2, 9, 10, 26, 33, 34, 38, 39, 41, 52, 55], "analyt": 43, "analyz": [33, 37, 43, 44, 54, 55], "anatinu": 42, "anca": 55, "ancestor": 37, "ancestr": 55, "ancuta": 55, "andrea": [9, 10], "andrew": [9, 10, 32, 37], "anemon": 42, "angel": [44, 45], "ani": [0, 11, 26, 27, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55], "anim": [33, 42], "animal_fac": 42, "anneal": 37, "annot": [36, 38], "announc": 7, "annoyingli": 34, "annual": 45, "anomali": [33, 34, 38], "anonym": 43, "anoth": [8, 11, 26, 28, 31, 32, 33, 35, 36, 38, 39, 40, 42, 43, 44, 47, 48, 50, 53, 54], "answer": [4, 6, 7, 25, 26, 27, 32, 35, 38, 40, 41, 43, 46, 48, 49, 52, 53, 54, 55], "anteat": 42, "anti": 44, "anymor": [34, 38, 40, 49], "anyth": [0, 27, 30, 33, 40, 41, 44, 51], "anytim": 55, "anywher": 30, "ap": [47, 55], "ap_lr": 33, "ap_svc": 33, "apart": [28, 39], "apeendixa": 37, "api": [33, 41, 43, 47], "app": [26, 45, 47], "appeal": 41, "appear": [2, 7, 30, 35, 49, 53, 55], "append": [4, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 48, 49, 50, 51, 52, 53], "appendix_b": 41, "appendixb": 42, "appli": [0, 2, 6, 9, 10, 25, 26, 27, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 55], "applic": [0, 5, 25, 30, 32, 33, 34, 36, 37, 41, 44, 45, 47, 52, 55], "appreci": [38, 55], "approach": [10, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 47, 49, 54, 55], "appropri": [0, 4, 11, 26, 27, 30, 33, 34, 38, 39, 43, 44, 47, 55], "approv": [33, 52, 55], "approx": [28, 36], "approxim": [26, 32, 37], "april": 43, "apt": 5, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 32, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "arang": [8, 27, 28, 31, 32, 33, 34, 49, 51], "arbitrari": [36, 38, 39, 43], "architectur": 42, "archiv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "area": [32, 34, 35, 37, 38, 51], "aren": [7, 34, 37, 38, 42, 43, 45, 54], "arena": 37, "arg": [27, 30, 45], "argh": 44, "argmin": [27, 28, 33, 38], "argsort": [36, 41], "argu": [38, 41, 51], "argument": [8, 26, 30, 32, 33, 34, 36, 45, 47, 50], "arima": 43, "arima_model": 43, "aris": [0, 25, 41], "aristotl": 28, "arithmet": 8, "around": [7, 28, 30, 33, 34, 43, 44, 48], "aroundn": 25, "arr": 44, "arr1": 8, "arr2": 8, "arrai": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51], "array_equ": 8, "arriv": 37, "arthur": 25, "articl": [10, 26, 27, 29, 33, 38, 40, 41, 42], "articul": 47, "artifici": [10, 41], "artist": [28, 29, 32, 51], "as_fram": [28, 49], "ascend": [8, 30, 31, 32, 34, 35, 36, 37, 43, 44, 47, 53], "ased": 39, "asi": 45, "asia": 30, "asid": [4, 27, 35, 49], "ask": [3, 7, 11, 25, 26, 27, 28, 30, 33, 37, 38, 40, 41, 44, 45, 48, 55], "asleep": 31, "aspartate_aminotransferas": 25, "aspect": [31, 36, 37, 39, 40, 44, 47], "assault": 55, "assert": [7, 30, 33, 35, 36, 52], "assess": [6, 10, 25, 26, 27, 29, 33, 36, 38, 55], "assign": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 50, 52, 54], "assist": 25, "assoc": [33, 35, 36, 52], "associ": [0, 25, 27, 28, 33, 34, 36, 37, 38, 41, 42, 43, 44, 47, 53, 55], "assum": [25, 26, 30, 31, 33, 34, 39, 40, 41, 43, 47, 52], "assumpt": 44, "asterisk": 32, "astyp": [8, 43, 44, 54], "astype_arrai": 44, "astype_array_saf": 44, "async_": 45, "async_help": 45, "asyncio": 45, "asyncio_loop": 45, "atabak": 55, "atratu": 42, "attack": 26, "attempt": [27, 51, 52], "attend": 55, "attent": [6, 41], "attic": 34, "attract": 41, "attribut": [0, 1, 25, 26, 28, 29, 31, 32, 37, 38, 41, 42, 51, 53], "attrit": 44, "auc": [44, 47, 52, 55], "audienc": [52, 55], "audio": [42, 55], "audit": 55, "auditor": 55, "augment": 33, "august": 43, "australia": [43, 54], "authent": 38, "author": [0, 41, 55], "auto": [25, 32, 33, 37, 38], "autocorrel": 43, "autom": [26, 34, 41], "automat": [29, 30, 34, 37, 41, 43, 44, 54], "autoregress": 31, "autumn": 43, "autumn_month": 43, "aux": 45, "av": [34, 36], "avail": [0, 1, 7, 9, 10, 11, 27, 30, 32, 33, 34, 39, 40, 41, 42, 43, 44, 47, 52, 53, 54, 55], "avebedrm": 31, "aveoccup": 31, "averag": [27, 28, 30, 31, 32, 34, 36, 38, 39, 41, 44, 45, 47, 49, 55], "average_precis": 33, "average_precision_scor": 33, "average_word_length": 45, "averaging_model": [35, 53], "averaging_model_ndt": 35, "averoom": 31, "avg": [33, 40, 43], "avg_sent_emb": 41, "avoid": [7, 8, 26, 29, 33, 34, 39, 43, 44, 46, 47, 49, 52, 55], "awai": [4, 6, 26, 31, 38, 40, 42, 44, 47], "await": 45, "awar": [30, 44, 55], "award": 55, "awesom": 9, "ax": [27, 28, 31, 33, 38, 39, 42, 44, 49, 52], "axi": [7, 8, 25, 26, 27, 29, 30, 31, 36, 38, 39, 41, 42, 43, 54], "axvlin": 38, "az": 45, "b": [8, 10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44], "b3": [29, 36], "babe": 25, "babi": [37, 41], "bachelor": [33, 35, 36, 52], "back": [8, 29, 32, 41, 47], "backdrop": 43, "background": [26, 55], "bad": [8, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 42, 43], "badgeryscreek": 43, "bag": [37, 41, 42, 47, 51], "bai": [29, 30, 37], "baidu": 27, "bal_scor": 33, "balanc": [6, 28, 35, 38, 40, 46, 52, 53], "ballarat": [43, 54], "balust": 42, "balustrad": 42, "bambi": 40, "banist": 42, "bank": [33, 36, 43, 44, 52], "bannist": 42, "bar": [33, 34, 36, 42, 43, 44, 54], "baranski": 45, "barbu": 55, "barri": 31, "base": [5, 8, 11, 15, 26, 27, 29, 30, 31, 32, 33, 34, 36, 38, 39, 41, 44, 45, 47, 48, 51, 52, 53, 55], "base_ev": 45, "base_scor": 35, "base_valu": 36, "baseblockmanag": 44, "baselin": [14, 44, 47, 48, 50, 51, 54], "baseline_hazard_": 44, "bash": 5, "basi": [26, 28], "basic": [2, 8, 26, 32, 37, 40, 42, 44, 45, 53, 54], "batch": [41, 42], "batch_siz": 42, "batch_t": 42, "bath": 25, "bathroom": [25, 26, 31], "bayesian": 32, "bayesopt": 32, "beagl": [25, 42], "bear": 42, "beat": [35, 44], "beauti": [40, 41], "becam": 42, "becaus": [7, 8, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 54, 55], "becom": [4, 27, 28, 31, 32, 33, 36, 37, 38, 41], "bed": 33, "bedroom": [25, 26, 31], "bedroomabvgr": [34, 36], "bedrooms_per_household": [29, 30, 50], "beef": 41, "been": [4, 6, 10, 25, 26, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 55], "befor": [4, 10, 11, 25, 26, 27, 28, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 48, 49, 51, 52, 53, 54], "begin": [26, 31, 37, 40, 43, 44, 47], "beginn": 42, "behav": [32, 36], "behavior": [27, 29, 33, 40], "behaviour": [30, 52, 53], "behind": [25, 31, 55], "being": [4, 25, 27, 29, 33, 34, 35, 36, 39, 41, 44, 49, 55], "believ": [32, 36, 43], "bell": 42, "belong": [26, 31, 39, 48], "below": [5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55], "bench": 42, "benchmark": 42, "bendigo": [43, 54], "benefici": 30, "benefit": [4, 28, 35, 39, 41, 47], "bengio": 32, "ber": 41, "bergstra": 32, "berri": 41, "bertop": 41, "best": [2, 26, 27, 28, 32, 33, 34, 35, 36, 38, 39, 40, 44, 48, 49, 51, 53], "best_alpha": 34, "best_depth": 27, "best_estimator_": [32, 34], "best_n_neighbour": 28, "best_param": 32, "best_paramet": 32, "best_params_": [32, 34, 51], "best_scor": 32, "best_score_": [32, 34, 51], "bestalpha_coeff": 34, "better": [6, 25, 26, 28, 29, 30, 31, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 55], "between": [2, 8, 11, 25, 27, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 55], "bewar": 41, "beyond": [27, 32, 37], "bia": [31, 33, 36, 44, 47, 52], "bias": [33, 36, 41, 44, 52, 55], "bicycl": [26, 43], "big": [7, 28, 30, 32, 33, 35, 37, 38, 39, 40, 41, 42, 44, 49], "bigalpha_coeff": 34, "bigger": [28, 30, 31, 34, 36, 39, 41, 42, 43], "biggest": [34, 37, 54], "bike": 43, "bill": 42, "billboard": 43, "billion": 34, "billionth": 43, "bin": [29, 32, 34, 37, 43, 44, 45, 48], "binar": [26, 30], "binari": [26, 29, 30, 31, 42, 44, 46, 47, 52], "binary_feat": 30, "binary_featur": [33, 35, 36, 52, 53], "binary_transform": [33, 35, 36, 52, 53], "bincount": [33, 35, 52], "bind": [28, 49], "binomi": 32, "biolog": 37, "biologi": 30, "bit": [11, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 51, 52, 54], "black": [28, 36, 38, 42, 43, 54], "bld": 45, "bldgtype": [34, 36], "bldgtype_1fam": 34, "bldgtype_2fmcon": 34, "bldgtype_duplex": 34, "bldgtype_twnh": 34, "bldgtype_twnhs": 34, "blei": 41, "blend": 41, "blindli": [33, 34], "blob": 46, "block": [31, 44], "blog": [41, 43], "bloomberg": [9, 10], "blq": [34, 36], "blue": [26, 28, 32, 33, 36, 37, 38, 43], "bmatrix": [37, 40], "board": 4, "boathous": 42, "bob_dylan": 41, "bodi": 45, "boggl": 35, "bond": 33, "bonu": 35, "book": [1, 9, 33, 34, 40, 41, 43, 55], "bookmark": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "bool": [34, 43], "boom": 45, "boost": [19, 20, 41, 47], "booster": 35, "bootstrap": 11, "border": [26, 31, 39, 41, 46, 48], "bore": 31, "boston": 31, "both": [2, 6, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 50, 51, 52, 55], "bother": 36, "bottom": 39, "bought": 40, "bound": [37, 44], "boundari": [27, 39, 41, 49], "bow_df": 30, "box": [9, 36, 47], "boxplot": 36, "boyc": 26, "br": 41, "bracket": 8, "brain": [37, 42], "branch": [26, 39, 41, 44], "break": [33, 47, 49], "breakwat": 42, "breath": 47, "breathtak": 41, "breed": 47, "breiman": 35, "brief": [4, 31, 35], "briefli": [25, 33, 35, 37], "bring": [6, 36, 39, 45, 47], "british": [1, 41], "british_columbia": 41, "broad": [28, 49], "broadcast": 41, "broader": [2, 35, 41], "broadli": [26, 28, 31, 33, 35, 38, 39, 41], "brownle": 37, "browser": 11, "brush": 42, "bsmtcond": [34, 36], "bsmtexposur": [34, 36], "bsmtfinsf1": [34, 36], "bsmtfinsf2": [34, 36], "bsmtfintype1": [34, 36], "bsmtfintype2": [34, 36], "bsmtfullbath": [34, 36], "bsmthalfbath": [34, 36], "bsmtqual": [34, 36], "bsmtunfsf": [34, 36], "btw": 36, "bubbl": [40, 42], "bucket": [37, 45], "budget": [32, 40], "bug": [4, 8], "bui": 40, "build": [0, 2, 11, 27, 29, 30, 35, 37, 38, 41, 43, 46, 49, 54, 55], "built": [8, 25, 26, 27, 31, 32, 36, 43, 54], "bullshit": [10, 44], "bulwark": 42, "bunch": [8, 11, 26, 34, 35, 42, 44, 49], "bundl": [7, 11], "bureau": 31, "busi": [33, 38, 44, 45], "bustl": 43, "butterfli": 39, "buzz": 25, "bypass": 55, "c": [0, 5, 8, 9, 10, 11, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 51, 55], "c1": 39, "c2": 39, "c_1": 38, "c_2": 38, "c_3": 38, "c_log": [28, 49], "c_widget": [28, 49], "ca": [5, 9, 45, 55], "ca_transform": 30, "cal_hous": 31, "calcul": [7, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 49, 52, 54], "california": [29, 37], "california_h": 37, "californian": 29, "call": [8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 53, 54], "callback": 35, "calm": 47, "came": 43, "camera": 30, "campu": [37, 55], "can": [4, 6, 7, 10, 11, 25, 26, 28, 30, 31, 32, 33, 34, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "canada": [5, 27, 28, 30, 31, 41, 45, 47], "canada_usa_c": [26, 27, 28, 31, 48], "canadian": 41, "canadien": 41, "canberra": [43, 54], "cancel": 55, "cancer": [25, 37], "candid": [32, 35, 41, 49], "cannot": [0, 8, 27, 28, 32, 33, 35, 36, 37, 39, 43, 44, 45, 55], "canva": [1, 7, 10], "capabl": 9, "capit": [33, 35, 36, 52], "caption": [7, 42], "captiv": 41, "captur": [27, 29, 31, 35, 37, 39, 40, 41, 43, 44, 47, 55], "car": [25, 41, 42], "card": [25, 26, 33, 44, 52], "care": [5, 7, 27, 29, 32, 33, 34, 36, 37, 38, 43, 44, 47, 51, 53, 54], "carefulli": [1, 33, 34, 52, 55], "carpentri": 5, "carri": [26, 27, 28, 30, 32, 33, 34, 35, 38, 40, 41, 43, 45, 49, 51, 54], "caruana": 36, "case": [6, 11, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 54, 55], "cash": 25, "cast": [32, 40, 45], "castl": 42, "cat": [25, 33, 35, 41, 42, 45, 47], "catamount": [25, 42], "catboost": [36, 47, 55], "catboostclassifi": 35, "catboostregressor": 35, "catch": [33, 55], "categor": [26, 32, 33, 34, 35, 37, 38, 40, 41, 44, 47, 49, 50, 52, 54], "categori": [28, 29, 33, 34, 35, 36, 37, 38, 42, 47, 52], "categorical_feat": [30, 32, 47, 51], "categorical_featur": [30, 33, 34, 35, 36, 43, 44, 52, 53, 54], "categorical_transform": [30, 33, 34, 35, 36, 43, 52, 53, 54], "categories_": [29, 30], "cater": 38, "caus": [33, 36, 37, 40, 44, 51], "causal": [36, 37], "caution": 43, "cbar": 31, "cbtf": [10, 55], "cc": [0, 1], "cc_df": [33, 52], "cconj": 41, "cell": [7, 8, 25, 29, 30, 32, 33, 34, 35, 36, 37, 40, 42, 44, 45, 48, 49, 51, 53], "cell_nam": 45, "censor": [10, 47, 55], "censu": [31, 33, 35, 36, 52], "census_df": [33, 52], "cent": 34, "center": [28, 38, 39, 42, 46], "centercrop": 42, "centers_idx": 38, "central": 5, "centralair": [34, 36], "centralair_i": 34, "centralair_n": 34, "centric": 55, "centroid": [38, 39], "centroids_idx": 38, "centroids_idx_init": 38, "centuri": 41, "certain": [11, 28, 31, 32, 33, 36, 37, 38, 41, 44, 52], "certainli": 48, "certainti": 33, "cezannec": 42, "chage": 51, "chain": 30, "challeng": [6, 27, 37, 38, 40, 42, 43, 47, 53, 55], "chanc": [26, 27, 32, 33, 34, 37, 38, 44, 52], "chang": [0, 5, 7, 8, 11, 26, 27, 28, 29, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 48, 49, 51, 52, 53, 54, 55], "channel": [1, 11, 42], "chapter": 10, "charact": [30, 33, 41], "characterist": [26, 27, 31, 51], "charg": [0, 25, 44], "charl": 31, "charm": 41, "chart": [36, 43, 44, 54], "chat": 55, "chatgpt": 41, "che210d": 9, "cheaper": 37, "cheat": 9, "check": [4, 7, 10, 11, 25, 26, 27, 29, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 49, 52, 53, 54], "check_assumpt": 44, "check_invers": 30, "checklist": 47, "checkmark": 40, "checkout": 32, "cheetah": [25, 42], "chest": 27, "chestpaintyp": 53, "chetah": [25, 42], "chi": 44, "chicago": 45, "chicken": 38, "child": [33, 36], "children": 40, "chines": 41, "chn": 8, "choic": [2, 32, 34, 35, 36, 38, 39, 40, 43, 45, 49, 50, 51], "cholesterol": 53, "choos": [25, 32, 33, 35, 39, 47, 49], "chop": [32, 41], "choreograph": 45, "chosen": [27, 32, 33, 44, 47, 53], "chrbv": 44, "christin": 45, "christma": 45, "chunki": 38, "churn": 47, "ciml": 10, "cinematographi": 41, "cinereu": 42, "circl": [28, 33], "circumst": 7, "citat": 7, "cite": 44, "citi": [26, 27, 28, 43, 47, 48], "citibik": 43, "cities_df": [28, 31], "citizen": 44, "cityscap": 43, "civ": [33, 35, 36], "clai": 36, "claim": [0, 32, 33], "clarif": 38, "clarifi": 47, "clariti": 55, "class": [4, 5, 11, 25, 26, 27, 28, 29, 30, 31, 37, 38, 43, 44, 48, 49, 52, 53, 54], "class_attend": [26, 27, 47], "class_attendance_enc": 30, "class_attendance_level": 30, "class_label": 33, "class_labels_fil": 25, "class_nam": [26, 28, 35, 42], "class_sep": 33, "class_weight": [35, 52], "classes_": [31, 33, 35, 36, 42, 46], "classic": [28, 42, 46], "classif": [2, 10, 27, 28, 29, 30, 31, 34, 35, 36, 37, 40, 41, 43, 44, 46, 48, 49, 51, 52, 53, 55], "classifi": [27, 28, 29, 30, 32, 33, 36, 42, 46, 48, 50, 52, 53], "classification_df": [26, 27], "classification_report": [33, 42, 52], "classifiers_ndt": 35, "classify_imag": [25, 42], "classmat": [6, 49, 50, 51, 52, 53, 54, 55], "classroom": 10, "clean": [2, 25, 39, 54, 55], "clean_text": 41, "cleaned_hm": 33, "cleaner": [33, 36], "clear": [7, 33, 38, 49, 55], "clearli": [4, 6, 7, 32, 35, 36, 43], "cleric": [33, 35, 36], "clf": [25, 26, 28, 31, 42], "cli": 41, "click": [5, 7, 10, 33, 40], "client": 40, "clinic": 26, "clip": 25, "clone": [5, 7, 11], "close": [2, 27, 28, 31, 32, 33, 38, 39, 41, 43, 45, 46, 49, 55], "close_default_lr": 33, "close_zero_svm": 33, "closer": [28, 29, 31, 40, 48, 51, 55], "closest": [28, 29, 33, 38, 39, 41, 43], "cloth": 43, "cloud": [25, 26, 30, 31, 32, 34, 35, 45], "cloud3pm": [43, 54], "cloud9am": [43, 54], "clust_label": 38, "cluster": [2, 10, 40, 41, 43, 55], "cluster_cent": 38, "cluster_centers_": 38, "cluster_std": [39, 42], "clutter": 26, "cm": [28, 31, 33, 36, 40, 49, 52], "cmap": [29, 32, 33, 36, 42, 51], "cmn": 34, "cmp": 44, "cnn": [42, 43], "co": [30, 41], "coast": 42, "code": [4, 7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54], "code_ast": 45, "code_obj": 45, "codecademi": 9, "coef": [43, 44, 45, 54], "coef_": [31, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 53], "coef_df": [31, 36], "coef_nonzero": 43, "coeff": 31, "coeff_df": 43, "coeffici": [34, 35, 37, 40, 42, 43, 44, 45, 46, 47, 53, 54], "coefs_df": 37, "coher": 38, "col": [26, 30, 31, 40, 43, 47], "col1": 8, "col2": 8, "col3": 8, "col4": 8, "col5": 8, "col6": 8, "cold": 29, "colinear": 36, "collabor": [5, 40, 55], "collaps": 36, "colleagu": [8, 9], "collect": [25, 26, 29, 30, 33, 35, 36, 37, 40, 41, 42, 43, 44, 47, 53, 55], "colleg": [33, 35, 36, 52], "collinear": 37, "color": [19, 23, 24, 31, 36, 37, 38, 39, 43], "color_continuous_scal": 37, "color_threshold": 39, "colorbar": [29, 31], "colour": [30, 31, 32, 36, 38, 39, 42], "colsample_bylevel": 35, "colsample_bynod": 35, "colsample_bytre": 35, "columbia": [1, 9, 41], "column": [7, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "column_nam": 30, "column_stack": 37, "columntranform": 50, "columntransform": [10, 16, 17, 29, 32, 33, 34, 35, 36, 37, 43, 44, 45, 51, 52, 53, 54], "columntransformer__countvectorizer__max_featur": [32, 51], "columntransformercolumntransform": [30, 32, 34, 35, 37, 45], "columntransformerifittedcolumntransform": [30, 34], "columntransformerinot": [30, 35], "com": [0, 5, 8, 9, 11, 25, 26, 30, 31, 33, 34, 35, 42, 43, 44, 45, 52], "comat": 41, "combin": [26, 29, 30, 32, 33, 37, 40, 42, 43, 44, 48, 49, 51, 53], "come": [11, 25, 26, 29, 30, 33, 37, 40, 41, 42, 43, 44, 48], "comedi": 40, "comfort": 5, "command": [4, 11, 33, 41], "comment": [8, 9, 54], "commerci": 0, "commit": [7, 33, 55], "common": [1, 8, 26, 27, 28, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 46, 49, 55], "commonli": [26, 29, 32, 33, 38, 44], "commun": [2, 10, 11, 30, 32, 34, 55], "commut": 8, "comp_dict": 33, "compact": [32, 37], "compani": [33, 38, 40, 41, 44, 45, 52], "compar": [8, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 46, 47, 51, 52, 53, 54, 55], "comparison": [39, 42, 44, 47], "compassion": 55, "compat": [8, 36, 45], "compatibitl": 8, "compel": 43, "compet": 45, "competit": [35, 42, 46], "compil": 45, "complain": [6, 45], "complaint": [6, 55], "complement": 41, "complet": [1, 6, 7, 25, 29, 32, 35, 36, 37, 39, 41, 44, 48, 49, 52, 53, 55], "complex": [26, 28, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 49, 55], "compli": 0, "complic": [4, 26, 27, 32, 34, 37], "compon": [30, 33, 40, 43, 55], "components_": 41, "compos": [28, 30, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 50, 51, 52, 53, 54], "composit": 30, "compound": [41, 42, 44, 45], "comprehend": 41, "comprehens": [38, 47, 55], "compress": [30, 38], "compris": [25, 26, 38], "comput": [7, 9, 10, 11, 25, 30, 32, 33, 35, 36, 37, 38, 39, 41, 43, 46, 52, 53, 55], "computation": 37, "compute_class_weight": 33, "computer_programm": 41, "coms4995": 29, "con": [38, 42], "concat": [25, 28, 29, 30, 31, 36], "concaten": [30, 41], "concav": 37, "concensu": 27, "concentr": [32, 47], "concept": [10, 26, 27, 36, 37, 38, 43, 47, 49, 55], "conceptu": 35, "concern": [4, 30, 35, 55], "concess": 7, "concis": 26, "concord": 44, "concordance_index": 44, "concordance_index_": 44, "concret": 25, "conda": [25, 33, 34, 35, 36, 38, 41, 44, 45], "condit": [0, 25, 26, 30, 37, 41, 44, 55], "condition1": [34, 36], "condition1_arteri": 34, "condition1_feedr": 34, "condition1_norm": 34, "condition1_posa": 34, "condition1_posn": 34, "condition1_rra": 34, "condition1_rran": 34, "condition1_rrn": 34, "condition1_rrnn": 34, "condition2": [34, 36], "condition2_arteri": 34, "condition2_feedr": 34, "condition2_norm": 34, "condition2_posa": 34, "condition2_posn": [34, 36], "condition2_rra": 34, "condition2_rran": 34, "condition2_rrnn": 34, "conditional_aft": 44, "confid": [25, 27, 36, 44, 47, 49, 52, 53], "confidenti": 33, "config": [11, 45], "configur": [32, 34, 35], "confirm": 11, "conflict": [11, 39, 55], "confound": 37, "confus": [8, 18, 28, 30, 34, 38, 49, 52], "confusion_matrix": [33, 42, 44], "confusionmatrixdisplai": [33, 52], "congrat": 30, "conjunct": 37, "connect": [0, 26, 39, 40], "connot": 41, "conort": 37, "consciou": 55, "consecut": 43, "consequ": [7, 25, 30, 33, 40, 52], "consid": [4, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43, 47, 49, 55], "consider": [2, 33, 35, 38, 40, 44, 55], "consist": [6, 7, 26, 27, 29, 38], "constant": [26, 33, 34, 35, 36, 43, 44, 52, 54], "constitu": 35, "constitut": [41, 55], "construct": 40, "constructor": [26, 29], "consult": [28, 49, 55], "consum": [25, 37, 38, 40, 47], "consumpt": 43, "contact": [25, 55], "contain": [8, 11, 19, 23, 24, 25, 26, 29, 30, 31, 34, 40, 41, 42, 45, 46, 55], "content": [1, 4, 11, 38, 41, 42, 47, 55], "contest": 6, "context": [26, 29, 31, 32, 33, 35, 36, 37, 39, 40, 42, 43, 47, 49, 55], "contextu": 55, "contin": 30, "conting": 39, "continu": [15, 30, 32, 34, 35, 37, 41, 43, 54], "contract": [0, 44], "contract_month": 44, "contract_on": 44, "contract_two": 44, "contrast": [47, 55], "contribut": [28, 31, 36, 42, 53, 55], "control": [5, 8, 26, 27, 28, 30, 31, 34, 35, 42, 55], "convei": 55, "conveni": [8, 32, 33, 38, 41, 43, 44], "converg": 38, "convers": [33, 34, 36, 41, 51], "convert": [25, 29, 30, 31, 35, 36, 37, 41, 43, 44, 54], "convinc": 30, "convolut": [37, 42], "convolutional_neural_network": 42, "cooccurrencematrix": 41, "cook": 38, "cool": 42, "coolwarm": 31, "coordin": 55, "copi": [0, 7, 8, 11, 26, 32, 35, 36, 38, 40, 42, 43, 44, 53, 54, 55], "copy_arrai": 45, "copyright": 0, "cor": 36, "coral": 42, "core": [9, 27, 29, 30, 32, 33, 34, 37, 39, 40, 43, 44, 45, 47, 54, 55], "corefer": 41, "corgi": [25, 42], "coro": 45, "corona_nlp_test": 45, "coronapocalyps": 45, "coronaviru": 45, "corpor": [5, 45], "corpora": [30, 41], "corpu": [30, 33, 41], "corr": 36, "corr_df": 36, "correct": [7, 25, 26, 27, 28, 33, 35, 36, 44, 48, 49, 53], "correctli": [10, 11, 26, 27, 33], "correl": [43, 47], "correspond": [10, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 38, 40, 43, 49, 51], "cosin": 41, "cosine_similar": 41, "cost": [8, 25, 42, 55], "cost_rep": 8, "costli": 33, "cot": 42, "cote": 42, "could": [6, 8, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 40, 41, 43, 44, 49, 51, 52, 54, 55], "count": [8, 26, 29, 30, 33, 34, 37, 41, 42, 43, 44, 45, 46, 49, 51, 52, 54, 55], "counter": 33, "counti": 49, "countri": [27, 28, 30, 31, 33, 35, 36, 52, 55], "country_columbia": 36, "country_dominican": 36, "country_guatemala": 36, "country_hondura": 36, "country_hong": 36, "country_hungari": 36, "country_india": 36, "country_iran": 36, "country_miss": [35, 36], "country_puerto": 36, "country_scotland": 36, "country_south": 36, "country_taiwan": 36, "country_thailand": 36, "country_trinadad": [35, 36], "country_unit": [35, 36], "country_vietnam": [35, 36], "country_yugoslavia": [35, 36], "countvector": [25, 31, 32, 33, 41, 45, 47, 51], "countvectorizercountvector": [30, 32, 45], "countvectorizeroriginaltweet": 45, "countvectorizersong_titl": 32, "coupl": [4, 26, 32, 39, 45, 54], "cours": [1, 2, 4, 5, 6, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51], "coursera": [9, 10], "coursework": 55, "court": 41, "covari": [26, 44], "cover": [8, 33, 35, 38, 42, 43, 55], "coverag": 33, "covid": 45, "covid2019": 45, "cox": 55, "coxph_fitt": 44, "coxphfitt": 44, "cph": [44, 47], "cph_param": 44, "cpp": 45, "cpsc": [9, 10, 11, 25, 26, 35, 37, 41, 42, 43, 45, 55], "cpsc330": [0, 11, 25, 26, 27, 30, 32, 36, 41, 42, 44, 45, 55], "cpsc330env": 11, "cpu": [32, 42, 45], "craft": [28, 33, 35, 36, 38, 49], "crash": [10, 45], "crate": 42, "creat": [8, 9, 11, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "create_lag_df": 43, "create_lag_featur": [43, 54], "create_y_from_r": 40, "creativ": 1, "credit": [0, 26, 33, 35, 41, 43, 44, 52], "creditcard": [33, 52], "crime": 31, "crimin": 36, "criteria": [26, 39], "criterion": 39, "critic": 55, "cross": [15, 26, 28, 30, 32, 34, 35, 36, 38, 40, 44, 45, 47, 50, 51, 52, 53, 54], "cross_val": 35, "cross_val_predict": [33, 35, 44], "cross_val_scor": [29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45, 47, 50, 51, 52, 53, 54], "cross_valid": [28, 29, 30, 31, 32, 33, 35, 36, 37, 40, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54], "cross_validate_std": 27, "crowd": [35, 39], "crown": 55, "crucial": [25, 27, 31, 36, 38, 39, 40, 41], "crude": 41, "cs189": 9, "cs189_ch7": 9, "csrc": 45, "csv": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "ct": 30, "cuda": 42, "cui": 55, "cultiv": 55, "cultur": [42, 55], "cupi": 45, "curios": 25, "curiou": [25, 49], "current": [35, 41, 42, 43, 44, 45], "curriculum": 55, "curv": [7, 8, 38, 47, 49, 55], "custom": [5, 8, 25, 26, 30, 33, 34, 40, 45, 47], "custom_plot_tre": [26, 27, 35, 36], "customerid": 44, "customiz": 45, "cut": 39, "cv": [27, 30, 33, 34, 35, 36, 37, 43, 44, 47, 49, 51], "cv_feat": 45, "cv_results_": [32, 34, 51], "cv_score": [27, 34], "cv_train_scor": 49, "cv_valid_scor": 49, "cycl": 8, "cyclic": 43, "cycling_data": 8, "cygnu": 42, "d": [4, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 52, 53, 54], "d1b": 55, "d1c": 55, "d1e": 55, "d1f": 55, "d3": 38, "da": 25, "dabeaz": 9, "dad": 37, "dai": [4, 8, 10, 37, 42, 44, 47, 54, 55], "daili": [44, 47], "dall": 43, "damag": [0, 33], "dan": 41, "danceabl": [28, 29, 32, 51], "dark": 45, "darker": 32, "dashboard": [28, 49], "data": [2, 5, 7, 8, 9, 10, 11, 15, 16, 39, 41, 44, 46, 47, 48, 50, 51, 52, 53, 55], "data_dict": 31, "data_dir": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54], "data_to_wrap": 30, "data_transform": 42, "data_transforms_bw": 42, "data_url": [33, 52], "datacamp": 9, "datafram": [25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 54], "dataload": 42, "dataloaders_bw": 42, "datapoint": 31, "dataquest": 9, "dataset": [8, 18, 25, 27, 28, 35, 36, 37, 38, 39, 44, 45, 46, 47, 49, 51, 52, 55], "dataset2": 38, "dataset_s": 42, "date": [7, 11, 25, 26, 40, 44, 45, 47, 49, 54, 55], "date_rang": 43, "dates_rain": [43, 54], "datetim": 44, "datetime64": [43, 54], "datetimeindex": 43, "daughter": 33, "daum\u00e9": 10, "daunt": 40, "dave": 41, "david": [10, 41], "day_nam": [43, 54], "daylight": [43, 54], "dayofweek": 43, "days_sinc": 43, "dbscan": 55, "dc": [43, 44, 45], "dcc": 31, "dd": [43, 54], "de": [41, 43], "deactiv": 11, "deadlin": 55, "deal": [0, 27, 28, 29, 34, 41, 44, 47, 50], "death": 55, "debat": [8, 36], "debbi": 45, "debug": [4, 36], "decad": 42, "decemb": [43, 54], "decid": [8, 26, 28, 31, 35, 36, 37, 38, 39, 41, 43, 44, 47], "decis": [2, 6, 10, 14, 27, 29, 32, 33, 35, 37, 42, 46, 47, 48, 50, 53, 55], "decision_boundari": 46, "decision_funct": 33, "decisiontreeclassifi": [27, 28, 29, 30, 31, 32, 36, 48, 49, 50, 51, 53], "decisiontreeclassifierdecisiontreeclassifi": 35, "decisiontreeregressor": [26, 34, 48, 49], "deck": 9, "declar": 55, "decomposit": [39, 40, 41], "decor": 45, "decreas": [27, 31, 32, 35, 36, 38, 49], "deduct": 7, "deem": 6, "deep": [2, 9, 32, 36, 37, 41, 44], "deepen": [47, 55], "deeper": [2, 32, 33, 34, 36], "deepexplain": 36, "def": [27, 28, 29, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 45, 49, 51, 54], "defalut": 51, "default": [5, 11, 26, 27, 30, 31, 32, 33, 34, 35, 38, 39, 42, 43, 44, 46, 51, 52, 55], "default_threshold": 33, "defaultdict": 40, "defin": [26, 28, 29, 30, 33, 35, 36, 38, 39, 40, 43, 54], "definit": [8, 28, 36, 38, 41, 43, 46, 47, 48], "degre": 33, "degrees_freedom": 44, "degrees_of_freedom": 44, "del": 35, "delai": [10, 11, 37], "deleg": 41, "delet": [4, 7, 29], "delgado": 35, "delight": 41, "deliver": 7, "delv": [41, 55], "demo": [10, 35, 55], "demograph": [26, 40], "demonstr": [26, 27, 29, 31, 32, 34, 35, 38, 40, 41, 42], "denomin": [34, 45], "denot": [26, 40], "dens": [39, 41], "densenet": 42, "densenet121": 42, "densenet121_weight": 42, "densiti": [36, 39, 47], "dep": 41, "department": 55, "departur": 37, "depend": [2, 8, 11, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 41, 43, 44, 53], "dependence_plot": 36, "dependents_no": 44, "dependents_y": 44, "deploi": [27, 33, 40, 47], "deploy": [36, 43, 55], "deprec": [27, 29, 33, 34, 44, 46], "deprecationwarn": [35, 44], "depth": [10, 26, 27, 32, 35, 39, 48, 49], "dequ": [35, 36, 53], "deriv": [0, 26, 31, 33, 40, 44, 47, 52], "descend": [8, 39, 42, 47], "descent": 43, "descr": 31, "describ": [8, 25, 26, 27, 28, 29, 31, 33, 34, 40, 41, 43, 49, 52, 54, 55], "descript": [34, 44, 45], "deserv": 6, "design": [26, 36, 39, 42, 51, 55], "desir": [33, 41, 44, 50], "desk": 55, "despit": [37, 41], "det": [41, 45], "detach": 42, "detail": [7, 28, 30, 35, 42, 55], "detect": [25, 26, 33, 34, 38, 39, 43, 52], "determin": [28, 38, 39, 41, 44, 49, 53, 55], "detriment": [33, 40, 52], "dev": [27, 46], "develop": [9, 10, 25, 27, 29, 30, 32, 33, 34, 35, 41, 42, 45, 47, 55], "devianc": 44, "deviat": [6, 27, 29, 35, 36], "devic": [35, 42, 45], "deviceprotect": 44, "deviceprotection_no": 44, "deviceprotection_y": 44, "df": [25, 26, 27, 29, 30, 32, 33, 34, 36, 37, 42, 43, 44, 45, 48, 54], "df_concat": 25, "df_float_1": 8, "df_float_2": 8, "df_hour_week_ohe_poli": 43, "df_locat": [43, 54], "di": 44, "diagnos": [27, 36, 47], "diagnosi": 33, "diagnost": 44, "diagon": [28, 33, 36], "diagram": [30, 32, 35, 36], "dialogu": 41, "dict": [33, 40], "dict_kei": 35, "dictionari": [8, 29, 32, 33, 35, 36], "did": [6, 26, 28, 36, 38, 41, 43, 45, 49, 51, 52, 53, 55], "didn": [32, 35, 36, 39, 43, 44], "die": 45, "diet": 26, "diff": [43, 54], "differ": [2, 5, 7, 8, 10, 11, 25, 26, 27, 28, 30, 31, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55], "differenti": [25, 26, 55], "difficult": [4, 6, 7, 33, 37, 38], "difficulti": [38, 47], "dig": [33, 34], "digit": 43, "dilemma": 40, "dim": 42, "dimens": [8, 31, 37], "dimension": [2, 8, 31, 32, 33, 35, 37, 38, 41], "direct": [31, 36, 37, 39, 41, 45], "direct_bilirubin": 25, "directli": [8, 10, 30, 34, 42, 44, 55], "director": 40, "directori": [11, 26, 27, 29], "dirichlet": [41, 42], "disabl": 41, "disadvantag": [32, 35, 39, 40, 50], "disast": 25, "discard": [37, 41], "disciplin": [33, 37], "disclos": [45, 55], "discourag": 8, "discours": 40, "discov": [37, 38], "discoveri": 25, "discret": [26, 37, 55], "discrete_scatt": [26, 27, 28, 31, 38, 39, 42, 46, 48, 49], "discretization_feat": 37, "discrimin": 35, "discuss": [1, 4, 27, 28, 29, 31, 36, 37, 38, 39, 43, 47, 49, 50, 51, 53, 54, 55], "diseas": [26, 33, 44], "dispatch": 45, "dispatch_queu": 45, "dispatch_shel": 45, "displaci": [41, 45], "displai": [7, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 39, 40, 42, 43, 44, 48, 49, 50, 51, 52, 54], "display_heatmap": [32, 51], "display_label": [33, 52], "disput": 41, "disrespect": 4, "dist": [28, 38, 39], "distanc": [8, 29, 37, 39, 40, 41], "distinct": [33, 37, 43], "distinguish": [26, 28, 30, 33, 49], "distract": 55, "distribut": [0, 11, 27, 33, 36, 37, 39, 41, 42, 43, 51, 54, 55], "district": [29, 31], "districtdatalab": 38, "disturb": 25, "dive": 36, "divers": [35, 38, 40, 43, 55], "divid": [31, 33, 35, 36, 43, 49], "divis": 36, "divorc": [35, 36], "dktal": 44, "dlwqn": 44, "dmp": 55, "do": [0, 4, 5, 6, 7, 8, 10, 11, 25, 26, 27, 28, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "do_execut": 45, "doc": [8, 9, 36, 41, 42, 45, 55], "doctor": [33, 35, 36, 52], "document": [0, 1, 7, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 51, 52, 53, 55], "document_top": 41, "documentari": 40, "doe": [5, 8, 11, 25, 27, 28, 29, 32, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 47, 49, 51, 53, 54, 55], "doesn": [7, 8, 27, 29, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 47], "dog": [33, 42], "dollar": [4, 31, 34], "dolli": 45, "domain": [0, 25, 36, 38, 41], "domin": [29, 34, 42], "domingo": [10, 27, 37], "don": [4, 25, 27, 30, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46], "done": [5, 11, 27, 30, 32, 33, 42, 43, 47, 50, 52], "dont": 45, "door": 42, "dot": [28, 31, 33, 35, 36, 37, 39, 41], "dot_product": 41, "doubl": 32, "down": [27, 33, 36, 44, 49, 53, 55], "downfal": 40, "downgrad": 45, "download": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 31, 33, 34, 36, 41, 42, 45, 49, 53], "dpi": 37, "dr": [41, 55], "draft": 10, "drag": 7, "drama": 40, "drastic": 33, "draw": [31, 32, 41], "drawback": [36, 40, 55], "drawn": 35, "dream": 42, "drinker": 41, "drive": [25, 36], "driven": [11, 32, 33], "drop": [7, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55], "drop_dupl": [28, 32], "drop_feat": [30, 47], "drop_featur": [33, 34, 35, 36, 43, 44, 45, 52, 54], "dropdown": [19, 23, 24], "dropdrop": [30, 34, 35, 45], "drope": 29, "dropna": [33, 43, 54], "dropoff": 38, "drug": 25, "dsci": [9, 10, 36, 46], "dsl": 44, "dt": 49, "dt88trtd17lf726d55bq16c40000gr": 45, "dt_best": 49, "dt_pipe": 32, "dtype": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 52, 53, 54], "dual": 33, "duan": 55, "duck": 42, "duckbil": 42, "due": [7, 31, 35, 37, 40, 55], "dummi": [26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 48, 50, 51, 52, 53, 54], "dummy_clf": [26, 48], "dummy_scor": 28, "dummy_valid_accuraci": 28, "dummyclassifi": [27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 42, 45, 48, 49, 50, 51, 52, 53, 54], "dummyregressor": [30, 35, 36, 37, 45, 50, 53], "dun": 25, "dunno": 25, "duplex": 34, "duplic": 8, "durat": [7, 37, 43, 44], "duration_col": 44, "duration_m": [28, 29, 32], "dure": [4, 8, 10, 25, 26, 28, 30, 31, 32, 35, 36, 37, 40, 47, 48, 49, 50, 51, 52, 53, 54, 55], "dwell": 34, "e": [6, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 55], "e737c5242822": 44, "e_": 27, "each": [7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55], "earli": [36, 44], "earlier": [29, 35, 37, 43, 44], "early_stopping_round": 35, "earn": 55, "earnest": 55, "easi": [7, 28, 29, 31, 35, 36, 37, 38, 39, 41, 45], "easier": [5, 7, 33, 36, 37, 40], "easiest": [36, 44, 45], "easili": [35, 37, 43, 48, 54], "echidna": 42, "econom": [30, 43], "ecosystem": 42, "ed": 1, "eda": [27, 41, 44, 47, 54], "edg": [26, 32], "edgecolor": [32, 43, 54], "edit": [32, 41], "edu": 9, "educ": [33, 35, 36, 40, 52], "education_level": [33, 35, 36, 52], "effect": [28, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 47, 49, 52], "effici": 32, "effort": [4, 11, 32, 37, 38, 40, 42, 55], "egg": 38, "eghbal": 55, "either": [4, 26, 27, 28, 30, 33, 36, 38, 39, 41, 42, 43, 49, 51], "elast": 44, "elbow": 39, "elect": 41, "electr": [34, 36], "electrical_fusea": 34, "electrical_fusef": 34, "electrical_fusep": 34, "electrical_miss": 34, "electrical_mix": 34, "electrical_sbrkr": 34, "electron": [44, 55], "eleg": 29, "elegantli": 41, "element": [0, 9, 10, 27, 30, 41, 48], "eli5": 36, "elif": [26, 43, 44], "elimin": 55, "els": [26, 30, 33, 42, 43, 44, 45, 52], "email": [25, 27, 33, 55], "emb": [7, 28, 33, 38, 39], "embed": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 42, 47, 55], "emoji": 45, "emoticon": [37, 38], "emp": 36, "empathi": 41, "emphas": 55, "emphasi": 55, "emploi": [43, 44, 47], "employ": 40, "employe": 26, "empti": [31, 41, 42, 43, 54], "en": [43, 44, 45, 54], "en_core_web_lr": 41, "en_core_web_md": [41, 45], "enabl": [11, 40, 41, 43], "enable_categor": 35, "enable_halving_search_cv": 32, "enc": [29, 30, 43], "enclosedporch": [34, 36], "encod": [16, 17, 25, 27, 32, 33, 34, 36, 40, 44, 47, 50, 52, 54], "encompass": [44, 47], "encount": [30, 32], "encourag": [11, 55], "end": [4, 8, 25, 27, 28, 31, 32, 33, 37, 38, 39, 40, 41, 43, 44, 49, 55], "endors": 0, "endpoint": 44, "energi": [28, 29, 32, 43, 51], "engag": 55, "engin": [9, 10, 30, 33, 34, 38, 40, 41, 44, 54, 55], "england": 45, "english": [25, 29, 32, 33, 41, 42, 45, 51], "enhanc": 55, "enjoi": [10, 31], "enjoy_class": 30, "enjoy_cours": [30, 47], "enjoy_course_enc": 30, "enjoy_the_mo": 33, "enough": [7, 28, 30, 33, 34, 35, 38, 40, 47, 51, 52, 54], "ensembl": [10, 19, 20, 34, 36, 37, 39, 40, 43, 44, 45, 53, 54, 55], "ensiti": 39, "ensur": [7, 29, 35, 43, 54, 55], "ent": [41, 45], "enter": [30, 44, 51], "enterpris": 5, "entertain": 41, "enthusiast": 25, "entir": [4, 8, 27, 34, 42, 43, 45, 53, 55], "entiti": [37, 40, 41, 45], "entitl": 30, "entlebuch": [25, 42], "entri": [28, 29, 30, 31, 33, 34, 37, 40, 43, 44, 54], "entropi": 26, "enumer": 35, "env": [11, 26, 27, 30, 32, 36, 44, 45, 46], "environ": [3, 5, 8, 25, 29, 30, 32, 33, 34, 35, 36, 37, 41, 42, 44, 45, 55], "environemnt": 11, "environment": 47, "ep": [26, 27, 28, 31, 39, 48], "epoch": 43, "epsilon": 39, "equal": [8, 28, 30, 33, 34, 35, 36, 39, 40, 43, 47, 54, 55], "equat": [4, 31], "equip": [28, 44, 55], "equival": [8, 33, 35, 52], "err": 41, "error": [4, 6, 7, 8, 11, 26, 28, 30, 31, 35, 36, 37, 41, 44, 45, 47, 49, 53, 55], "error_": 27, "erupt": 25, "erythrocebu": [25, 42], "es": [43, 54], "eskimo": 33, "esl": 10, "especi": [2, 26, 28, 32, 33, 35, 37, 40, 43], "essenti": [44, 47], "estat": 26, "estim": [27, 28, 30, 31, 32, 37, 38, 44, 47, 53], "estimators_": 35, "et": [35, 41], "etc": [2, 7, 8, 26, 37, 42, 43, 44, 45, 55], "ethic": [10, 55], "euclidean": [38, 39, 41], "euclidean_dist": [28, 29, 38, 39, 41], "ev": 45, "eva": 40, "eva_model": 40, "eval": 42, "eval_metr": [35, 36], "eval_on_featur": 43, "evalu": [8, 10, 26, 27, 32, 34, 36, 38, 43, 49, 53, 55], "evapor": [43, 54], "even": [0, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31, 32, 33, 37, 38, 39, 40, 43, 44, 45, 47, 49, 50, 52, 55], "event": [0, 33, 34, 45, 55], "event_col": 44, "event_observ": 44, "ever": [26, 46], "everi": [8, 26, 27, 35, 39, 43, 49], "everydai": [8, 41], "everyon": [6, 36, 47], "everyth": [30, 33, 40, 43, 53], "everywher": 43, "evict": 45, "evok": 41, "ex": [34, 36], "ex1_idx": 36, "ex2_idx": 36, "exact": [4, 44], "exactli": [7, 25, 27, 36, 49, 51], "exam": [6, 10], "examin": [27, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 52, 54], "exampl": [0, 4, 5, 6, 7, 8, 11, 34, 39, 40, 42, 43, 46, 47, 48, 49, 51, 52, 54, 55], "example1": 26, "example2": 26, "exceedingli": 49, "excel": [30, 31, 34, 36, 44, 47, 50], "except": [0, 7, 8, 27, 43, 44, 54, 55], "exception": 4, "exchang": [33, 47], "excit": 40, "exec": 45, "execut": [4, 7, 38], "execute_request": 45, "exercis": [7, 9, 10, 41, 45, 49, 50, 51, 52, 53, 54, 55], "exerciseangina": 53, "exhaust": 51, "exist": [8, 33, 37, 44, 52], "exp": [31, 44], "expand": [10, 26, 55], "expect": [1, 4, 7, 8, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54, 55], "expected_valu": 36, "expenditur": 43, "expens": [25, 33, 34, 37, 38, 40], "experi": [25, 32, 40, 41, 55], "experienc": 55, "experiment": 32, "expert": [25, 26, 27, 32, 36, 37, 52], "explain": [4, 7, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 52, 53, 55], "explan": [4, 27, 28, 47, 52], "explanatori": 26, "explicit": [33, 44], "explicitli": [8, 25], "exploit": 6, "explor": [26, 27, 30, 32, 33, 36, 37, 40, 41, 42, 49, 51], "exploratori": [34, 44, 47], "explos": 45, "expm1": 34, "expon": 32, "exponenti": 32, "export_graphviz": [26, 48], "exposur": 40, "express": [0, 8, 30, 31, 37, 41], "extend": [41, 42, 46, 55], "extend_block": 44, "extens": [28, 33, 36, 38, 39, 41, 43, 49, 55], "extent": [38, 41], "extercond": [34, 36], "exterior": 36, "exterior1st": [34, 36], "exterior1st_asbshng": 34, "exterior1st_asphshn": 34, "exterior1st_brkcomm": 34, "exterior1st_brkfac": 34, "exterior1st_cblock": 34, "exterior1st_cemntbd": 34, "exterior1st_hdboard": 34, "exterior1st_imstucc": [34, 36], "exterior1st_metalsd": 34, "exterior1st_plywood": 34, "exterior1st_ston": 34, "exterior1st_stucco": 34, "exterior1st_vinylsd": 34, "exterior1st_wd": 34, "exterior1st_wdsh": 34, "exterior2nd": [34, 36], "exterior2nd_asbshng": 34, "exterior2nd_asphshn": 34, "exterior2nd_brk": 34, "exterior2nd_brkfac": 34, "exterior2nd_cblock": 34, "exterior2nd_cmentbd": 34, "exterior2nd_hdboard": 34, "exterior2nd_imstucc": 34, "exterior2nd_metalsd": 34, "exterior2nd_oth": 34, "exterior2nd_plywood": 34, "exterior2nd_ston": 34, "exterior2nd_stucco": 34, "exterior2nd_vinylsd": 34, "exterior2nd_wd": 34, "exterqu": [34, 36], "extra": [4, 38, 43, 54, 55], "extract": [37, 38, 40, 41, 42, 45, 54, 55], "extractor": 47, "extrapol": [43, 44], "extratreesclassifi": 35, "extrem": [6, 30, 33, 35, 36, 40, 44, 45], "ey": 45, "f": [8, 11, 25, 26, 27, 28, 29, 30, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 49, 53, 54, 55], "f1": [18, 34, 47, 55], "f1_score": 33, "f403": 45, "fa": [34, 36], "face": [25, 26, 28, 40, 42], "facebook": [40, 41, 55], "facial": 28, "facil": 55, "facilit": [8, 55], "fact": [25, 32, 33, 35, 42, 43, 44, 54], "factor": [26, 32, 36, 37, 39, 40, 44], "fail": [7, 8, 10, 11, 27, 29, 30, 37, 39, 41, 44, 45], "failur": [7, 25, 44, 53, 55], "fair": [6, 27, 29, 34, 36, 38, 47, 55], "fairli": [27, 32, 33, 36, 52], "fake": 28, "fall": [28, 38, 41, 43], "fals": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 47, 52, 53, 54], "famili": [25, 32, 33, 34, 35, 36, 38, 55], "familiar": [8, 11, 26, 29, 49, 54, 55], "famou": [9, 10, 42], "fanci": [4, 25, 32], "fancier": 37, "far": [26, 28, 29, 30, 31, 33, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 49, 51, 53], "farm": 33, "farthest": 26, "fashion": [35, 41], "fast": [27, 28, 31, 35, 36, 41, 44, 55], "faster": [25, 32, 35, 37, 42], "fastest": 35, "fastingb": 53, "fasttext": 41, "favourit": 41, "fc": 31, "fcluster": 39, "feat": [32, 43, 45], "feat1": 38, "feat2": 38, "feat_nam": [43, 45], "feat_vec": 40, "featur": [10, 16, 17, 21, 22, 23, 24, 27, 33, 35, 38, 39, 41, 44, 46, 49, 50, 51, 52, 53, 55], "feature_extract": [25, 30, 31, 32, 33, 41, 45, 51], "feature_importances_": 37, "feature_nam": [26, 27, 31, 35, 36, 37, 41], "feature_names_out": 30, "feature_select": 37, "feature_typ": 35, "features_lag": 43, "features_nonzero": 43, "features_poli": 43, "februari": 43, "feder": [33, 36, 43], "feedback": [26, 47], "feel": [5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 38, 47], "feli": [25, 42], "fell": 31, "femal": [33, 35, 36, 44, 52], "female_cm": [33, 52], "female_pr": [33, 52], "fenc": [34, 36, 42], "fernandez": 35, "fetch_california_h": 31, "few": [8, 10, 25, 31, 34, 35, 37, 40, 42, 43, 44, 48, 53], "fewer": [11, 35, 37, 39], "fewest": 53, "fiber": 44, "fiction": 45, "field": [2, 4, 25, 30, 41, 42, 43, 55], "fig": [27, 28, 31, 33, 37, 38, 39, 42, 49, 52], "figsiz": [26, 27, 28, 29, 31, 33, 36, 37, 38, 39, 42, 43, 44, 49, 52], "figur": [4, 8, 11, 25, 26, 28, 32, 34, 36, 37, 38, 39, 42, 43, 44, 49], "file": [0, 1, 4, 5, 7, 8, 11, 19, 26, 30, 33, 36, 42, 44, 45, 52, 54], "filenam": 42, "fill": [28, 31, 32, 40, 49, 53, 55], "fill_diagon": 28, "fill_valu": [33, 34, 35, 36, 43, 52, 54], "film": [41, 45], "filter": [4, 25, 27, 38, 43, 47, 54, 55], "filterwarn": [28, 44, 53], "final": [6, 7, 10, 27, 29, 35, 37, 48, 50, 53], "final_estim": 35, "final_estimator_": [35, 53], "financ": [42, 43], "find": [7, 8, 10, 25, 26, 29, 32, 34, 35, 36, 38, 39, 40, 41, 45, 46, 51, 52, 55], "fine": [7, 29, 30, 33, 40, 42, 43, 53], "finish": [25, 34], "fira": [0, 1, 55], "firasm": [33, 52], "fireplac": [34, 36], "fireplacequ": [34, 36], "first": [4, 8, 10, 26, 28, 30, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 55], "first_dai": 43, "first_day_retail": 43, "firth": 41, "fish": [33, 36], "fist": 43, "fit": [0, 25, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54], "fit_intercept": 33, "fit_predict": 39, "fit_resampl": 33, "fit_tim": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45], "fit_transform": [29, 30, 33, 35, 36, 37, 39, 40, 41, 43, 47, 52], "fittedcolumntransform": [30, 35], "fittedpipelin": [30, 32, 34], "fittedvotingclassifi": 35, "fitter": 44, "five": 32, "fix": [29, 30, 35, 44, 46, 49, 55], "flag": 44, "flagstaff": 45, "flaki": 33, "flashcard": 47, "flat": 39, "flatten": [35, 36, 39, 43, 53], "flatten_train": 42, "flatten_transform": 42, "flatten_valid": 42, "flaw": [27, 29], "flawless": 31, "flexibl": [7, 25, 37, 42, 47, 55], "flibbertigibbet": 41, "flickr_cat_000002": 42, "flight": 37, "flip": [10, 27, 33, 34], "flip_i": 33, "float": [8, 34, 37, 44, 45], "float32": [41, 42], "float64": [26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 43, 44, 54], "floatlogslid": [28, 49], "floatslid": [28, 33, 38, 39, 49], "floor": [25, 26], "flower": [28, 33, 49], "fmt": 32, "fn": 33, "fnlwgt": [33, 35, 36, 52], "focu": [10, 25, 29, 30, 31, 36, 39, 40, 41, 43, 47, 49, 50, 51, 52, 53, 55], "focus": [25, 31, 38, 41, 47, 54], "fold": [27, 29, 30, 32, 33, 34, 35, 49], "folder": [5, 6, 27, 29, 36, 45], "folk": [44, 55], "follow": [0, 5, 6, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 49, 55], "font": [25, 26, 27, 38, 39, 40, 43, 44], "font_scal": 36, "fontsiz": [26, 27, 28, 33, 35, 36, 38, 42, 48, 49], "food": [38, 41, 42, 55], "foot": [34, 36], "footag": 31, "footstal": 42, "forc": [33, 36, 49], "force_plot": 36, "forecast": [26, 44, 47, 54, 55], "forest": [33, 34, 42, 43, 44, 47, 53, 55], "forev": 43, "forg": [11, 33, 34, 35, 36, 41, 44, 45], "forget": [26, 30, 35, 53], "form": [10, 30, 33, 37, 39, 40, 41, 44, 47], "formal": 55, "format": [0, 10, 26, 33, 39, 41, 43, 44, 54], "former": 44, "formul": [4, 32], "formula": [31, 34, 42, 46], "forum": [6, 7], "forward": 44, "found": [7, 10, 27, 30, 32, 34, 38, 40, 41, 45, 47, 51, 53, 55], "foundat": [9, 10, 33, 34, 36, 55], "foundation_brktil": 34, "foundation_cblock": 34, "foundation_pconc": 34, "foundation_slab": 34, "foundation_ston": 34, "foundation_wood": 34, "fountain": 42, "four": [26, 27, 37, 39, 47], "fourth": 39, "foxhound": [25, 42], "foyer": 34, "fp": 33, "fpr": 33, "fpr_lr": 33, "fpr_svc": 33, "frac": [26, 31, 33, 34, 38, 41, 42], "fractal": 37, "fraction": [30, 33, 40], "fragment": 49, "frame": [29, 30, 33, 34, 37, 43, 44, 54], "framework": [26, 32], "fraud": [26, 33, 34, 38, 43, 52], "fraudul": [26, 33, 52], "free": [0, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 34, 41, 44], "freedom": [0, 45], "french": 29, "freq": [43, 54], "frequenc": [30, 41, 43, 44, 47, 54], "frequent": [26, 29, 40, 41, 44], "fresh": 40, "fri": [10, 43], "fridai": [10, 55], "friend": [26, 27, 33, 36, 39, 40, 47, 55], "from": [0, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "from_block": 44, "from_estim": [33, 52], "front": 55, "frozen": 45, "fruit": 41, "frustrat": [4, 6, 32], "full": [32, 35, 42, 43, 44, 55], "fullbath": [34, 36], "fulli": 39, "fun": [33, 41, 42], "func": [8, 30, 31, 34], "function": [2, 25, 26, 27, 28, 30, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 51, 52, 54], "functiontransform": [30, 44], "fund": 45, "fundament": [2, 9, 10, 15, 29, 31, 32, 34, 37, 42, 44, 55], "funni": [25, 35, 45], "furnish": 0, "furnitur": 47, "further": [33, 35, 37, 38, 42, 44, 49, 51, 52], "futur": [27, 29, 32, 34, 44, 47, 51, 54, 55], "futurewarn": [27, 29, 34, 36, 46], "fyi": 44, "g": [6, 7, 8, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55], "g26r0dcx4b35vf3nk31216hc0000gr": [29, 36], "gain": [6, 26, 33, 35, 36, 52, 55], "game": [26, 36], "gamma": [31, 32, 35, 49, 51], "gamma_log": [28, 49], "gamma_widget": [28, 49], "gap": [27, 43, 44, 47, 49], "garagearea": [34, 36], "garagecar": [34, 36], "garagecond": [34, 36], "garagefinish": [34, 36], "garagefinish_fin": 34, "garagefinish_miss": 34, "garagefinish_rfn": 34, "garagefinish_unf": 34, "garagequ": [34, 36], "garagetyp": [34, 36], "garagetype_2typ": 34, "garagetype_attchd": 34, "garagetype_bas": 34, "garagetype_builtin": 34, "garagetype_carport": 34, "garagetype_detchd": 34, "garagetype_miss": 34, "garageyrblt": [34, 36], "garlic": 38, "gauss": 41, "gaussian": 39, "gaussianmixtur": 39, "gave": [40, 43], "gbr": 8, "gca": [38, 39, 44], "gd": [25, 34, 36], "gdprv": [34, 36], "gdwo": [34, 36], "gelbart": [0, 1, 26, 41, 51], "gender": [25, 30, 33, 41, 43, 44, 52], "gender_femal": 44, "gender_mal": 44, "gener": [7, 9, 15, 26, 29, 30, 32, 33, 34, 36, 39, 41, 42, 43, 44, 46, 47, 49, 51, 52, 54, 55], "genet": 37, "genom": 37, "genr": 40, "gensim": 41, "gentl": 55, "geograph": 31, "geometr": 26, "georg": 41, "geq": 31, "ger": 8, "german": 41, "get": [4, 5, 6, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55], "get_avg_word_length": 45, "get_cmap": 29, "get_depth": 49, "get_dummi": 29, "get_featur": 42, "get_feature_names_out": [29, 30, 33, 34, 35, 36, 37, 41, 43, 44, 45, 52, 54], "get_length_in_word": 45, "get_lr_data_per_us": 40, "get_permutation_import": 36, "get_relative_length": 45, "get_season": 43, "get_senti": 45, "get_stat": 40, "get_user_profil": 40, "getattr": 44, "gif": [38, 39], "gift": 45, "gini": [26, 36], "git": [3, 8], "github": [0, 1, 7, 9, 10, 11, 25, 29, 30, 32, 33, 34, 35, 36, 37, 42, 45, 51, 52], "githubusercont": 8, "gitlf": 33, "giulia": [0, 1], "give": [0, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 48, 49, 52], "given": [0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 52, 54], "gladwel": 38, "glob": [25, 42], "global": [29, 33, 35, 38, 41, 47], "glove": [41, 55], "glq": [34, 36], "gmail": [25, 38], "go": [5, 7, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54], "goal": [2, 28, 29, 32, 33, 38, 39, 40, 41, 45, 51, 53, 54, 55], "goe": [2, 27, 28, 30, 33, 35, 36, 39, 40, 42], "gold": 8, "goldcoast": 43, "golden": [28, 47, 49], "good": [9, 11, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54], "googl": [4, 10, 25, 26, 35, 36, 37, 38, 41, 45], "google_news_vector": 41, "got": [28, 31, 32, 33, 34, 42], "gotten": [44, 53], "gov": [33, 35, 36], "govern": [41, 55], "gpe": 41, "gpt": [40, 41], "gpu": [35, 41, 42], "grad": [33, 35, 36, 52], "grade": [3, 7, 10, 25, 27, 30, 32, 47, 49, 50, 51, 52, 53, 54], "grader": 6, "grades_df": 47, "gradescop": [1, 6, 10, 55], "gradient": [19, 20, 47], "gradientboostingclassifi": 35, "gradientboostingregressor": 35, "gradientexplain": 36, "grading_concern": 6, "graduat": 42, "grai": 42, "grain": [31, 36], "gram": 41, "grammat": 41, "grandma": 37, "grandmoth": 33, "grant": 0, "granular": 39, "graph": [10, 42, 43], "graphic": 42, "graphviz": [26, 48], "grasp": [47, 55], "grayscal": 42, "great": [25, 26, 28, 30, 31, 36, 37, 41, 42, 43, 45], "greater": [11, 37, 38], "greater_is_bett": 34, "greedili": 39, "green": [28, 32, 38, 46], "grei": 55, "grid": [31, 34, 43, 44, 47, 51, 54], "grid_search": [32, 51], "gridsearchcv": [28, 35, 36, 51, 53], "gridsearchcvifittedgridsearchcv": 32, "grip": 41, "grlivarea": [34, 36], "groak": 41, "groceri": [42, 45], "groin": 42, "ground": [27, 37, 39, 40, 55], "ground_truth_categori": 33, "group": [7, 26, 28, 30, 31, 35, 37, 47, 49, 50, 53, 55], "groupbi": [43, 54], "grow": [32, 35, 37], "grow_polici": 35, "growth": [43, 44], "groyn": 42, "grv": 34, "gt": [30, 31, 32, 33, 34, 35], "gtl": 36, "guarante": [32, 33, 35, 38, 42], "guenon": 42, "guess": [28, 29, 41, 45], "guid": [7, 9, 10, 37, 42, 55], "guidanc": 36, "guidelin": [36, 37], "guido": 10, "h": [33, 35, 36, 38, 41, 42, 44, 45, 52], "ha": [2, 5, 6, 10, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 49, 52, 53, 54, 55], "habit": 30, "hacki": [42, 46], "had": [25, 29, 30, 31, 33, 40, 42, 43, 44], "hadn": 44, "hal": 10, "half": [6, 10, 26, 31, 37, 39], "halfbath": [34, 36], "halvingrandomsearchcv": 32, "halvingrandomsearchcvifittedhalvingrandomsearchcv": 32, "ham": 25, "hand": [4, 9, 33, 40, 52, 55], "handi": 33, "handl": [35, 36, 39, 44, 45, 46, 47, 49, 55], "handle_unknow": 30, "handle_unknown": [29, 30, 32, 33, 34, 35, 36, 43, 44, 47, 51, 52, 53, 54], "handler": [33, 36], "handrail": 42, "handwritten": 33, "hang": 33, "happen": [4, 6, 25, 28, 30, 32, 35, 36, 37, 40, 43, 44, 47, 54, 55], "happi": [33, 38, 44], "happier": 55, "happydb": 33, "hard": [8, 25, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 53], "hardli": 40, "hardwar": 42, "harmon": 33, "harri": 41, "has_cupi": 45, "has_emoji": 45, "has_rais": 45, "hasn": [4, 40, 44], "hassl": [8, 36, 43], "hat": [31, 34, 35], "have": [0, 4, 6, 7, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55], "haven": [27, 44, 47], "haylei": 26, "hazard": 55, "hc_truncation_toy_demo": 39, "hdbscan": 39, "he": [27, 30, 55], "head": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54], "headlin": 41, "health": 41, "healthcar": 36, "healthi": 41, "heard": 27, "heart": [26, 45, 53], "heart_df": 53, "heartdiseas": 53, "heat": [32, 34, 36, 51], "heating_floor": 34, "heating_gasa": 34, "heating_gasw": 34, "heating_grav": 34, "heating_othw": [34, 36], "heating_wal": 34, "heatingqc": [34, 36], "heatmap": 36, "heavi": [35, 45], "heavili": [40, 42, 43, 52], "heeren": 41, "height": [26, 27, 33, 41, 45, 48], "hell": 45, "help": [3, 7, 11, 25, 27, 29, 30, 32, 33, 36, 38, 39, 40, 41, 43, 44, 45, 48, 49, 50, 54, 55], "henc": [5, 33, 34, 36, 38], "her": [25, 40, 41], "here": [1, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55], "herebi": 0, "herself": 45, "herta": 28, "heurist": [26, 32], "hi": [41, 49], "hidden": [37, 42], "hide": [8, 42], "hier_label": 39, "hier_labels1": 39, "hier_labels2": 39, "hierarch": [47, 55], "hierarchi": [26, 39], "high": [6, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 55], "high_corr": 36, "higher": [26, 27, 28, 31, 33, 34, 35, 36, 37, 38, 40, 44, 49, 51, 52], "highest": [35, 36, 40, 41, 42, 46, 49, 52], "highland": 45, "highli": [10, 11, 29, 36, 40], "highlight": [4, 42, 47], "highwai": 31, "hinder": 55, "hindi": 29, "hint": [36, 49], "hist": [29, 32, 34, 37, 44], "histgradientboostingclassifi": 35, "histgradientboostingregressor": 35, "histogram": 44, "histor": 47, "histori": [31, 40, 43, 55], "hit": [25, 32], "hitter": 45, "hl": [34, 36], "hmid": 33, "hmmm": 44, "hockei": 41, "hold": 51, "holder": 0, "holdout": 33, "holidai": [10, 40, 55], "home": [26, 31, 33, 42], "homepag": 1, "homework": [3, 4, 6, 8, 10, 11, 28, 31, 32, 41, 47, 55], "honour": 55, "hood": 27, "hope": 27, "hopefulli": 51, "hopeless": 37, "hopelessli": 28, "horizont": [26, 30], "host": [5, 44], "hot": [16, 27, 30, 36, 47, 54], "hound": [25, 42], "hour": [4, 11, 33, 35, 36, 37, 40, 43, 47, 52, 55], "hourli": [44, 47], "hous": [18, 34, 36, 37, 44, 49], "houseag": 31, "household": [29, 30, 31, 37, 50], "housestyl": [34, 36], "housestyle_1": 34, "housestyle_1stori": 34, "housestyle_2": 34, "housestyle_2stori": 34, "housestyle_sfoy": 34, "housestyle_slvl": 34, "housing_df": [26, 29, 30, 37, 49, 50], "housing_median_ag": [29, 30, 37, 50], "houston": 45, "how": [0, 3, 8, 11, 25, 30, 32, 33, 34, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55], "howard": 38, "howev": [2, 8, 29, 30, 33, 34, 36, 38, 40, 43, 44, 46, 49, 52], "hsjcy": 44, "hstack": 43, "html": [7, 9, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 44, 45, 48, 50, 52], "http": [0, 5, 8, 9, 11, 25, 26, 27, 29, 30, 31, 33, 34, 35, 42, 43, 44, 45, 52, 55], "hug": 40, "huge": [30, 34, 41, 42, 43, 44, 54], "human": [0, 25, 28, 29, 30, 31, 32, 33, 36, 37, 38, 41, 42, 52], "humidity3pm": [43, 54], "humidity3pm_lag1": [43, 54], "humidity9am": [43, 54], "hummu": [38, 41], "humour": [10, 41], "hundr": 31, "hurrai": 53, "hurrican": 25, "husband": [33, 35, 36], "hussar": [25, 42], "hw": 25, "hw1": [4, 10, 48], "hw2": [10, 28, 29, 51], "hw3": 10, "hw4": 10, "hw5": [10, 55], "hw6": 10, "hw6a": 7, "hw6b": 7, "hw7": 10, "hw8": 10, "hw9": 10, "hybrid": 40, "hyperband": 32, "hyperopt": 32, "hyperparamet": [10, 27, 33, 39, 40, 41, 42, 51], "hyperparamt": [27, 32, 44], "hyperparlan": 31, "hyperplan": 31, "hypothesi": [41, 44], "hypothet": [31, 38], "i": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 31, 34, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "i1": 35, "i2": 35, "ia": 45, "ibm": 45, "ic": 41, "icc": 55, "iclick": 10, "id": [25, 26, 34, 36, 40, 49], "idea": [8, 26, 27, 29, 32, 36, 38, 39, 40, 41, 42, 43, 44, 47, 49, 54], "ideal": [4, 33, 35, 37, 40, 44], "ident": [41, 42, 45], "identif": [25, 45], "identifi": [26, 27, 28, 29, 32, 33, 34, 38, 39, 41, 42, 43, 47, 52, 54, 55], "idf": 30, "idx": 42, "idxmax": 28, "if_binari": [30, 33, 35, 36, 47, 50, 52, 53], "ifram": [27, 33], "igloo": 41, "ignor": [26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 43, 44, 47, 51, 52, 53, 54], "ignore_index": 8, "ii": 33, "iii": 10, "ij": [31, 40], "ik": 35, "ill": 55, "illus": [33, 52], "illustr": [39, 43], "iloc": [8, 26, 27, 28, 29, 30, 35, 36, 41, 43, 45, 48, 53, 54], "im": 45, "imag": [7, 27, 33, 36, 37, 38, 39, 43, 47, 52, 55], "image_dataset": 42, "image_datasets_bw": 42, "image_s": 42, "imagefold": 42, "imagenet": 46, "imagenet1k_v1": 42, "imagenet_class": [25, 42], "imagin": [25, 26, 27, 29, 31, 33, 36, 37, 38, 41, 44, 47, 48, 52], "imaginari": [27, 41], "imbal": [18, 38, 44, 52], "imbalanc": [33, 34, 46], "imblearn": 33, "img": [25, 42], "img_classifi": 25, "img_path": 25, "img_t": 42, "immedi": [36, 40, 55], "imp": [29, 30, 43], "impact": [7, 30, 31, 35, 36, 39, 43, 49, 54, 55], "implement": [2, 4, 25, 29, 33, 34, 35, 37, 39, 40, 41, 44, 46], "impli": [0, 44], "implic": [29, 47, 55], "implicit": 41, "import": [8, 10, 21, 22, 23, 24, 46, 50, 51, 52, 53, 55], "importance_typ": 35, "importances_mean": 36, "impos": 29, "imposs": 38, "impress": 36, "improv": [32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 47, 51, 55], "impur": [26, 35], "imput": [16, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 47, 50, 51, 52, 53, 54], "imread": 42, "imshow": [25, 42], "inbox": 27, "inc": [36, 41], "incept": [40, 42], "inception": 42, "incl": 34, "includ": [0, 2, 4, 5, 6, 7, 8, 11, 26, 29, 30, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55], "include_bia": [37, 43], "incom": [27, 31, 33, 35, 36, 52], "incomplet": 44, "inconsist": 30, "incorpor": [32, 34, 37, 44, 47], "incorrect": 44, "incorrectli": [25, 33], "increas": [8, 27, 28, 30, 31, 35, 36, 37, 38, 39, 42, 49, 51], "increasingli": 25, "incred": 42, "inde": 36, "independ": [8, 9, 26, 32, 34, 35, 37, 43, 55], "index": [25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 49, 52, 53, 54], "index_col": [8, 28, 29, 32, 33, 40, 51], "india": 41, "indian": 33, "indian_liver_pati": 25, "indic": [0, 30, 38, 40, 41, 42, 43, 44], "individu": [35, 36, 38, 40, 41, 44, 53, 55], "industri": [35, 37, 41, 42], "inequ": [33, 52], "inertia_": 38, "inertia_valu": 38, "inf": [28, 44], "infeas": 32, "infer": [26, 41, 42, 43, 48], "infin": 28, "infinit": 32, "inflamm": 9, "inflat": 36, "inflect": [38, 41], "influenc": [26, 27, 32, 36, 38, 40, 44, 49], "info": [1, 3, 8, 29, 30, 33, 34, 37, 41, 43, 44, 49, 53, 54], "inform": [1, 4, 7, 11, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 49, 52, 53, 54, 55], "inhabit": 55, "inher": [33, 43, 44, 52], "initi": [39, 42, 45], "initj": 36, "inject": [37, 40, 47], "inland": [29, 30, 37, 50], "inlin": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 48, 49, 51, 52, 53], "inner": [30, 32, 41], "inplac": [8, 25, 26, 32], "input": [8, 26, 29, 31, 35, 36, 39, 41, 42, 43, 45, 47, 54], "input_img": 42, "inputs_bw": 42, "insid": [9, 30, 33], "insight": [2, 28, 33, 36, 38, 55], "inspct": 33, "inspect": [36, 39], "inspir": [26, 33, 35], "instal": [25, 28, 33, 34, 35, 36, 38, 41, 42, 44, 45], "instanc": [25, 26, 27, 30, 31, 33, 38, 39, 40, 41, 42, 43, 46], "instanti": [32, 49], "instead": [5, 8, 11, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 49, 51, 52, 53], "institut": 45, "instruct": [3, 4, 5, 11, 28, 55], "instructor": [4, 6, 25, 55], "instrument": [28, 29, 32, 51], "int": [29, 30, 33, 35, 36, 41, 43, 45, 52, 53, 54], "int32": [28, 38, 39, 43], "int64": [26, 28, 30, 33, 34, 40, 43, 44, 45], "integ": [8, 27, 29, 32, 35, 36, 43], "integr": 55, "intellig": [10, 41], "intend": 0, "intens": 41, "inter": 45, "interact": [9, 28, 32, 33, 36, 38, 39, 40, 43, 45, 49], "interaction_constraint": 35, "interaction_onli": [37, 43], "interactive_plot": [28, 49], "interactiveshel": 45, "intercept": [36, 42, 46], "intercept_": [31, 35, 42, 46], "intercept_sc": 33, "interest": [2, 25, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 51, 53, 54], "interfac": 35, "intermedi": [39, 42], "intern": [0, 1, 26, 42, 43, 44, 45], "internet": 44, "internetservic": 44, "internetservice_dsl": 44, "internetservice_fib": 44, "internetservice_no": 44, "internship": 25, "interpret": [10, 11, 21, 22, 23, 24, 28, 29, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 52, 55], "interv": [43, 44, 47, 51, 55], "intrins": 43, "intro": [10, 19, 20, 41, 42], "introduc": [30, 33, 44], "introduct": [9, 10, 11, 13, 16, 43, 44, 49, 55], "intslid": [28, 49], "intuit": [28, 29, 30, 32, 34, 36, 38, 39, 44, 45, 55], "invalid": 32, "inventori": 47, "invers": [31, 34], "inverse_func": 34, "investig": [28, 36, 49], "involv": [2, 4, 32, 34, 35, 39, 41, 42], "io": [9, 29, 42, 44, 45], "io_loop": 45, "ipkernel": 45, "ipykernel": 45, "ipykernel_19402": 36, "ipykernel_32469": 29, "ipykernel_79734": 27, "ipykernel_86208": 45, "ipykernel_launch": 45, "ipynb": [7, 8], "ipython": [25, 26, 27, 28, 29, 30, 31, 33, 41, 45, 48, 50, 52], "ipywidget": [28, 49], "ir1": [34, 36], "ir2": [34, 36], "iri": [28, 49], "iris_df": [28, 49], "irregular": 55, "irregularli": 47, "irrelev": [28, 37, 41], "irrelevant_po": 41, "irrespect": [27, 31, 55], "is_avail": 42, "is_leap_year": [43, 54], "is_stop": 41, "is_year_end": [43, 54], "isinst": 44, "island": [29, 30], "isn": [27, 28, 33, 34, 35], "isnul": 29, "isol": [11, 33, 34, 36], "issu": [4, 6, 7, 35, 40, 44, 47, 51, 55], "issubclass": 44, "isupp": 45, "itali": 41, "item": [25, 35, 36, 38, 40, 41, 42, 44, 47, 53], "item_inverse_mapp": 40, "item_kei": 40, "item_mapp": 40, "iter": [32, 37, 38, 39, 42], "iterable_with_config": 30, "iterrow": 40, "its": [8, 25, 27, 28, 30, 31, 33, 36, 38, 39, 41, 42, 43, 44, 45, 46, 49, 51, 54, 55], "itself": [7, 33, 35, 39], "j": [8, 31, 36, 37, 38, 40, 42], "j6": 45, "jackin": 32, "jackpot": 30, "jaguar": [25, 42], "jam": 32, "jame": [41, 44, 45], "jan": 1, "januari": 43, "japan": 41, "jargon": 26, "jason": [10, 37], "javascript": 36, "jellyfish": 42, "jennif": 45, "jerri": 40, "jet": 29, "jetti": 42, "jieba": 41, "jim": 40, "jmlr": 32, "job": [30, 43, 44, 54], "joblib": 30, "john": 35, "join": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55], "jointli": 43, "joke": [25, 40], "jolen": 45, "joseph": 55, "journal": 41, "journei": [10, 39, 55], "jpg": 42, "ju": 25, "jubatu": [25, 42], "judg": 37, "juic": 41, "juli": 43, "jun": 55, "june": [10, 43], "junh": 55, "jupyt": [1, 7, 8, 9, 11, 25, 29, 30, 32, 33, 34, 35, 36, 37, 42, 45], "jupyter_notebook": 44, "jupyterlab": 36, "jurafski": 41, "just": [4, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47, 49, 53, 54, 55], "justic": [36, 55], "justif": 53, "k": [7, 10, 15, 27, 31, 33, 34, 35, 37, 41, 42, 44, 45, 46, 49, 55], "k_neighbor": 33, "k_valu": 28, "kaggl": [26, 29, 33, 34, 35, 36, 37, 42, 52, 53], "kaggler": 37, "kangaroo": 42, "kaplan": 55, "kaplanmeierfitt": 44, "kb": [30, 34, 44], "kbinsdiscret": 37, "kbinsdiscretizer__latitude_0": 37, "kbinsdiscretizer__latitude_1": 37, "kbinsdiscretizer__latitude_2": 37, "kbinsdiscretizer__latitude_3": 37, "kbinsdiscretizer__latitude_4": 37, "kbinsdiscretizer__latitude_5": 37, "kbinsdiscretizer__latitude_6": 37, "kbinsdiscretizer__latitude_7": 37, "kbinsdiscretizer__latitude_8": 37, "kbinsdiscretizer__latitude_9": 37, "kbinsdiscretizer__longitude_11": 37, "kbinsdiscretizer__longitude_12": 37, "kbinsdiscretizer__longitude_13": 37, "kbinsdiscretizer__longitude_14": 37, "kbinsdiscretizer__longitude_15": 37, "kbinsdiscretizer__longitude_16": 37, "kbinsdiscretizer__longitude_17": 37, "kbinsdiscretizer__longitude_18": 37, "kbinsdiscretizer__longitude_19": 37, "kbinsdiscretizerkbinsdiscret": 37, "kc_house_data": [25, 26, 49], "keep": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 33, 35, 36, 37, 38, 40, 41, 44, 49, 50, 55], "keep_empty_featur": 40, "kei": [9, 26, 27, 28, 29, 32, 33, 34, 35, 40, 41, 44, 51, 53, 55], "kelbowvisu": 38, "kellei": 31, "kelli": 55, "kept": 27, "kera": 36, "kernel": [7, 10, 15, 29, 31, 32, 36, 37, 49], "kernelapp": 45, "kernelbas": 45, "kernelexplain": 36, "keyword": [4, 32, 45], "kfold": 33, "kick": 41, "kilian": 36, "kill": 44, "kimia": 55, "kind": [0, 25, 26, 27, 29, 30, 31, 33, 34, 36, 38, 39, 40, 42, 43, 44, 46, 54], "king": [40, 41, 49], "kitchenabvgr": [34, 36], "kitchenqu": [34, 36], "kk": 38, "km": [44, 47], "km_label": 38, "kmean": [38, 39, 47], "kmf": 44, "kmqfw": 44, "kneighborregressor": 29, "kneighborsclassifi": [29, 30, 31, 37, 49, 50], "kneighborsregressor": [29, 30, 31, 50], "kneighborsregressorkneighborsregressor": [29, 30], "knew": 38, "knn": [2, 15, 27, 28, 29, 30, 31, 36, 37, 40, 42, 46, 47, 53], "knn1": 28, "knn100": 28, "knn_pipe": 30, "knn_scale": 29, "knn_unscal": 29, "knn_valid_accuraci": 28, "knnimput": 40, "knob": 26, "know": [8, 10, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55], "knowledg": [8, 26, 30, 32, 37, 38, 41, 47], "knowleg": 47, "known": [40, 41, 44], "koala": 42, "kolhatkar": [0, 1, 41], "kr9rkqfj4w78h49djkz8yy9r0000gp": 27, "ksatr": 44, "kvarada": [11, 26, 27, 30, 32, 36, 42, 44, 46], "kvarada01": 11, "kwarg": [27, 29, 30, 44, 45], "l": 11, "l1": [10, 44], "l10": 10, "l11": 10, "l12": 10, "l123": 4, "l13": 10, "l14": 10, "l15": 10, "l16": 10, "l17": [4, 10], "l18": 10, "l19": 10, "l1_ratio": 33, "l2": [10, 33, 41, 44], "l20": 10, "l21": 10, "l22": 10, "l23": 10, "l3": 10, "l4": 10, "l5": 10, "l6": 10, "l7": 10, "l8": 10, "l9": [4, 10], "lab": [11, 26, 27, 38, 40], "lab1": [26, 27, 30, 47], "lab2": [26, 27, 30, 47], "lab3": [26, 27, 30, 47], "lab4": [26, 27, 30, 47], "label": [7, 8, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 50], "label_": [41, 45], "label_encod": [35, 36], "label_n_clust": 39, "labelencod": [35, 36], "labels": [33, 38], "labels_": [38, 39], "lack": [27, 40], "lag": [44, 47], "lag_df": 43, "lakeshor": 42, "lakesid": 42, "lambda": [8, 26, 31, 39, 42, 43, 44, 45], "land": 44, "landcontour": [34, 36], "landcontour_bnk": 34, "landcontour_hl": 34, "landcontour_low": 34, "landcontour_lvl": 34, "landmark": 47, "landown": 45, "landscap": [38, 41], "landslop": [34, 36], "landslope_gtl": [34, 36], "landslope_mod": [34, 36], "landslope_sev": [34, 36], "languag": [2, 9, 29, 30, 40, 42, 45], "language_enc": 29, "language_english": 29, "language_french": 29, "language_hindi": 29, "language_mandarin": 29, "language_spanish": 29, "language_vietnames": 29, "laptop": 25, "lar": 25, "larg": [25, 27, 28, 29, 31, 33, 34, 38, 39, 41, 42, 47, 49, 52], "larger": [26, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 44], "largest": 34, "larvatu": [25, 42], "last": [8, 26, 27, 28, 29, 30, 33, 36, 40, 42, 43, 44, 45, 49, 51, 53, 54, 55], "last_row": 8, "lastp": 39, "lat": [25, 26], "late": [33, 55], "latent": [40, 41, 42], "latentdirichletalloc": 41, "later": [11, 26, 30, 33, 42, 43, 49], "latest": [30, 36, 44], "latex": [4, 7], "latin": [25, 33, 52], "latitud": [27, 28, 29, 30, 31, 37, 50], "latitude_0": 37, "latitude_1": 37, "latitude_10": 37, "latitude_11": 37, "latitude_12": 37, "latitude_13": 37, "latitude_14": 37, "latitude_15": 37, "latitude_16": 37, "latitude_17": 37, "latitude_18": 37, "latitude_19": 37, "latitude_2": 37, "latitude_3": 37, "latitude_4": 37, "latitude_5": 37, "latitude_6": 37, "latitude_7": 37, "latitude_8": 37, "latitude_9": 37, "latter": 34, "launch_inst": 45, "launch_new_inst": 45, "lauvagrand": 45, "law": 41, "lawsuit": 41, "layer": 42, "layout": [28, 49], "lazi": 28, "lbfg": 33, "lda": 42, "ldot": 32, "lead": [8, 10, 27, 31, 34, 39, 40, 41, 44], "leaf": [26, 39], "leak": [29, 44, 47], "leakag": 47, "leaner": 27, "learn": [2, 9, 10, 11, 12, 13, 14, 16, 17, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "learner": [27, 28, 35], "learning_method": 41, "learning_r": 35, "learnxinyminut": 9, "least": [4, 10, 27, 28, 33, 34, 36, 37, 38, 39, 53, 54, 55], "least_confident_i": 31, "least_confident_x": 31, "leav": [7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 39, 42, 44, 46], "lec11": 19, "lectur": [5, 7, 8, 11, 19, 47, 52], "lecun": 36, "lee": 36, "left": [7, 25, 32, 33, 34, 38, 39, 41, 43, 44, 55], "legal": [0, 41], "legend": [7, 8, 28, 31, 33, 34, 37, 38, 42, 43, 44, 46], "legendari": 45, "leisur": 33, "lemma": 41, "lemma_": 41, "lemmat": 41, "lemon": 38, "len": [27, 29, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45], "length": [26, 27, 28, 31, 34, 36, 38, 39, 41, 43, 44, 45, 49, 54], "leo": 35, "leopard": [25, 42], "leq": [37, 38], "less": [5, 6, 10, 25, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 44, 47, 49, 52], "lesson": [9, 29, 45], "lesssim": 27, "let": [25, 26, 27, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "letter": [31, 45], "lev": 34, "level": [28, 31, 33, 34, 35, 36, 37, 39, 41, 42, 43, 52, 55], "leverag": [36, 40], "lewi": 45, "lexic": 41, "lexicon": 45, "lg": [19, 23, 24], "lgbm": [35, 36, 47, 55], "lgbmclassifi": [25, 35, 36, 53], "lgbmclassifierifittedlgbmclassifi": [25, 36], "lgbmclassifierlgbmclassifi": 35, "lgbmregressor": [25, 35], "li": 31, "liabil": 0, "liabl": 0, "liao": 25, "lib": [26, 27, 30, 32, 36, 44, 45, 46], "librari": [4, 8, 11, 27, 33, 36, 37, 41, 42, 43, 45, 49], "licensor": 0, "life": [26, 31, 38, 40, 48, 55], "lifelin": [44, 55], "lifetim": 44, "lighter": 32, "lightgbm": [25, 36, 53], "lightweight": 41, "like": [2, 4, 7, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55], "likelihood": 44, "likewis": 7, "lime": 36, "limit": [0, 25, 26, 27, 30, 35, 36, 45, 47, 48, 51, 55], "linalg": 41, "line": [4, 8, 11, 26, 30, 31, 32, 33, 34, 38, 41, 42, 43, 44, 45, 49, 51], "line2d": 8, "linear": [10, 17, 21, 22, 23, 24, 32, 33, 35, 37, 39, 40, 42, 43, 44, 46, 47], "linear_model": [25, 31, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 52, 53, 54], "linear_svc": 31, "linearli": [31, 37, 43], "linearregress": [31, 34, 37, 44, 45], "linestyl": [38, 43, 54], "linewidth": 43, "linger": 28, "lingual": 41, "linguist": 30, "link": [0, 4, 5, 7, 10, 25, 26, 30, 31, 34, 35, 39, 44], "linkag": 39, "linkage_arrai": 39, "linkage_typ": 39, "linkedin": 40, "linspac": [31, 32, 34, 37, 51], "lion": 40, "list": [4, 7, 8, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 44, 53, 55], "listedcolormap": 31, "liter": 45, "literatur": 35, "littl": [8, 33, 42], "live": [10, 11, 28, 29, 30, 32, 38, 44, 51], "liver": 26, "livestream": 55, "ll": [6, 7, 10, 11, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 54, 55], "llazx": 44, "llm": 10, "lo": 45, "load": [8, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 45, 49, 50, 52], "load_breast_canc": 37, "load_citibik": 43, "load_iri": [28, 49], "loan": [33, 52], "loc": [8, 28, 31, 33, 36, 40, 43, 44, 54], "local": [5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 33, 35, 36, 37, 42, 45], "locat": [8, 30, 38, 40, 41, 43, 45, 53, 54, 55], "location_katherin": 43, "location_mountginini": 43, "location_townsvil": 43, "location_witchcliff": 43, "location_wollongong": 43, "lock": 27, "log": [28, 34, 35, 44, 49, 53, 55], "log10": 34, "log1p": 34, "log2": 44, "log_likelihood_ratio_test": 44, "logarithm": [28, 49], "logic": 37, "logical_xor": 37, "login": 40, "logisit": 42, "logist": [17, 35, 36, 43, 44, 45, 46, 47, 52, 53, 54], "logisticregress": [25, 31, 34, 35, 36, 37, 41, 42, 45, 46, 52, 53, 54], "logisticregressionifittedlogisticregress": 42, "logisticregressionlogisticregress": [33, 35, 42, 45], "logloss": 36, "lognorm": 32, "logspac": [32, 51], "loguniform": [32, 51], "lol": 30, "london": 45, "lone": 39, "long": [0, 25, 26, 31, 33, 35, 39, 40, 44, 47, 55], "longer": [7, 32, 33, 42, 44], "longest": 26, "longitud": [27, 28, 29, 30, 31, 37, 50], "longitude_0": 37, "longitude_1": 37, "longitude_10": 37, "longitude_11": 37, "longitude_12": 37, "longitude_13": 37, "longitude_14": 37, "longitude_15": 37, "longitude_16": 37, "longitude_17": 37, "longitude_18": 37, "longitude_19": 37, "longitude_2": 37, "longitude_3": 37, "longitude_4": 37, "longitude_5": 37, "longitude_6": 37, "longitude_7": 37, "longitude_8": 37, "longitude_9": 37, "look": [1, 11, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53], "lookatm": 25, "loop": [32, 35, 43, 46, 47], "loos": 39, "lose": [6, 30], "loss": [2, 33, 34, 35, 36, 41, 44, 52], "lot": [5, 9, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 42, 43, 44, 51, 55], "lotarea": [34, 36], "lotconfig": [34, 36], "lotconfig_corn": 34, "lotconfig_culdsac": 34, "lotconfig_fr2": 34, "lotconfig_fr3": 34, "lotconfig_insid": 34, "lotfrontag": [34, 36], "lotshap": [34, 36], "lotshape_ir1": 34, "lotshape_ir2": 34, "lotshape_ir3": 34, "lotshape_reg": 34, "loud": [28, 29, 32, 47, 51], "loui": 43, "lourenzutti": 32, "love": 45, "low": [6, 27, 28, 32, 33, 34, 36, 37, 38, 39, 44], "lower": [27, 28, 33, 34, 36, 38, 40, 41, 44, 51, 55], "lowercas": [29, 30], "lowest": [49, 55], "lowqualfinsf": [34, 36], "lr": [31, 33, 34, 36, 42, 43, 44, 45, 46], "lr_1": 37, "lr_2": 37, "lr_3": 37, "lr_coef": [36, 43, 44, 54], "lr_coefs_landslop": 36, "lr_flatten_pip": 42, "lr_item": 40, "lr_pipe": [34, 36, 43], "lr_pred": [33, 34], "lr_scale": 36, "lr_schedul": 42, "lr_x": 40, "lr_y": 40, "ls15hb": 25, "lstm": 43, "lt": [27, 29, 30, 32, 33, 34, 35, 36, 37, 44], "ltorgo": 31, "lucki": [28, 32], "luckili": [51, 53], "lundberg": 36, "luster": 39, "lvert": 41, "lvl": [34, 36], "lwq": [34, 36], "lynx": [25, 42], "l\u00e9cuyer": 41, "m": [11, 25, 27, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "m_neighbor": 33, "ma": 32, "macaqu": [25, 42], "macbook": 11, "machin": [2, 9, 10, 11, 13, 14, 15, 29, 30, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 49, 54, 55], "mackworth": 10, "made": [0, 6, 7, 8, 25, 26, 33, 35, 36, 40, 41, 42, 43, 51], "magazin": 41, "magnitud": [32, 34, 36, 41, 43, 54], "maguir": 40, "mahsa": 55, "mai": [0, 7, 8, 10, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55], "mail": 44, "main": [8, 11, 26, 28, 30, 35, 38, 39, 47, 55], "mainland": 31, "maintain": [35, 40, 47], "mainten": 35, "maj1": [34, 36], "maj2": [34, 36], "major": [2, 27, 28, 29, 30, 41, 47, 48, 53], "major_biologi": 30, "major_comput": 30, "major_econom": 30, "major_linguist": 30, "major_mathemat": 30, "major_mechan": 30, "major_phys": 30, "major_psychologi": 30, "make": [2, 4, 5, 6, 7, 11, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55], "make_blob": [28, 38, 39, 42, 46], "make_circl": 39, "make_classif": [28, 33], "make_column_transform": [32, 33, 34, 35, 36, 37, 43, 44, 45, 50, 51, 52, 53, 54], "make_forg": 28, "make_grid": 42, "make_imb_pipelin": 33, "make_moon": 39, "make_num_tree_plot": 35, "make_pipelin": [25, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54], "make_scor": [34, 37, 45], "malcolm": [38, 40], "malcom": 38, "male": [33, 35, 36, 44, 52], "male_cm": [33, 52], "male_pr": [33, 52], "mall": 45, "man": [40, 41], "manag": [5, 43, 44, 47, 55], "mandarin": 29, "mango": 41, "mani": [2, 5, 8, 10, 25, 26, 27, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 51, 53, 54, 55], "manner": [0, 35], "manual": [11, 25, 30, 33, 37, 38, 39, 41, 51], "manufactur": 42, "map": [10, 26, 27, 30, 32, 40, 51], "mape": 47, "mape_scor": 34, "mapper": 40, "march": 43, "marit": [33, 35, 36, 52], "mark": [6, 7, 32, 33, 39, 55], "marker": [28, 31, 38], "markers": [31, 33], "market": [25, 38, 42, 43], "marri": [33, 35, 36], "martin": 41, "mask": 32, "massiv": [30, 32], "master": [8, 32, 33, 35, 36, 41, 52], "masvnrarea": [34, 36], "masvnrtyp": [34, 36], "masvnrtype_brkcmn": 34, "masvnrtype_brkfac": 34, "masvnrtype_miss": 34, "masvnrtype_ston": 34, "match": [30, 31, 33, 35, 36, 43, 53, 54], "materi": [8, 11, 19, 25, 26, 27, 28, 38, 41, 44, 47, 55], "matern": 37, "math": [2, 38, 40, 44], "mathcal": 28, "mathemat": [2, 30, 35, 47], "mathematician": 41, "mathia": 45, "matlab": 8, "matplotlib": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "matplotlibdeprecationwarn": 36, "matric": [28, 33, 40, 52], "matrix": [18, 30, 39, 41, 47, 52], "matter": [29, 30, 33, 35, 39, 47], "max": [8, 27, 29, 31, 32, 33, 34, 35, 38, 39, 43, 54], "max_bin": 35, "max_cat_threshold": 35, "max_cat_to_onehot": 35, "max_clust": 39, "max_colwidth": [25, 26, 27, 28, 29, 30, 31, 32, 33, 39, 40, 48, 49, 50, 51, 52], "max_delta_step": 35, "max_depth": [27, 28, 32, 35, 36, 48, 49], "max_depth_widget": [28, 49], "max_df": 30, "max_displai": 36, "max_featur": [25, 30, 32, 35, 51], "max_it": [25, 33, 35, 36, 37, 41, 42, 43, 44, 45, 46, 52], "max_leaf_nod": 26, "max_leav": 35, "max_opt": [28, 33, 38, 39], "max_row": 44, "maxclust": 39, "maxent": 46, "maxhr": 53, "maxim": [25, 33, 34, 38], "maximum": [26, 29, 34, 35, 38, 39, 49, 55], "maxosx": 11, "maxtemp": [43, 54], "may": 10, "mayb": [33, 36, 43, 55], "maybe_coerce_valu": 44, "mb": [29, 30, 33, 37, 43, 44, 54], "md": [11, 26, 41], "me": [8, 25, 32, 45], "mean": [5, 6, 8, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 40, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55], "mean_absolute_percentage_error": 34, "mean_cv_error": 27, "mean_cv_scor": [28, 31, 32], "mean_fit_tim": [32, 34], "mean_scor": [27, 29, 32, 45], "mean_score_tim": [32, 34], "mean_squared_error": [34, 37, 45], "mean_std_cross_val_scor": [27, 29, 30, 35, 36, 44, 45], "mean_test_neg_mean_squared_error": 34, "mean_test_scor": [32, 34, 51], "mean_train_error": 27, "mean_train_neg_mean_squared_error": 34, "mean_train_scor": [28, 31, 32, 34], "meaning": [28, 30, 33, 36, 38, 41, 50, 55], "meaningless": 39, "measur": [0, 25, 26, 27, 28, 33, 34, 36, 38, 39, 40, 41, 43, 44, 47, 49, 53, 54], "mechan": [30, 47], "medal": 8, "median": [26, 29, 30, 31, 34, 36, 37, 43, 44, 54], "median_house_valu": [29, 30, 37, 50], "median_incom": [29, 30, 37, 50], "medic": [33, 38, 55], "medinc": 31, "medit": 33, "medium": [0, 28, 44, 47], "meet": 41, "meier": 55, "melbourneairport": [43, 54], "member": [31, 35, 55], "membership": [30, 38, 39], "memori": [8, 29, 30, 33, 34, 35, 37, 42, 43, 44, 47, 54], "mention": [0, 4, 31, 44], "menu": 11, "merchant": 0, "merg": [0, 5, 11, 39], "meshgrid": 37, "mess": [40, 44], "messag": [4, 6, 11, 27, 30], "messi": [37, 41], "met": 55, "meta": 35, "metacademi": 10, "method": [2, 26, 28, 29, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 53, 54, 55], "methodologi": [29, 43], "metric": [10, 28, 30, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 52, 53, 55], "mexico": 33, "mglearn": [26, 27, 28, 29, 30, 31, 32, 33, 38, 41, 42, 43, 46, 48, 49, 51, 52], "mi": [25, 32, 33], "microsoft": 45, "midnight": 43, "midterm": [6, 10], "might": [6, 10, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 47, 49, 55], "mike": [0, 1, 9, 26, 51], "mikolov": 41, "milk": 41, "mill": 35, "millennia": 55, "million": 42, "min": [10, 31, 34, 39, 43, 54], "min1": [34, 36], "min2": [34, 36], "min_child_weight": 35, "min_df": 30, "min_sampl": 39, "min_samples_leaf": 26, "min_samples_split": 26, "min_token_len": 41, "min_token_length": 41, "mind": [27, 29, 30, 35, 36, 40, 44, 47, 55], "mine": 10, "minibatchkmean": 39, "miniconda": 11, "miniconda3": [11, 45], "miniforge3": [26, 27, 30, 32, 36, 44, 46], "minim": [5, 26, 34, 38, 39], "minimum": [8, 27, 29, 39, 41], "minmaxscal": [29, 30], "minor": [6, 44], "mintemp": [43, 54], "minut": [4, 26, 37, 44, 47], "miracl": 45, "miscalcul": 10, "miscfeatur": [34, 36], "miscfeature_gar2": 34, "miscfeature_miss": 34, "miscfeature_othr": 34, "miscfeature_sh": 34, "miscfeature_tenc": 34, "misclassifi": 52, "misconduct": 55, "miscval": [34, 36], "mislead": [27, 33], "miss": [11, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 43, 44, 47, 49, 51, 52, 54, 55], "mistak": [29, 35, 44, 49], "mit": [0, 1], "mitig": [40, 55], "mitlp": 44, "mitt": 41, "mitten": 41, "mix": 34, "mixtur": [39, 41, 42], "ml": [2, 9, 10, 14, 15, 26, 29, 35, 39, 41, 42, 55], "ml_experi": [26, 27, 30, 47], "mlpclassifi": 42, "mlpregressor": 42, "mm": [43, 54], "mmsto": 25, "mn": [34, 36], "mnprv": [34, 36], "mnww": [34, 36], "mobil": [30, 42], "mobilenet": 42, "mod": [34, 36], "mode": [28, 29, 32, 51], "model": [2, 10, 19, 20, 21, 22, 23, 24, 32, 33, 38, 39, 40, 43, 46, 48, 51, 54, 55], "model_nam": 40, "model_select": [25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54], "modern": [10, 28, 41], "modif": 44, "modifi": [0, 11, 33, 44, 55], "modul": [9, 10, 26, 27, 33, 45], "moe": 32, "mole": 42, "mom": 37, "moment": [33, 51, 53, 55], "mon": [10, 43], "mondai": [10, 43, 55], "monei": [8, 44], "monitor": 41, "monkei": [25, 42], "monotone_constraint": 35, "montani": 45, "month": [27, 30, 34, 44, 54], "month_nam": [43, 54], "monthli": 44, "monthlycharg": 44, "montreal": [41, 45], "moon": 39, "moosvi": [0, 1, 41, 55], "moral": [0, 38], "more": [1, 2, 5, 6, 8, 10, 11, 14, 27, 32, 35, 36, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55], "morn": 25, "morpholog": 41, "moskowitz": 38, "mosold": [34, 36], "mosold_1": 34, "mosold_10": 34, "mosold_11": 34, "mosold_12": 34, "mosold_2": 34, "mosold_3": 34, "mosold_4": 34, "mosold_5": 34, "mosold_6": 34, "mosold_7": 34, "mosold_8": 34, "mosold_9": 34, "most": [7, 8, 11, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 53, 55], "most_confident_i": 31, "most_confident_x": 31, "most_frequ": [26, 28, 29, 33, 34, 36, 48], "most_similar": 41, "mostli": [8, 30, 43], "motiv": [19, 20, 21, 22, 23, 24, 25, 30], "mountginini": 43, "move": [7, 12, 31, 36, 37, 48, 53, 55], "movi": [31, 41, 45], "movie_feats_df": 40, "movie_id": 40, "movie_nam": 40, "movies_rated_by_pat": 40, "movies_to_pr": 40, "movieto": 45, "mpimg": 42, "mri": 47, "mrtssm448usn": 43, "mse": [26, 40, 47], "msg": [30, 44], "mssubclass": [34, 36], "mssubclass_120": 34, "mssubclass_160": 34, "mssubclass_180": 34, "mssubclass_190": 34, "mssubclass_20": 34, "mssubclass_30": 34, "mssubclass_40": 34, "mssubclass_45": 34, "mssubclass_50": 34, "mssubclass_60": 34, "mssubclass_70": 34, "mssubclass_75": 34, "mssubclass_80": 34, "mssubclass_85": 34, "mssubclass_90": 34, "mszone": [34, 36], "mszoning_c": [34, 36], "mszoning_fv": 34, "mszoning_rh": 34, "mszoning_rl": 34, "mszoning_rm": 34, "much": [4, 5, 8, 26, 27, 28, 29, 30, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 49, 51, 55], "mueller": 10, "multi": [34, 36, 38, 41, 43], "multi_class": [33, 46], "multi_strategi": 35, "multiclass": [42, 46], "multicoliniar": 36, "multicultur": 41, "multilevel": 34, "multimod": 38, "multinomi": 46, "multipl": [7, 8, 27, 31, 32, 35, 36, 41, 42, 43, 44, 54], "multiplelin": 44, "multiplelines_no": 44, "multiplelines_y": 44, "multipli": [31, 32, 33, 35, 37, 44], "music": [40, 45], "musqueam": 55, "must": [0, 6, 7, 8, 26, 27, 29, 36, 39, 41, 44, 45, 55], "mutual": 39, "mwf": 55, "my": [6, 11, 25, 32, 33, 38, 41, 45, 55], "my_heatmap": [32, 51], "my_map": 34, "mypreprocessor": 41, "myself": 26, "m\u00fcller": 9, "n": [10, 26, 28, 31, 32, 34, 35, 36, 37, 39, 40, 41, 43, 45, 46, 49, 54], "n_bin": 37, "n_class": [28, 33, 52], "n_cluster": [38, 39], "n_clusters_per_class": 33, "n_compon": 41, "n_constitu": 35, "n_estim": [37, 43, 44], "n_exampl": 38, "n_feat": 28, "n_featur": [28, 33, 38, 51], "n_features_to_select": 37, "n_inform": 33, "n_init": 38, "n_iter": 51, "n_job": [30, 33, 34, 35, 51], "n_neighbor": [40, 49], "n_neighbors_selector": 28, "n_neighbors_widget": [28, 49], "n_redund": 33, "n_rental": 43, "n_rentalsin3hour": 43, "n_rentalsin6hour": 43, "n_repeat": 36, "n_resourc": 32, "n_sampl": [28, 33, 38, 39, 42, 46, 52], "n_split": 43, "n_threshold": 33, "n_topic": 41, "n_train": 43, "n_word": [41, 45], "na": [34, 36], "nafter": 41, "nah": 30, "naiv": 39, "name": [4, 5, 6, 7, 8, 11, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38, 41, 42, 43, 44, 45, 49, 53, 54, 55], "named_estimators_": 35, "named_step": [31, 33, 34, 35, 36, 37, 43, 45, 54], "named_transformers_": [30, 33, 34, 35, 36, 37, 43, 44, 45, 52, 54], "nan": [29, 30, 33, 34, 35, 36, 37, 40, 43, 44, 45, 47, 52, 54], "nanmean": 40, "nanosecond": 43, "narr": 41, "narrow": 40, "nasali": [25, 42], "nation": 55, "nativ": [33, 35, 36, 42, 46, 52], "natur": [2, 25, 30, 33, 35, 37, 42, 46, 55], "navig": [7, 11], "nbsp": [25, 29, 30, 32, 34, 35, 36, 37, 42], "nbviewer": [25, 29, 30, 32, 33, 34, 35, 36, 37, 42, 45], "nc": 1, "ncol": 31, "ndarrai": [8, 30], "ndate": 45, "ndframe": [37, 44], "ndim": 8, "ne": [43, 54], "nearbi": [28, 38], "nearest": [15, 33, 39, 49], "necessari": [0, 7, 26, 32, 47, 50], "necessarili": [27, 34, 35, 40], "necvq": 44, "need": [5, 7, 8, 11, 25, 26, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 53, 54, 55], "neg": [26, 27, 28, 31, 34, 35, 36, 41, 43, 44, 45, 49, 52], "neg_mean_absolute_percentage_error": 34, "neg_mean_squared_error": 34, "neg_root_mean_square_error": 34, "neg_root_mean_squared_error": 34, "neigh": 28, "neighbor": [28, 29, 30, 31, 33, 37, 39, 49, 50], "neighborhood": [31, 34, 36], "neighborhood_blmngtn": 34, "neighborhood_bluest": 34, "neighborhood_brdal": 34, "neighborhood_brksid": 34, "neighborhood_clearcr": 34, "neighborhood_collgcr": 34, "neighborhood_crawfor": 34, "neighborhood_edward": 34, "neighborhood_gilbert": 34, "neighborhood_idotrr": 34, "neighborhood_meadowv": 34, "neighborhood_mitchel": 34, "neighborhood_nam": 34, "neighborhood_noridg": [34, 36], "neighborhood_npkvil": 34, "neighborhood_nridght": [34, 36], "neighborhood_nwam": 34, "neighborhood_oldtown": [34, 36], "neighborhood_sawy": [34, 36], "neighborhood_sawyerw": [34, 36], "neighborhood_somerst": [34, 36], "neighborhood_stonebr": [34, 36], "neighborhood_swisu": [34, 36], "neighborhood_timb": [34, 36], "neighborhood_veenk": [34, 36], "neighbour": [15, 27, 36, 38, 39, 41, 49], "neighbourhood": [31, 37, 39, 50], "neither": [27, 30, 40], "neq": [36, 40], "ner": 41, "nervou": 26, "nest": [32, 47], "net": [42, 44], "netflix": [40, 45], "network": [10, 25, 30, 35, 37, 38, 40, 43, 55], "neu": 45, "neural": [10, 37, 43, 55], "neutral": 45, "never": [33, 35, 36, 40, 42, 44], "new": [10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 54], "new_cent": 38, "new_column": [34, 36, 43, 44, 54], "new_data": 44, "new_df": [43, 54], "new_exampl": [26, 38], "new_feature_nam": [43, 54], "new_valu": 44, "newaxi": 8, "newcastl": 45, "newer": 34, "newli": [29, 34, 37, 39], "newsgroup": 41, "newswir": 41, "next": [11, 26, 27, 28, 29, 30, 33, 34, 35, 41, 42, 43, 50, 51, 52, 53, 55], "nfeat": 28, "nfeats_accuraci": 28, "ng": [9, 10, 32, 37], "ngram": 37, "ngram_rang": 30, "nhqxu": 44, "nice": [4, 32, 33, 35, 36, 39, 42, 44], "nicki": 32, "night": [33, 43], "niki": 55, "nlemma": 41, "nlp": [30, 42, 45], "nltk": [41, 45], "nltk_data": 45, "nn": [10, 29, 42, 45, 49], "nne": [43, 54], "nnw": [43, 54], "nnz": 30, "no_grad": 42, "nobodi": 25, "node": [26, 35, 39, 42, 48], "nois": [39, 47, 49], "non": [1, 8, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 47, 52, 54, 55], "noncommerci": 1, "none": [10, 27, 29, 30, 31, 32, 33, 35, 37, 39, 43, 44, 45, 53], "noninfring": 0, "nonzero": 30, "noqa": [32, 45], "nor": [7, 27, 30], "norg": [41, 45], "norm": [32, 41], "normal": [6, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 52, 53], "norvig": 10, "notat": 28, "note": [0, 3, 7, 9, 10, 11, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 40, 46, 47, 51, 52, 54, 55], "notebook": [5, 7, 9, 11, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 42, 45, 50, 54], "notic": [0, 30, 31, 33, 34, 37], "notion": [28, 32, 38, 40], "notna": [43, 54], "noun": [41, 45], "nov": 43, "novel": 47, "novemb": 43, "novic": 9, "now": [8, 11, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 45, 48, 49, 50, 51, 52, 53], "np": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "nperson": 45, "npie": 8, "npo": 41, "npr": [37, 41, 45, 47], "ntest": [28, 32, 49], "ntoken": 41, "ntree": 35, "null": [29, 30, 33, 34, 37, 43, 44, 54], "null_distribut": 44, "num": [33, 35, 36, 52], "num_output_channel": 42, "num_parallel_tre": 35, "num_sent": 33, "num_work": 42, "number": [4, 6, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 47, 49, 51, 54, 55], "number_test": 32, "numer": [2, 26, 29, 30, 31, 33, 34, 35, 40, 41, 43, 44, 49, 50, 52, 54], "numeric_feat": [30, 32, 37, 47, 51], "numeric_featur": [30, 33, 34, 35, 36, 43, 44, 45, 52, 53, 54], "numeric_looking_column": 34, "numeric_transform": [30, 33, 34, 35, 36, 43, 52, 53, 54], "numpi": [9, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "numpy_dtyp": 44, "nutrit": 41, "nw": [43, 54], "nwith": 28, "ny": 45, "o": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "obelisk": 42, "object": [27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 45, 47, 48, 49, 51, 52, 54], "observ": [25, 26, 27, 28, 35, 36, 38, 39, 43, 44, 49, 52, 53, 54], "obtain": [0, 31, 38, 39, 40, 44, 49, 51], "obviou": [39, 41], "occasion": 33, "occup": [33, 35, 36, 52], "occupation_farm": 36, "occupation_miss": 36, "occupation_priv": 36, "occupi": 55, "occur": [8, 26, 27, 30, 41, 44], "occurr": [41, 44], "ocean": [29, 30, 37, 50], "ocean_proxim": [29, 30, 37, 50], "ocean_proximity_": [29, 30], "ocean_proximity_inland": [29, 30], "ocean_proximity_island": [29, 30], "ocean_proximity_near": [29, 30], "oct": 31, "octob": 43, "oe": [30, 47], "oe_encod": 47, "off": [31, 32, 33, 34, 37, 38, 41, 42, 44, 47, 51, 55], "off_shelf": 53, "offens": 4, "offer": [8, 35, 40, 41, 44, 55], "offic": [4, 11, 47, 55], "offici": [41, 55], "offlin": 40, "offset": 31, "often": [8, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49], "ogunrind": 25, "oh": [36, 37, 42, 43, 44, 47, 51, 54], "ohe_column": [34, 36], "ohe_enc": 30, "ohe_encod": 47, "ohe_feature_nam": [36, 43, 54], "ohehotencod": 30, "ois": 39, "ok": [25, 28, 34, 43, 44, 47, 54], "okai": 38, "ola": 41, "old": [9, 35, 36], "old_cent": 38, "older": 34, "oldpeak": 53, "olymp": 8, "omit": 36, "omw": 41, "onc": [6, 7, 8, 11, 26, 27, 29, 30, 32, 37, 39, 40, 41, 42, 51, 52, 53, 55], "onca": [25, 42], "one": [6, 8, 9, 11, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55], "one_c": 28, "one_ex_preprocess": 36, "one_ex_preprocessed_perturb": 36, "one_exampl": 36, "one_example_perturb": 36, "onehot": [30, 37], "onehotencod": [29, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45, 47, 50, 51, 52, 53, 54], "onehotencoder__major_biologi": 30, "onehotencoder__major_comput": 30, "onehotencoder__major_econom": 30, "onehotencoder__major_linguist": 30, "onehotencoder__major_mathemat": 30, "onehotencoder__major_mechan": 30, "onehotencoder__major_phys": 30, "onehotencoder__major_psychologi": 30, "onehotencoderonehotencod": [30, 32, 34, 35], "ones": [8, 25, 28, 29, 35, 36, 38, 40, 41, 49, 53], "onevsoneclassifi": 46, "onevsrestclassifi": 46, "onli": [2, 4, 8, 11, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 52, 55], "onlin": [3, 5, 7, 11, 26, 41, 55], "onlinebackup": 44, "onlinebackup_no": 44, "onlinebackup_y": 44, "onlinesecur": 44, "onlinesecurity_no": 44, "onlinesecurity_y": 44, "ontonot": 41, "op": 33, "open": [5, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 42, 55], "openporchsf": [34, 36], "oper": [4, 8, 11, 30, 37, 41], "operand": 8, "opinion": 35, "opportun": 40, "oppos": [34, 35], "opposit": [8, 34, 35, 36, 54], "opt": [11, 35], "optic": 44, "optim": [2, 10, 26, 27, 28, 30, 33, 35, 36, 37, 38, 39, 42, 44, 51], "optimist": 32, "option": [7, 8, 10, 26, 34, 38, 41, 51, 53, 54], "oracl": 10, "orang": 31, "order": [5, 7, 8, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 47], "ordering_ordinal_oth": [34, 36], "ordering_ordinal_reg": [34, 36], "ordin": [34, 47, 50], "ordinal_feat": 30, "ordinal_featur": [33, 35, 36, 52], "ordinal_features_oth": [34, 36], "ordinal_features_reg": [34, 36], "ordinal_transform": [33, 35, 36, 52], "ordinal_transformer_oth": [34, 36], "ordinal_transformer_reg": [34, 36], "ordinalencod": [29, 30, 33, 34, 35, 36, 37, 43, 44, 45, 47, 50, 52, 53, 54], "ordinalencoderordinalencod": [30, 34, 35], "ordinari": 34, "oreilli": [42, 43], "org": [9, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 41, 42, 45], "organ": [25, 26, 29, 41], "orgin": 8, "orig_featur": [43, 54], "orig_pr": 36, "orig_scor": 33, "origin": [29, 30, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 49, 51, 54, 55], "original_hm": 33, "originaltweet": 45, "ornithorhynchu": 42, "oscar": 31, "ostblom": 41, "other": [0, 1, 4, 5, 6, 7, 11, 26, 27, 29, 30, 31, 32, 33, 35, 36, 39, 40, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55], "otherwis": [0, 7, 30], "ounc": [25, 42], "our": [5, 6, 8, 11, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55], "ourselv": [26, 33, 42, 43], "out": [0, 4, 7, 8, 11, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 47, 49, 51, 53, 54, 55], "out_col": [27, 29, 45], "out_step": 33, "outcom": 12, "outer": 45, "outlier": [34, 39, 47], "outlook": 44, "output": [7, 8, 11, 25, 26, 27, 30, 31, 33, 35, 36, 41, 42, 43, 47, 53, 54, 55], "outsid": [7, 33, 35, 36, 40, 41, 43, 44], "over": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 32, 34, 42, 43, 44, 47, 55], "over_confident_i": 31, "over_confident_x": 31, "over_sampl": 33, "overal": [11, 33, 36, 38, 41, 42, 47, 52, 53, 55], "overallcond": [34, 36], "overallqu": [34, 36], "overconfid": [36, 37], "overfit": [10, 28, 31, 34, 35, 37, 42, 49, 51, 53, 55], "overflow": 7, "overhead": 30, "overlap": [2, 27, 38], "overli": [28, 32, 49], "overload": [40, 44], "overpredict": 34, "oversample_pip": 33, "overshadow": 41, "overus": 35, "overview": [38, 39, 40, 41], "overwhelm": 38, "overzeal": 6, "own": [4, 5, 8, 27, 29, 33, 34, 36, 37, 38, 39, 41, 42, 43, 45, 46, 54], "p": [31, 32, 39, 41, 44], "p_i": 38, "p_value_threshold": 44, "pace": [31, 38, 41, 55], "packag": [5, 8, 26, 27, 30, 32, 33, 36, 38, 39, 40, 41, 42, 44, 45, 46, 55], "pad": 42, "page": [1, 4, 10, 25, 29, 30, 32, 33, 34, 35, 36, 37, 41, 42, 45, 53, 55], "pai": 36, "pain": [4, 42, 43, 54], "pair": [39, 41, 46], "pairwis": [28, 39], "panda": [9, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "pane": [28, 49], "panel": [28, 33, 36, 38, 39, 49], "panic": 45, "panther": [25, 42], "panthera": [25, 42], "paper": [7, 36, 37, 41, 42, 44, 45], "paperlessbil": 44, "paperlessbilling_no": 44, "paperlessbilling_y": 44, "paradigm": [25, 26, 38], "paradox": 40, "paragraph": 41, "parallel": [30, 32, 35], "param": [28, 30, 32, 34, 49], "param_columntransformer__countvectorizer__max_featur": 32, "param_dist": [32, 51], "param_distribut": [32, 51], "param_grid": [27, 28, 32, 34, 51], "param_grid1": [32, 51], "param_grid2": [32, 51], "param_grid3": 32, "param_grid4": 32, "param_ridge__alpha": 34, "param_svc__c": 32, "param_svc__gamma": 32, "paramet": [28, 29, 30, 34, 35, 36, 38, 39, 41, 43, 44, 45, 48, 49, 51, 52, 53, 54], "parametr": 39, "params_": 44, "params_str": 32, "paramter": 28, "pardu": [25, 42], "parent": [39, 45], "park": [37, 42, 45], "pars": 41, "parse_d": [8, 43, 54], "parser": 41, "part": [4, 9, 10, 11, 29, 30, 31, 32, 33, 35, 36, 37, 39, 41, 43, 45, 53, 55], "part1": 40, "part2": 40, "parti": 41, "partial": [4, 44], "particip": 55, "particular": [0, 9, 11, 29, 30, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 49, 52], "particularli": [35, 40, 55], "partit": [30, 38, 39], "partner": [44, 55], "partner_no": 44, "partner_y": 44, "parton": 45, "pass": [8, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 42, 49], "passthrough": [30, 32, 44, 45, 51, 53], "passthrough__ml_experi": 30, "passthrough_feat": [30, 32, 47, 51], "passthrough_featur": [44, 45, 53], "passthroughpassthrough": [30, 32, 45], "past": [26, 27, 35, 43, 44, 47], "pat": 40, "pat_i": 40, "pat_model": 40, "pat_x": 40, "pata": [25, 42], "path": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "patial": 39, "patient": [26, 53], "patio": 42, "patric": 36, "patrick": 55, "pattern": [25, 26, 27, 30, 32, 37, 38, 43, 49, 54], "pave": [34, 36], "paveddr": [34, 36], "paveddrive_i": 34, "paveddrive_n": 34, "paveddrive_p": 34, "paymentmethod": 44, "paymentmethod_bank": 44, "paymentmethod_credit": 44, "paymentmethod_electron": 44, "paymentmethod_mail": 44, "pca": [33, 39, 40], "pcarter": 9, "pd": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "pdf": [7, 9, 19], "peac": 41, "pedest": 42, "pedro": [10, 27, 37], "peek": 54, "peer": [47, 55], "pembrok": [25, 42], "penal": [6, 44], "penalti": [33, 55], "peopl": [4, 26, 27, 29, 31, 33, 35, 38, 40, 41, 42, 43, 44, 45, 47, 49, 52, 55], "per": [8, 31, 33, 34, 35, 36, 40, 42, 43, 46, 47, 51, 52, 54], "perceiv": 6, "percent": 34, "percent_error": 34, "percentag": [26, 33, 40], "perfect": [6, 26, 27, 33, 34, 36, 40, 44, 45], "perfectli": [2, 40, 41], "perform": [26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 47, 48, 50, 51, 52, 53, 54, 55], "performac": 27, "perhap": [34, 43, 46], "perimet": 37, "period": [41, 43, 44, 45, 55], "perm_sorted_idx": 36, "perman": 8, "permiss": [0, 55], "permit": [0, 29, 33, 55], "permut": 36, "persist": 40, "person": [0, 4, 6, 10, 25, 33, 38, 41, 42, 43, 44, 45, 55], "perspect": [35, 40], "pertain": 5, "perthairport": [43, 54], "perturb": [36, 39], "perturbed_pr": 36, "peter": 10, "ph": 41, "phascolarcto": 42, "phase": 27, "phd": 41, "phdei": 44, "phenomenon": [40, 44, 49], "philippin": 45, "philosoph": 41, "phone": [25, 44, 55], "phoneservic": 44, "phoneservice_no": 44, "phoneservice_y": 44, "photo": [45, 47], "photograph": 55, "phrase": 41, "physic": [30, 43], "pi": 8, "pick": [26, 31, 33, 35, 36, 37, 38, 39, 42, 46, 48, 49, 51, 52, 53], "pictur": [35, 36, 39, 41, 43], "pie": 8, "piec": [31, 44], "pil": [25, 42], "pin": 42, "pineappl": 41, "pip": [11, 36, 41, 42, 45], "pipe": [29, 30, 31, 32, 33, 35, 41, 42, 45, 51, 52], "pipe_bestalpha": 34, "pipe_bigalpha": 34, "pipe_catboost": 35, "pipe_dt": [35, 36, 53], "pipe_forward": 37, "pipe_knn": 53, "pipe_lgbm": [35, 36, 53], "pipe_lr": [33, 35, 36, 52, 53], "pipe_lr_all_feat": 37, "pipe_lr_balanc": [33, 52], "pipe_lr_model_bas": 37, "pipe_lr_weight": [33, 52], "pipe_rf": [35, 36, 53], "pipe_rf_demo": 35, "pipe_ridg": [31, 34], "pipe_sklearn_gb": 35, "pipe_sklearn_histgb": 35, "pipe_smallalpha": 34, "pipe_svc": 33, "pipe_svm": [32, 51], "pipe_xgb": [35, 36], "pipe_xor": 37, "pipelin": [2, 10, 16, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 50, 51, 52, 53, 54, 55], "pipeline__lab1": 30, "pipeline__lab2": 30, "pipeline__lab3": 30, "pipeline__lab4": 30, "pipeline__quiz1": 30, "pipeline__rooms_per_household": 37, "pipeline__university_year": 30, "pipelineifittedpipelin": [29, 30, 32, 33, 37, 42, 45], "pipelineinot": [30, 32, 34], "pipelinepipelin": 32, "pitfal": 43, "pixel": 36, "pizza": 41, "pkg": 11, "place": [5, 41, 43, 55], "plagiar": 55, "plai": [26, 28, 32, 36, 39, 48, 49], "plain": 38, "plan": [11, 25, 34, 37, 44, 45, 50, 53, 55], "plane": 31, "plant": 47, "plastic": 41, "platform": [4, 45], "platypu": 42, "player": [36, 42], "pleas": [1, 4, 7, 11, 25, 29, 30, 32, 33, 34, 35, 36, 37, 42, 45, 51, 55], "plinth": 42, "plot": [7, 26, 27, 28, 29, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 49, 51, 52, 54], "plot_2d_scor": 31, "plot_2d_separ": [28, 31, 49], "plot_confusion_matrix": 33, "plot_confusion_matrix_exampl": 33, "plot_cross_valid": [27, 43], "plot_dbscan": 39, "plot_dbscan_with_label": 39, "plot_dendrogram_clust": 39, "plot_elbow": 38, "plot_example_dist": 38, "plot_fruit_tre": 26, "plot_grid_search_overview": 32, "plot_k_means_dbscan_comparison": 39, "plot_km_initi": 38, "plot_km_it": 38, "plot_km_iter": 38, "plot_kmean": 39, "plot_knn_clf": 28, "plot_knn_decision_boundari": 28, "plot_knn_regress": 28, "plot_lda_w_vector": 41, "plot_linkage_criteria": 39, "plot_logistic_regress": 31, "plot_logistic_regression_graph": 42, "plot_multiclass_lr_ovr": 46, "plot_original_clust": 39, "plot_partial_effects_on_outcom": 44, "plot_result": [28, 49], "plot_scal": 29, "plot_silhouette_dist": 38, "plot_single_hidden_layer_graph": 42, "plot_support_vector": 28, "plot_survival_funct": 44, "plot_svc_c": 28, "plot_svc_gamma": 28, "plot_time_spacing_distribut": [43, 54], "plot_train_test_point": 28, "plot_tree_decision_boundari": 27, "plot_tree_decision_boundary_and_tre": [26, 27, 48], "plot_two_hidden_layer_graph": 42, "plot_typ": 36, "plot_x_dendrogram": 39, "plotli": [37, 41], "plotting_funct": [26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 42, 46, 48, 49, 50, 51, 52, 53], "plotting_functions_unsup": [38, 39, 40, 41], "plt": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "plu": [31, 42], "plural": 30, "pm": [1, 10, 43, 54, 55], "pmltt": 10, "pn": [28, 33, 38, 39, 49], "po": [27, 29, 31, 34, 36, 41, 45], "pobox": 25, "point": [4, 10, 25, 26, 27, 29, 30, 31, 32, 34, 37, 39, 44, 46, 47, 49, 52, 55], "point_ind": 38, "point_index": 38, "pointless": 51, "polarity_scor": 45, "pole": 42, "polici": [3, 4, 7, 55], "polit": [40, 41, 42], "poly_transform": 43, "polynomialfeatur": [37, 43], "pomegran": 42, "pool": 10, "poolarea": [34, 36], "poolqc": [34, 36], "poor": [30, 34, 37, 47, 50], "poorli": [28, 34, 39, 43], "pope": 41, "popul": [29, 30, 31, 37, 43, 50], "popular": [8, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 55], "population_per_household": [29, 30, 50], "porter": 41, "porterstemm": 41, "portion": [0, 27, 29, 32, 34, 36, 53, 54, 55], "portug": [33, 36], "pos_": [41, 45], "pos_label": 34, "posit": [26, 27, 28, 29, 31, 34, 35, 36, 41, 43, 44, 45, 52], "posix": 44, "possibl": [4, 5, 6, 8, 25, 26, 27, 29, 32, 33, 35, 36, 37, 39, 40, 41, 42, 44, 47, 49, 50, 51, 52, 55], "possibli": [7, 41], "post": [4, 6, 8, 10, 41, 43, 55], "postprocess": 42, "potenti": [28, 29, 38, 41, 55], "potteri": 41, "powder": 41, "power": [8, 27, 35, 40, 41, 42], "pplicat": 39, "pr": 47, "practic": [0, 6, 9, 10, 27, 29, 37, 42, 47, 50, 51, 55], "prairielearn": [10, 55], "pre": [10, 11, 19, 23, 24, 25, 35, 37, 41, 45, 47], "precis": [18, 34, 47, 52, 55], "precision_lr": 33, "precision_recall_curv": 33, "precision_scor": 33, "precision_svc": 33, "precisionrecallcurvedisplai": 33, "precisionrecalldisplai": 33, "pred": [33, 34, 40, 43, 44], "pred_df": [25, 40], "pred_dict": 25, "pred_g": 40, "pred_lin_reg": 40, "pred_train": 34, "pred_x": 40, "prediciton": 44, "predict": [2, 17, 27, 28, 29, 32, 33, 34, 37, 38, 39, 41, 43, 45, 47, 49, 50, 51, 52, 53, 54, 55], "predict_expect": 44, "predict_for_usr": 40, "predict_proba": [33, 35, 36, 42, 46, 53], "predict_survival_funct": 44, "predicted_categori": 33, "predicted_n_rent": 43, "predicted_quiz2": 26, "predicted_sal": 43, "predicted_target": 25, "predictor": [26, 47], "prefer": [25, 35, 38, 40, 51], "prefix": 8, "preliminari": [29, 37], "prepar": [29, 37, 42], "prepend": 11, "preprocess": [10, 16, 18, 27, 28, 31, 32, 33, 35, 36, 37, 39, 40, 42, 44, 45, 49, 50, 51, 53, 55], "preprocess_featur": [43, 54], "preprocessing_fin": 44, "preprocessing_notenur": 44, "preprocessor": [30, 32, 33, 34, 35, 36, 43, 44, 45, 50, 51, 52, 53, 54], "preprocessor1": 37, "preprocessor2": 37, "preprocessor3": 37, "prerequisit": [2, 44, 55], "preschool": [33, 35, 36, 52], "presenc": [30, 36, 44], "present": [7, 27, 33, 40, 41, 42, 43, 44, 47, 49, 54], "preserv": [33, 38], "pressure3pm": [43, 54], "pressure9am": [43, 54], "pretend": [26, 27, 43], "pretrain": [41, 42, 45], "pretti": [26, 30, 31, 33, 35, 38, 41, 43, 44, 54], "prevent": [32, 41, 44, 55], "previou": [26, 34, 35, 38, 39, 43, 44, 47, 51, 52, 54], "previous": [40, 42, 43], "price": [8, 18, 29, 31, 34, 36, 37, 44, 49], "primari": [8, 19, 23, 24, 28], "primarili": [26, 36, 42], "prime": 25, "principl": [9, 26, 47, 55], "print": [7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 54], "print_top": 41, "prior": [38, 43, 47], "priorit": [37, 47], "privaci": [0, 38, 55], "privat": [7, 33, 35, 36], "privileg": 6, "prize": 30, "pro": [38, 42], "prob": [31, 35], "proba": 42, "probabilist": 2, "probabl": [17, 25, 28, 29, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 47, 52, 53, 54], "problem": [4, 6, 10, 25, 30, 31, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 49, 51, 52, 53, 54, 55], "problemat": [33, 36, 44], "probosci": [25, 42], "proce": 55, "procedur": 35, "proceed": [27, 54], "process": [2, 5, 7, 26, 28, 29, 30, 32, 37, 38, 39, 42, 45, 49, 51, 55], "process_on": 45, "prod": [30, 32], "produc": [2, 7, 34, 36, 39, 44, 47, 49], "product": [5, 32, 40, 41], "prof": [33, 35, 36, 52], "profession": 40, "profil": 34, "profile_df": 40, "profilereport": 34, "program": [0, 4, 9, 11, 25, 41, 55], "programm": 41, "progress": 38, "project": [11, 29, 35, 37, 42, 47, 55], "promin": 41, "promis": [25, 41, 43], "promot": 44, "prompt": [11, 55], "pron": [41, 45], "prone": 32, "proper": [42, 48], "properli": [7, 44], "properti": [26, 34, 36, 37], "prophet": 43, "propn": 45, "proport": [26, 27, 30, 31, 33, 34, 35, 36, 52, 55], "proportional_hazard_test": 44, "prostitut": 41, "prototyp": 47, "prove": 33, "provid": [0, 5, 7, 11, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 47, 51, 52, 53, 54, 55], "provinc": [30, 41], "proxi": 27, "proxim": [31, 41, 55], "prune": 37, "psychologi": [30, 47], "pt": [31, 32, 42], "public": [0, 4, 7, 41, 45], "publish": [0, 10, 31, 41], "pud": 34, "pull": [11, 31, 41], "punct": [41, 45], "punctuat": [30, 41], "punkt": 45, "punkt_tab": 45, "purchas": [25, 40], "pure": [26, 43], "purpos": [0, 26, 27, 29, 40, 41, 43, 47, 48, 49, 53, 55], "push": [7, 36], "put": [7, 8, 11, 26, 27, 29, 30, 37, 38, 39, 40, 51], "px": [37, 41], "py": [26, 27, 29, 30, 32, 35, 36, 38, 39, 44, 45, 46], "pybind11": 45, "pybo": 32, "pydata": 37, "pyplot": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "pysurviv": 44, "python": [3, 4, 10, 25, 32, 34, 40, 41, 42, 43, 44, 45, 55], "python3": [9, 26, 27, 30, 32, 36, 44, 45, 46], "pythonwarn": 34, "pytorch": [25, 42], "pytorch_1711403226120": 45, "pyviz": 33, "q": 10, "qualiti": [33, 36, 38, 39], "quantifi": [33, 52], "queri": [29, 33, 35, 38, 40, 41, 43, 44, 52, 54, 55], "query_point": 28, "quest": 37, "question": [6, 7, 55], "quick": [4, 41, 55], "quickli": [26, 28, 29, 32, 39, 44, 47, 55], "quickstart": 9, "quirk": 27, "quit": [6, 25, 26, 29, 32, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45], "quiz": [1, 10, 41], "quiz1": [26, 27, 30, 47], "quiz2": [27, 30, 47], "quizz": 26, "r": [26, 30, 31, 33, 43, 53, 55], "r1": 35, "r2": [34, 35, 47, 49], "r2_score": [34, 37, 45], "r4": 35, "race": [30, 33, 35, 36, 52, 55], "radial": 28, "radiu": [37, 39], "rail": 42, "rain": [43, 54], "rain_df": [43, 54], "rain_df_modifi": [43, 54], "rainfal": [43, 54], "rainfall_lag1": [43, 54], "rainfall_lag2": [43, 54], "rainfall_lag3": [43, 54], "raintodai": [43, 54], "raintoday_miss": [43, 54], "raintoday_no": [43, 54], "raintoday_y": [43, 54], "raintomorrow": [43, 54], "rais": [6, 30, 33, 43, 44, 54], "rand": [8, 35], "randint": [32, 51], "randn": [31, 37], "random": [6, 8, 27, 28, 31, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 53, 55], "random_forest_data": 35, "random_search": [32, 51], "random_st": [25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53], "randomforestclassifi": [36, 37, 43, 53, 54], "randomforestclassifierrandomforestclassifi": 35, "randomforestregressor": [34, 35, 36, 37, 43, 44, 45, 53], "randomhorizontalflip": 42, "randomizedsearchcv": [28, 35, 36, 51, 53], "randomizedsearchcvifittedrandomizedsearchcv": 32, "randomli": [27, 31, 32, 33, 35, 44, 52], "randomoversampl": 33, "randomresizedcrop": 42, "randomst": [37, 39], "randomundersampl": 33, "rang": [4, 8, 27, 28, 29, 30, 31, 35, 38, 40, 41, 42, 43, 44, 45, 51, 55], "rangeindex": [30, 37, 43, 44, 54], "rank": [33, 37, 40, 41, 44, 52], "rank_test_mape_scor": 34, "rank_test_neg_mean_squared_error": 34, "rank_test_scor": [32, 34], "ranking_": 37, "rare": [30, 33, 34, 38, 41, 47], "rate": [25, 31, 33, 35, 38, 44, 47, 52], "rated_item": 40, "rather": [25, 30, 32, 33, 34, 35, 36, 38, 41, 42], "ratings_df": 40, "ratio": [33, 35, 41, 44], "ravel": [33, 47], "raw": [8, 30, 33, 36, 37, 41, 42, 46, 52], "raw_model_output": 31, "raw_scor": 36, "rbf": [10, 15, 27, 29, 31, 32, 35, 36, 37, 47, 49, 51], "rcparam": [25, 26, 27, 33, 38, 39, 40, 42, 43, 44, 48, 54], "re": [4, 7, 8, 11, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 54], "reach": [6, 38, 55], "read": [1, 4, 7, 10, 28, 29, 30, 33, 34, 35, 36, 41, 43, 53, 54], "read_csv": [8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54], "read_excel": 8, "read_html": 8, "read_json": 8, "readabl": [0, 8], "reader": 55, "readi": [7, 27, 28, 29, 31], "readlin": 42, "readm": 44, "readthedoc": 44, "real": [27, 28, 29, 30, 31, 33, 36, 38, 39, 40, 41, 42, 45, 47], "realdonaldtrump": 45, "realist": [29, 43, 54], "realiti": [27, 34, 44], "realli": [8, 27, 31, 32, 35, 37, 39, 40, 42, 43, 44], "reason": [0, 2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 32, 33, 34, 36, 38, 40, 41, 43, 44, 47, 55], "rebuild": 45, "rec": [34, 36], "recal": [18, 26, 27, 28, 29, 30, 31, 34, 38, 43, 47, 52, 55], "recall_lr": 33, "recall_scor": 33, "recall_svc": 33, "receiv": [6, 7, 30, 39, 42, 43], "recent": [8, 11, 25, 30, 37, 40, 41, 43, 44, 45], "recip": 27, "recogn": [27, 39, 43, 55], "recognit": [25, 26, 28, 33, 41, 55], "recommend": [2, 4, 8, 10, 11, 25, 27, 28, 32, 33, 38, 41, 42, 53, 55], "record": [26, 44], "recreat": 54, "rectangular": 38, "recurr": 43, "recurs": 55, "red": [26, 28, 33, 36, 37, 38, 43], "redbon": 32, "redefin": 44, "redistribut": 0, "reduc": [7, 8, 25, 28, 32, 33, 34, 35, 36, 37, 40, 41, 42, 46, 49, 52, 55], "reduct": [2, 33, 35, 37, 38], "redund": [31, 36], "ref": [33, 44, 52], "refer": [8, 26, 27, 28, 29, 30, 31, 33, 36, 38, 40, 41, 42, 49, 55], "referenc": 55, "referenti": 41, "refin": [28, 49], "refit": 34, "reflect": [28, 34, 36, 41, 49, 51, 55], "reflection_period": 33, "reg": [26, 35, 53], "reg_model": 26, "regard": 55, "regardless": 7, "regex": 41, "region": [26, 33, 39, 43, 46, 51, 54], "region_data": [43, 54], "regist": 55, "registri": 45, "regrad": 6, "regress": [2, 10, 17, 25, 29, 30, 36, 37, 40, 43, 44, 45, 46, 47, 49, 52, 53, 54, 55], "regression_df": 26, "regressor": [26, 29, 30, 34, 43, 53], "regular": [28, 30, 31, 35, 41, 43, 44, 47], "regulatori": 36, "reinforc": [25, 38], "reject": [33, 52], "rel": [31, 36, 39, 41, 45, 46, 52], "rel_char_len": 45, "relabel": 38, "relat": [2, 6, 11, 25, 31, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 53, 55], "relationship": [33, 35, 36, 37, 41, 43, 45, 47, 48, 49, 52, 54, 55], "relationship_husband": 36, "relationship_own": 36, "releas": [7, 10], "relev": [4, 8, 10, 26, 28, 29, 32, 36, 43, 55], "reli": [27, 28, 37, 39, 40, 43, 49], "reliabl": [25, 38], "religi": 41, "remain": [5, 34, 37, 40, 43], "remaind": 6, "rememb": [7, 28, 30, 32, 33, 36, 37, 39, 42, 43, 44, 48, 49, 51, 54], "remind": 48, "remix": 0, "remov": [7, 29, 33, 35, 36, 37, 41, 42, 44, 46, 51, 52, 54], "renam": [25, 33, 36, 43], "render": [4, 7, 25, 29, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 45], "rent": 43, "rental": 43, "rentals_df": 43, "rentals_lag5": 43, "rentals_lag5_i": 43, "rentals_lag5_x": 43, "rentals_model": 43, "repair": [33, 35, 36], "repeat": [8, 37, 38, 39, 42, 51, 52, 53], "repeatedli": 6, "replac": [25, 29, 33, 35, 36, 40, 44, 52], "reply_cont": 45, "repo": [10, 33], "report": [6, 26, 32, 34, 37, 43, 45, 52], "repositori": [0, 5, 10, 11, 31, 33, 55], "repres": [26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 53], "represent": [25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 47], "reproduc": [4, 27, 32, 35, 55], "republ": 36, "request": [6, 41, 55], "requir": [5, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 47, 49, 54], "rerun": [25, 29, 30, 32, 33, 34, 35, 36, 37, 42, 45], "res_mean": 27, "resampl": 33, "research": [25, 27, 32, 40, 41], "reserv": [43, 55], "reset_index": 25, "reshap": [8, 31, 32, 42, 43, 51], "resid": 31, "residu": 35, "resiz": 42, "resnet": 42, "resolut": 41, "resolv": 55, "resort": 31, "resourc": [3, 5, 10, 26, 35, 36, 41, 42, 47], "respect": [31, 32, 33, 35, 36, 51], "respons": [4, 7, 26, 38, 41, 55], "rest": [31, 32, 42, 44, 47, 54], "restart": [7, 11], "restaur": 40, "restingbp": 53, "restingecg": 53, "restrict": [0, 34, 35, 41], "result": [2, 7, 8, 10, 11, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 49, 51, 52, 53, 54, 55], "result_block": 44, "result_img": 42, "results_df": [27, 28, 31, 49], "results_dict": [27, 28, 29, 30, 32], "results_single_valid_df": 49, "retail": [45, 47], "retail_df": 43, "retail_df_test": 43, "retail_df_train": 43, "retail_lag_5": 43, "retail_model": 43, "retail_test_5": 43, "retail_test_5_pr": 43, "retail_train_5": 43, "retail_train_5_d": 43, "retail_train_5_i": 43, "retail_train_5_x": 43, "retent": 44, "retrain": [32, 51], "return": [5, 8, 11, 26, 27, 28, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 51, 54], "return_gener": 30, "return_train_scor": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45, 49, 51, 53], "reus": [33, 55], "revenu": 40, "revers": [30, 34], "review": [4, 10, 31, 38, 45, 47, 51, 52, 53, 55], "revisit": [33, 47], "revok": 0, "reward": [25, 30, 38], "rf": [43, 44], "rf_imp_df": 36, "rfe_cv": 37, "rfe_pip": 37, "rfecv": 37, "rgb": 25, "rich": [36, 41, 44, 47], "rico": 36, "rid": [11, 30, 35, 36, 41, 44], "ridg": [36, 37, 40, 43, 44, 45], "ridge__alpha": 34, "ridge_pr": 34, "ridge_tun": 34, "ridgecv": [37, 45], "ridgecv_pip": 34, "ridgeridg": [34, 37], "right": [0, 10, 25, 31, 32, 33, 34, 37, 38, 39, 40, 41, 47, 51, 52, 55], "rightarrow": [26, 28, 31, 33, 34, 35, 38, 39, 40, 41, 47], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": 41, "rise": [37, 41], "risk": [10, 33, 37, 49, 53], "river": 31, "rl": [34, 36], "rmse": [40, 47], "rng": [37, 39], "rnn": 43, "ro": 33, "roast": 38, "robot": [40, 41], "robust": [25, 27, 28, 29, 32, 35, 39, 49, 51], "roc": [47, 55], "roc_auc": 33, "roc_auc_scor": 33, "roc_curv": 33, "roc_lr": 33, "roc_svc": 33, "roccurvedisplai": 33, "rodolfo": 32, "rodr\u00edguez": 41, "roger": 37, "role": [31, 32, 36, 42], "roman": 40, "romanc": 40, "romant": 40, "ronald": 31, "roof": 36, "roofmatl": [34, 36], "roofmatl_clytil": [34, 36], "roofmatl_compshg": [34, 36], "roofmatl_membran": 34, "roofmatl_met": 34, "roofmatl_rol": 34, "roofmatl_tar": 34, "roofmatl_wdshak": 34, "roofmatl_wdshngl": [34, 36], "roofstyl": [34, 36], "roofstyle_flat": 34, "roofstyle_g": 34, "roofstyle_gambrel": 34, "roofstyle_hip": 34, "roofstyle_mansard": 34, "roofstyle_sh": 34, "room": [25, 26, 31, 34, 37, 45, 55], "rooms_per_household": [29, 30, 37, 50], "rooms_per_household_0": 37, "rooms_per_household_1": 37, "rooms_per_household_10": 37, "rooms_per_household_11": 37, "rooms_per_household_12": 37, "rooms_per_household_13": 37, "rooms_per_household_14": 37, "rooms_per_household_15": 37, "rooms_per_household_16": 37, "rooms_per_household_17": 37, "rooms_per_household_18": 37, "rooms_per_household_19": 37, "rooms_per_household_2": 37, "rooms_per_household_3": 37, "rooms_per_household_4": 37, "rooms_per_household_5": 37, "rooms_per_household_6": 37, "rooms_per_household_7": 37, "rooms_per_household_8": 37, "rooms_per_household_9": 37, "root": [11, 26, 28, 40, 42, 47], "rose": 41, "rostin": 55, "rotat": [43, 54], "rough": 4, "roughli": [5, 27, 41, 47], "round": [8, 28, 29, 32, 33, 35, 39, 42, 49], "rout": [5, 26, 43], "row": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 48, 49, 53, 54, 55], "rry": 41, "rsh": 32, "ru": [8, 33], "rubric": 31, "rule": [1, 8, 25, 26, 28, 31, 33, 35, 41, 47, 49, 52], "run": [4, 5, 7, 10, 11, 25, 27, 28, 30, 32, 33, 34, 36, 38, 39, 41, 42, 45, 46, 48, 49, 51, 53], "run_ast_nod": 45, "run_cel": 45, "run_cell_async": 45, "run_cod": 45, "run_forev": 45, "runner": 45, "runpi": 45, "runtimewarn": 32, "rush": 37, "russel": 10, "rv": 32, "rv_continuous_frozen": 32, "rv_discrete_frozen": 32, "rvert_2": 41, "s1": [8, 41], "s19": 29, "s2": [8, 41], "s_lag": [43, 54], "sa": 1, "sabrina": 10, "sadli": 41, "safe": 29, "safeti": 42, "sai": [8, 26, 28, 29, 30, 33, 34, 35, 36, 41, 43, 47, 52], "said": [27, 29, 31, 36, 39, 40, 41], "sal": [34, 36], "sale": [8, 33, 34, 43, 49], "salecondit": [34, 36], "salecondition_abnorml": 34, "salecondition_adjland": 34, "salecondition_alloca": 34, "salecondition_famili": 34, "salecondition_norm": 34, "salecondition_parti": 34, "salepric": [34, 36], "sales_data": 43, "salesforc": 45, "saletyp": [34, 36], "saletype_cod": 34, "saletype_con": 34, "saletype_conld": 34, "saletype_conli": 34, "saletype_conlw": 34, "saletype_cwd": 34, "saletype_new": 34, "saletype_oth": 34, "saletype_wd": 34, "salt": [31, 36], "sam": 40, "same": [6, 7, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 52, 54], "sampl": [26, 28, 29, 31, 32, 36, 39, 42, 43, 44, 48, 49, 52, 53, 54], "sample_df": 33, "sample_text": 45, "sampling_strategi": 33, "samuel": 25, "sand": 42, "sandbar": 42, "saniti": [26, 44], "sarah": 10, "sat": 43, "satisfactori": 38, "satisfi": [38, 55], "saturdai": [10, 43], "save": [7, 8, 30, 32, 36, 41, 42, 43, 45, 50, 51, 54], "saw": [29, 31, 32, 33, 39, 47], "sb": 37, "scalabl": [25, 39], "scalar": 8, "scale": [16, 27, 28, 30, 32, 33, 34, 35, 37, 39, 42, 44, 47, 49, 50, 51], "scale_pos_weight": 35, "scaler": [29, 36, 37], "scan": 47, "scatter": [29, 34, 36, 37], "scatter_3d": 37, "scatterplot": 37, "scc": 41, "scenario": [27, 30, 35, 36, 37, 39, 43, 44, 47, 55], "schedul": [44, 47], "schmidt": 32, "school": [25, 33, 35, 36, 40, 52], "scienc": [2, 9, 10, 11, 30, 38, 43, 47, 49, 55], "scientif": [40, 41], "scientist": [9, 10, 39], "scikit": [9, 11, 16, 17, 26, 28, 31, 32, 33, 35, 38, 39, 42, 43, 45, 46, 51, 52, 55], "scipi": [11, 32, 39, 41, 51], "scm": 5, "scope": [41, 43], "score": [17, 18, 25, 28, 29, 30, 35, 36, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55], "score_func": 34, "score_lr_print_coeff": [43, 54], "score_param": 30, "score_tim": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45], "scorer": [30, 34], "scores_averag": 53, "scores_dict": 31, "scores_imag": 31, "scores_stack": 53, "scoring_method": 44, "scoring_metr": [35, 36, 45], "scotland": 41, "scratch": [2, 42], "screen": 7, "screennam": 45, "screenplai": 41, "screenporch": [34, 36], "script": 11, "scroog": 45, "sd": [19, 23, 24], "sdng": 34, "se": [43, 44, 54], "sea": 42, "seaborn": [36, 37, 38, 39, 40], "seacoast": 42, "search": [4, 5, 11, 34, 41, 47, 51], "search_multi": 34, "seashor": 42, "season": 54, "season_autumn": 43, "season_fal": 43, "season_summ": 43, "season_wint": 43, "seat": [42, 55], "seattl": 45, "seawal": 42, "second": [4, 6, 26, 31, 35, 36, 39, 42, 43], "secondari": 25, "secpompeo": 45, "section": [7, 11, 26, 27, 37, 53, 55], "secur": [36, 55], "see": [1, 4, 6, 7, 8, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55], "seed": [31, 32, 38, 39], "seem": [26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 43, 44, 45, 46, 49, 51, 52], "seemingli": [33, 52], "seen": [8, 25, 27, 28, 29, 30, 31, 37, 39, 40, 44, 47, 49, 51, 53], "sefa": 55, "segment": [33, 41, 42, 44, 47, 55], "select": [5, 6, 10, 11, 27, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 44, 55], "select_dtyp": 34, "select_knn": 37, "select_rf": 37, "select_svc": 37, "selectfrommodel": 37, "self": [25, 30, 44, 45, 55], "sell": [0, 8, 26], "semant": [38, 39, 41, 55], "semest": 55, "semi": [10, 41], "semicolon": 8, "semilogx": 34, "send": [4, 25, 45], "senior": 44, "seniorcitizen": 44, "sens": [6, 27, 30, 31, 33, 34, 36, 37, 38, 40, 41, 43, 44, 46], "sensibl": 7, "sensit": [27, 29, 32, 33, 34, 38, 44], "sent": [25, 41], "sent_token": 41, "sentenc": 41, "sentiment": [26, 31, 41, 45], "sentimentintensityanalyz": 45, "sepal": [28, 49], "separ": [26, 27, 29, 30, 31, 33, 37, 38, 40, 41, 43, 46, 47, 48, 49, 50, 51, 52], "septemb": 43, "sequenc": [27, 30, 42, 43], "sequenti": [26, 35, 43, 44, 47], "sequentialfeatureselector": 37, "ser": [27, 29, 44], "seri": [2, 10, 27, 29, 30, 33, 37, 42, 44, 45, 55], "serial": 35, "seriou": [6, 33, 40, 41, 44, 55], "serv": [5, 26, 36, 55], "server": 5, "servic": [35, 36, 40, 44, 45], "session": [38, 47, 55], "set": [7, 8, 9, 10, 25, 26, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 54], "set_config": [32, 35], "set_index": [27, 28, 32, 33, 34], "set_opt": [25, 26, 27, 28, 29, 30, 31, 32, 33, 39, 40, 48, 49, 50, 51, 52], "set_properti": 25, "set_titl": [28, 31, 33, 42, 49, 52], "set_xlabel": [28, 31, 38, 49], "set_ylabel": [28, 31, 38, 49], "settl": [51, 52], "setup": [3, 7, 11, 48], "setup_default_warn": 45, "sev": [34, 36], "sever": [11, 29, 31, 38, 39, 41, 42, 43, 46, 54, 55], "sex": [33, 35, 36, 37, 52, 53], "sexual": 55, "shadab": 55, "shadow": [19, 23, 24], "shaikh": 55, "shall": [0, 41], "shallow": 35, "shape": [26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54], "shape_df": 27, "shape_dict": 27, "share": [0, 37, 55], "sharealik": 1, "sharex": 29, "shashwat": 55, "she": [25, 40, 45], "shed": [34, 36], "sheet": [9, 47], "shelf": [35, 41, 51], "shell": [5, 9, 45], "shelv": 45, "shift": [43, 54], "shit": 45, "shng": 34, "shop": 40, "short": [10, 11, 27, 32, 35, 41, 55], "shorter": 44, "shorthand": 29, "shot": 37, "should": [5, 7, 8, 11, 26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55], "shouldn": [33, 35, 49], "show": [4, 7, 11, 25, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 47, 49, 51, 53, 54], "show_plot": 44, "showcas": 41, "shown": [7, 11, 25, 26, 28, 33, 35, 38, 39, 43], "shrink": [32, 37], "shuffl": [27, 42, 43, 54], "si": 25, "sibl": 37, "sick": [38, 45], "sid": 45, "side": [6, 42], "sift": 40, "sigma": 42, "sign": [4, 34, 36, 42, 49, 51, 53, 55], "signal": [27, 41], "signific": [29, 42, 55], "significantli": [30, 33, 40], "sigoptsearchcv": 32, "silhouett": 39, "silhouettevisu": [38, 39], "sim": 36, "sim_word": 41, "simard": 36, "similar": [10, 11, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 46], "similarity_": 41, "similarli": [36, 38, 44], "simp": 43, "simpl": [10, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 47, 48, 52], "simplefilt": [35, 36], "simpleimput": [29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45, 47, 50, 51, 52, 53, 54], "simpleimputersimpleimput": [29, 30, 34, 35, 37], "simpler": [31, 32, 49], "simplest": 30, "simpli": [29, 37, 38], "simplic": [26, 30, 40], "simplist": [28, 36, 49], "simul": 37, "sin": 8, "sinc": [5, 31, 34, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 54], "singl": [8, 28, 29, 31, 32, 33, 35, 36, 39, 43, 44, 47, 48, 49, 51, 52], "sit": 55, "site": [5, 26, 27, 30, 32, 36, 44, 45, 46, 55], "situat": [6, 25, 33, 35, 38, 42, 44, 55], "six": [27, 35, 43], "size": [25, 26, 27, 28, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 53, 54, 55], "skew": 34, "skill": [35, 55], "skin": 45, "skip": 52, "skipna": 44, "sklearn": [10, 25, 27, 28, 31, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "sklearn_gb": 35, "sklearn_histgb": 35, "sktime": 43, "skyblu": [43, 54], "skyscrap": 43, "slate": 54, "slice": 8, "slide": [9, 10, 19, 29, 42, 55], "slightli": [30, 31, 33, 35, 44], "slope": 31, "sloppi": 29, "slot": 55, "slow": [28, 35, 37, 42], "slower": [35, 38], "slowest": 53, "sm": [25, 30], "smac": 32, "small": [11, 27, 28, 30, 32, 34, 35, 36, 37, 38, 40, 42, 44, 47, 49, 51, 53], "small_citi": 28, "small_train_df": 28, "smallalpha_coeff": 34, "smaller": [28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 43, 44, 49, 51], "smallest": [31, 34, 38, 39], "smart": [38, 45], "smile": 45, "smooth": [28, 49], "smoothli": 11, "smote_pip": 33, "sms_df": 25, "sn": [36, 38, 39], "snake": [31, 42], "snake_length": 31, "snakes_df": 31, "snbf": 35, "snippet": 7, "snow": [25, 42], "snp": 37, "so": [0, 4, 5, 7, 8, 10, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55], "social": [38, 39, 40, 43], "societ": 55, "societi": [33, 41, 52], "sofist": 49, "soft": [31, 35, 53], "softmax": 47, "softwar": [1, 5, 11, 44], "solar": 40, "sold": [8, 34], "sole": [33, 39], "solidifi": 47, "solut": [25, 26, 27, 35, 38, 44, 45, 47, 55], "solv": [4, 25, 26, 28, 37, 41, 49, 55], "solver": 33, "some": [4, 6, 7, 8, 11, 25, 27, 28, 29, 30, 31, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55], "someon": [25, 26, 27, 37, 44], "someth": [4, 7, 11, 26, 30, 33, 34, 35, 36, 38, 43, 44, 47, 55], "sometim": [6, 26, 27, 30, 31, 32, 35, 36, 41], "somewhat": 34, "somewher": [25, 34], "song": [28, 29, 40, 45, 51], "song_titl": [28, 29, 32, 51], "soo": 55, "soon": [25, 28, 29, 43], "sopha": 25, "sophist": [32, 36, 41], "sort": [5, 10, 26, 27, 29, 36, 40, 41, 42, 43, 54], "sort_index": [8, 32, 34, 43, 54], "sort_valu": [29, 30, 31, 32, 34, 35, 36, 37, 43, 44, 45, 53, 54], "sound": [36, 37], "soundtrack": 41, "sourc": [11, 25, 26, 27, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 45, 48, 51, 55], "south": 30, "space": [28, 31, 32, 37, 38, 39, 41, 45, 54, 55], "spaci": 37, "spacy_download": 41, "spacymoji": 45, "spam": [27, 33, 38], "spam_predict": 25, "span": [41, 43], "spanish": 29, "spars": [28, 31, 35, 40, 41, 47], "sparse_output": [29, 30, 33, 34, 35, 36, 43, 44, 47, 52, 53, 54], "spatial": 31, "speak": 5, "spearmint": 32, "speci": [28, 47, 49], "special": [25, 30, 40, 41, 42, 43, 44, 49, 55], "specialti": [33, 35, 36], "specif": [8, 26, 27, 32, 33, 36, 38, 40, 41, 42, 43, 44, 47, 49, 51, 53, 55], "specifi": [8, 26, 27, 30, 32, 33, 38, 39, 42, 51, 53], "spectrogram": 37, "speech": [37, 41, 45], "speechi": [28, 29, 32, 51], "speed": [8, 26, 35, 42], "spell": 25, "spend": [25, 29, 37, 45, 55], "spent": [6, 29, 37], "spheric": [39, 47], "spici": 38, "spini": 42, "spit": 42, "split": [15, 26, 28, 30, 31, 32, 34, 35, 37, 40, 41, 44, 45, 47, 52, 53, 54, 55], "split0_test_r2": 34, "split0_test_scor": 32, "split0_train_neg_mean_squared_error": 34, "split0_train_scor": 32, "split1_test_r2": 34, "split1_test_scor": 32, "split1_train_neg_mean_squared_error": 34, "split1_train_scor": 32, "split2_test_r2": 34, "split2_test_scor": 32, "split2_train_neg_mean_squared_error": 34, "split2_train_scor": 32, "split3_test_r2": 34, "split3_test_scor": 32, "split3_train_neg_mean_squared_error": 34, "split3_train_scor": 32, "split4_test_scor": 32, "split4_train_neg_mean_squared_error": 34, "split4_train_scor": 32, "spoken": 30, "sport": [41, 42, 43], "spot": [33, 34, 49], "spotifi": [28, 40, 51], "spotify_df": [28, 29, 32, 51], "spotlight": [5, 11], "spous": [33, 35, 36], "spread": 39, "spring_month": 43, "sqft": 36, "sqft_abov": [25, 26], "sqft_basement": [25, 26], "sqft_live": [25, 26], "sqft_living15": [25, 26], "sqft_lot": [25, 26], "sqft_lot15": [25, 26], "sqrt": [28, 34, 36, 40, 41], "squar": [8, 26, 28, 31, 36, 40, 44, 45, 47, 55], "squash": [31, 42], "squeez": [8, 44], "src": [27, 33], "sse": [43, 54], "ssw": 43, "st": [43, 45], "st_slope": 53, "stabil": 11, "stabl": [27, 33, 35, 49], "stack": [7, 47, 55], "stack_method": 53, "stacking_model": [35, 53], "stacking_model_tre": 35, "stackingclassifi": [35, 53], "stackingregressor": 35, "staff": 6, "stai": [33, 44], "stakehold": 55, "stale": 38, "stand": [28, 32, 41], "standard": [4, 6, 27, 29, 32, 35, 36, 37, 41], "standardscal": [30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54], "standardscalerstandardscal": [29, 30, 32, 33, 34, 35, 37, 42, 45], "stanford": 41, "star": [28, 38, 40, 45], "start": [7, 8, 11, 26, 27, 28, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54], "startswith": 36, "starttim": 43, "stat": [32, 44, 51], "state": [6, 8, 27, 33, 35, 36, 40, 45, 52], "statement": [7, 27, 28, 29, 30, 31, 32, 33, 34, 37, 42, 44], "station": 43, "statist": [9, 10, 26, 31, 36, 40, 41, 44, 55], "statistician": 28, "statlib": 31, "statsmodel": [43, 44], "statu": [33, 35, 36, 52], "status_marri": 36, "status_nev": 36, "std": [27, 28, 29, 33, 34, 42, 43, 45, 46, 54], "std_cv_error": 27, "std_cv_score": 28, "std_fit_tim": [32, 34], "std_score": [27, 29, 45], "std_score_tim": [32, 34], "std_test_neg_mean_squared_error": 34, "std_test_scor": [27, 32], "std_train_error": 27, "std_train_neg_mean_squared_error": 34, "std_train_scor": [27, 28, 32], "stdki": 44, "stem": 41, "step": [7, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55], "stereotyp": 41, "stick": 43, "still": [4, 11, 32, 33, 34, 35, 37, 38, 43, 44, 45, 49, 50, 51, 52], "stochast": [37, 38], "stock": [25, 43], "stop": [8, 38, 41, 42, 44, 49], "stop_word": [32, 33, 41, 45, 51], "stopword": 41, "storag": 28, "store": [7, 8, 28, 29, 30, 32, 33, 35, 36, 39, 40, 42, 43, 44, 45], "stori": [34, 35, 45], "storylin": 41, "str": [32, 36, 41, 43, 44, 45, 54], "straight": 44, "straightforward": 36, "strain": 7, "strang": [36, 44], "strata": 44, "strategi": [26, 28, 29, 30, 33, 34, 36, 38, 40, 43, 44, 47, 48, 52, 54], "stratif": 44, "stratifi": 44, "stratifiedkfold": [27, 33], "stream": [44, 45], "streamingmovi": 44, "streamingmovies_no": 44, "streamingmovies_y": 44, "streamingtv": 44, "streamingtv_no": 44, "streamingtv_y": 44, "street": [34, 36], "street_grvl": 34, "street_pav": 34, "strength": [41, 47], "stress": 38, "strftime": [43, 44], "string": [8, 11, 28, 33, 34, 35, 36, 41, 43, 44, 49, 53], "strip": [36, 42], "strong": [35, 44, 47], "stronger": 35, "strongli": 35, "structur": [8, 38, 41, 42], "struggl": [38, 43], "stuart": [10, 35], "stuck": [4, 8], "student": [4, 5, 6, 7, 25, 26, 31, 33, 34, 36, 37, 38, 39, 40, 42, 45, 55], "studi": [25, 30, 37, 41, 44], "stuff": [28, 42, 44], "stump": [26, 27, 28, 35, 48], "stupid": 45, "style": [25, 34, 37, 38, 40, 41, 42, 45], "sub": [32, 38, 41, 44, 47], "subdirectori": 36, "subgroup": 44, "subject": [0, 44, 55], "sublicens": 0, "submiss": [3, 55], "submit": [8, 10, 55], "subplot": [27, 28, 31, 33, 38, 42, 44, 49, 52], "subplot_kw": 27, "subprocess": 34, "subscrib": 44, "subscript": [43, 44], "subset": [26, 27, 32, 35, 42, 43, 46, 49], "substanti": 0, "substitut": 0, "subtl": 41, "subtleti": [27, 34], "subtract": [28, 33, 36], "suburb": 45, "subword": 41, "succe": [37, 55], "success": [5, 8, 11, 25, 33, 35, 40, 41, 42, 43], "successfulli": [11, 25, 45], "sudo": 5, "suei": 32, "suffer": 32, "suffici": [7, 41], "suggest": [0, 10, 26, 40, 44], "suicid": 41, "suit": 40, "suitabl": [11, 25, 38, 40, 47, 53, 55], "sum": [8, 28, 29, 30, 31, 35, 36, 38, 42, 45], "sum_": [28, 34, 38, 41, 42], "sum_i": [36, 41], "sum_prob_ex1_class_0": 35, "sum_prob_ex1_class_1": 35, "summar": [10, 25, 31, 33, 34, 38, 41], "summari": [0, 46, 47, 49], "summary_plot": 36, "summat": 35, "summer": [1, 40, 43], "summer_month": 43, "sun": [41, 43], "sundai": 43, "sundial": 42, "sunshin": [43, 54], "super": [30, 45, 47], "superfici": 28, "superior": 55, "supermarket": 45, "supervis": [29, 30, 32, 33, 34, 37, 39, 41, 43, 44, 47, 54, 55], "suppli": 55, "support": [11, 15, 26, 29, 33, 35, 36, 37, 39, 41, 45, 46, 49, 55], "support_": [28, 37], "suppos": [25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 47, 48], "suppress": 8, "suprem": 41, "sure": [4, 7, 8, 11, 27, 28, 30, 33, 34, 35, 36, 39, 42, 43, 49, 52, 53, 54, 55], "surgeri": 44, "suri": 55, "surpris": [36, 40], "surprisingli": [30, 31], "surround": [4, 55], "survei": 38, "surviv": [2, 10, 55], "survival_function_": 44, "suscept": 39, "suspect": 32, "svc": [28, 29, 30, 31, 32, 35, 36, 37, 42, 45, 49, 50, 51, 53], "svc__c": [32, 51], "svc__gamma": [32, 51], "svc_pipe": 32, "svc_pred": 33, "svcsvc": [30, 32, 33], "svm": [10, 27, 29, 30, 32, 35, 36, 37, 42, 43, 45, 46, 47, 49, 50, 51, 53], "svm_estim": 33, "svr": [28, 30, 36], "svr_c_pipe": 30, "svr_pipe": 30, "sw": [43, 54], "swai": 25, "swamp": 28, "swan": 42, "swcarpentri": 9, "sweep": 33, "sweet": 45, "switch": [36, 38, 43, 44, 54], "sy": [25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53], "sydnei": 43, "syllabu": [3, 7, 10, 12], "symbol": 26, "symmetri": 37, "sync": 5, "synonym": 41, "syntact": 41, "syntax": [4, 8, 25, 37, 44], "synthet": [37, 46], "system": [2, 4, 5, 6, 10, 11, 25, 27, 28, 30, 33, 36, 38, 43, 52, 55], "systemat": [26, 30, 32, 36, 41], "t": [4, 5, 7, 8, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 53, 54, 55], "ta": [7, 25, 34, 36, 48, 49, 50, 51, 52, 53, 54], "tabbi": [25, 42], "tabl": [7, 53], "tabular": [8, 25, 42, 43], "tackl": [27, 29, 33, 39, 49], "taco": 37, "tag": [4, 41, 45], "tail": [8, 43], "tailor": [38, 55], "take": [2, 4, 5, 6, 11, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55], "taken": [43, 46, 51, 55], "talk": [26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 55], "tall": 41, "target": [27, 28, 29, 31, 32, 33, 35, 36, 37, 40, 42, 43, 44, 47, 49, 50, 51, 52, 53, 54], "target_column": [35, 36, 44, 53], "target_nam": 33, "target_names_toi": 33, "tariff": 41, "task": [29, 30, 31, 32, 36, 37, 38, 40, 42, 43, 44, 45, 47, 51, 54, 55], "tast": [38, 40], "taught": [30, 41, 55], "tba": 10, "tbd": [19, 55], "teach": [4, 25, 29, 41, 47], "team": [4, 8, 25, 35, 36, 41, 53], "tech": [28, 33, 36], "technic": 55, "techniqu": [10, 28, 32, 37, 40, 42, 44, 46, 47, 55], "technolog": 0, "technologi": 41, "techsupport": 44, "techsupport_no": 44, "techsupport_y": 44, "ted": 38, "tediou": 39, "telco": 44, "telecom": 44, "telephon": 41, "tell": [27, 28, 29, 31, 33, 36, 37, 40, 41, 43, 44, 49, 51, 54], "temp3pm": [43, 54], "temp9am": [43, 54], "temperatur": 26, "tempo": [28, 29, 32, 51], "tempor": [44, 47, 54], "tend": [27, 28, 31, 35, 37, 40, 43, 44, 55], "tendenc": 27, "tensor": 42, "tensor_numpi": 45, "tensorflow": [11, 36, 42], "tent": 55, "tenur": [44, 47], "tenure_lm": 44, "tenure_predict": 44, "term": [0, 2, 26, 28, 30, 31, 33, 36, 37, 40, 41, 44, 47], "termin": [5, 11, 26, 38], "terminologi": [14, 27, 33, 47, 48], "terrac": 42, "terribl": [34, 40], "territori": 55, "tesoro": 32, "test": [1, 7, 8, 11, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 39, 44, 46, 47, 49, 51, 52, 53, 54, 55], "test_accuraci": 33, "test_average_precis": 33, "test_df": [25, 29, 30, 31, 33, 34, 35, 36, 37, 43, 44, 45, 50, 52, 53, 54], "test_df_churn": 44, "test_df_nan": [33, 35, 36, 52], "test_df_sort": 43, "test_df_surv": 44, "test_exampl": 35, "test_f1": 33, "test_format": 28, "test_g50k": 35, "test_imag": [25, 42], "test_l50k": 35, "test_mape_scor": 34, "test_nam": 44, "test_neg_mean_squared_error": 34, "test_neg_root_mean_square_error": 34, "test_point": [28, 46], "test_precis": 33, "test_r2": 34, "test_recal": 33, "test_roc_auc": 33, "test_sampl": 53, "test_scor": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45, 49], "test_shap_valu": 36, "test_siz": [25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 43, 45, 46, 49, 50, 51, 52, 53], "test_sklearn": 34, "test_statist": 44, "test_x": 44, "text": [7, 10, 16, 17, 25, 26, 31, 32, 33, 34, 35, 36, 37, 40, 42, 47, 51, 55], "text_feat": [32, 51], "text_featur": 45, "text_pp": 41, "textbook": [3, 9], "textrm": 27, "textual": 55, "textur": 37, "tf": 30, "tfidfvector": 31, "th": [31, 40, 55], "than": [6, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 48, 49, 52, 53, 55], "thank": [25, 41, 49], "thankfulli": [43, 54], "thei": [7, 8, 10, 26, 27, 28, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55], "theirs": 41, "them": [2, 4, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 55], "theme": 41, "themselv": [38, 39, 41], "theoret": [29, 33, 35, 47], "theori": 36, "thepopbreak": 45, "therefor": 49, "thermostat": 26, "thi": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 14, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "thick": 38, "thinc": 45, "thing": [5, 7, 8, 10, 26, 27, 28, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 53, 54], "think": [4, 25, 26, 27, 28, 30, 31, 33, 34, 36, 37, 38, 40, 42, 43, 44, 47, 48, 49, 51, 52, 54, 55], "third": 39, "thk": 25, "thorough": [11, 53], "thoroughli": 47, "those": [5, 8, 11, 29, 34, 35, 36, 40, 44, 55], "though": [27, 30, 31, 38, 39, 40, 45], "thought": [4, 28, 36, 44, 47], "thousand": [31, 39, 40], "threahold": 37, "threaten": 45, "three": [8, 26, 29, 31, 33, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 52, 55], "thresh": 8, "threshold": [26, 31, 35, 37, 39, 41, 44], "thresholds_lr": 33, "thresholds_svc": 33, "through": [7, 11, 26, 33, 34, 37, 39, 40, 42, 55], "throughout": 27, "throw": [30, 42, 44, 47], "thu": [6, 32, 43, 44], "thumb": [26, 45], "thursdai": 55, "ti": 30, "tick": 43, "tick_label": 36, "tick_param": 38, "tiger": [25, 42], "tight": [28, 39, 49], "tight_layout": 42, "tightrop": [28, 49], "tile": 36, "till": [28, 41, 44], "timber": 41, "time": [2, 4, 8, 10, 11, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 51, 52, 53, 55], "time_diff": [43, 54], "time_signatur": [28, 29, 32, 51], "timedelta": [43, 54], "timeit": [8, 46], "timeseri": [42, 43], "timeseriessplit": [43, 44, 47, 54], "timestamp": [43, 54], "timezon": [10, 44], "tinder": 40, "tini": [7, 27, 33, 39], "tip": 41, "tire": 45, "titan": 40, "titi": 25, "titl": [7, 27, 28, 31, 34, 37, 39, 42, 43, 44, 49, 54], "tn": 33, "to_datetim": [43, 54], "to_html": [25, 26, 27], "to_notebook_ifram": 34, "to_numpi": [28, 40, 43], "to_str": [25, 42], "toarrai": [30, 36, 43], "tobago": [35, 36], "todai": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 40, 42, 43, 44, 47, 53, 54], "todens": [36, 37], "togeth": [5, 8, 26, 28, 29, 30, 38, 41, 49, 55], "toi": [8, 27, 28, 37, 38, 39, 40, 43, 47], "toilet": [42, 45], "token": [7, 45, 55], "token_pattern": 30, "tol": [33, 37], "told": [5, 55], "tolist": [25, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 40, 43, 44, 45, 54], "tomasbeuzen": 8, "tomorrow": [26, 43, 44, 47, 54], "ton": 32, "tone": 45, "too": [6, 7, 27, 28, 30, 32, 34, 35, 36, 43, 44, 49, 51, 54, 55], "took": 43, "tool": [7, 8, 10, 11, 30, 31, 33, 34, 36, 39, 40, 42, 43, 44, 47, 55], "toolbox": [28, 35, 41], "toolkit": 41, "top": [26, 30, 32, 33, 39, 43, 54], "topic": [2, 8, 10, 26, 33, 34, 38, 40, 42, 47, 55], "topic2vec": 41, "topics_per_chunk": 41, "topn": [25, 42], "torch": [42, 45], "torchvis": [25, 42], "tornado": 45, "toronto": [41, 45], "tort": 0, "total": [8, 10, 26, 29, 30, 33, 34, 35, 36, 37, 41, 43, 44, 54], "total_bedroom": [29, 30, 37, 50], "total_bilirubin": 25, "total_protien": 25, "total_room": [29, 30, 37, 50], "total_second": [43, 54], "totalbsmtsf": [34, 36], "totalcharg": 44, "totem": 42, "totensor": 42, "toti": [0, 1, 41], "totrmsabvgrd": [34, 36], "toward": [31, 36, 41, 52, 55], "towardsdatasci": [42, 44], "town": 45, "townsvil": 43, "toy_clust": 41, "toy_clust_df": 38, "toy_df": [30, 41], "toy_lda_data": 41, "toy_movie_feat": 40, "toy_rat": 40, "toy_spam": 30, "toy_x": 41, "tp": 33, "tpot": 32, "tpr": 33, "tpr_lr": 33, "tpr_svc": 33, "tr_score": 49, "traceback": [4, 8, 30, 44, 45], "track": [30, 55], "trade": [31, 33, 37, 38, 47, 55], "tradeoff": [15, 28, 29, 31, 34, 37, 38, 42], "tradit": [25, 40, 42, 44, 55], "tradition": 55, "trail": 8, "train": [7, 28, 29, 32, 34, 35, 36, 37, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54], "train_accuraci": 33, "train_dataload": 42, "train_df": [25, 29, 30, 31, 33, 34, 35, 36, 37, 43, 44, 45, 50, 52, 53, 54], "train_df_churn": 44, "train_df_nan": [33, 35, 36, 52], "train_df_ord": [43, 54], "train_df_sort": 43, "train_df_surv": 44, "train_df_surv_not_churn": 44, "train_f1": 33, "train_flatten": 42, "train_for_usr": 40, "train_load": 42, "train_mape_scor": 34, "train_mat": 40, "train_mat_imp": 40, "train_neg_mean_squared_error": 34, "train_neg_root_mean_square_error": 34, "train_precis": 33, "train_r2": 34, "train_recal": 33, "train_scor": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 43, 44, 45, 49], "train_shap_valu": 36, "train_sklearn": 34, "train_test_split": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54], "train_x": 40, "traitlet": 45, "transact": [26, 33, 43, 52], "transfer": 44, "transfer_learning_tutori": 42, "transform": [0, 28, 32, 33, 35, 36, 39, 41, 42, 43, 44, 45, 47, 49, 50, 54], "transformed_exampl": 35, "transformed_oh": 29, "transformedtargetregressor": [34, 37, 45, 47], "transformedtargetregressortransformedtargetregressor": 34, "transformerdecod": 45, "transformerencod": 45, "translat": [9, 10, 25], "transpar": [33, 47], "transpos": [37, 42], "trasform": 29, "trash": 48, "traumat": 55, "treat": [8, 27, 29, 30, 33, 34, 40, 43, 44, 47, 52, 54], "treati": 55, "treatment": 30, "tree": [2, 10, 14, 19, 20, 27, 28, 29, 30, 31, 32, 34, 37, 39, 42, 43, 44, 46, 47, 48, 50, 51, 53], "tree1": 35, "tree2": 35, "tree3": 35, "tree_numeric_transform": 36, "treeexplain": 36, "trend": [44, 47, 55], "tri": [35, 36, 46, 51, 52, 53], "trial": [32, 44], "triangl": [28, 38], "trick": [5, 34], "tricki": [30, 32, 36, 40], "trigger": [28, 45], "trigram": 41, "trivial": 39, "troubl": 11, "true": [8, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54], "truli": [34, 41], "truncat": 39, "truncate_mod": 39, "truncation_mod": 39, "trust": [25, 29, 30, 32, 33, 34, 35, 36, 37, 40, 42, 45], "trustworthi": [39, 53], "truth": [35, 37, 38, 39, 40, 43], "try": [4, 5, 8, 10, 11, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55], "tsa": 43, "tscv": 43, "tslearn": 43, "tsunami": 25, "ttr": 34, "ttr_pipe": 34, "tue": 43, "tuesdai": [10, 37, 43, 54, 55], "tuggeranong": 43, "tumor": 47, "tune": [27, 32, 35, 39, 40, 42, 51, 53], "turn": [4, 27, 41, 42, 44, 50, 51, 55], "tusker": 42, "tutori": [4, 5, 9, 10, 11, 40, 42, 47, 55], "tweak": [28, 49], "tweet": [41, 45], "tweetat": 45, "twice": [8, 27, 30, 31], "twist": 41, "twitter_allowed_char": 45, "two": [4, 6, 7, 8, 9, 26, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 52, 55], "two_citi": 28, "two_song": 29, "two_songs_subset": 29, "tx": [31, 45], "txt": [25, 42], "typ": [34, 36], "type": [4, 8, 11, 26, 28, 29, 30, 32, 35, 37, 39, 40, 41, 42, 45, 47, 49, 50, 51, 54, 55], "typeerror": 44, "typic": [2, 7, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 38, 40, 43, 51], "u": [4, 11, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54], "u6": 26, "u_1": 28, "u_2": 28, "u_i": 28, "u_n": 28, "ubc": [0, 4, 5, 8, 9, 10, 11, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55], "ubc_img": 42, "ucsb": 9, "ud036": 9, "udac": 9, "ufunc": 34, "ultim": [4, 27], "ultralyt": 42, "uluru": [43, 54], "umbrella": 40, "un": [34, 44], "unabl": [25, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 44, 45, 55], "unambigu": 41, "unassign": [38, 39], "unbalanc": 52, "unbias": [33, 52], "unced": 55, "uncertain": [31, 53], "uncertain_indic": 53, "uncertainti": [31, 33], "unchang": 36, "uncia": [25, 42], "uncomfort": 40, "uncorrel": 36, "under": [0, 1, 7, 26, 27, 34, 42, 44], "under_sampl": 33, "underestim": 44, "underfit": [28, 31, 32, 42, 49, 51], "underli": [2, 36, 37, 38], "underneath": 7, "underpredict": 34, "undersample_pip": 33, "understand": [0, 1, 4, 7, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 52, 55], "understood": 33, "unemploi": 44, "unexpect": [30, 31, 32, 41], "unexplain": 34, "unf": [34, 36], "unfinish": 34, "unfortun": [6, 32, 36, 38, 39, 51], "uniform": [32, 33, 39, 51], "unimport": [32, 36], "uninstal": 11, "uninterpret": 36, "unintuit": 8, "union": 8, "uniqu": [29, 30, 33, 34, 35, 36, 40, 41, 43, 44, 52, 54], "unit": [31, 33, 34, 35, 36, 41, 42, 44, 45], "unitless": 34, "univers": [1, 9, 41], "university_year": [30, 47], "unix": [5, 43], "unknown": [6, 41, 47], "unlabel": [25, 27, 39], "unless": [7, 55], "unlik": [8, 27, 28, 30, 34, 36, 38, 39], "unlimit": 43, "unlucki": 27, "unmarri": [35, 36], "unnam": 25, "unoffici": 55, "unqualifi": [33, 52], "unreason": [6, 34], "unreli": 27, "unscal": 29, "unseen": [26, 37, 38, 42, 49], "unsqueez": 42, "unstructur": 41, "unsupervis": [25, 40, 41, 42, 55], "unsur": 7, "until": [4, 26, 27, 32, 37, 38, 39, 44], "unus": 49, "unwieldi": [26, 29], "unzip": 36, "uoft": 41, "up": [7, 8, 25, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 51, 55], "uparrow": 39, "upcom": 38, "updat": [10, 11, 28, 29, 30, 35, 38, 49], "update_cent": 38, "update_plot": [28, 49], "update_z": 38, "upgrad": [41, 45], "upload": 7, "upon": [0, 26, 27, 30, 33, 35, 36, 37, 38, 39, 41], "upper": [33, 44], "uppercas": 45, "upto": 43, "ur": 25, "urgent": [30, 41], "url": [4, 27, 33, 44, 52], "us": [0, 2, 4, 5, 10, 11, 31, 32, 36, 39, 40, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54], "usa": [8, 27, 28, 31, 41], "usag": [29, 30, 33, 34, 37, 41, 43, 44, 54], "usec_": 44, "useless": [32, 36, 37], "user": [11, 25, 26, 27, 29, 30, 32, 35, 36, 38, 39, 42, 44, 45, 46, 47, 51], "user_global_n": 45, "user_id": 40, "user_inverse_mapp": 40, "user_kei": 40, "user_mapp": 40, "user_n": 45, "user_nam": 40, "usernam": 45, "userwarn": [26, 27, 30, 35, 36, 45], "usf": 30, "using_copy_on_writ": 44, "using_cow": 44, "usual": [10, 11, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 54, 55], "utc": [43, 44], "utcnow": 44, "util": [5, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 44, 45, 47, 48, 49, 50, 51, 53], "utilities_allpub": 34, "utilities_nosewa": 34, "utility_mat": 40, "v": [3, 7, 10, 30, 31, 39, 41, 43, 44, 47], "v1": [25, 33], "v10": 33, "v11": 33, "v12": 33, "v13": 33, "v14": 33, "v15": 33, "v16": 33, "v17": 33, "v18": 33, "v19": 33, "v2": [25, 33], "v20": 33, "v21": 33, "v22": 33, "v23": 33, "v24": 33, "v25": 33, "v26": 33, "v27": 33, "v28": 33, "v3": 33, "v4": 33, "v5": 33, "v6": 33, "v7": 33, "v8": 33, "v9": 33, "v_1": 28, "v_2": 28, "v_i": 28, "v_n": 28, "vacat": 31, "vaccin": 45, "vader": 45, "vader_lexicon": 45, "vader_senti": 45, "vain": 32, "val": [40, 44], "valenc": [28, 29, 32, 45, 51], "valid": [10, 15, 26, 28, 30, 34, 35, 36, 37, 38, 40, 42, 44, 45, 47, 50, 51, 52, 53, 54], "valid_dataload": 42, "valid_flatten": 42, "valid_load": 42, "valid_mat": 40, "valid_sample_df": 35, "valid_sample_i": 35, "valid_sample_x": 35, "valid_scor": 49, "valid_x": 40, "valu": [7, 8, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54], "valuabl": [37, 39, 55], "value_count": [26, 30, 33, 35, 36, 43, 44, 45, 52, 53, 54], "value_throttl": [28, 49], "valueerror": [8, 29, 30, 44], "values_format": [33, 52], "vancouv": 41, "vanilla": 31, "var": [27, 29, 36, 45, 51], "var_": 36, "varada": [0, 1], "vari": [26, 32, 35, 39, 44, 49, 55], "variabl": [7, 8, 26, 29, 30, 31, 32, 34, 36, 37, 43, 44, 49, 54], "varianc": [34, 36, 39, 43, 49], "variant": [36, 39], "variat": [27, 31, 33, 34, 37], "varieti": [25, 35, 41], "variou": [25, 28, 34, 36, 42, 43, 44, 47, 49, 51, 55], "vault": 27, "ve": [7, 8, 25, 27, 28, 33, 34, 36, 40, 42, 43, 46, 54], "vec": [30, 41, 42], "vec1": 41, "vec1_i": 41, "vec2": 41, "vec2_i": 41, "vec8": 30, "vec8_binari": 30, "vec_binari": 30, "vecom": 32, "vector": [15, 26, 31, 33, 40, 42, 49, 53], "verb": [41, 45], "verbos": [25, 33, 35, 36], "veri": [2, 4, 5, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 54, 55], "verifi": 52, "versa": [34, 49, 52], "version": [4, 5, 7, 8, 11, 27, 29, 31, 32, 34, 36, 39, 41, 43, 44, 45, 46, 52, 54, 55], "versu": 9, "vert": 36, "vertic": [26, 33, 43], "vgg": 42, "vgg16": 42, "vgg16_weight": 42, "via": [1, 4, 7, 11, 33, 37, 55], "vice": [34, 49, 52], "video": [1, 7, 8, 9, 10, 11, 19, 23, 24, 40, 42, 44, 49, 52, 55], "vietnames": 29, "view": [6, 7, 11, 25, 26, 36, 39, 42, 43, 44], "viewpoint": 40, "vif": 36, "vikski": 41, "violat": [29, 30, 44, 55], "virginia": 42, "viridi": [32, 51], "visibl": 51, "vision": [10, 46], "visit": [8, 55], "visual": [10, 26, 27, 28, 30, 31, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 47, 50, 51, 55], "voc": [33, 35, 36, 52], "vocab": 41, "vocabulari": [30, 31, 41], "vocabulary_": 30, "voic": 25, "volcano": 25, "vote": [28, 29, 35, 46, 53], "voting_ndt": 35, "votingclassifi": [35, 53], "votingclassifierinot": 35, "votingregressor": 35, "w": [11, 30, 31, 34, 38, 41, 43, 54, 55], "w_0": 31, "w_1": 31, "w_1x_1": 31, "w_2x_2": 31, "w_3x_3": 31, "w_4x_4": 31, "w_d": 31, "w_dx_d": 31, "w_j": 31, "wa": [4, 5, 11, 26, 27, 29, 31, 33, 35, 36, 40, 41, 42, 44, 45, 46, 48, 49, 51, 54, 55], "wa_fn": 44, "wai": [0, 2, 6, 8, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 54, 55], "wait": [4, 25, 26, 28, 30, 44, 55], "waitlist": 55, "waiv": 55, "walk": [28, 33, 49], "walker": [25, 42], "wallabi": 42, "want": [4, 6, 7, 8, 11, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 50, 51, 52, 54, 55], "war": 40, "ward": 39, "warm": 29, "warm_start": 33, "warn": [6, 27, 28, 30, 34, 35, 36, 44, 46, 53], "warranti": 0, "washington": 45, "washroom": 55, "wast": [4, 30], "watch": [10, 11, 28, 31, 40, 41, 47], "waterfal": 36, "waterfront": [25, 26], "wavelet": 37, "wd": [34, 36], "we": [4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "weak": 47, "weather": [26, 43], "weatherau": [43, 54], "web": [5, 41, 47], "weblog": 41, "websit": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "wed": [10, 43], "wednesdai": [10, 43, 55], "week": [6, 13, 14, 27, 28, 29, 30, 33, 34, 35, 36, 40, 41, 43, 52, 55], "weekdai": 43, "weekend": [8, 43], "weekli": 45, "weight": [28, 35, 37, 40, 41, 42, 52, 55], "weighted_averag": 33, "weinberg": 36, "weird": 34, "welcom": [48, 55], "well": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 47, 51, 54, 55], "welsh": [25, 42], "went": [34, 45, 51, 53], "were": [0, 6, 30, 31, 33, 34, 42, 43, 44, 51, 53, 55], "what": [7, 8, 9, 26, 28, 32, 39, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "whatev": 37, "when": [4, 6, 7, 11, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55], "wher": 45, "where": [0, 7, 10, 11, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 47, 49, 52, 54], "wherea": [2, 26, 31, 32, 34, 36, 39], "whether": [0, 4, 7, 8, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 43, 44, 45, 48, 53, 54, 55], "which": [4, 6, 8, 11, 27, 28, 29, 30, 31, 32, 34, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55], "whichev": 35, "while": [26, 27, 31, 32, 33, 35, 36, 38, 40, 41, 44, 45, 51], "white": [33, 35, 36, 39, 41], "whitespac": [41, 44], "who": [4, 5, 6, 25, 33, 36, 38, 39, 43, 44, 45, 47, 55], "whole": [27, 32, 34, 36, 40, 51], "whom": [0, 45], "whose": 4, "why": [8, 27, 28, 33, 34, 35, 38, 39, 41, 43, 44, 47, 48, 49, 50, 51], "wid": 33, "wide": [11, 31, 32, 35, 37, 40, 42], "wider": [28, 49], "widespread": 41, "widget": [28, 33, 38, 39, 49], "width": [26, 27, 28, 33, 41, 48, 49], "wife": [25, 33, 35, 36], "wiki": 41, "wiki_df": 41, "wiki_dict": 41, "wikipedia": [41, 42], "wikipedia2vec": 41, "wild": [25, 27, 42], "willing": 33, "win": [28, 30, 35, 36, 37, 40, 46], "wind": 26, "winddir3pm": [43, 54], "winddir3pm_miss": [43, 54], "winddir3pm_ss": [43, 54], "winddir3pm_ssw": [43, 54], "winddir3pm_sw": [43, 54], "winddir3pm_w": [43, 54], "winddir3pm_wnw": [43, 54], "winddir3pm_wsw": [43, 54], "winddir9am": [43, 54], "windgustdir": [43, 54], "windgustspe": [43, 54], "window": [10, 44], "windsor": 45, "windspeed3pm": [43, 54], "windspeed9am": [43, 54], "wine_1": 8, "winter": 43, "winter_month": 43, "wire": 40, "wisdom": 35, "wish": [25, 26, 38, 55], "within": [26, 29, 31, 35, 37, 38, 39, 44, 47, 51], "without": [0, 7, 25, 26, 33, 35, 36, 37, 40, 42, 43, 44, 51, 55], "wnw": [43, 54], "wolv": 39, "woman": 41, "wombat": 42, "won": [5, 11, 26, 27, 28, 30, 31, 37, 40, 41, 42, 43, 44, 45], "wonder": [25, 27], "wooddecksf": [34, 36], "word": [25, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 47, 51, 55], "word1": 41, "word2": 41, "word2vec": [41, 42, 55], "word3": 41, "word_pair": 41, "word_token": [41, 45], "wordnet": 41, "wordnetlemmat": 41, "work": [0, 4, 5, 7, 8, 11, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 51, 53, 54, 55], "work_of_art": 45, "workclass": [33, 35, 36, 52], "workclass_feder": [35, 36], "workclass_loc": [35, 36], "workclass_miss": 36, "workclass_nev": [35, 36], "workclass_priv": [35, 36], "workclass_self": 36, "workclass_st": 36, "workclass_without": 36, "workflow": [26, 55], "world": [28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 47], "worm": 42, "worri": [25, 38, 39, 40, 53], "wors": [26, 32, 34, 35, 44, 48, 51, 52], "worst": [33, 37, 38], "worth": [26, 28, 33, 34, 52], "worthi": 31, "would": [4, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55], "wouldn": [30, 32, 44], "wow": 36, "wrap": 30, "wrapper": 37, "write": [4, 7, 25, 32, 36, 37, 38, 41, 45, 49, 53, 55], "written": [7, 30, 36, 43, 54], "wrong": [11, 27, 31, 34, 37, 38, 44, 51], "wrote": [41, 43, 54], "wsw": [43, 54], "www": [9, 31], "x": [4, 8, 11, 27, 28, 29, 30, 31, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52], "x0": 37, "x0_male": 33, "x1": [37, 40], "x139": 55, "x1x2": 37, "x2": [37, 39, 40], "x27": [29, 30, 32, 33, 34, 35, 37, 42, 45], "x_": 31, "x_1": [31, 37, 38], "x_1x_2": 37, "x_2": [31, 37, 38], "x_binari": 26, "x_citi": 28, "x_count": 30, "x_d": 31, "x_femal": [33, 52], "x_hour": 43, "x_hour_week": 43, "x_hour_week_onehot": 43, "x_hour_week_onehot_poli": 43, "x_hour_week_onehot_poly_lag": 43, "x_i": [31, 40], "x_imp_ohe_train": 29, "x_init": 38, "x_int": 30, "x_label": [26, 27, 28, 48], "x_lag_featur": 43, "x_lag_features_imp": 43, "x_male": [33, 52], "x_mask": 30, "x_multi": 46, "x_n": 37, "x_orig": 39, "x_re": 33, "x_small_citi": 28, "x_spotifi": [28, 32, 51], "x_subset": [26, 27], "x_test": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53], "x_test_big": 32, "x_test_enc": [36, 43, 44, 54], "x_test_happi": 33, "x_test_imp": 29, "x_test_multi": 46, "x_test_pr": 43, "x_test_predict": 29, "x_test_scal": 29, "x_test_transform": 29, "x_toi": [28, 29, 30, 43], "x_toy_oh": 29, "x_toy_ord": [29, 30], "x_tr": 49, "x_train": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53], "x_train_big": [33, 52], "x_train_enc": [33, 34, 36, 43, 44, 52, 54], "x_train_happi": 33, "x_train_hous": 37, "x_train_imp": 29, "x_train_imp_sc": 29, "x_train_multi": 46, "x_train_oversampl": 33, "x_train_perm": 36, "x_train_pp": 30, "x_train_predict": 29, "x_train_scal": [29, 37], "x_train_subsampl": 33, "x_train_tini": 32, "x_train_transform": 29, "x_train_usr": 40, "x_transform": 30, "x_valid": [33, 40, 49, 52], "x_vari": 39, "x_xor": 37, "xanni": 32, "xavier": [37, 40], "xcode": 5, "xgbclassifi": [35, 36], "xgbclassifierxgbclassifi": 35, "xgboost": 36, "xgbregressor": [25, 35], "xia": 55, "xlabel": [8, 26, 27, 28, 31, 32, 33, 34, 36, 39, 42, 43, 44, 46, 48, 51, 54], "xlim": 44, "xor": [31, 37], "xt": 30, "xtick": [27, 33, 43, 54], "xticklabel": [32, 51], "xticks_rot": 33, "xwm\u0259\u03b8kw\u0259y": 55, "xx": [37, 38], "y": [8, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54], "y_": 40, "y_citi": 28, "y_femal": [33, 52], "y_hat": [31, 35], "y_i": [34, 35, 37, 40], "y_init": 38, "y_label": [26, 27, 28, 48], "y_male": [33, 52], "y_mat": 40, "y_multi": 46, "y_pred": [33, 43], "y_pred_lower_threshold": 33, "y_pred_toi": 33, "y_pred_train": 43, "y_re": 33, "y_small_citi": 28, "y_spotifi": [32, 51], "y_test": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54], "y_test_big": 32, "y_test_happi": 33, "y_test_multi": 46, "y_test_num": [35, 36], "y_toi": [28, 43], "y_tr": 49, "y_train": [25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54], "y_train_big": [33, 52], "y_train_happi": 33, "y_train_hous": 37, "y_train_multi": 46, "y_train_num": [35, 36], "y_train_ord": [43, 54], "y_train_oversampl": 33, "y_train_subsampl": 33, "y_train_tini": 32, "y_train_usr": 40, "y_true_toi": 33, "y_valid": [33, 40, 42, 49, 52], "y_vari": 39, "y_xor": 37, "yale": 41, "yann": 36, "ycxmx": 44, "ye": [4, 25, 26, 29, 30, 36, 38, 39, 40, 42, 43, 45, 47, 54], "year": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 40, 41, 42, 43, 44], "yearbuilt": [34, 36], "yearremodadd": [34, 36], "yellow": 32, "yellowbrick": [38, 39], "yesterdai": [43, 54], "yet": [10, 11, 31, 36, 40, 43, 44, 49, 55], "yield": 51, "yifei": 55, "yjh": [25, 26, 30, 31, 34, 35], "ylabel": [8, 26, 27, 28, 31, 32, 33, 34, 39, 42, 43, 44, 46, 48, 49, 51, 54], "ylim": 44, "yml": 11, "yolo": 42, "yolo8": 42, "yolo_input": 42, "yolo_result": 42, "yolo_test": 42, "yolov8n": 42, "york": [43, 45], "you": [0, 1, 4, 5, 6, 7, 8, 10, 11, 36, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "your": [0, 2, 4, 6, 7, 8, 10, 11, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "your_miniconda_path": 45, "your_nam": 11, "yourself": [4, 30, 33, 40, 55], "youtub": [1, 10, 40, 41, 55], "yr_built": [25, 26], "yr_renov": [25, 26], "yrpxn": 44, "yrsold": [34, 36], "ytick": [27, 33], "yticklabel": [32, 51], "yy": [37, 43, 54], "yyyi": [43, 54], "z": [8, 31, 37, 38, 39, 40, 42, 44], "z_i": 42, "z_j": 42, "z_km": 38, "z_train": 42, "z_valid": 42, "zachari": 44, "zarei": 55, "zero": [8, 27, 30, 32, 40, 41], "zero_divis": 33, "zhu": 55, "zip": [28, 31, 40, 49], "zipcod": [25, 26, 49], "zmqshell": 45, "zone": [43, 54], "zoom": [7, 51, 55], "\u0259m": 55, "\u03bc": 46}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025S1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "What are git and GitHub?", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Schedule and Deliverables", "Setting up coding environment", "&lt;no title&gt;", "Class Meeting 1A", "Class Meeting 1B", "Class Meeting 1C", "Class Meeting 2A", "Class Meeting 2B", "Class Meeting 3A", "Class Meeting 3B - Review", "Class Meeting 3C", "Class Meeting 4A", "Class Meeting 4B", "Class Meeting 4C", "Class Meeting 5A", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Appendix A: Demo of feature engineering for text data", "Appendix B: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 4", "Tutorial 5", "Tutorial 6", "Tutorial 7", "Syllabus"], "titleterms": {"": [25, 27, 28, 29, 30, 33, 34, 36, 43], "0": 35, "04": 15, "05": 16, "06": 16, "07": 17, "08": 17, "09": 18, "1": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54], "10": [18, 34, 53], "11": [20, 35], "12": [21, 35, 36], "13": [22, 37], "14": [23, 37, 38], "15": [23, 38, 39], "16": [24, 39, 40], "17": [24, 40, 41], "18": 42, "19": [42, 43], "1a": 13, "1b": 14, "1c": 15, "2": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 44, 47, 48, 49, 50, 51, 52, 53, 54], "20": 44, "2025s1": 1, "21": 44, "2a": 16, "2b": 17, "3": [15, 25, 26, 27, 29, 37, 38, 39, 44, 48, 49, 50, 51, 52, 53, 54], "330": [1, 2, 3, 6, 8], "340": 2, "3a": 18, "3b": 19, "3c": 20, "4": [15, 26, 27, 28, 48, 49, 50, 51, 52, 53, 54], "4a": 21, "4b": 22, "4c": 23, "5": [8, 16, 26, 27, 28, 29, 30, 33, 36, 37, 38, 41, 42, 44, 49, 50, 51, 52, 53, 54], "5a": 24, "6": [16, 30, 49, 51, 52, 53, 54], "7": [17, 31, 51, 53, 54], "8": [17, 32, 51, 53], "9": [18, 33, 53], "A": [4, 33, 39, 43, 45], "No": 8, "Not": 47, "One": [29, 43, 46], "The": [27, 31, 32, 35, 37, 38, 53], "__": 32, "about": [8, 37, 40], "academ": 55, "access": [7, 31, 55], "accommod": 55, "acknowledg": 55, "activ": [33, 36, 37, 38, 41, 52], "actual": 30, "ad": 8, "addit": [7, 36], "address": 33, "advantag": 32, "advic": 37, "ai": 55, "algorithm": [26, 28, 37, 38], "all": [25, 26, 29, 31, 33, 38, 39, 40], "alpha": [31, 34], "altern": [26, 29], "an": [35, 45], "analogi": 28, "analysi": [43, 44, 47, 49, 54], "announc": [26, 28, 30, 31, 35], "answer": 44, "ap": 33, "api": 29, "appendix": [45, 46], "appli": [1, 8, 29, 30, 34], "applic": 38, "applymap": 8, "approach": [40, 43, 44, 46], "approxim": 27, "ar": [5, 25, 26, 29, 31, 33, 38, 39, 40], "area": 33, "argument": [27, 28], "arrai": 8, "articl": 9, "ask": 4, "assign": [7, 55], "associ": 31, "assum": 44, "attent": [26, 28], "attribut": 36, "auc": 33, "autom": 32, "averag": [33, 35, 40, 53], "avoid": 27, "b": [38, 46], "backward": 37, "bad": 32, "bag": [30, 45], "balanc": 33, "base": [28, 35, 37, 40, 43, 54], "baselin": [26, 29, 33, 35, 36, 40, 49], "basic": 41, "befor": 29, "best": 37, "better": [27, 32, 33, 37], "between": [26, 28, 48], "beyond": [36, 40], "bia": [27, 32], "big": [26, 27, 29], "binari": 33, "book": 10, "boost": 35, "bootstrap": 35, "boundari": [26, 28, 31, 48], "bow": 30, "box": 42, "break": [8, 26, 27, 28, 29, 30, 37, 41, 42, 44], "broadcast": 8, "build": [25, 26, 34, 40], "c": [28, 32], "calcul": 31, "california": [30, 31, 50], "can": [8, 27, 29, 35, 36, 37, 38], "canada": [26, 48], "care": 40, "carri": [29, 37], "case": [30, 31, 39], "catboost": 35, "categor": [29, 30, 36, 43], "categori": 30, "censor": 44, "centr": 55, "certain": 30, "cfa": 55, "chang": 33, "charact": 25, "characterist": 33, "cheatsheet": 8, "choos": [28, 38], "churn": 44, "cite": 7, "citi": 31, "class": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 32, 33, 34, 35, 36, 40, 42, 46, 55], "class_attend": 30, "class_weight": 33, "classif": [26, 33, 42, 47], "classifi": [26, 31, 35, 45], "clearli": 37, "cluster": [38, 39, 47], "co": 55, "code": [11, 55], "coeffici": [31, 36], "color": [48, 49, 50, 51, 52, 53, 54], "column": [8, 29, 30, 43], "columntransform": [30, 50], "combin": 35, "come": [27, 28], "command": 5, "comment": [26, 32, 33, 34, 38, 39, 40], "common": [29, 38], "commonli": 41, "commun": 47, "compact": 29, "companion": 9, "complet": 40, "complex": 27, "complic": [43, 54], "compon": 31, "comprehens": 50, "comput": [42, 47], "con": [28, 39, 47], "concern": 6, "concess": 55, "conda": 11, "conduct": 55, "confid": 31, "confus": 33, "consid": 44, "construct": 35, "content": 40, "context": 41, "continu": 26, "conveni": 30, "correct": 38, "correl": 36, "countri": [26, 48], "countvector": 30, "cours": [9, 10, 25, 55], "cover": [40, 44], "cox": 44, "cpsc": [1, 2, 3, 6, 8], "creat": [7, 26, 27, 30, 40], "credit": [11, 55], "cross": [27, 29, 33, 37, 43, 49], "cross_val_scor": 27, "cross_valid": [27, 34], "csv": 8, "curs": 28, "curv": [33, 44], "custom": [38, 44], "cv": 32, "dai": 43, "data": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 45, 49, 54], "datafram": [8, 30], "dataset": [7, 26, 29, 30, 31, 32, 33, 34, 42, 43, 50, 53, 54], "date": [10, 43], "datetim": [43, 54], "dbscan": 39, "deal": [30, 33], "debug": 11, "decis": [26, 28, 31, 36, 49], "decisiontreeclassifi": [26, 35], "decreas": 33, "deep": [42, 43], "defin": 37, "definit": 25, "deliver": 10, "demo": [37, 43, 45], "demonstr": 33, "dendrogram": 39, "depend": 37, "deploy": [27, 47], "descript": 55, "desktop": 5, "detail": [33, 34, 39], "detect": 42, "df": 8, "did": [27, 29, 30, 33, 34, 40, 44], "differ": [29, 32, 33, 34, 36, 47], "dimens": 28, "dimension": 28, "discuss": [32, 33, 40, 41, 52], "diseas": 25, "distanc": [28, 38], "distribut": 32, "do": [29, 30, 32, 33, 35, 36, 37], "document": [3, 8, 38], "doe": [26, 31, 39], "domain": 37, "drop": 8, "due": 10, "dummi": 45, "dummyclassifi": [26, 35, 43, 44], "dummyregressor": [26, 29, 34], "eda": [29, 33, 34, 49], "effect": 35, "elbow": 38, "element": 8, "elimin": 37, "embed": 41, "encod": [29, 30, 37, 43], "engin": [37, 43, 45, 47], "ensembl": [35, 47], "environ": 11, "error": [27, 32, 33, 34, 40], "estim": [29, 35], "ethic": 47, "euclidean": 28, "eva": [25, 27], "evalu": [33, 39, 40, 44, 47, 52], "evalut": 33, "event": 44, "everyon": 44, "exactli": 31, "exam": [47, 55], "examin": [30, 34, 47], "exampl": [25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 41, 44, 45], "exercis": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 40, 42, 44, 48], "exhaust": 32, "explain": 36, "explan": 36, "explor": [28, 38], "exploratori": [43, 49, 54], "extract": [30, 43], "extractor": 42, "f1": 33, "failur": 39, "fair": [33, 52], "fancier": 32, "faster": 8, "fastest": 8, "featur": [25, 26, 28, 29, 30, 31, 34, 36, 37, 40, 42, 43, 45, 47, 54], "feature_importances_": 36, "few": [33, 39], "fictiti": 25, "figur": 7, "filter": [8, 40], "final": [26, 32, 38, 39, 40, 43, 47, 49, 55], "find": [28, 37], "first": 29, "fit": [26, 29, 35], "flatten": 42, "follow": [25, 26, 27, 38, 39, 40], "font": [48, 49, 50, 51, 52, 53, 54], "forecast": 43, "forest": [35, 36], "format": [7, 8], "formul": 40, "forum": 4, "forward": 37, "from": [8, 45], "function": [8, 31, 34], "fundament": [27, 28, 35, 47], "further": [43, 45], "futur": 43, "gamma": 28, "garbag": 37, "gener": [4, 6, 27, 28, 31, 35, 37], "geometr": 28, "get": 36, "git": [5, 11], "github": 5, "given": [25, 26], "global": 40, "goal": 27, "golden": [27, 29, 30], "good": 33, "grade": [4, 6, 26, 55], "gradescop": 7, "gradient": 35, "grid": 32, "gridsearchcv": [32, 34], "group": [33, 38, 52], "guid": 47, "guidelin": [4, 6, 7], "ha": 25, "halv": 32, "handl": 33, "have": [35, 36], "hazard": 44, "heatmap": 32, "help": [4, 37], "here": 27, "hierarch": 39, "home": 39, "homework": 7, "hot": [29, 37, 43], "hous": [25, 26, 29, 30, 31, 50], "how": [4, 7, 26, 27, 28, 29, 31, 35, 36, 37, 39], "hyper": 32, "hyperparamet": [26, 28, 30, 31, 32, 34, 35, 38, 47, 49], "i": [25, 27, 29, 30, 32, 33, 35, 36, 37, 38, 40, 41, 45], "iclick": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 55], "idea": [28, 33, 35, 37], "identifi": [30, 36], "imag": [25, 42], "imagenet": 42, "imbal": [33, 34, 35, 36], "import": [1, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 54], "improv": 45, "imput": [29, 40], "incorpor": 30, "increas": 33, "index": 8, "inertia": 38, "info": 7, "inform": [36, 43], "initi": 38, "inject": 35, "input": [25, 38], "instal": [5, 11], "instruct": [0, 7], "interact": 37, "intercept": 31, "interim": [33, 36, 37, 43], "interpret": [31, 36], "intra": 38, "intro": 40, "introduct": [8, 25, 36, 37, 38, 39, 41, 42, 47], "intuit": 31, "involv": 43, "jupyterlab": 11, "k": [28, 29, 38, 39, 40], "kaplan": 44, "kei": 36, "kernel": 28, "kind": 35, "kneighborsclassifi": 28, "label": [25, 38], "lag": [43, 54], "land": 55, "languag": 41, "larg": 32, "late": 7, "latitud": [26, 48], "lda": 41, "learn": [1, 5, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 55], "least": 31, "lectur": [10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 55], "lecture03": 15, "let": [28, 29, 30, 33, 34, 36], "licens": [0, 1], "lightgbm": 35, "limit": [6, 31, 39], "line": 5, "linear": [31, 34, 36], "link": 1, "list": 9, "liver": 25, "ll": 27, "lo": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 43], "logist": [31, 33, 42], "logisticregress": [33, 43, 44], "longitud": [26, 48], "look": [33, 38], "loop": 8, "lower": 32, "mac": 5, "machin": [1, 25, 26, 27, 28, 33, 38], "maco": 11, "macro": 33, "magnitud": 31, "mai": 37, "main": [31, 40], "make": [8, 31], "make_column_transform": 30, "make_pipelin": 29, "mani": [30, 32], "manual": 32, "mape": 34, "materi": [0, 9, 10], "matplotlib": 8, "matric": 30, "matrix": [33, 40], "max_depth": 26, "mean": [34, 38, 39, 41], "measur": 37, "media": 41, "meet": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 55], "meier": 44, "messag": [25, 39], "meta": 46, "method": [8, 32, 37, 38], "metric": [33, 34, 47], "midterm": [38, 55], "might": 44, "min": [8, 26, 27, 28, 29, 30, 33, 36, 37, 38, 41, 42, 44], "minor": 33, "misc": [9, 10], "miscellan": 40, "ml": [25, 27, 28, 33, 36, 47, 52], "model": [25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 41, 42, 44, 45, 47, 49, 52], "model_select": 32, "month": 43, "more": [26, 28, 29, 30, 31, 33, 34, 37, 39, 43, 54], "most": 31, "motiv": [27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 43], "movi": 40, "mse": 34, "much": 32, "multi": [33, 42, 46], "multiclass": 47, "multipl": [28, 30, 34], "multipli": 8, "n_estim": 35, "n_iter": 32, "n_job": 32, "n_neighbor": 28, "name": [27, 34, 40], "natur": 41, "nearest": [28, 29, 38, 40], "need": [29, 32], "neg": 33, "neighbour": [28, 29, 40], "nest": 8, "netflix": 35, "network": 42, "neural": 42, "nlp": [41, 47], "nn": 28, "non": [28, 30, 36], "notat": 8, "note": [8, 27, 43, 49], "now": 44, "number": [35, 38, 43], "numer": [36, 37], "numpi": 8, "object": [26, 35, 41, 42, 43, 44, 55], "observ": 33, "occasion": 29, "off": [27, 28, 35], "oh": [29, 30], "ok": [29, 30], "onc": 33, "one": [30, 37], "onehotencod": 30, "onli": [30, 44], "onlin": [9, 10], "oper": 33, "optim": [32, 47], "option": [11, 28, 29, 32, 33, 35, 37, 44], "ordin": [29, 30, 36, 55], "other": [8, 28, 34, 37, 38, 41, 43, 44], "our": [7, 27, 29, 45], "out": [29, 37, 42], "outcom": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40], "outlin": [48, 49, 50, 51, 52, 53, 54], "output": 38, "over": [8, 28, 31, 33], "overfit": [27, 32], "oversampl": 33, "overview": [28, 33], "ovo": 46, "ovr": 46, "packag": [11, 43], "panda": 8, "pandas_profil": 34, "paper": [33, 35], "paradigm": 29, "paramet": [26, 31, 32, 33, 47], "parametr": 28, "pars": [43, 54], "part": 47, "pass": [32, 55], "patient": 25, "perfect": 38, "permutation_import": 36, "persona": 25, "pick": [27, 32], "pictur": [26, 27, 29], "pipelin": [29, 41], "plan": 39, "playground": [28, 49], "plot": [8, 36, 38, 44], "point": [28, 33, 36, 38, 43], "polici": 6, "poll": 38, "popular": 25, "posit": 33, "posix": 43, "possibl": [30, 34, 38, 45], "post": 9, "pr": 33, "practic": [26, 28], "pre": [13, 14, 15, 16, 17, 18, 20, 21, 22, 42], "precis": 33, "predict": [25, 26, 30, 31, 35, 36, 40, 42, 44, 46, 48], "predict_proba": 31, "prepar": [7, 47], "preprocess": [29, 30, 34, 41, 43, 47, 52, 54], "preval": 25, "price": [25, 26], "prize": 35, "pro": [28, 39, 47], "probabl": [31, 32], "problem": [26, 27, 28, 29, 32, 37, 40, 43, 45], "procedur": 33, "process": 41, "product": 25, "profil": 40, "program": 26, "project": 45, "proport": 44, "python": [8, 9, 11], "q": 4, "qualiti": 37, "queri": [8, 28], "question": [4, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54], "quick": 28, "quiz": 26, "quiz2": 26, "quot": 37, "r": 34, "random": [32, 35, 36], "random_st": 27, "randomforestclassifi": [35, 44], "randomizedsearchcv": [32, 34], "rang": 32, "rate": 40, "raw": 31, "rbf": 28, "read": [8, 26, 32, 42], "real": [26, 48], "realist": 30, "reason": 6, "recal": 33, "recap": [26, 28, 39, 44, 48, 50], "receiv": 33, "recommend": [29, 40, 47], "record": 55, "recurs": 37, "red": [48, 49, 50, 51, 52, 53, 54], "refer": [9, 10, 44], "reflect": [26, 27, 38, 39], "registr": 55, "regress": [26, 28, 31, 33, 34, 35, 42], "regressor": 28, "relat": [4, 26, 28], "relev": [9, 33, 35, 37], "remark": 43, "rememb": 38, "remind": [26, 40], "remov": 8, "renam": 8, "report": [7, 33], "repositori": 7, "represent": [30, 42], "requir": 55, "rescu": 27, "resourc": [9, 32, 33, 37, 38, 39, 40], "rest": 46, "result": 32, "retail": 43, "review": 19, "rfe": 37, "ridg": [31, 34], "ridgecv": 34, "right": 44, "rmse": 34, "roc": 33, "root": 34, "row": 8, "rule": [27, 29, 30], "run": 29, "same": 8, "sampl": [33, 35, 38], "sauc": 38, "save": 25, "scale": [25, 29, 31, 36], "schedul": [10, 55], "scheme": 55, "scikit": [27, 29, 30, 34], "score": [26, 27, 31, 32, 33, 34, 37, 38, 45], "search": [28, 32, 37], "season": 43, "segment": 38, "select": [25, 26, 37, 38, 39, 40, 47], "separ": [34, 36], "seri": [8, 43, 47, 54], "set": [5, 11, 27, 32, 33], "set_config": 30, "shap": 36, "shape": [8, 39], "shaplei": 36, "short": 9, "should": [35, 40], "show": 36, "sigmoid": [31, 42], "sign": 31, "silhouett": 38, "similar": 28, "simpl": [27, 45], "simplefeatur": 36, "simul": 53, "singl": 27, "size": 8, "sklearn": [26, 29, 30, 32, 33, 35, 36], "slide": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24], "slowest": 8, "smote": 33, "social": 41, "softmax": 42, "softwar": [0, 42, 43], "solv": 32, "some": [26, 32, 33, 35, 37], "sort": 8, "sort_valu": 8, "sourc": 7, "space": 43, "spaci": [41, 45], "spaghetti": 38, "spam": [25, 30], "spars": 30, "specif": [4, 37], "split": [27, 29, 33, 43, 49], "spotifi": [29, 32], "squar": 34, "stack": [35, 53], "standardscal": 29, "statement": [25, 26, 38, 39, 40], "step": [26, 41, 50], "strategi": [35, 46], "stratifi": 33, "strength": [31, 35], "studi": 47, "submiss": 7, "submit": 7, "success": 32, "summari": [8, 25, 26, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "summer": 10, "supervis": [25, 26, 27, 28, 38, 40], "support": 28, "surviv": [44, 47], "svc": 33, "svm": [28, 31], "syllabu": [1, 55], "syntax": [29, 30, 32], "synthet": 33, "system": [40, 47], "ta": 55, "tabular": [26, 28], "tackl": 34, "take": 39, "target": [25, 26, 30, 34, 38], "task": 41, "teach": [10, 55], "team": 55, "techniqu": [29, 33], "templat": 7, "tempor": 43, "ten": 10, "tent": 10, "terminologi": [26, 42], "test": [5, 27, 32, 43], "test_df": 27, "test_siz": 27, "text": [30, 41, 45], "than": [30, 32, 37], "thei": 35, "them": 8, "thi": [8, 25, 29, 30, 36], "thing": 29, "threshold": 33, "time": [6, 25, 43, 44, 47, 54], "tip": 47, "todai": [27, 29, 30, 33, 34], "toi": [26, 30, 33, 41], "token": 41, "tool": 41, "topic": 41, "trade": [27, 28, 35], "tradeoff": [27, 33, 35], "tradit": [26, 43], "train": [25, 26, 27, 30, 31, 33, 42, 43, 52], "train_df": 27, "train_siz": 27, "transfer": 42, "transform": [29, 30, 34, 37], "transpar": 36, "tree": [26, 35, 36, 49], "trend": 43, "true": [25, 38, 39, 40], "try": [29, 34], "tune": [34, 38, 49], "tutori": [48, 49, 50, 51, 52, 53, 54], "two": 30, "type": [25, 27, 33, 34, 36, 38, 43, 44], "typic": [27, 41], "ubc": 1, "ubuntu": 5, "under": 33, "underfit": 27, "undersampl": 33, "unequ": 43, "unknown": 30, "unlabel": 38, "unseen": [25, 27], "unsupervis": [26, 38], "up": [5, 11, 27, 28], "updat": 7, "url": 8, "us": [7, 8, 25, 26, 27, 28, 29, 30, 33, 34, 35, 37, 38, 41, 42, 46, 48, 55], "usa": [26, 48], "user": [5, 40], "usual": 37, "util": 40, "v": [2, 26, 27, 28, 33, 36, 38, 42, 46], "valid": [27, 29, 32, 33, 43, 49], "varianc": 27, "vector": [8, 28, 41], "video": [13, 14, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 28, 29, 31, 33, 34, 35, 38, 39, 41], "view": [28, 30], "violat": 27, "virtual": 11, "vision": [42, 47], "visual": [9, 32], "wai": [32, 37], "want": [30, 36, 44], "warn": [26, 37], "we": [8, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 44], "weak": 35, "weight": [31, 33], "what": [5, 11, 25, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 44], "when": [8, 29, 32], "where": [30, 44], "whether": 25, "which": [25, 26, 33, 35, 38, 39, 40], "why": [11, 25, 30, 32, 36, 37, 40, 42], "window": [5, 11], "wise": 8, "without": 38, "word": [30, 41, 45], "work": [26, 35, 39], "workflow": [25, 27, 33], "would": 27, "wrapper": 46, "write": 26, "x": [25, 26, 34, 36], "xgboost": 35, "y": [25, 26, 34, 36], "ye": 44, "yield": 32, "you": [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44], "your": [5, 26]}})